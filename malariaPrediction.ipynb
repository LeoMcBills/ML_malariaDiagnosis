{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXzz3CZdBpckH5J0KGdCpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8818a9a4a4a24dd9b95715b52531caa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90e5ae39d8f2407c972870293e78c37b",
              "IPY_MODEL_410e407f2172487d81e3898966713ea9",
              "IPY_MODEL_024e5d9d041f4c1ea5355f101486a349"
            ],
            "layout": "IPY_MODEL_574eabd6f91a4e11b6d0ca0cafae73d4"
          }
        },
        "90e5ae39d8f2407c972870293e78c37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4145b61b700e476da241c32be8aeaa71",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b0d1b6edce4ef7844615a8f64ee2d8",
            "value": "Dl Completed...: 100%"
          }
        },
        "410e407f2172487d81e3898966713ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778430534af1471c996552ff53c7927a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1da80c4ce98748579ee35e539f0182e5",
            "value": 1
          }
        },
        "024e5d9d041f4c1ea5355f101486a349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_080a6b48e577415191aa3577daf7a0dc",
            "placeholder": "​",
            "style": "IPY_MODEL_611764ca2d9a463a913747bdd38ec7cc",
            "value": " 1/1 [01:15&lt;00:00,  4.99s/ url]"
          }
        },
        "574eabd6f91a4e11b6d0ca0cafae73d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4145b61b700e476da241c32be8aeaa71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b0d1b6edce4ef7844615a8f64ee2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778430534af1471c996552ff53c7927a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1da80c4ce98748579ee35e539f0182e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "080a6b48e577415191aa3577daf7a0dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "611764ca2d9a463a913747bdd38ec7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e1eb14006704f01b6ba18178dbe8f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cdcba615fad48608cc97f15e0bb43a3",
              "IPY_MODEL_5d0def990c6a453ab786326bf2315b08",
              "IPY_MODEL_c763af8584d346b9bab309bdd37ad3ac"
            ],
            "layout": "IPY_MODEL_034d8f89c2164a749c66fd449995bc32"
          }
        },
        "1cdcba615fad48608cc97f15e0bb43a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_871dd0bc81d647e7aadbf176c803f148",
            "placeholder": "​",
            "style": "IPY_MODEL_11794b9cba7d4f1e96c8541e285422e2",
            "value": "Dl Size...: 100%"
          }
        },
        "5d0def990c6a453ab786326bf2315b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa406f275e6d4a00b649d4ffd8cc3d96",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c7eb9dead9f4029b92bf4b891ffa208",
            "value": 1
          }
        },
        "c763af8584d346b9bab309bdd37ad3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf37a944a5d74e47a89d611aaea5f975",
            "placeholder": "​",
            "style": "IPY_MODEL_33372000e63243f18b5a65f7a46a2b0d",
            "value": " 337/337 [01:15&lt;00:00, 89.15 MiB/s]"
          }
        },
        "034d8f89c2164a749c66fd449995bc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871dd0bc81d647e7aadbf176c803f148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11794b9cba7d4f1e96c8541e285422e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa406f275e6d4a00b649d4ffd8cc3d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1c7eb9dead9f4029b92bf4b891ffa208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf37a944a5d74e47a89d611aaea5f975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33372000e63243f18b5a65f7a46a2b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee4c03f5a7849a1806dfc5c30b3b224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74e62f9ef9614e939cfae09aef06ed6e",
              "IPY_MODEL_f07394b8fd4e4b2d9db5a4f17897932e",
              "IPY_MODEL_08e51f4dc6f7427dbbca7ca7fb7fc562"
            ],
            "layout": "IPY_MODEL_8b79443f59aa463fbe4b327382ff61a0"
          }
        },
        "74e62f9ef9614e939cfae09aef06ed6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e17e2220d4f4e29900888fd802c29a8",
            "placeholder": "​",
            "style": "IPY_MODEL_d02f4668b0a348b2ad5aa971ad1a5c85",
            "value": "Extraction completed...: 100%"
          }
        },
        "f07394b8fd4e4b2d9db5a4f17897932e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38bc0329cde42ab9c01ebfde73bbd0c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_068fa51aea0c466b834a87c55c75f3bd",
            "value": 1
          }
        },
        "08e51f4dc6f7427dbbca7ca7fb7fc562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb0e4b58e9a4db5bd762a2275e86049",
            "placeholder": "​",
            "style": "IPY_MODEL_67de3102409849b28fad222c86332cb5",
            "value": " 27560/27560 [01:15&lt;00:00, 748.26 file/s]"
          }
        },
        "8b79443f59aa463fbe4b327382ff61a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e17e2220d4f4e29900888fd802c29a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d02f4668b0a348b2ad5aa971ad1a5c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f38bc0329cde42ab9c01ebfde73bbd0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "068fa51aea0c466b834a87c55c75f3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fb0e4b58e9a4db5bd762a2275e86049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67de3102409849b28fad222c86332cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e915c83f86148159db405ae677c4459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a19dd2b35bda4d5d99436b5fd04f7e60",
              "IPY_MODEL_a699047e76b44604bd1088bdb0f8a347",
              "IPY_MODEL_5045673a08044336afacd50e663c6707"
            ],
            "layout": "IPY_MODEL_ff082510a22e489f85a0b7bf7bc5cc77"
          }
        },
        "a19dd2b35bda4d5d99436b5fd04f7e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0a48b884ce4d1db5ea7d60aff7d749",
            "placeholder": "​",
            "style": "IPY_MODEL_aac2d1504cd24c23827db4d9ada96e20",
            "value": "Generating splits...: 100%"
          }
        },
        "a699047e76b44604bd1088bdb0f8a347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aacf92db65c844c49a5bbe63dcff1fe5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e20ac6e41bd94c2d83861579360a2728",
            "value": 1
          }
        },
        "5045673a08044336afacd50e663c6707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_190fc246c5c54bba8d3e0d8da94a0218",
            "placeholder": "​",
            "style": "IPY_MODEL_bcdaf84788b140f8bb919cc1b4742249",
            "value": " 1/1 [00:25&lt;00:00, 25.40s/ splits]"
          }
        },
        "ff082510a22e489f85a0b7bf7bc5cc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ca0a48b884ce4d1db5ea7d60aff7d749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac2d1504cd24c23827db4d9ada96e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aacf92db65c844c49a5bbe63dcff1fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e20ac6e41bd94c2d83861579360a2728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "190fc246c5c54bba8d3e0d8da94a0218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcdaf84788b140f8bb919cc1b4742249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "532a65733ae545278cd9aa40df8e3f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20b5f0dc024b47efabd47d117fb0160c",
              "IPY_MODEL_99930eb97d7a4a14846a172c6abf505e",
              "IPY_MODEL_846b04b98ca945328660e81024d51eb4"
            ],
            "layout": "IPY_MODEL_dd940c213cd74a24bd51478591b19e8b"
          }
        },
        "20b5f0dc024b47efabd47d117fb0160c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b25a25f934a04f33aac311b30fc50c20",
            "placeholder": "​",
            "style": "IPY_MODEL_dacec1a174da49f9847dee78565682f6",
            "value": "Generating train examples...: 100%"
          }
        },
        "99930eb97d7a4a14846a172c6abf505e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c9e05fe965412baaf71ee48890abf4",
            "max": 27558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c12389182440c8b350a5a87beba3a2",
            "value": 27558
          }
        },
        "846b04b98ca945328660e81024d51eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d7330a71b44c5f8eff33f14af9cdd6",
            "placeholder": "​",
            "style": "IPY_MODEL_55b2ac496ecc4bc39b8684e405a709d9",
            "value": " 27466/27558 [00:23&lt;00:00, 1487.62 examples/s]"
          }
        },
        "dd940c213cd74a24bd51478591b19e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b25a25f934a04f33aac311b30fc50c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dacec1a174da49f9847dee78565682f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64c9e05fe965412baaf71ee48890abf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c12389182440c8b350a5a87beba3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49d7330a71b44c5f8eff33f14af9cdd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b2ac496ecc4bc39b8684e405a709d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72e74dee0b814f728bd7586404ec9c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83646e1536cb450da60cc306f09c5513",
              "IPY_MODEL_65762de515e34de7b544b859934993fe",
              "IPY_MODEL_6deb7a053f6c40de81ebb6f4c842d253"
            ],
            "layout": "IPY_MODEL_d4c9f30e73134906bf39598b25b845ab"
          }
        },
        "83646e1536cb450da60cc306f09c5513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a440ecd0ae3418ca6f383b23616e057",
            "placeholder": "​",
            "style": "IPY_MODEL_bc57e0e235e84d6dae7b6ecade71488b",
            "value": "Shuffling /root/tensorflow_datasets/malaria/1.0.0.incompleteXNJCSM/malaria-train.tfrecord*...:  96%"
          }
        },
        "65762de515e34de7b544b859934993fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e783c24c1b453eb25726e0686d2c6c",
            "max": 27558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e536bd76e558485c833436b148964cb3",
            "value": 27558
          }
        },
        "6deb7a053f6c40de81ebb6f4c842d253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99421b6b7bd942f982a44582c29b9fab",
            "placeholder": "​",
            "style": "IPY_MODEL_78af0b62cb084b93ad7340aa4a2fd084",
            "value": " 26402/27558 [00:01&lt;00:00, 12194.20 examples/s]"
          }
        },
        "d4c9f30e73134906bf39598b25b845ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0a440ecd0ae3418ca6f383b23616e057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc57e0e235e84d6dae7b6ecade71488b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e783c24c1b453eb25726e0686d2c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e536bd76e558485c833436b148964cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99421b6b7bd942f982a44582c29b9fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78af0b62cb084b93ad7340aa4a2fd084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoMcBills/ML_malariaDiagnosis/blob/main/malariaPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, InputLayer, Flatten, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, FalsePositives, FalseNegatives, TruePositives, TrueNegatives, Precision, Recall, AUC\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import Callback, CSVLogger"
      ],
      "metadata": {
        "id": "2xcSYnzElSh7"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xtMRIn-91wpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "8818a9a4a4a24dd9b95715b52531caa8",
            "90e5ae39d8f2407c972870293e78c37b",
            "410e407f2172487d81e3898966713ea9",
            "024e5d9d041f4c1ea5355f101486a349",
            "574eabd6f91a4e11b6d0ca0cafae73d4",
            "4145b61b700e476da241c32be8aeaa71",
            "c2b0d1b6edce4ef7844615a8f64ee2d8",
            "778430534af1471c996552ff53c7927a",
            "1da80c4ce98748579ee35e539f0182e5",
            "080a6b48e577415191aa3577daf7a0dc",
            "611764ca2d9a463a913747bdd38ec7cc",
            "0e1eb14006704f01b6ba18178dbe8f0e",
            "1cdcba615fad48608cc97f15e0bb43a3",
            "5d0def990c6a453ab786326bf2315b08",
            "c763af8584d346b9bab309bdd37ad3ac",
            "034d8f89c2164a749c66fd449995bc32",
            "871dd0bc81d647e7aadbf176c803f148",
            "11794b9cba7d4f1e96c8541e285422e2",
            "fa406f275e6d4a00b649d4ffd8cc3d96",
            "1c7eb9dead9f4029b92bf4b891ffa208",
            "cf37a944a5d74e47a89d611aaea5f975",
            "33372000e63243f18b5a65f7a46a2b0d",
            "7ee4c03f5a7849a1806dfc5c30b3b224",
            "74e62f9ef9614e939cfae09aef06ed6e",
            "f07394b8fd4e4b2d9db5a4f17897932e",
            "08e51f4dc6f7427dbbca7ca7fb7fc562",
            "8b79443f59aa463fbe4b327382ff61a0",
            "2e17e2220d4f4e29900888fd802c29a8",
            "d02f4668b0a348b2ad5aa971ad1a5c85",
            "f38bc0329cde42ab9c01ebfde73bbd0c",
            "068fa51aea0c466b834a87c55c75f3bd",
            "2fb0e4b58e9a4db5bd762a2275e86049",
            "67de3102409849b28fad222c86332cb5",
            "7e915c83f86148159db405ae677c4459",
            "a19dd2b35bda4d5d99436b5fd04f7e60",
            "a699047e76b44604bd1088bdb0f8a347",
            "5045673a08044336afacd50e663c6707",
            "ff082510a22e489f85a0b7bf7bc5cc77",
            "ca0a48b884ce4d1db5ea7d60aff7d749",
            "aac2d1504cd24c23827db4d9ada96e20",
            "aacf92db65c844c49a5bbe63dcff1fe5",
            "e20ac6e41bd94c2d83861579360a2728",
            "190fc246c5c54bba8d3e0d8da94a0218",
            "bcdaf84788b140f8bb919cc1b4742249",
            "532a65733ae545278cd9aa40df8e3f6e",
            "20b5f0dc024b47efabd47d117fb0160c",
            "99930eb97d7a4a14846a172c6abf505e",
            "846b04b98ca945328660e81024d51eb4",
            "dd940c213cd74a24bd51478591b19e8b",
            "b25a25f934a04f33aac311b30fc50c20",
            "dacec1a174da49f9847dee78565682f6",
            "64c9e05fe965412baaf71ee48890abf4",
            "88c12389182440c8b350a5a87beba3a2",
            "49d7330a71b44c5f8eff33f14af9cdd6",
            "55b2ac496ecc4bc39b8684e405a709d9",
            "72e74dee0b814f728bd7586404ec9c72",
            "83646e1536cb450da60cc306f09c5513",
            "65762de515e34de7b544b859934993fe",
            "6deb7a053f6c40de81ebb6f4c842d253",
            "d4c9f30e73134906bf39598b25b845ab",
            "0a440ecd0ae3418ca6f383b23616e057",
            "bc57e0e235e84d6dae7b6ecade71488b",
            "62e783c24c1b453eb25726e0686d2c6c",
            "e536bd76e558485c833436b148964cb3",
            "99421b6b7bd942f982a44582c29b9fab",
            "78af0b62cb084b93ad7340aa4a2fd084"
          ]
        },
        "outputId": "49d8461b-8fb2-4d34-c8da-7ce3a5dbd6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 337.08 MiB (download: 337.08 MiB, generated: Unknown size, total: 337.08 MiB) to /root/tensorflow_datasets/malaria/1.0.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8818a9a4a4a24dd9b95715b52531caa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e1eb14006704f01b6ba18178dbe8f0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ee4c03f5a7849a1806dfc5c30b3b224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e915c83f86148159db405ae677c4459"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...:   0%|          | 0/27558 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "532a65733ae545278cd9aa40df8e3f6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/malaria/1.0.0.incompleteXNJCSM/malaria-train.tfrecord*...:   0%|          …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72e74dee0b814f728bd7586404ec9c72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset malaria downloaded and prepared to /root/tensorflow_datasets/malaria/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files = True, split=['train'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz60OwkvpFM4",
        "outputId": "640d6d41-8565-4f8c-a864-415b2b34e3b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='malaria',\n",
              "    full_name='malaria/1.0.0',\n",
              "    description=\"\"\"\n",
              "    The Malaria dataset contains a total of 27,558 cell images with equal instances\n",
              "    of parasitized and uninfected cells from the thin blood smear slide images of\n",
              "    segmented cells.\n",
              "    \"\"\",\n",
              "    homepage='https://lhncbc.nlm.nih.gov/publication/pub9932',\n",
              "    data_path=PosixGPath('/tmp/tmpg30sjvk9tfds'),\n",
              "    file_format=tfrecord,\n",
              "    download_size=337.08 MiB,\n",
              "    dataset_size=317.62 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'train': <SplitInfo num_examples=27558, num_shards=4>,\n",
              "    },\n",
              "    citation=\"\"\"@article{rajaraman2018pre,\n",
              "      title={Pre-trained convolutional neural networks as feature extractors toward\n",
              "      improved malaria parasite detection in thin blood smear images},\n",
              "      author={Rajaraman, Sivaramakrishnan and Antani, Sameer K and Poostchi, Mahdieh\n",
              "      and Silamut, Kamolrat and Hossain, Md A and Maude, Richard J and Jaeger,\n",
              "      Stefan and Thoma, George R},\n",
              "      journal={PeerJ},\n",
              "      volume={6},\n",
              "      pages={e4568},\n",
              "      year={2018},\n",
              "      publisher={PeerJ Inc.}\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):\n",
        "  DATASET_SIZE = len(dataset)\n",
        "  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "\n",
        "  val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "  val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))\n",
        "\n",
        "  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))\n",
        "  return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "EgL1OuMmpvcE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "# dataset = tf.data.Dataset.range(10)\n",
        "# print(list(dataset.as_numpy_iterator()))\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
        "\n",
        "print(list(train_dataset.take(1).as_numpy_iterator()))\n",
        "print(list(val_dataset.take(1).as_numpy_iterator()))\n",
        "print(list(test_dataset.take(1).as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHS5b1MHqPaH",
        "outputId": "d9d1eb48-c273-4521-c774-3c081e64dabf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=uint8), 1)]\n",
            "[(array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=uint8), 0)]\n",
            "[(array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=uint8), 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pYs-MmyL5UYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Visualization\n"
      ],
      "metadata": {
        "id": "Tj7XEXw7rgMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(train_dataset.take(16)):\n",
        "  ax = plt.subplot(4, 4, i + 1)\n",
        "  plt.imshow(image)\n",
        "  plt.title(dataset_info.features['label'].int2str(label))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "sQcUWvwc5Ux7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "f1f24e6d-aa74-467d-bfa1-b7da701f5774"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info.features['label'].int2str(0)"
      ],
      "metadata": {
        "id": "AyL5BAfCr91l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17743938-c6ab-4781-fa7d-8cf9d14b846a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'parasitized'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "POiYCK_-vbVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IM_SIZE = 224\n",
        "def resize_rescale(image, label):\n",
        "  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label"
      ],
      "metadata": {
        "id": "YDvMjR1SvhMy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(resize_rescale)\n",
        "val_dataset = val_dataset.map(resize_rescale)\n",
        "test_dataset = test_dataset.map(resize_rescale)\n",
        "train_dataset\n",
        "# val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwI_wTmKxIgz",
        "outputId": "3507a624-84f9-4478-f3df-07467bc767df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_dataset.take(1):\n",
        "  print(image, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWdOj6SAxa3J",
        "outputId": "ed177fd4-522c-4ee7-d2da-67c7da79cd68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]], shape=(224, 224, 3), dtype=float32) tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m9RVCOryulP",
        "outputId": "db358ca1-b875-4e4e-8b65-f39aed1ec30a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W8eX_FEYCp_",
        "outputId": "2aea48e0-ba52-4d60-bbad-392edf5f8392"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Squential API Model"
      ],
      "metadata": {
        "id": "Z8TSg1CSF6hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n",
        "\n",
        "    Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "    Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(1000, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(100, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation = \"sigmoid\"),\n",
        "\n",
        "])\n",
        "lenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9MuiLWczaly",
        "outputId": "df04e7ba-c1af-4548-a796-0cc2d3210115"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 6)       168       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 222, 222, 6)       24        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 6)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 16)      880       \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 109, 109, 16)      64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 46656)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              46657000  \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 1000)              4000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               100100    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 100)               400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46762737 (178.39 MB)\n",
            "Trainable params: 46760493 (178.38 MB)\n",
            "Non-trainable params: 2244 (8.77 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional API Model"
      ],
      "metadata": {
        "id": "UM4-KKzp0Wvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input Image\")\n",
        "\n",
        "x = Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation='relu')(func_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D (pool_size = 2, strides = 2)(x)\n",
        "\n",
        "x = Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = MaxPool2D (pool_size = 2, strides = 2)(x)\n",
        "\n",
        "feature_extractor_model = Model(func_input, output, name = \"Feature_Extractor\")\n",
        "\n",
        "feature_extractor_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjRPFp49_VUY",
        "outputId": "e1d38196-98a9-4ae5-ce29-9c5a374ebfa9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Feature_Extractor\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input Image (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 222, 222, 6)       168       \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 222, 222, 6)       24        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 111, 111, 6)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 109, 109, 16)      880       \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 109, 109, 16)      64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 54, 54, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1136 (4.44 KB)\n",
            "Trainable params: 1092 (4.27 KB)\n",
            "Non-trainable params: 44 (176.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating my feature extractor using a sequential model\n",
        "feature_extractor_seq_model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n",
        "\n",
        "    Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "    Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "])\n",
        "feature_extractor_seq_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRckO5hwUi4v",
        "outputId": "61d60e7a-bdad-4935-8d24-8e6105937b05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 222, 222, 6)       168       \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 222, 222, 6)       24        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 111, 111, 6)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 109, 109, 16)      880       \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 109, 109, 16)      64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 54, 54, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1136 (4.44 KB)\n",
            "Trainable params: 1092 (4.27 KB)\n",
            "Non-trainable params: 44 (176.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input Image\")\n",
        "\n",
        "x = feature_extractor_seq_model(func_input)\n",
        "x = Flatten()(x)\n",
        "x = Dense(1000, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(100, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "lenet_model_func = Model(func_input, func_output, name = \"Lenet_Model\")\n",
        "\n",
        "lenet_model_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTV6ExXa0dM6",
        "outputId": "513c7c40-f590-47ca-d03c-1758b96d12ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Lenet_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input Image (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 54, 54, 16)        1136      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1000)              46657000  \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 1000)              4000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               100100    \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 100)               400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46762737 (178.39 MB)\n",
            "Trainable params: 46760493 (178.38 MB)\n",
            "Non-trainable params: 2244 (8.77 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model subclassing"
      ],
      "metadata": {
        "id": "eMa9oag9Wahy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(Layer):\n",
        "  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "\n",
        "    self.conv_1 = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)\n",
        "    self.batch_1 = BatchNormalization()\n",
        "    self.pool_1 = MaxPool2D (pool_size = pool_size, strides = 2 * strides)\n",
        "\n",
        "    self.conv_2 = Conv2D(filters = filters * 2, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)\n",
        "    self.batch_2 = BatchNormalization()\n",
        "    self.pool_2 = MaxPool2D (pool_size = pool_size, strides = 2 * strides)\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    x = self.conv_1(x)\n",
        "    x = self.batch_1(x)\n",
        "    x = self.pool_1(x)\n",
        "\n",
        "    x = self.conv_2(x)\n",
        "    x = self.batch_2(x)\n",
        "    x = self.pool_2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "feature_sub_classed = FeatureExtractor(8, 3, 1, \"valid\", \"relu\", 2)"
      ],
      "metadata": {
        "id": "FR1LF2ftTg6i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input Image\")\n",
        "\n",
        "x = feature_sub_classed(func_input)\n",
        "x = Flatten()(x)\n",
        "x = Dense(100, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(10, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "lenet_model_func = Model(func_input, func_output, name = \"Lenet_Model\")\n",
        "\n",
        "lenet_model_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckvFAnrgdEZz",
        "outputId": "3f3caf32-a998-4446-9a60-75941d421870"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Lenet_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input Image (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " feature_extractor (Feature  (None, 54, 54, 16)        1488      \n",
            " Extractor)                                                      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               4665700   \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 100)               400       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 10)                40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4668649 (17.81 MB)\n",
            "Trainable params: 4668381 (17.81 MB)\n",
            "Non-trainable params: 268 (1.05 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# self, filters, kernel_size, strides, padding, activation, pool_size\n",
        "\n",
        "class LenetModel(Model):\n",
        "  def __init__(self):\n",
        "    super(LenetModel, self).__init__()\n",
        "\n",
        "    self.feature_extractor = FeatureExtractor(8, 3, 1, \"valid\", \"relu\", 2)\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "    self.dense_1 = Dense(100, activation = \"relu\")\n",
        "    self.batch_1 = BatchNormalization()\n",
        "\n",
        "    self.dense_2 = Dense(10, activation = \"relu\")\n",
        "    self.batch_2 = BatchNormalization()\n",
        "\n",
        "    self.dense_3 = Dense(1, activation = \"sigmoid\")\n",
        "\n",
        "  def call(self, x, training):\n",
        "\n",
        "    x = self.feature_extractor(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_1(x)\n",
        "    x = self.batch_1(x)\n",
        "    x = self.dense_2(x)\n",
        "    x = self.batch_2(x)\n",
        "    x = self.dense_3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "lenet_sub_classed = LenetModel()\n",
        "lenet_sub_classed(tf.zeros([1, 224, 224, 3]))\n",
        "lenet_model_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjr0sUCTe7-Y",
        "outputId": "da4571c9-4e97-4296-c2bf-fdd7bb9e80bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Lenet_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input Image (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " feature_extractor (Feature  (None, 54, 54, 16)        1488      \n",
            " Extractor)                                                      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               4665700   \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 100)               400       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 10)                40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4668649 (17.81 MB)\n",
            "Trainable params: 4668381 (17.81 MB)\n",
            "Non-trainable params: 268 (1.05 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Layers"
      ],
      "metadata": {
        "id": "l5GEnrSGrfqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.events import pre_execute\n",
        "# , initializer = \"random_normal\"\n",
        "class NeuralearnDense(Layer):\n",
        "  def __init__(self, output_units, activation):\n",
        "    super(NeuralearnDense, self).__init__()\n",
        "    self.output_units = output_units\n",
        "    self.activation = activation\n",
        "\n",
        "  def build(self, input_features_shape):\n",
        "    self.w = self.add_weight(shape = (input_features_shape[-1], self.output_units), trainable=True)\n",
        "    self.b = self.add_weight(shape = (self.output_units,), trainable=True)\n",
        "\n",
        "  def call(self, input_features):\n",
        "    pre_output = tf.matmul(input_features, self.w) + self.b\n",
        "    if self.activation == \"relu\":\n",
        "      return tf.nn.relu(pre_output)\n",
        "    elif self.activation == \"sigmoid\":\n",
        "      return tf.math.sigmoid(pre_output)\n",
        "    else:\n",
        "      return pre_output"
      ],
      "metadata": {
        "id": "n6M0Ywx7rfFz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IM_SIZE =224\n",
        "lenet_model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n",
        "\n",
        "    Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "    Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "    Flatten(),\n",
        "    NeuralearnDense(100, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    NeuralearnDense(100, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation = \"sigmoid\"),\n",
        "\n",
        "])\n",
        "lenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_K6wYEO0rMt",
        "outputId": "8ca93285-120d-4bd6-cbbb-df38d8e95040"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 222, 222, 6)       168       \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 222, 222, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 111, 111, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 109, 109, 16)      880       \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 109, 109, 16)      64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 54, 54, 16)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " neuralearn_dense (Neuralea  (None, 100)               4665700   \n",
            " rnDense)                                                        \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 100)               400       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " neuralearn_dense_1 (Neural  (None, 100)               10100     \n",
            " earnDense)                                                      \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 100)               400       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4677837 (17.84 MB)\n",
            "Trainable params: 4677393 (17.84 MB)\n",
            "Non-trainable params: 444 (1.73 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# self, filters, kernel_size, strides, padding, activation, pool_size\n",
        "\n",
        "class LenetModel(Model):\n",
        "  def __init__(self):\n",
        "    super(LenetModel, self).__init__()\n",
        "\n",
        "    self.feature_extractor = FeatureExtractor(8, 3, 1, \"valid\", \"relu\", 2)\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "    self.dense_1 = Dense(100, activation = \"relu\")\n",
        "    self.batch_1 = BatchNormalization()\n",
        "\n",
        "    self.dense_2 = Dense(10, activation = \"relu\")\n",
        "    self.batch_2 = BatchNormalization()\n",
        "\n",
        "    self.dense_3 = Dense(1, activation = \"sigmoid\")\n",
        "\n",
        "  def call(self, x, training):\n",
        "\n",
        "    x = self.feature_extractor(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_1(x)\n",
        "    x = self.batch_1(x)\n",
        "    x = self.dense_2(x)\n",
        "    x = self.batch_2(x)\n",
        "    x = self.dense_3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "lenet_sub_classed = LenetModel()\n",
        "lenet_sub_classed(tf.zeros([1, 224, 224, 3]))\n",
        "lenet_model_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm1tzd4_jbUa",
        "outputId": "0c82f2a2-af6c-4c16-ae84-4181d5aa706e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Lenet_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input Image (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " feature_extractor (Feature  (None, 54, 54, 16)        1488      \n",
            " Extractor)                                                      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               4665700   \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 100)               400       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 10)                40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4668649 (17.81 MB)\n",
            "Trainable params: 4668381 (17.81 MB)\n",
            "Non-trainable params: 268 (1.05 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IM_SIZE = 224\n",
        "lenet_model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n",
        "\n",
        "    Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "    Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = 2, strides = 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(1000, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(100, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation = \"sigmoid\"),\n",
        "\n",
        "])\n",
        "lenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlpE_sEVj_Cv",
        "outputId": "cac63597-be1b-4dfa-feef-621b78a5edf9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 222, 222, 6)       168       \n",
            "                                                                 \n",
            " batch_normalization_26 (Ba  (None, 222, 222, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 111, 111, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 109, 109, 16)      880       \n",
            "                                                                 \n",
            " batch_normalization_27 (Ba  (None, 109, 109, 16)      64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 54, 54, 16)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1000)              46657000  \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, 1000)              4000      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               100100    \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, 100)               400       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46762737 (178.39 MB)\n",
            "Trainable params: 46760493 (178.38 MB)\n",
            "Non-trainable params: 2244 (8.77 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error Sunctioning"
      ],
      "metadata": {
        "id": "urlz8TFKM9uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We generally use BinaryCrossEntropy loss\n",
        "y_true = [0, 1, 0, 0]\n",
        "y_pred = [0.6, 0.51, 0.94, 1]\n",
        "bce = tf.keras.losses.BinaryCrossentropy() # from_logits=True\n",
        "bce(y_true, y_pred)"
      ],
      "metadata": {
        "id": "wQsPSBeKMdop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47a1323-157d-49b7-a574-de7bce6c372e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4.9340706>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  metrics = [TruePositives(name='tp'),FalsePositives(name='fp'), TrueNegatives(name='tn'), FalseNegatives(name='fn'),\n",
        "#                 BinaryAccuracy(name='accuracy'), Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]"
      ],
      "metadata": {
        "id": "iQm7MuALiXIw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import metrics\n",
        "from keras.src.losses import BinaryCrossentropy\n",
        "metrics = [TruePositives(name='tp'),FalsePositives(name='fp'), TrueNegatives(name='tn'), FalseNegatives(name='fn'),\n",
        "                BinaryAccuracy(name='accuracy'), Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n",
        "lenet_model.compile(optimizer = Adam(learning_rate = 0.1),\n",
        "              loss = BinaryCrossentropy(),\n",
        "                    metrics = metrics)\n",
        "              # metrics = RootMeanSquaredError()"
      ],
      "metadata": {
        "id": "PZLUWldcPmOV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callbacks"
      ],
      "metadata": {
        "id": "kFRNSinaZ8Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LossCallback(Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    print(\"\\n For Epoch Number {} the model has a loss of {}\".format(epoch + 1, logs[\"loss\"]))\n",
        "\n",
        "  def on_batch_end(self, batch, logs):\n",
        "    print(\"\\n For Batch Number {} the model has a loss of {} \".format(batch + 1, logs))"
      ],
      "metadata": {
        "id": "cwZdx4jCZ52J"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSVLogger"
      ],
      "metadata": {
        "id": "nrXVQ8Q8cxh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_callback = CSVLogger(\n",
        "    'logs.csv', separator=',', append=False\n",
        ")"
      ],
      "metadata": {
        "id": "PbO0xKSwc5r3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lenet_model.fit(train_dataset, epochs = 3, verbose = 1, callbacks = [LossCallback(),])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjB0pqBpQzgp",
        "outputId": "c8ffd0e2-80a1-408b-f4f0-3685b4ffdf66"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\n",
            " For Batch Number 1 the model has a loss of {'loss': 0.6239879131317139, 'tp': 5.0, 'fp': 6.0, 'tn': 15.0, 'fn': 6.0, 'accuracy': 0.625, 'precision': 0.4545454680919647, 'recall': 0.4545454680919647, 'auc': 0.7186146974563599} \n",
            "  1/689 [..............................] - ETA: 2:06 - loss: 0.6240 - tp: 5.0000 - fp: 6.0000 - tn: 15.0000 - fn: 6.0000 - accuracy: 0.6250 - precision: 0.4545 - recall: 0.4545 - auc: 0.7186\n",
            " For Batch Number 2 the model has a loss of {'loss': 0.6897897720336914, 'tp': 15.0, 'fp': 10.0, 'tn': 23.0, 'fn': 16.0, 'accuracy': 0.59375, 'precision': 0.6000000238418579, 'recall': 0.4838709533214569, 'auc': 0.6060605645179749} \n",
            "  2/689 [..............................] - ETA: 47s - loss: 0.6898 - tp: 15.0000 - fp: 10.0000 - tn: 23.0000 - fn: 16.0000 - accuracy: 0.5938 - precision: 0.6000 - recall: 0.4839 - auc: 0.6061\n",
            " For Batch Number 3 the model has a loss of {'loss': 0.6541883945465088, 'tp': 24.0, 'fp': 13.0, 'tn': 37.0, 'fn': 22.0, 'accuracy': 0.6354166865348816, 'precision': 0.6486486196517944, 'recall': 0.52173912525177, 'auc': 0.6521738767623901} \n",
            "  3/689 [..............................] - ETA: 53s - loss: 0.6542 - tp: 24.0000 - fp: 13.0000 - tn: 37.0000 - fn: 22.0000 - accuracy: 0.6354 - precision: 0.6486 - recall: 0.5217 - auc: 0.6522\n",
            " For Batch Number 4 the model has a loss of {'loss': 0.6234639883041382, 'tp': 39.0, 'fp': 14.0, 'tn': 47.0, 'fn': 28.0, 'accuracy': 0.671875, 'precision': 0.7358490824699402, 'recall': 0.5820895433425903, 'auc': 0.7100562453269958} \n",
            "  4/689 [..............................] - ETA: 55s - loss: 0.6235 - tp: 39.0000 - fp: 14.0000 - tn: 47.0000 - fn: 28.0000 - accuracy: 0.6719 - precision: 0.7358 - recall: 0.5821 - auc: 0.7101\n",
            " For Batch Number 5 the model has a loss of {'loss': 0.6257529854774475, 'tp': 49.0, 'fp': 20.0, 'tn': 57.0, 'fn': 34.0, 'accuracy': 0.6625000238418579, 'precision': 0.7101449370384216, 'recall': 0.5903614163398743, 'auc': 0.7053669691085815} \n",
            "  5/689 [..............................] - ETA: 52s - loss: 0.6258 - tp: 49.0000 - fp: 20.0000 - tn: 57.0000 - fn: 34.0000 - accuracy: 0.6625 - precision: 0.7101 - recall: 0.5904 - auc: 0.7054\n",
            " For Batch Number 6 the model has a loss of {'loss': 0.6177677512168884, 'tp': 61.0, 'fp': 26.0, 'tn': 64.0, 'fn': 41.0, 'accuracy': 0.6510416865348816, 'precision': 0.7011494040489197, 'recall': 0.5980392098426819, 'auc': 0.7149780988693237} \n",
            "  6/689 [..............................] - ETA: 50s - loss: 0.6178 - tp: 61.0000 - fp: 26.0000 - tn: 64.0000 - fn: 41.0000 - accuracy: 0.6510 - precision: 0.7011 - recall: 0.5980 - auc: 0.7150\n",
            " For Batch Number 7 the model has a loss of {'loss': 0.6059055328369141, 'tp': 74.0, 'fp': 32.0, 'tn': 72.0, 'fn': 46.0, 'accuracy': 0.6517857313156128, 'precision': 0.698113203048706, 'recall': 0.6166666746139526, 'auc': 0.7276842594146729} \n",
            "  7/689 [..............................] - ETA: 52s - loss: 0.6059 - tp: 74.0000 - fp: 32.0000 - tn: 72.0000 - fn: 46.0000 - accuracy: 0.6518 - precision: 0.6981 - recall: 0.6167 - auc: 0.7277\n",
            " For Batch Number 8 the model has a loss of {'loss': 0.6112143993377686, 'tp': 85.0, 'fp': 39.0, 'tn': 82.0, 'fn': 50.0, 'accuracy': 0.65234375, 'precision': 0.6854838728904724, 'recall': 0.6296296119689941, 'auc': 0.7207530736923218} \n",
            "  8/689 [..............................] - ETA: 51s - loss: 0.6112 - tp: 85.0000 - fp: 39.0000 - tn: 82.0000 - fn: 50.0000 - accuracy: 0.6523 - precision: 0.6855 - recall: 0.6296 - auc: 0.7208\n",
            " For Batch Number 9 the model has a loss of {'loss': 0.6035678386688232, 'tp': 100.0, 'fp': 44.0, 'tn': 90.0, 'fn': 54.0, 'accuracy': 0.6597222089767456, 'precision': 0.6944444179534912, 'recall': 0.649350643157959, 'auc': 0.7312706708908081} \n",
            "  9/689 [..............................] - ETA: 50s - loss: 0.6036 - tp: 100.0000 - fp: 44.0000 - tn: 90.0000 - fn: 54.0000 - accuracy: 0.6597 - precision: 0.6944 - recall: 0.6494 - auc: 0.7313\n",
            " For Batch Number 10 the model has a loss of {'loss': 0.6005609035491943, 'tp': 111.0, 'fp': 52.0, 'tn': 101.0, 'fn': 56.0, 'accuracy': 0.6625000238418579, 'precision': 0.6809815764427185, 'recall': 0.6646706461906433, 'auc': 0.7390903830528259} \n",
            " 10/689 [..............................] - ETA: 51s - loss: 0.6006 - tp: 111.0000 - fp: 52.0000 - tn: 101.0000 - fn: 56.0000 - accuracy: 0.6625 - precision: 0.6810 - recall: 0.6647 - auc: 0.7391\n",
            " For Batch Number 11 the model has a loss of {'loss': 0.607860803604126, 'tp': 121.0, 'fp': 57.0, 'tn': 109.0, 'fn': 65.0, 'accuracy': 0.6534090638160706, 'precision': 0.6797752976417542, 'recall': 0.6505376100540161, 'auc': 0.7211102843284607} \n",
            " 11/689 [..............................] - ETA: 50s - loss: 0.6079 - tp: 121.0000 - fp: 57.0000 - tn: 109.0000 - fn: 65.0000 - accuracy: 0.6534 - precision: 0.6798 - recall: 0.6505 - auc: 0.7211\n",
            " For Batch Number 12 the model has a loss of {'loss': 0.6178035736083984, 'tp': 130.0, 'fp': 61.0, 'tn': 119.0, 'fn': 74.0, 'accuracy': 0.6484375, 'precision': 0.6806282997131348, 'recall': 0.6372548937797546, 'auc': 0.7077887058258057} \n",
            " 12/689 [..............................] - ETA: 49s - loss: 0.6178 - tp: 130.0000 - fp: 61.0000 - tn: 119.0000 - fn: 74.0000 - accuracy: 0.6484 - precision: 0.6806 - recall: 0.6373 - auc: 0.7078\n",
            " For Batch Number 13 the model has a loss of {'loss': 0.6259375214576721, 'tp': 138.0, 'fp': 65.0, 'tn': 128.0, 'fn': 85.0, 'accuracy': 0.6394230723381042, 'precision': 0.6798029541969299, 'recall': 0.6188340783119202, 'auc': 0.6929877996444702} \n",
            " 13/689 [..............................] - ETA: 51s - loss: 0.6259 - tp: 138.0000 - fp: 65.0000 - tn: 128.0000 - fn: 85.0000 - accuracy: 0.6394 - precision: 0.6798 - recall: 0.6188 - auc: 0.6930\n",
            " For Batch Number 14 the model has a loss of {'loss': 0.6225823760032654, 'tp': 148.0, 'fp': 70.0, 'tn': 138.0, 'fn': 92.0, 'accuracy': 0.6383928656578064, 'precision': 0.6788991093635559, 'recall': 0.6166666746139526, 'auc': 0.6961638331413269} \n",
            " 14/689 [..............................] - ETA: 51s - loss: 0.6226 - tp: 148.0000 - fp: 70.0000 - tn: 138.0000 - fn: 92.0000 - accuracy: 0.6384 - precision: 0.6789 - recall: 0.6167 - auc: 0.6962\n",
            " For Batch Number 15 the model has a loss of {'loss': 0.626218855381012, 'tp': 157.0, 'fp': 77.0, 'tn': 148.0, 'fn': 98.0, 'accuracy': 0.6354166865348816, 'precision': 0.6709401607513428, 'recall': 0.615686297416687, 'auc': 0.6897255182266235} \n",
            " 15/689 [..............................] - ETA: 51s - loss: 0.6262 - tp: 157.0000 - fp: 77.0000 - tn: 148.0000 - fn: 98.0000 - accuracy: 0.6354 - precision: 0.6709 - recall: 0.6157 - auc: 0.6897\n",
            " For Batch Number 16 the model has a loss of {'loss': 0.6225347518920898, 'tp': 167.0, 'fp': 80.0, 'tn': 161.0, 'fn': 104.0, 'accuracy': 0.640625, 'precision': 0.6761133670806885, 'recall': 0.61623615026474, 'auc': 0.6945919990539551} \n",
            " 16/689 [..............................] - ETA: 52s - loss: 0.6225 - tp: 167.0000 - fp: 80.0000 - tn: 161.0000 - fn: 104.0000 - accuracy: 0.6406 - precision: 0.6761 - recall: 0.6162 - auc: 0.6946\n",
            " For Batch Number 17 the model has a loss of {'loss': 0.6158549785614014, 'tp': 177.0, 'fp': 82.0, 'tn': 176.0, 'fn': 109.0, 'accuracy': 0.6488970518112183, 'precision': 0.6833977103233337, 'recall': 0.618881106376648, 'auc': 0.7012726068496704} \n",
            " 17/689 [..............................] - ETA: 52s - loss: 0.6159 - tp: 177.0000 - fp: 82.0000 - tn: 176.0000 - fn: 109.0000 - accuracy: 0.6489 - precision: 0.6834 - recall: 0.6189 - auc: 0.7013\n",
            " For Batch Number 18 the model has a loss of {'loss': 0.6226538419723511, 'tp': 185.0, 'fp': 87.0, 'tn': 188.0, 'fn': 116.0, 'accuracy': 0.6475694179534912, 'precision': 0.6801470518112183, 'recall': 0.6146179437637329, 'auc': 0.6963998675346375} \n",
            " 18/689 [..............................] - ETA: 53s - loss: 0.6227 - tp: 185.0000 - fp: 87.0000 - tn: 188.0000 - fn: 116.0000 - accuracy: 0.6476 - precision: 0.6801 - recall: 0.6146 - auc: 0.6964\n",
            " For Batch Number 19 the model has a loss of {'loss': 0.617201030254364, 'tp': 194.0, 'fp': 89.0, 'tn': 205.0, 'fn': 120.0, 'accuracy': 0.65625, 'precision': 0.685512363910675, 'recall': 0.6178343892097473, 'auc': 0.7044282555580139} \n",
            " 19/689 [..............................] - ETA: 54s - loss: 0.6172 - tp: 194.0000 - fp: 89.0000 - tn: 205.0000 - fn: 120.0000 - accuracy: 0.6562 - precision: 0.6855 - recall: 0.6178 - auc: 0.7044\n",
            " For Batch Number 20 the model has a loss of {'loss': 0.6186441779136658, 'tp': 200.0, 'fp': 94.0, 'tn': 219.0, 'fn': 127.0, 'accuracy': 0.6546875238418579, 'precision': 0.680272102355957, 'recall': 0.6116207838058472, 'auc': 0.7010923027992249} \n",
            " 20/689 [..............................] - ETA: 56s - loss: 0.6186 - tp: 200.0000 - fp: 94.0000 - tn: 219.0000 - fn: 127.0000 - accuracy: 0.6547 - precision: 0.6803 - recall: 0.6116 - auc: 0.7011\n",
            " For Batch Number 21 the model has a loss of {'loss': 0.6217038035392761, 'tp': 206.0, 'fp': 99.0, 'tn': 231.0, 'fn': 136.0, 'accuracy': 0.6502976417541504, 'precision': 0.6754098534584045, 'recall': 0.6023392081260681, 'auc': 0.6994329690933228} \n",
            " 21/689 [..............................] - ETA: 58s - loss: 0.6217 - tp: 206.0000 - fp: 99.0000 - tn: 231.0000 - fn: 136.0000 - accuracy: 0.6503 - precision: 0.6754 - recall: 0.6023 - auc: 0.6994\n",
            " For Batch Number 22 the model has a loss of {'loss': 0.6261544823646545, 'tp': 215.0, 'fp': 100.0, 'tn': 243.0, 'fn': 146.0, 'accuracy': 0.6505681872367859, 'precision': 0.682539701461792, 'recall': 0.5955678820610046, 'auc': 0.6938331127166748} \n",
            " 22/689 [..............................] - ETA: 58s - loss: 0.6262 - tp: 215.0000 - fp: 100.0000 - tn: 243.0000 - fn: 146.0000 - accuracy: 0.6506 - precision: 0.6825 - recall: 0.5956 - auc: 0.6938\n",
            " For Batch Number 23 the model has a loss of {'loss': 0.6280133128166199, 'tp': 221.0, 'fp': 100.0, 'tn': 256.0, 'fn': 159.0, 'accuracy': 0.648097813129425, 'precision': 0.6884735226631165, 'recall': 0.5815789699554443, 'auc': 0.6885423064231873} \n",
            " 23/689 [>.............................] - ETA: 58s - loss: 0.6280 - tp: 221.0000 - fp: 100.0000 - tn: 256.0000 - fn: 159.0000 - accuracy: 0.6481 - precision: 0.6885 - recall: 0.5816 - auc: 0.6885\n",
            " For Batch Number 24 the model has a loss of {'loss': 0.6291518807411194, 'tp': 229.0, 'fp': 102.0, 'tn': 270.0, 'fn': 167.0, 'accuracy': 0.6497395634651184, 'precision': 0.6918429136276245, 'recall': 0.5782828330993652, 'auc': 0.6875} \n",
            " 24/689 [>.............................] - ETA: 59s - loss: 0.6292 - tp: 229.0000 - fp: 102.0000 - tn: 270.0000 - fn: 167.0000 - accuracy: 0.6497 - precision: 0.6918 - recall: 0.5783 - auc: 0.6875\n",
            " For Batch Number 25 the model has a loss of {'loss': 0.6284338235855103, 'tp': 235.0, 'fp': 107.0, 'tn': 286.0, 'fn': 172.0, 'accuracy': 0.6512500047683716, 'precision': 0.6871345043182373, 'recall': 0.5773955583572388, 'auc': 0.6885514855384827} \n",
            " 25/689 [>.............................] - ETA: 59s - loss: 0.6284 - tp: 235.0000 - fp: 107.0000 - tn: 286.0000 - fn: 172.0000 - accuracy: 0.6513 - precision: 0.6871 - recall: 0.5774 - auc: 0.6886\n",
            " For Batch Number 26 the model has a loss of {'loss': 0.6292088627815247, 'tp': 243.0, 'fp': 109.0, 'tn': 303.0, 'fn': 177.0, 'accuracy': 0.65625, 'precision': 0.6903409361839294, 'recall': 0.5785714387893677, 'auc': 0.6881645917892456} \n",
            " 26/689 [>.............................] - ETA: 59s - loss: 0.6292 - tp: 243.0000 - fp: 109.0000 - tn: 303.0000 - fn: 177.0000 - accuracy: 0.6562 - precision: 0.6903 - recall: 0.5786 - auc: 0.6882\n",
            " For Batch Number 27 the model has a loss of {'loss': 0.6318817138671875, 'tp': 251.0, 'fp': 111.0, 'tn': 315.0, 'fn': 187.0, 'accuracy': 0.6550925970077515, 'precision': 0.6933701634407043, 'recall': 0.5730593800544739, 'auc': 0.6848537921905518} \n",
            " 27/689 [>.............................] - ETA: 59s - loss: 0.6319 - tp: 251.0000 - fp: 111.0000 - tn: 315.0000 - fn: 187.0000 - accuracy: 0.6551 - precision: 0.6934 - recall: 0.5731 - auc: 0.6849\n",
            " For Batch Number 28 the model has a loss of {'loss': 0.6326571702957153, 'tp': 256.0, 'fp': 114.0, 'tn': 330.0, 'fn': 196.0, 'accuracy': 0.6540178656578064, 'precision': 0.6918919086456299, 'recall': 0.5663716793060303, 'auc': 0.6810970306396484} \n",
            " 28/689 [>.............................] - ETA: 59s - loss: 0.6327 - tp: 256.0000 - fp: 114.0000 - tn: 330.0000 - fn: 196.0000 - accuracy: 0.6540 - precision: 0.6919 - recall: 0.5664 - auc: 0.6811\n",
            " For Batch Number 29 the model has a loss of {'loss': 0.6332696676254272, 'tp': 263.0, 'fp': 114.0, 'tn': 343.0, 'fn': 208.0, 'accuracy': 0.6530172228813171, 'precision': 0.6976127028465271, 'recall': 0.5583863854408264, 'auc': 0.6793892979621887} \n",
            " 29/689 [>.............................] - ETA: 59s - loss: 0.6333 - tp: 263.0000 - fp: 114.0000 - tn: 343.0000 - fn: 208.0000 - accuracy: 0.6530 - precision: 0.6976 - recall: 0.5584 - auc: 0.6794\n",
            " For Batch Number 30 the model has a loss of {'loss': 0.6306231617927551, 'tp': 271.0, 'fp': 115.0, 'tn': 358.0, 'fn': 216.0, 'accuracy': 0.6552083492279053, 'precision': 0.7020725607872009, 'recall': 0.5564681887626648, 'auc': 0.681431770324707} \n",
            " 30/689 [>.............................] - ETA: 59s - loss: 0.6306 - tp: 271.0000 - fp: 115.0000 - tn: 358.0000 - fn: 216.0000 - accuracy: 0.6552 - precision: 0.7021 - recall: 0.5565 - auc: 0.6814\n",
            " For Batch Number 31 the model has a loss of {'loss': 0.6281925439834595, 'tp': 283.0, 'fp': 116.0, 'tn': 369.0, 'fn': 224.0, 'accuracy': 0.6572580933570862, 'precision': 0.7092731595039368, 'recall': 0.5581853985786438, 'auc': 0.6842901110649109} \n",
            " 31/689 [>.............................] - ETA: 1:00 - loss: 0.6282 - tp: 283.0000 - fp: 116.0000 - tn: 369.0000 - fn: 224.0000 - accuracy: 0.6573 - precision: 0.7093 - recall: 0.5582 - auc: 0.6843\n",
            " For Batch Number 32 the model has a loss of {'loss': 0.6289151906967163, 'tp': 300.0, 'fp': 129.0, 'tn': 370.0, 'fn': 225.0, 'accuracy': 0.654296875, 'precision': 0.6993007063865662, 'recall': 0.5714285969734192, 'auc': 0.6852715015411377} \n",
            " 32/689 [>.............................] - ETA: 59s - loss: 0.6289 - tp: 300.0000 - fp: 129.0000 - tn: 370.0000 - fn: 225.0000 - accuracy: 0.6543 - precision: 0.6993 - recall: 0.5714 - auc: 0.6853 \n",
            " For Batch Number 33 the model has a loss of {'loss': 0.6300656795501709, 'tp': 317.0, 'fp': 144.0, 'tn': 370.0, 'fn': 225.0, 'accuracy': 0.6505681872367859, 'precision': 0.687635600566864, 'recall': 0.5848708748817444, 'auc': 0.6852449178695679} \n",
            " 33/689 [>.............................] - ETA: 1:01 - loss: 0.6301 - tp: 317.0000 - fp: 144.0000 - tn: 370.0000 - fn: 225.0000 - accuracy: 0.6506 - precision: 0.6876 - recall: 0.5849 - auc: 0.6852\n",
            " For Batch Number 34 the model has a loss of {'loss': 0.6399190425872803, 'tp': 329.0, 'fp': 164.0, 'tn': 370.0, 'fn': 225.0, 'accuracy': 0.642463207244873, 'precision': 0.6673427820205688, 'recall': 0.5938628315925598, 'auc': 0.6776524186134338} \n",
            " 34/689 [>.............................] - ETA: 1:01 - loss: 0.6399 - tp: 329.0000 - fp: 164.0000 - tn: 370.0000 - fn: 225.0000 - accuracy: 0.6425 - precision: 0.6673 - recall: 0.5939 - auc: 0.6777\n",
            " For Batch Number 35 the model has a loss of {'loss': 0.6443616151809692, 'tp': 340.0, 'fp': 168.0, 'tn': 378.0, 'fn': 234.0, 'accuracy': 0.6410714387893677, 'precision': 0.6692913174629211, 'recall': 0.592334508895874, 'auc': 0.67597895860672} \n",
            " 35/689 [>.............................] - ETA: 1:00 - loss: 0.6444 - tp: 340.0000 - fp: 168.0000 - tn: 378.0000 - fn: 234.0000 - accuracy: 0.6411 - precision: 0.6693 - recall: 0.5923 - auc: 0.6760\n",
            " For Batch Number 36 the model has a loss of {'loss': 0.6476728916168213, 'tp': 349.0, 'fp': 171.0, 'tn': 386.0, 'fn': 246.0, 'accuracy': 0.6380208134651184, 'precision': 0.6711538434028625, 'recall': 0.5865546464920044, 'auc': 0.6707271337509155} \n",
            " 36/689 [>.............................] - ETA: 1:00 - loss: 0.6477 - tp: 349.0000 - fp: 171.0000 - tn: 386.0000 - fn: 246.0000 - accuracy: 0.6380 - precision: 0.6712 - recall: 0.5866 - auc: 0.6707\n",
            " For Batch Number 37 the model has a loss of {'loss': 0.6477037072181702, 'tp': 357.0, 'fp': 173.0, 'tn': 396.0, 'fn': 258.0, 'accuracy': 0.6359797120094299, 'precision': 0.6735848784446716, 'recall': 0.5804877877235413, 'auc': 0.6694629192352295} \n",
            " 37/689 [>.............................] - ETA: 59s - loss: 0.6477 - tp: 357.0000 - fp: 173.0000 - tn: 396.0000 - fn: 258.0000 - accuracy: 0.6360 - precision: 0.6736 - recall: 0.5805 - auc: 0.6695 \n",
            " For Batch Number 38 the model has a loss of {'loss': 0.6465675830841064, 'tp': 367.0, 'fp': 176.0, 'tn': 406.0, 'fn': 267.0, 'accuracy': 0.6356908082962036, 'precision': 0.6758747696876526, 'recall': 0.578864336013794, 'auc': 0.6705407500267029} \n",
            " 38/689 [>.............................] - ETA: 59s - loss: 0.6466 - tp: 367.0000 - fp: 176.0000 - tn: 406.0000 - fn: 267.0000 - accuracy: 0.6357 - precision: 0.6759 - recall: 0.5789 - auc: 0.6705\n",
            " For Batch Number 39 the model has a loss of {'loss': 0.6452992558479309, 'tp': 381.0, 'fp': 178.0, 'tn': 415.0, 'fn': 274.0, 'accuracy': 0.6378205418586731, 'precision': 0.6815742254257202, 'recall': 0.5816794037818909, 'auc': 0.6727958917617798} \n",
            " 39/689 [>.............................] - ETA: 1:00 - loss: 0.6453 - tp: 381.0000 - fp: 178.0000 - tn: 415.0000 - fn: 274.0000 - accuracy: 0.6378 - precision: 0.6816 - recall: 0.5817 - auc: 0.6728\n",
            " For Batch Number 40 the model has a loss of {'loss': 0.6463552117347717, 'tp': 396.0, 'fp': 195.0, 'tn': 415.0, 'fn': 274.0, 'accuracy': 0.633593738079071, 'precision': 0.6700507402420044, 'recall': 0.5910447835922241, 'auc': 0.6715463399887085} \n",
            " 40/689 [>.............................] - ETA: 1:00 - loss: 0.6464 - tp: 396.0000 - fp: 195.0000 - tn: 415.0000 - fn: 274.0000 - accuracy: 0.6336 - precision: 0.6701 - recall: 0.5910 - auc: 0.6715\n",
            " For Batch Number 41 the model has a loss of {'loss': 0.6443513035774231, 'tp': 416.0, 'fp': 207.0, 'tn': 415.0, 'fn': 274.0, 'accuracy': 0.6333841681480408, 'precision': 0.6677367687225342, 'recall': 0.6028985381126404, 'auc': 0.6743639707565308} \n",
            " 41/689 [>.............................] - ETA: 1:00 - loss: 0.6444 - tp: 416.0000 - fp: 207.0000 - tn: 415.0000 - fn: 274.0000 - accuracy: 0.6334 - precision: 0.6677 - recall: 0.6029 - auc: 0.6744\n",
            " For Batch Number 42 the model has a loss of {'loss': 0.6468871235847473, 'tp': 429.0, 'fp': 226.0, 'tn': 415.0, 'fn': 274.0, 'accuracy': 0.6279761791229248, 'precision': 0.6549618244171143, 'recall': 0.6102418303489685, 'auc': 0.6712395548820496} \n",
            " 42/689 [>.............................] - ETA: 59s - loss: 0.6469 - tp: 429.0000 - fp: 226.0000 - tn: 415.0000 - fn: 274.0000 - accuracy: 0.6280 - precision: 0.6550 - recall: 0.6102 - auc: 0.6712 \n",
            " For Batch Number 43 the model has a loss of {'loss': 0.645704448223114, 'tp': 442.0, 'fp': 229.0, 'tn': 425.0, 'fn': 280.0, 'accuracy': 0.6300871968269348, 'precision': 0.6587183475494385, 'recall': 0.6121883392333984, 'auc': 0.6730464696884155} \n",
            " 43/689 [>.............................] - ETA: 59s - loss: 0.6457 - tp: 442.0000 - fp: 229.0000 - tn: 425.0000 - fn: 280.0000 - accuracy: 0.6301 - precision: 0.6587 - recall: 0.6122 - auc: 0.6730\n",
            " For Batch Number 44 the model has a loss of {'loss': 0.645661473274231, 'tp': 453.0, 'fp': 232.0, 'tn': 434.0, 'fn': 289.0, 'accuracy': 0.6299715638160706, 'precision': 0.6613138914108276, 'recall': 0.6105121374130249, 'auc': 0.672672688961029} \n",
            " 44/689 [>.............................] - ETA: 58s - loss: 0.6457 - tp: 453.0000 - fp: 232.0000 - tn: 434.0000 - fn: 289.0000 - accuracy: 0.6300 - precision: 0.6613 - recall: 0.6105 - auc: 0.6727\n",
            " For Batch Number 45 the model has a loss of {'loss': 0.6456500887870789, 'tp': 461.0, 'fp': 239.0, 'tn': 445.0, 'fn': 295.0, 'accuracy': 0.6291666626930237, 'precision': 0.6585714221000671, 'recall': 0.6097883582115173, 'auc': 0.6724778413772583} \n",
            " 45/689 [>.............................] - ETA: 57s - loss: 0.6457 - tp: 461.0000 - fp: 239.0000 - tn: 445.0000 - fn: 295.0000 - accuracy: 0.6292 - precision: 0.6586 - recall: 0.6098 - auc: 0.6725\n",
            " For Batch Number 46 the model has a loss of {'loss': 0.6459182500839233, 'tp': 470.0, 'fp': 245.0, 'tn': 455.0, 'fn': 302.0, 'accuracy': 0.62839674949646, 'precision': 0.6573426723480225, 'recall': 0.6088082790374756, 'auc': 0.6719133853912354} \n",
            "\n",
            " For Batch Number 47 the model has a loss of {'loss': 0.6440595388412476, 'tp': 477.0, 'fp': 247.0, 'tn': 471.0, 'fn': 309.0, 'accuracy': 0.6303191781044006, 'precision': 0.658839762210846, 'recall': 0.6068702340126038, 'auc': 0.6749532222747803} \n",
            " 47/689 [=>............................] - ETA: 56s - loss: 0.6441 - tp: 477.0000 - fp: 247.0000 - tn: 471.0000 - fn: 309.0000 - accuracy: 0.6303 - precision: 0.6588 - recall: 0.6069 - auc: 0.6750\n",
            " For Batch Number 48 the model has a loss of {'loss': 0.6442431807518005, 'tp': 482.0, 'fp': 251.0, 'tn': 485.0, 'fn': 318.0, 'accuracy': 0.6295573115348816, 'precision': 0.6575716137886047, 'recall': 0.6025000214576721, 'auc': 0.6747385263442993} \n",
            "\n",
            " For Batch Number 49 the model has a loss of {'loss': 0.6456965208053589, 'tp': 490.0, 'fp': 251.0, 'tn': 496.0, 'fn': 331.0, 'accuracy': 0.6288265585899353, 'precision': 0.6612685322761536, 'recall': 0.5968331098556519, 'auc': 0.6722211837768555} \n",
            " 49/689 [=>............................] - ETA: 54s - loss: 0.6457 - tp: 490.0000 - fp: 251.0000 - tn: 496.0000 - fn: 331.0000 - accuracy: 0.6288 - precision: 0.6613 - recall: 0.5968 - auc: 0.6722\n",
            " For Batch Number 50 the model has a loss of {'loss': 0.645382285118103, 'tp': 499.0, 'fp': 254.0, 'tn': 510.0, 'fn': 337.0, 'accuracy': 0.6306250095367432, 'precision': 0.6626825928688049, 'recall': 0.5968899726867676, 'auc': 0.6724616885185242} \n",
            "\n",
            " For Batch Number 51 the model has a loss of {'loss': 0.6444364786148071, 'tp': 511.0, 'fp': 260.0, 'tn': 519.0, 'fn': 342.0, 'accuracy': 0.6311274766921997, 'precision': 0.6627756357192993, 'recall': 0.5990621447563171, 'auc': 0.6736114025115967} \n",
            " 51/689 [=>............................] - ETA: 53s - loss: 0.6444 - tp: 511.0000 - fp: 260.0000 - tn: 519.0000 - fn: 342.0000 - accuracy: 0.6311 - precision: 0.6628 - recall: 0.5991 - auc: 0.6736\n",
            " For Batch Number 52 the model has a loss of {'loss': 0.6456018686294556, 'tp': 522.0, 'fp': 268.0, 'tn': 524.0, 'fn': 350.0, 'accuracy': 0.6286057829856873, 'precision': 0.6607595086097717, 'recall': 0.5986238718032837, 'auc': 0.6722463369369507} \n",
            " 52/689 [=>............................] - ETA: 53s - loss: 0.6456 - tp: 522.0000 - fp: 268.0000 - tn: 524.0000 - fn: 350.0000 - accuracy: 0.6286 - precision: 0.6608 - recall: 0.5986 - auc: 0.6722\n",
            " For Batch Number 53 the model has a loss of {'loss': 0.6487465500831604, 'tp': 531.0, 'fp': 282.0, 'tn': 528.0, 'fn': 355.0, 'accuracy': 0.6244103908538818, 'precision': 0.6531365513801575, 'recall': 0.5993227958679199, 'auc': 0.6687115430831909} \n",
            "\n",
            " For Batch Number 54 the model has a loss of {'loss': 0.6504029035568237, 'tp': 542.0, 'fp': 292.0, 'tn': 534.0, 'fn': 360.0, 'accuracy': 0.6226851940155029, 'precision': 0.6498801112174988, 'recall': 0.6008869409561157, 'auc': 0.6672292947769165} \n",
            " 54/689 [=>............................] - ETA: 51s - loss: 0.6504 - tp: 542.0000 - fp: 292.0000 - tn: 534.0000 - fn: 360.0000 - accuracy: 0.6227 - precision: 0.6499 - recall: 0.6009 - auc: 0.6672\n",
            " For Batch Number 55 the model has a loss of {'loss': 0.65110182762146, 'tp': 553.0, 'fp': 298.0, 'tn': 545.0, 'fn': 364.0, 'accuracy': 0.6238636374473572, 'precision': 0.6498237252235413, 'recall': 0.6030534505844116, 'auc': 0.6682073473930359} \n",
            "\n",
            " For Batch Number 56 the model has a loss of {'loss': 0.6504203081130981, 'tp': 562.0, 'fp': 303.0, 'tn': 556.0, 'fn': 371.0, 'accuracy': 0.6238839030265808, 'precision': 0.6497109532356262, 'recall': 0.6023579835891724, 'auc': 0.6686543226242065} \n",
            " 56/689 [=>............................] - ETA: 50s - loss: 0.6504 - tp: 562.0000 - fp: 303.0000 - tn: 556.0000 - fn: 371.0000 - accuracy: 0.6239 - precision: 0.6497 - recall: 0.6024 - auc: 0.6687\n",
            " For Batch Number 57 the model has a loss of {'loss': 0.6501806974411011, 'tp': 571.0, 'fp': 305.0, 'tn': 569.0, 'fn': 379.0, 'accuracy': 0.625, 'precision': 0.6518265008926392, 'recall': 0.6010526418685913, 'auc': 0.6683271527290344} \n",
            "\n",
            " For Batch Number 58 the model has a loss of {'loss': 0.6492578387260437, 'tp': 577.0, 'fp': 307.0, 'tn': 586.0, 'fn': 386.0, 'accuracy': 0.626616358757019, 'precision': 0.6527149081230164, 'recall': 0.5991692543029785, 'auc': 0.6695587038993835} \n",
            " 58/689 [=>............................] - ETA: 49s - loss: 0.6493 - tp: 577.0000 - fp: 307.0000 - tn: 586.0000 - fn: 386.0000 - accuracy: 0.6266 - precision: 0.6527 - recall: 0.5992 - auc: 0.6696\n",
            " For Batch Number 59 the model has a loss of {'loss': 0.6469099521636963, 'tp': 585.0, 'fp': 308.0, 'tn': 604.0, 'fn': 391.0, 'accuracy': 0.6297669410705566, 'precision': 0.6550951600074768, 'recall': 0.5993852615356445, 'auc': 0.6733556389808655} \n",
            "\n",
            " For Batch Number 60 the model has a loss of {'loss': 0.6473647356033325, 'tp': 590.0, 'fp': 311.0, 'tn': 617.0, 'fn': 402.0, 'accuracy': 0.6286458373069763, 'precision': 0.6548279523849487, 'recall': 0.5947580933570862, 'auc': 0.6726000905036926} \n",
            " 60/689 [=>............................] - ETA: 48s - loss: 0.6474 - tp: 590.0000 - fp: 311.0000 - tn: 617.0000 - fn: 402.0000 - accuracy: 0.6286 - precision: 0.6548 - recall: 0.5948 - auc: 0.6726\n",
            " For Batch Number 61 the model has a loss of {'loss': 0.6489015221595764, 'tp': 598.0, 'fp': 313.0, 'tn': 626.0, 'fn': 415.0, 'accuracy': 0.6270492076873779, 'precision': 0.6564215421676636, 'recall': 0.5903257727622986, 'auc': 0.6697637438774109} \n",
            " 61/689 [=>............................] - ETA: 48s - loss: 0.6489 - tp: 598.0000 - fp: 313.0000 - tn: 626.0000 - fn: 415.0000 - accuracy: 0.6270 - precision: 0.6564 - recall: 0.5903 - auc: 0.6698\n",
            " For Batch Number 62 the model has a loss of {'loss': 0.6471337080001831, 'tp': 608.0, 'fp': 318.0, 'tn': 639.0, 'fn': 419.0, 'accuracy': 0.6285282373428345, 'precision': 0.6565874814987183, 'recall': 0.5920155644416809, 'auc': 0.6717413067817688} \n",
            "\n",
            " For Batch Number 63 the model has a loss of {'loss': 0.6469041705131531, 'tp': 620.0, 'fp': 325.0, 'tn': 651.0, 'fn': 420.0, 'accuracy': 0.6304563283920288, 'precision': 0.6560846567153931, 'recall': 0.5961538553237915, 'auc': 0.6723085045814514} \n",
            " 63/689 [=>............................] - ETA: 47s - loss: 0.6469 - tp: 620.0000 - fp: 325.0000 - tn: 651.0000 - fn: 420.0000 - accuracy: 0.6305 - precision: 0.6561 - recall: 0.5962 - auc: 0.6723\n",
            " For Batch Number 64 the model has a loss of {'loss': 0.6457061767578125, 'tp': 631.0, 'fp': 329.0, 'tn': 661.0, 'fn': 427.0, 'accuracy': 0.630859375, 'precision': 0.6572916507720947, 'recall': 0.5964083075523376, 'auc': 0.6733469367027283} \n",
            " 64/689 [=>............................] - ETA: 47s - loss: 0.6457 - tp: 631.0000 - fp: 329.0000 - tn: 661.0000 - fn: 427.0000 - accuracy: 0.6309 - precision: 0.6573 - recall: 0.5964 - auc: 0.6733\n",
            " For Batch Number 65 the model has a loss of {'loss': 0.6438118815422058, 'tp': 644.0, 'fp': 331.0, 'tn': 672.0, 'fn': 433.0, 'accuracy': 0.6326923370361328, 'precision': 0.6605128049850464, 'recall': 0.5979573130607605, 'auc': 0.6753444671630859} \n",
            "\n",
            " For Batch Number 66 the model has a loss of {'loss': 0.642824649810791, 'tp': 653.0, 'fp': 334.0, 'tn': 684.0, 'fn': 441.0, 'accuracy': 0.6330492496490479, 'precision': 0.6616008281707764, 'recall': 0.5968921184539795, 'auc': 0.6758133769035339} \n",
            " 66/689 [=>............................] - ETA: 46s - loss: 0.6428 - tp: 653.0000 - fp: 334.0000 - tn: 684.0000 - fn: 441.0000 - accuracy: 0.6330 - precision: 0.6616 - recall: 0.5969 - auc: 0.6758\n",
            " For Batch Number 67 the model has a loss of {'loss': 0.6431851983070374, 'tp': 664.0, 'fp': 336.0, 'tn': 691.0, 'fn': 453.0, 'accuracy': 0.6319962739944458, 'precision': 0.6639999747276306, 'recall': 0.5944494009017944, 'auc': 0.6742038130760193} \n",
            "\n",
            " For Batch Number 68 the model has a loss of {'loss': 0.6422873735427856, 'tp': 674.0, 'fp': 343.0, 'tn': 701.0, 'fn': 458.0, 'accuracy': 0.6318933963775635, 'precision': 0.6627335548400879, 'recall': 0.5954063534736633, 'auc': 0.674604058265686} \n",
            " 68/689 [=>............................] - ETA: 45s - loss: 0.6423 - tp: 674.0000 - fp: 343.0000 - tn: 701.0000 - fn: 458.0000 - accuracy: 0.6319 - precision: 0.6627 - recall: 0.5954 - auc: 0.6746\n",
            " For Batch Number 69 the model has a loss of {'loss': 0.6421695947647095, 'tp': 684.0, 'fp': 347.0, 'tn': 712.0, 'fn': 465.0, 'accuracy': 0.6322463750839233, 'precision': 0.6634335517883301, 'recall': 0.5953002572059631, 'auc': 0.6751360893249512} \n",
            "\n",
            " For Batch Number 70 the model has a loss of {'loss': 0.6430236101150513, 'tp': 694.0, 'fp': 353.0, 'tn': 722.0, 'fn': 471.0, 'accuracy': 0.6321428418159485, 'precision': 0.6628462076187134, 'recall': 0.5957081317901611, 'auc': 0.6749639511108398} \n",
            " 70/689 [==>...........................] - ETA: 45s - loss: 0.6430 - tp: 694.0000 - fp: 353.0000 - tn: 722.0000 - fn: 471.0000 - accuracy: 0.6321 - precision: 0.6628 - recall: 0.5957 - auc: 0.6750\n",
            " For Batch Number 71 the model has a loss of {'loss': 0.6416548490524292, 'tp': 708.0, 'fp': 355.0, 'tn': 731.0, 'fn': 478.0, 'accuracy': 0.6333626508712769, 'precision': 0.6660395264625549, 'recall': 0.5969645977020264, 'auc': 0.6765176653862} \n",
            "\n",
            " For Batch Number 72 the model has a loss of {'loss': 0.6437397003173828, 'tp': 716.0, 'fp': 365.0, 'tn': 739.0, 'fn': 484.0, 'accuracy': 0.6315104365348816, 'precision': 0.6623497009277344, 'recall': 0.596666693687439, 'auc': 0.67514568567276} \n",
            " 72/689 [==>...........................] - ETA: 44s - loss: 0.6437 - tp: 716.0000 - fp: 365.0000 - tn: 739.0000 - fn: 484.0000 - accuracy: 0.6315 - precision: 0.6623 - recall: 0.5967 - auc: 0.6751\n",
            " For Batch Number 73 the model has a loss of {'loss': 0.6428328156471252, 'tp': 728.0, 'fp': 369.0, 'tn': 750.0, 'fn': 489.0, 'accuracy': 0.6327054500579834, 'precision': 0.663628101348877, 'recall': 0.5981922745704651, 'auc': 0.6765090227127075} \n",
            "\n",
            " For Batch Number 74 the model has a loss of {'loss': 0.642724335193634, 'tp': 736.0, 'fp': 376.0, 'tn': 762.0, 'fn': 494.0, 'accuracy': 0.6326013803482056, 'precision': 0.6618704795837402, 'recall': 0.5983740091323853, 'auc': 0.6770614385604858} \n",
            " 74/689 [==>...........................] - ETA: 43s - loss: 0.6427 - tp: 736.0000 - fp: 376.0000 - tn: 762.0000 - fn: 494.0000 - accuracy: 0.6326 - precision: 0.6619 - recall: 0.5984 - auc: 0.6771\n",
            " For Batch Number 75 the model has a loss of {'loss': 0.644778847694397, 'tp': 742.0, 'fp': 381.0, 'tn': 772.0, 'fn': 505.0, 'accuracy': 0.6308333277702332, 'precision': 0.6607301831245422, 'recall': 0.5950280427932739, 'auc': 0.6744296550750732} \n",
            "\n",
            " For Batch Number 76 the model has a loss of {'loss': 0.6447198390960693, 'tp': 749.0, 'fp': 384.0, 'tn': 783.0, 'fn': 516.0, 'accuracy': 0.6299341917037964, 'precision': 0.6610767841339111, 'recall': 0.5920948386192322, 'auc': 0.6748464703559875} \n",
            " 76/689 [==>...........................] - ETA: 43s - loss: 0.6447 - tp: 749.0000 - fp: 384.0000 - tn: 783.0000 - fn: 516.0000 - accuracy: 0.6299 - precision: 0.6611 - recall: 0.5921 - auc: 0.6748\n",
            " For Batch Number 77 the model has a loss of {'loss': 0.644680917263031, 'tp': 756.0, 'fp': 387.0, 'tn': 797.0, 'fn': 524.0, 'accuracy': 0.6302759647369385, 'precision': 0.6614173054695129, 'recall': 0.590624988079071, 'auc': 0.6745839715003967} \n",
            " 77/689 [==>...........................] - ETA: 42s - loss: 0.6447 - tp: 756.0000 - fp: 387.0000 - tn: 797.0000 - fn: 524.0000 - accuracy: 0.6303 - precision: 0.6614 - recall: 0.5906 - auc: 0.6746\n",
            " For Batch Number 78 the model has a loss of {'loss': 0.6443374156951904, 'tp': 766.0, 'fp': 390.0, 'tn': 812.0, 'fn': 528.0, 'accuracy': 0.6322115659713745, 'precision': 0.6626297831535339, 'recall': 0.5919629335403442, 'auc': 0.6755655407905579} \n",
            " 78/689 [==>...........................] - ETA: 42s - loss: 0.6443 - tp: 766.0000 - fp: 390.0000 - tn: 812.0000 - fn: 528.0000 - accuracy: 0.6322 - precision: 0.6626 - recall: 0.5920 - auc: 0.6756\n",
            " For Batch Number 79 the model has a loss of {'loss': 0.6435443758964539, 'tp': 776.0, 'fp': 394.0, 'tn': 824.0, 'fn': 534.0, 'accuracy': 0.6329113841056824, 'precision': 0.6632478833198547, 'recall': 0.5923663973808289, 'auc': 0.6767573952674866} \n",
            " 79/689 [==>...........................] - ETA: 42s - loss: 0.6435 - tp: 776.0000 - fp: 394.0000 - tn: 824.0000 - fn: 534.0000 - accuracy: 0.6329 - precision: 0.6632 - recall: 0.5924 - auc: 0.6768\n",
            " For Batch Number 80 the model has a loss of {'loss': 0.644071102142334, 'tp': 784.0, 'fp': 398.0, 'tn': 833.0, 'fn': 545.0, 'accuracy': 0.631640613079071, 'precision': 0.663282573223114, 'recall': 0.5899172425270081, 'auc': 0.6754658222198486} \n",
            " 80/689 [==>...........................] - ETA: 42s - loss: 0.6441 - tp: 784.0000 - fp: 398.0000 - tn: 833.0000 - fn: 545.0000 - accuracy: 0.6316 - precision: 0.6633 - recall: 0.5899 - auc: 0.6755\n",
            " For Batch Number 81 the model has a loss of {'loss': 0.643581748008728, 'tp': 796.0, 'fp': 404.0, 'tn': 840.0, 'fn': 552.0, 'accuracy': 0.6311728358268738, 'precision': 0.6633333563804626, 'recall': 0.5905044674873352, 'auc': 0.6759254932403564} \n",
            "\n",
            " For Batch Number 82 the model has a loss of {'loss': 0.6431206464767456, 'tp': 811.0, 'fp': 410.0, 'tn': 848.0, 'fn': 555.0, 'accuracy': 0.6322408318519592, 'precision': 0.6642096638679504, 'recall': 0.5937042236328125, 'auc': 0.6765744686126709} \n",
            " 82/689 [==>...........................] - ETA: 41s - loss: 0.6431 - tp: 811.0000 - fp: 410.0000 - tn: 848.0000 - fn: 555.0000 - accuracy: 0.6322 - precision: 0.6642 - recall: 0.5937 - auc: 0.6766\n",
            " For Batch Number 83 the model has a loss of {'loss': 0.6441336274147034, 'tp': 821.0, 'fp': 427.0, 'tn': 852.0, 'fn': 556.0, 'accuracy': 0.6298945546150208, 'precision': 0.6578525900840759, 'recall': 0.5962236523628235, 'auc': 0.674899160861969} \n",
            "\n",
            " For Batch Number 84 the model has a loss of {'loss': 0.6447609066963196, 'tp': 831.0, 'fp': 436.0, 'tn': 859.0, 'fn': 562.0, 'accuracy': 0.628720223903656, 'precision': 0.6558800339698792, 'recall': 0.5965542197227478, 'auc': 0.674000084400177} \n",
            " 84/689 [==>...........................] - ETA: 41s - loss: 0.6448 - tp: 831.0000 - fp: 436.0000 - tn: 859.0000 - fn: 562.0000 - accuracy: 0.6287 - precision: 0.6559 - recall: 0.5966 - auc: 0.6740\n",
            " For Batch Number 85 the model has a loss of {'loss': 0.6455311179161072, 'tp': 838.0, 'fp': 441.0, 'tn': 867.0, 'fn': 574.0, 'accuracy': 0.626838207244873, 'precision': 0.6551993489265442, 'recall': 0.5934844017028809, 'auc': 0.6726420521736145} \n",
            "\n",
            " For Batch Number 86 the model has a loss of {'loss': 0.6450863480567932, 'tp': 844.0, 'fp': 443.0, 'tn': 885.0, 'fn': 580.0, 'accuracy': 0.6282703280448914, 'precision': 0.6557886600494385, 'recall': 0.5926966071128845, 'auc': 0.672930121421814} \n",
            " 86/689 [==>...........................] - ETA: 41s - loss: 0.6451 - tp: 844.0000 - fp: 443.0000 - tn: 885.0000 - fn: 580.0000 - accuracy: 0.6283 - precision: 0.6558 - recall: 0.5927 - auc: 0.6729\n",
            " For Batch Number 87 the model has a loss of {'loss': 0.6460314989089966, 'tp': 855.0, 'fp': 445.0, 'tn': 891.0, 'fn': 593.0, 'accuracy': 0.6271551847457886, 'precision': 0.6576923131942749, 'recall': 0.5904695987701416, 'auc': 0.6713443398475647} \n",
            "\n",
            " For Batch Number 88 the model has a loss of {'loss': 0.6466096043586731, 'tp': 861.0, 'fp': 448.0, 'tn': 906.0, 'fn': 601.0, 'accuracy': 0.6274858117103577, 'precision': 0.6577540040016174, 'recall': 0.5889192819595337, 'auc': 0.67125403881073} \n",
            " 88/689 [==>...........................] - ETA: 40s - loss: 0.6466 - tp: 861.0000 - fp: 448.0000 - tn: 906.0000 - fn: 601.0000 - accuracy: 0.6275 - precision: 0.6578 - recall: 0.5889 - auc: 0.6713\n",
            " For Batch Number 89 the model has a loss of {'loss': 0.6475595831871033, 'tp': 865.0, 'fp': 456.0, 'tn': 919.0, 'fn': 608.0, 'accuracy': 0.6264045238494873, 'precision': 0.6548069715499878, 'recall': 0.5872369408607483, 'auc': 0.6696764230728149} \n",
            "\n",
            " For Batch Number 90 the model has a loss of {'loss': 0.6476627588272095, 'tp': 870.0, 'fp': 460.0, 'tn': 934.0, 'fn': 616.0, 'accuracy': 0.6263889074325562, 'precision': 0.6541353464126587, 'recall': 0.585464358329773, 'auc': 0.6692088842391968} \n",
            " 90/689 [==>...........................] - ETA: 40s - loss: 0.6477 - tp: 870.0000 - fp: 460.0000 - tn: 934.0000 - fn: 616.0000 - accuracy: 0.6264 - precision: 0.6541 - recall: 0.5855 - auc: 0.6692\n",
            " For Batch Number 91 the model has a loss of {'loss': 0.6475288271903992, 'tp': 875.0, 'fp': 463.0, 'tn': 949.0, 'fn': 625.0, 'accuracy': 0.6263736486434937, 'precision': 0.6539611220359802, 'recall': 0.5833333134651184, 'auc': 0.6695809960365295} \n",
            "\n",
            " For Batch Number 92 the model has a loss of {'loss': 0.6472495794296265, 'tp': 880.0, 'fp': 464.0, 'tn': 967.0, 'fn': 633.0, 'accuracy': 0.6273776888847351, 'precision': 0.6547619104385376, 'recall': 0.5816259384155273, 'auc': 0.6697766780853271} \n",
            " 92/689 [===>..........................] - ETA: 39s - loss: 0.6472 - tp: 880.0000 - fp: 464.0000 - tn: 967.0000 - fn: 633.0000 - accuracy: 0.6274 - precision: 0.6548 - recall: 0.5816 - auc: 0.6698\n",
            " For Batch Number 93 the model has a loss of {'loss': 0.6480978727340698, 'tp': 883.0, 'fp': 465.0, 'tn': 981.0, 'fn': 647.0, 'accuracy': 0.6263440847396851, 'precision': 0.6550444960594177, 'recall': 0.5771241784095764, 'auc': 0.6679505705833435} \n",
            " 93/689 [===>..........................] - ETA: 39s - loss: 0.6481 - tp: 883.0000 - fp: 465.0000 - tn: 981.0000 - fn: 647.0000 - accuracy: 0.6263 - precision: 0.6550 - recall: 0.5771 - auc: 0.6680\n",
            " For Batch Number 94 the model has a loss of {'loss': 0.6487665772438049, 'tp': 888.0, 'fp': 466.0, 'tn': 995.0, 'fn': 659.0, 'accuracy': 0.6259973645210266, 'precision': 0.6558345556259155, 'recall': 0.5740142464637756, 'auc': 0.6666021347045898} \n",
            " 94/689 [===>..........................] - ETA: 39s - loss: 0.6488 - tp: 888.0000 - fp: 466.0000 - tn: 995.0000 - fn: 659.0000 - accuracy: 0.6260 - precision: 0.6558 - recall: 0.5740 - auc: 0.6666\n",
            " For Batch Number 95 the model has a loss of {'loss': 0.6494703888893127, 'tp': 893.0, 'fp': 471.0, 'tn': 1006.0, 'fn': 670.0, 'accuracy': 0.6246710419654846, 'precision': 0.6546920537948608, 'recall': 0.5713371634483337, 'auc': 0.6651510000228882} \n",
            "\n",
            " For Batch Number 96 the model has a loss of {'loss': 0.6494966745376587, 'tp': 901.0, 'fp': 473.0, 'tn': 1018.0, 'fn': 680.0, 'accuracy': 0.6246744990348816, 'precision': 0.6557496190071106, 'recall': 0.5698924660682678, 'auc': 0.6649842262268066} \n",
            " 96/689 [===>..........................] - ETA: 38s - loss: 0.6495 - tp: 901.0000 - fp: 473.0000 - tn: 1018.0000 - fn: 680.0000 - accuracy: 0.6247 - precision: 0.6557 - recall: 0.5699 - auc: 0.6650\n",
            " For Batch Number 97 the model has a loss of {'loss': 0.6494195461273193, 'tp': 908.0, 'fp': 480.0, 'tn': 1033.0, 'fn': 683.0, 'accuracy': 0.625322163105011, 'precision': 0.6541786789894104, 'recall': 0.5707102417945862, 'auc': 0.6646094918251038} \n",
            " 97/689 [===>..........................] - ETA: 38s - loss: 0.6494 - tp: 908.0000 - fp: 480.0000 - tn: 1033.0000 - fn: 683.0000 - accuracy: 0.6253 - precision: 0.6542 - recall: 0.5707 - auc: 0.6646\n",
            " For Batch Number 98 the model has a loss of {'loss': 0.6496042013168335, 'tp': 915.0, 'fp': 483.0, 'tn': 1048.0, 'fn': 690.0, 'accuracy': 0.625956654548645, 'precision': 0.6545064449310303, 'recall': 0.5700934529304504, 'auc': 0.6640574932098389} \n",
            "\n",
            " For Batch Number 99 the model has a loss of {'loss': 0.6493314504623413, 'tp': 924.0, 'fp': 488.0, 'tn': 1062.0, 'fn': 694.0, 'accuracy': 0.626893937587738, 'precision': 0.6543909311294556, 'recall': 0.5710753798484802, 'auc': 0.6642701625823975} \n",
            " 99/689 [===>..........................] - ETA: 38s - loss: 0.6493 - tp: 924.0000 - fp: 488.0000 - tn: 1062.0000 - fn: 694.0000 - accuracy: 0.6269 - precision: 0.6544 - recall: 0.5711 - auc: 0.6643\n",
            " For Batch Number 100 the model has a loss of {'loss': 0.6494969129562378, 'tp': 932.0, 'fp': 491.0, 'tn': 1073.0, 'fn': 704.0, 'accuracy': 0.6265624761581421, 'precision': 0.6549543142318726, 'recall': 0.5696821808815002, 'auc': 0.6639383435249329} \n",
            "\n",
            " For Batch Number 101 the model has a loss of {'loss': 0.6504195332527161, 'tp': 937.0, 'fp': 495.0, 'tn': 1085.0, 'fn': 715.0, 'accuracy': 0.6256188154220581, 'precision': 0.6543295979499817, 'recall': 0.5671913027763367, 'auc': 0.6624944806098938} \n",
            "101/689 [===>..........................] - ETA: 38s - loss: 0.6504 - tp: 937.0000 - fp: 495.0000 - tn: 1085.0000 - fn: 715.0000 - accuracy: 0.6256 - precision: 0.6543 - recall: 0.5672 - auc: 0.6625\n",
            " For Batch Number 102 the model has a loss of {'loss': 0.6504934430122375, 'tp': 944.0, 'fp': 498.0, 'tn': 1098.0, 'fn': 724.0, 'accuracy': 0.625612735748291, 'precision': 0.6546463370323181, 'recall': 0.5659472346305847, 'auc': 0.662156879901886} \n",
            "102/689 [===>..........................] - ETA: 37s - loss: 0.6505 - tp: 944.0000 - fp: 498.0000 - tn: 1098.0000 - fn: 724.0000 - accuracy: 0.6256 - precision: 0.6546 - recall: 0.5659 - auc: 0.6622\n",
            " For Batch Number 103 the model has a loss of {'loss': 0.6498323678970337, 'tp': 949.0, 'fp': 502.0, 'tn': 1115.0, 'fn': 730.0, 'accuracy': 0.6262136101722717, 'precision': 0.6540316939353943, 'recall': 0.5652173757553101, 'auc': 0.6628045439720154} \n",
            "\n",
            " For Batch Number 104 the model has a loss of {'loss': 0.6493673324584961, 'tp': 955.0, 'fp': 504.0, 'tn': 1133.0, 'fn': 736.0, 'accuracy': 0.6274038553237915, 'precision': 0.6545579433441162, 'recall': 0.5647546052932739, 'auc': 0.6634907126426697} \n",
            "104/689 [===>..........................] - ETA: 37s - loss: 0.6494 - tp: 955.0000 - fp: 504.0000 - tn: 1133.0000 - fn: 736.0000 - accuracy: 0.6274 - precision: 0.6546 - recall: 0.5648 - auc: 0.6635\n",
            " For Batch Number 105 the model has a loss of {'loss': 0.6499014496803284, 'tp': 960.0, 'fp': 505.0, 'tn': 1146.0, 'fn': 749.0, 'accuracy': 0.6267856955528259, 'precision': 0.6552901268005371, 'recall': 0.5617319941520691, 'auc': 0.6621738076210022} \n",
            "\n",
            " For Batch Number 106 the model has a loss of {'loss': 0.6500635743141174, 'tp': 965.0, 'fp': 506.0, 'tn': 1159.0, 'fn': 762.0, 'accuracy': 0.6261792182922363, 'precision': 0.6560162901878357, 'recall': 0.5587724447250366, 'auc': 0.6616646647453308} \n",
            "106/689 [===>..........................] - ETA: 37s - loss: 0.6501 - tp: 965.0000 - fp: 506.0000 - tn: 1159.0000 - fn: 762.0000 - accuracy: 0.6262 - precision: 0.6560 - recall: 0.5588 - auc: 0.6617\n",
            " For Batch Number 107 the model has a loss of {'loss': 0.6508823037147522, 'tp': 968.0, 'fp': 510.0, 'tn': 1172.0, 'fn': 774.0, 'accuracy': 0.625, 'precision': 0.6549391150474548, 'recall': 0.5556831359863281, 'auc': 0.660137951374054} \n",
            "\n",
            " For Batch Number 108 the model has a loss of {'loss': 0.6514132022857666, 'tp': 972.0, 'fp': 514.0, 'tn': 1183.0, 'fn': 787.0, 'accuracy': 0.6235532164573669, 'precision': 0.654105007648468, 'recall': 0.5525866746902466, 'auc': 0.6590818762779236} \n",
            "108/689 [===>..........................] - ETA: 36s - loss: 0.6514 - tp: 972.0000 - fp: 514.0000 - tn: 1183.0000 - fn: 787.0000 - accuracy: 0.6236 - precision: 0.6541 - recall: 0.5526 - auc: 0.6591\n",
            " For Batch Number 109 the model has a loss of {'loss': 0.6509345769882202, 'tp': 980.0, 'fp': 517.0, 'tn': 1198.0, 'fn': 793.0, 'accuracy': 0.6244266033172607, 'precision': 0.654642641544342, 'recall': 0.552735447883606, 'auc': 0.65948885679245} \n",
            "109/689 [===>..........................] - ETA: 36s - loss: 0.6509 - tp: 980.0000 - fp: 517.0000 - tn: 1198.0000 - fn: 793.0000 - accuracy: 0.6244 - precision: 0.6546 - recall: 0.5527 - auc: 0.6595\n",
            " For Batch Number 110 the model has a loss of {'loss': 0.6508926153182983, 'tp': 990.0, 'fp': 520.0, 'tn': 1211.0, 'fn': 799.0, 'accuracy': 0.6252840757369995, 'precision': 0.6556291580200195, 'recall': 0.5533818006515503, 'auc': 0.6596046090126038} \n",
            "\n",
            " For Batch Number 111 the model has a loss of {'loss': 0.6508053541183472, 'tp': 996.0, 'fp': 525.0, 'tn': 1225.0, 'fn': 806.0, 'accuracy': 0.6252815127372742, 'precision': 0.6548323631286621, 'recall': 0.5527191758155823, 'auc': 0.6594151258468628} \n",
            "111/689 [===>..........................] - ETA: 36s - loss: 0.6508 - tp: 996.0000 - fp: 525.0000 - tn: 1225.0000 - fn: 806.0000 - accuracy: 0.6253 - precision: 0.6548 - recall: 0.5527 - auc: 0.6594\n",
            " For Batch Number 112 the model has a loss of {'loss': 0.651123046875, 'tp': 1002.0, 'fp': 533.0, 'tn': 1236.0, 'fn': 813.0, 'accuracy': 0.6244419813156128, 'precision': 0.6527687311172485, 'recall': 0.5520660877227783, 'auc': 0.658717691898346} \n",
            "\n",
            " For Batch Number 113 the model has a loss of {'loss': 0.6506295204162598, 'tp': 1012.0, 'fp': 533.0, 'tn': 1249.0, 'fn': 822.0, 'accuracy': 0.6252765655517578, 'precision': 0.6550161838531494, 'recall': 0.5517993569374084, 'auc': 0.6592535376548767} \n",
            "113/689 [===>..........................] - ETA: 36s - loss: 0.6506 - tp: 1012.0000 - fp: 533.0000 - tn: 1249.0000 - fn: 822.0000 - accuracy: 0.6253 - precision: 0.6550 - recall: 0.5518 - auc: 0.6593\n",
            " For Batch Number 114 the model has a loss of {'loss': 0.6505811214447021, 'tp': 1019.0, 'fp': 536.0, 'tn': 1263.0, 'fn': 830.0, 'accuracy': 0.625548243522644, 'precision': 0.6553054451942444, 'recall': 0.551108717918396, 'auc': 0.6593132019042969} \n",
            "\n",
            " For Batch Number 115 the model has a loss of {'loss': 0.6506413221359253, 'tp': 1027.0, 'fp': 537.0, 'tn': 1274.0, 'fn': 842.0, 'accuracy': 0.625271737575531, 'precision': 0.6566495895385742, 'recall': 0.5494917035102844, 'auc': 0.6589334607124329} \n",
            "115/689 [====>.........................] - ETA: 35s - loss: 0.6506 - tp: 1027.0000 - fp: 537.0000 - tn: 1274.0000 - fn: 842.0000 - accuracy: 0.6253 - precision: 0.6566 - recall: 0.5495 - auc: 0.6589\n",
            " For Batch Number 116 the model has a loss of {'loss': 0.6503335237503052, 'tp': 1035.0, 'fp': 540.0, 'tn': 1285.0, 'fn': 852.0, 'accuracy': 0.625, 'precision': 0.6571428775787354, 'recall': 0.5484896898269653, 'auc': 0.6592105627059937} \n",
            "\n",
            " For Batch Number 117 the model has a loss of {'loss': 0.650769829750061, 'tp': 1042.0, 'fp': 547.0, 'tn': 1297.0, 'fn': 858.0, 'accuracy': 0.6247329115867615, 'precision': 0.6557583212852478, 'recall': 0.5484210252761841, 'auc': 0.6586055755615234} \n",
            "117/689 [====>.........................] - ETA: 35s - loss: 0.6508 - tp: 1042.0000 - fp: 547.0000 - tn: 1297.0000 - fn: 858.0000 - accuracy: 0.6247 - precision: 0.6558 - recall: 0.5484 - auc: 0.6586\n",
            " For Batch Number 118 the model has a loss of {'loss': 0.650580644607544, 'tp': 1054.0, 'fp': 552.0, 'tn': 1306.0, 'fn': 864.0, 'accuracy': 0.625, 'precision': 0.6562889218330383, 'recall': 0.5495307445526123, 'auc': 0.6589489579200745} \n",
            "\n",
            " For Batch Number 119 the model has a loss of {'loss': 0.6505507230758667, 'tp': 1065.0, 'fp': 557.0, 'tn': 1316.0, 'fn': 870.0, 'accuracy': 0.6252626180648804, 'precision': 0.6565967798233032, 'recall': 0.5503876209259033, 'auc': 0.6590320467948914} \n",
            "119/689 [====>.........................] - ETA: 35s - loss: 0.6506 - tp: 1065.0000 - fp: 557.0000 - tn: 1316.0000 - fn: 870.0000 - accuracy: 0.6253 - precision: 0.6566 - recall: 0.5504 - auc: 0.6590\n",
            " For Batch Number 120 the model has a loss of {'loss': 0.6513795852661133, 'tp': 1072.0, 'fp': 566.0, 'tn': 1329.0, 'fn': 873.0, 'accuracy': 0.6252604126930237, 'precision': 0.6544566750526428, 'recall': 0.5511568188667297, 'auc': 0.6583117842674255} \n",
            "\n",
            " For Batch Number 121 the model has a loss of {'loss': 0.6514682173728943, 'tp': 1078.0, 'fp': 572.0, 'tn': 1344.0, 'fn': 878.0, 'accuracy': 0.6255165338516235, 'precision': 0.653333306312561, 'recall': 0.5511247515678406, 'auc': 0.6582624912261963} \n",
            "121/689 [====>.........................] - ETA: 34s - loss: 0.6515 - tp: 1078.0000 - fp: 572.0000 - tn: 1344.0000 - fn: 878.0000 - accuracy: 0.6255 - precision: 0.6533 - recall: 0.5511 - auc: 0.6583\n",
            " For Batch Number 122 the model has a loss of {'loss': 0.6510249376296997, 'tp': 1087.0, 'fp': 572.0, 'tn': 1356.0, 'fn': 889.0, 'accuracy': 0.6257684230804443, 'precision': 0.6552140116691589, 'recall': 0.5501012206077576, 'auc': 0.6589542627334595} \n",
            "122/689 [====>.........................] - ETA: 34s - loss: 0.6510 - tp: 1087.0000 - fp: 572.0000 - tn: 1356.0000 - fn: 889.0000 - accuracy: 0.6258 - precision: 0.6552 - recall: 0.5501 - auc: 0.6590\n",
            " For Batch Number 123 the model has a loss of {'loss': 0.6516230702400208, 'tp': 1092.0, 'fp': 576.0, 'tn': 1370.0, 'fn': 898.0, 'accuracy': 0.6255081295967102, 'precision': 0.6546762585639954, 'recall': 0.548743724822998, 'auc': 0.6583945751190186} \n",
            "\n",
            " For Batch Number 124 the model has a loss of {'loss': 0.651655375957489, 'tp': 1095.0, 'fp': 580.0, 'tn': 1389.0, 'fn': 904.0, 'accuracy': 0.6260080933570862, 'precision': 0.6537313461303711, 'recall': 0.5477738976478577, 'auc': 0.6585060358047485} \n",
            "124/689 [====>.........................] - ETA: 34s - loss: 0.6517 - tp: 1095.0000 - fp: 580.0000 - tn: 1389.0000 - fn: 904.0000 - accuracy: 0.6260 - precision: 0.6537 - recall: 0.5478 - auc: 0.6585\n",
            " For Batch Number 125 the model has a loss of {'loss': 0.6516200304031372, 'tp': 1102.0, 'fp': 581.0, 'tn': 1405.0, 'fn': 912.0, 'accuracy': 0.6267499923706055, 'precision': 0.6547831296920776, 'recall': 0.5471698045730591, 'auc': 0.6587468981742859} \n",
            "\n",
            " For Batch Number 126 the model has a loss of {'loss': 0.6524119973182678, 'tp': 1106.0, 'fp': 584.0, 'tn': 1418.0, 'fn': 924.0, 'accuracy': 0.6259920597076416, 'precision': 0.6544378995895386, 'recall': 0.5448275804519653, 'auc': 0.6575755476951599} \n",
            "126/689 [====>.........................] - ETA: 34s - loss: 0.6524 - tp: 1106.0000 - fp: 584.0000 - tn: 1418.0000 - fn: 924.0000 - accuracy: 0.6260 - precision: 0.6544 - recall: 0.5448 - auc: 0.6576\n",
            " For Batch Number 127 the model has a loss of {'loss': 0.6527544856071472, 'tp': 1111.0, 'fp': 585.0, 'tn': 1430.0, 'fn': 938.0, 'accuracy': 0.6252460479736328, 'precision': 0.6550707817077637, 'recall': 0.5422157049179077, 'auc': 0.656983494758606} \n",
            "127/689 [====>.........................] - ETA: 34s - loss: 0.6528 - tp: 1111.0000 - fp: 585.0000 - tn: 1430.0000 - fn: 938.0000 - accuracy: 0.6252 - precision: 0.6551 - recall: 0.5422 - auc: 0.6570\n",
            " For Batch Number 128 the model has a loss of {'loss': 0.6520071029663086, 'tp': 1119.0, 'fp': 589.0, 'tn': 1446.0, 'fn': 942.0, 'accuracy': 0.626220703125, 'precision': 0.6551522016525269, 'recall': 0.5429403185844421, 'auc': 0.6581473350524902} \n",
            "128/689 [====>.........................] - ETA: 34s - loss: 0.6520 - tp: 1119.0000 - fp: 589.0000 - tn: 1446.0000 - fn: 942.0000 - accuracy: 0.6262 - precision: 0.6552 - recall: 0.5429 - auc: 0.6581\n",
            " For Batch Number 129 the model has a loss of {'loss': 0.6512987017631531, 'tp': 1127.0, 'fp': 593.0, 'tn': 1460.0, 'fn': 948.0, 'accuracy': 0.6266957521438599, 'precision': 0.6552325487136841, 'recall': 0.5431325435638428, 'auc': 0.659126341342926} \n",
            "\n",
            " For Batch Number 130 the model has a loss of {'loss': 0.6511942148208618, 'tp': 1136.0, 'fp': 595.0, 'tn': 1472.0, 'fn': 957.0, 'accuracy': 0.6269230842590332, 'precision': 0.6562680602073669, 'recall': 0.5427615642547607, 'auc': 0.6591276526451111} \n",
            "130/689 [====>.........................] - ETA: 33s - loss: 0.6512 - tp: 1136.0000 - fp: 595.0000 - tn: 1472.0000 - fn: 957.0000 - accuracy: 0.6269 - precision: 0.6563 - recall: 0.5428 - auc: 0.6591\n",
            " For Batch Number 131 the model has a loss of {'loss': 0.6515395045280457, 'tp': 1144.0, 'fp': 600.0, 'tn': 1485.0, 'fn': 963.0, 'accuracy': 0.6271469593048096, 'precision': 0.6559633016586304, 'recall': 0.5429520606994629, 'auc': 0.6589871048927307} \n",
            "\n",
            " For Batch Number 132 the model has a loss of {'loss': 0.6504712700843811, 'tp': 1154.0, 'fp': 602.0, 'tn': 1502.0, 'fn': 966.0, 'accuracy': 0.6287878751754761, 'precision': 0.6571754217147827, 'recall': 0.5443395972251892, 'auc': 0.6604787111282349} \n",
            "132/689 [====>.........................] - ETA: 33s - loss: 0.6505 - tp: 1154.0000 - fp: 602.0000 - tn: 1502.0000 - fn: 966.0000 - accuracy: 0.6288 - precision: 0.6572 - recall: 0.5443 - auc: 0.6605\n",
            " For Batch Number 133 the model has a loss of {'loss': 0.6507605314254761, 'tp': 1164.0, 'fp': 606.0, 'tn': 1514.0, 'fn': 972.0, 'accuracy': 0.6292293071746826, 'precision': 0.6576271057128906, 'recall': 0.5449438095092773, 'auc': 0.6605082750320435} \n",
            "\n",
            " For Batch Number 134 the model has a loss of {'loss': 0.6512120366096497, 'tp': 1171.0, 'fp': 610.0, 'tn': 1524.0, 'fn': 983.0, 'accuracy': 0.6284981369972229, 'precision': 0.6574957966804504, 'recall': 0.5436397194862366, 'auc': 0.6597945690155029} \n",
            "134/689 [====>.........................] - ETA: 33s - loss: 0.6512 - tp: 1171.0000 - fp: 610.0000 - tn: 1524.0000 - fn: 983.0000 - accuracy: 0.6285 - precision: 0.6575 - recall: 0.5436 - auc: 0.6598\n",
            " For Batch Number 135 the model has a loss of {'loss': 0.6520072221755981, 'tp': 1179.0, 'fp': 615.0, 'tn': 1533.0, 'fn': 993.0, 'accuracy': 0.6277777552604675, 'precision': 0.6571906208992004, 'recall': 0.5428176522254944, 'auc': 0.6587167978286743} \n",
            "135/689 [====>.........................] - ETA: 33s - loss: 0.6520 - tp: 1179.0000 - fp: 615.0000 - tn: 1533.0000 - fn: 993.0000 - accuracy: 0.6278 - precision: 0.6572 - recall: 0.5428 - auc: 0.6587\n",
            " For Batch Number 136 the model has a loss of {'loss': 0.6525760889053345, 'tp': 1188.0, 'fp': 618.0, 'tn': 1544.0, 'fn': 1002.0, 'accuracy': 0.6277573704719543, 'precision': 0.6578072905540466, 'recall': 0.5424657464027405, 'auc': 0.6580696105957031} \n",
            "\n",
            " For Batch Number 137 the model has a loss of {'loss': 0.6525639295578003, 'tp': 1196.0, 'fp': 624.0, 'tn': 1556.0, 'fn': 1008.0, 'accuracy': 0.6277372241020203, 'precision': 0.6571428775787354, 'recall': 0.5426497459411621, 'auc': 0.6578232645988464} \n",
            "137/689 [====>.........................] - ETA: 32s - loss: 0.6526 - tp: 1196.0000 - fp: 624.0000 - tn: 1556.0000 - fn: 1008.0000 - accuracy: 0.6277 - precision: 0.6571 - recall: 0.5426 - auc: 0.6578\n",
            " For Batch Number 138 the model has a loss of {'loss': 0.6521982550621033, 'tp': 1210.0, 'fp': 628.0, 'tn': 1563.0, 'fn': 1015.0, 'accuracy': 0.6279438138008118, 'precision': 0.6583242416381836, 'recall': 0.5438202023506165, 'auc': 0.6585493087768555} \n",
            "138/689 [=====>........................] - ETA: 32s - loss: 0.6522 - tp: 1210.0000 - fp: 628.0000 - tn: 1563.0000 - fn: 1015.0000 - accuracy: 0.6279 - precision: 0.6583 - recall: 0.5438 - auc: 0.6585\n",
            " For Batch Number 139 the model has a loss of {'loss': 0.6512786746025085, 'tp': 1225.0, 'fp': 634.0, 'tn': 1569.0, 'fn': 1020.0, 'accuracy': 0.6281474828720093, 'precision': 0.6589564085006714, 'recall': 0.5456570386886597, 'auc': 0.6596829295158386} \n",
            "139/689 [=====>........................] - ETA: 32s - loss: 0.6513 - tp: 1225.0000 - fp: 634.0000 - tn: 1569.0000 - fn: 1020.0000 - accuracy: 0.6281 - precision: 0.6590 - recall: 0.5457 - auc: 0.6597\n",
            " For Batch Number 140 the model has a loss of {'loss': 0.6522051692008972, 'tp': 1239.0, 'fp': 652.0, 'tn': 1569.0, 'fn': 1020.0, 'accuracy': 0.6267856955528259, 'precision': 0.6552088856697083, 'recall': 0.5484727621078491, 'auc': 0.6588889956474304} \n",
            "\n",
            " For Batch Number 141 the model has a loss of {'loss': 0.6530660390853882, 'tp': 1249.0, 'fp': 665.0, 'tn': 1574.0, 'fn': 1024.0, 'accuracy': 0.6256648898124695, 'precision': 0.6525600552558899, 'recall': 0.5494940876960754, 'auc': 0.6582410931587219} \n",
            "141/689 [=====>........................] - ETA: 32s - loss: 0.6531 - tp: 1249.0000 - fp: 665.0000 - tn: 1574.0000 - fn: 1024.0000 - accuracy: 0.6257 - precision: 0.6526 - recall: 0.5495 - auc: 0.6582\n",
            " For Batch Number 142 the model has a loss of {'loss': 0.6530861854553223, 'tp': 1260.0, 'fp': 668.0, 'tn': 1589.0, 'fn': 1027.0, 'accuracy': 0.6269806623458862, 'precision': 0.6535269618034363, 'recall': 0.5509400963783264, 'auc': 0.6587527394294739} \n",
            "142/689 [=====>........................] - ETA: 32s - loss: 0.6531 - tp: 1260.0000 - fp: 668.0000 - tn: 1589.0000 - fn: 1027.0000 - accuracy: 0.6270 - precision: 0.6535 - recall: 0.5509 - auc: 0.6588\n",
            " For Batch Number 143 the model has a loss of {'loss': 0.6524403095245361, 'tp': 1270.0, 'fp': 670.0, 'tn': 1602.0, 'fn': 1034.0, 'accuracy': 0.6276223659515381, 'precision': 0.6546391844749451, 'recall': 0.5512152910232544, 'auc': 0.6599058508872986} \n",
            "\n",
            " For Batch Number 144 the model has a loss of {'loss': 0.65293288230896, 'tp': 1276.0, 'fp': 674.0, 'tn': 1613.0, 'fn': 1045.0, 'accuracy': 0.626953125, 'precision': 0.654358983039856, 'recall': 0.549763023853302, 'auc': 0.6590036153793335} \n",
            "144/689 [=====>........................] - ETA: 32s - loss: 0.6529 - tp: 1276.0000 - fp: 674.0000 - tn: 1613.0000 - fn: 1045.0000 - accuracy: 0.6270 - precision: 0.6544 - recall: 0.5498 - auc: 0.6590\n",
            " For Batch Number 145 the model has a loss of {'loss': 0.6522626876831055, 'tp': 1284.0, 'fp': 674.0, 'tn': 1628.0, 'fn': 1054.0, 'accuracy': 0.6275861859321594, 'precision': 0.6557711958885193, 'recall': 0.5491873621940613, 'auc': 0.6601390242576599} \n",
            "\n",
            " For Batch Number 146 the model has a loss of {'loss': 0.651816189289093, 'tp': 1290.0, 'fp': 676.0, 'tn': 1644.0, 'fn': 1062.0, 'accuracy': 0.627996563911438, 'precision': 0.6561546325683594, 'recall': 0.5484693646430969, 'auc': 0.6607112288475037} \n",
            "146/689 [=====>........................] - ETA: 32s - loss: 0.6518 - tp: 1290.0000 - fp: 676.0000 - tn: 1644.0000 - fn: 1062.0000 - accuracy: 0.6280 - precision: 0.6562 - recall: 0.5485 - auc: 0.6607\n",
            " For Batch Number 147 the model has a loss of {'loss': 0.6522355675697327, 'tp': 1297.0, 'fp': 679.0, 'tn': 1657.0, 'fn': 1071.0, 'accuracy': 0.6279761791229248, 'precision': 0.6563765406608582, 'recall': 0.5477195978164673, 'auc': 0.6607082486152649} \n",
            "\n",
            " For Batch Number 148 the model has a loss of {'loss': 0.6537075042724609, 'tp': 1303.0, 'fp': 686.0, 'tn': 1664.0, 'fn': 1083.0, 'accuracy': 0.6264780163764954, 'precision': 0.6551030874252319, 'recall': 0.5461022853851318, 'auc': 0.6585903763771057} \n",
            "148/689 [=====>........................] - ETA: 31s - loss: 0.6537 - tp: 1303.0000 - fp: 686.0000 - tn: 1664.0000 - fn: 1083.0000 - accuracy: 0.6265 - precision: 0.6551 - recall: 0.5461 - auc: 0.6586\n",
            " For Batch Number 149 the model has a loss of {'loss': 0.6539188623428345, 'tp': 1316.0, 'fp': 692.0, 'tn': 1670.0, 'fn': 1090.0, 'accuracy': 0.626258373260498, 'precision': 0.6553784608840942, 'recall': 0.5469658970832825, 'auc': 0.65833580493927} \n",
            "149/689 [=====>........................] - ETA: 31s - loss: 0.6539 - tp: 1316.0000 - fp: 692.0000 - tn: 1670.0000 - fn: 1090.0000 - accuracy: 0.6263 - precision: 0.6554 - recall: 0.5470 - auc: 0.6583\n",
            " For Batch Number 150 the model has a loss of {'loss': 0.6539981365203857, 'tp': 1328.0, 'fp': 703.0, 'tn': 1676.0, 'fn': 1093.0, 'accuracy': 0.6258333325386047, 'precision': 0.6538650989532471, 'recall': 0.5485336780548096, 'auc': 0.6582251191139221} \n",
            "\n",
            " For Batch Number 151 the model has a loss of {'loss': 0.6542515158653259, 'tp': 1342.0, 'fp': 714.0, 'tn': 1682.0, 'fn': 1094.0, 'accuracy': 0.6258277893066406, 'precision': 0.6527237296104431, 'recall': 0.5509031414985657, 'auc': 0.6581112742424011} \n",
            "151/689 [=====>........................] - ETA: 31s - loss: 0.6543 - tp: 1342.0000 - fp: 714.0000 - tn: 1682.0000 - fn: 1094.0000 - accuracy: 0.6258 - precision: 0.6527 - recall: 0.5509 - auc: 0.6581\n",
            " For Batch Number 152 the model has a loss of {'loss': 0.6539848446846008, 'tp': 1356.0, 'fp': 719.0, 'tn': 1688.0, 'fn': 1101.0, 'accuracy': 0.6258223652839661, 'precision': 0.6534940004348755, 'recall': 0.5518925786018372, 'auc': 0.658607542514801} \n",
            "\n",
            " For Batch Number 153 the model has a loss of {'loss': 0.6539336442947388, 'tp': 1366.0, 'fp': 728.0, 'tn': 1697.0, 'fn': 1105.0, 'accuracy': 0.625612735748291, 'precision': 0.6523399949073792, 'recall': 0.5528126358985901, 'auc': 0.6586809158325195} \n",
            "153/689 [=====>........................] - ETA: 31s - loss: 0.6539 - tp: 1366.0000 - fp: 728.0000 - tn: 1697.0000 - fn: 1105.0000 - accuracy: 0.6256 - precision: 0.6523 - recall: 0.5528 - auc: 0.6587\n",
            " For Batch Number 154 the model has a loss of {'loss': 0.654210090637207, 'tp': 1370.0, 'fp': 738.0, 'tn': 1710.0, 'fn': 1110.0, 'accuracy': 0.625, 'precision': 0.6499051451683044, 'recall': 0.5524193644523621, 'auc': 0.6582119464874268} \n",
            "\n",
            " For Batch Number 155 the model has a loss of {'loss': 0.6552816033363342, 'tp': 1373.0, 'fp': 738.0, 'tn': 1723.0, 'fn': 1126.0, 'accuracy': 0.624193549156189, 'precision': 0.6504026651382446, 'recall': 0.5494197607040405, 'auc': 0.6567276120185852} \n",
            "155/689 [=====>........................] - ETA: 31s - loss: 0.6553 - tp: 1373.0000 - fp: 738.0000 - tn: 1723.0000 - fn: 1126.0000 - accuracy: 0.6242 - precision: 0.6504 - recall: 0.5494 - auc: 0.6567\n",
            " For Batch Number 156 the model has a loss of {'loss': 0.6552672982215881, 'tp': 1377.0, 'fp': 739.0, 'tn': 1737.0, 'fn': 1139.0, 'accuracy': 0.6237980723381042, 'precision': 0.6507561206817627, 'recall': 0.5472972989082336, 'auc': 0.6566950678825378} \n",
            "\n",
            " For Batch Number 157 the model has a loss of {'loss': 0.654930830001831, 'tp': 1385.0, 'fp': 741.0, 'tn': 1751.0, 'fn': 1147.0, 'accuracy': 0.6242038011550903, 'precision': 0.6514581441879272, 'recall': 0.5469984412193298, 'auc': 0.6573014855384827} \n",
            "157/689 [=====>........................] - ETA: 30s - loss: 0.6549 - tp: 1385.0000 - fp: 741.0000 - tn: 1751.0000 - fn: 1147.0000 - accuracy: 0.6242 - precision: 0.6515 - recall: 0.5470 - auc: 0.6573\n",
            " For Batch Number 158 the model has a loss of {'loss': 0.6547146439552307, 'tp': 1395.0, 'fp': 748.0, 'tn': 1762.0, 'fn': 1151.0, 'accuracy': 0.624406635761261, 'precision': 0.6509566307067871, 'recall': 0.5479183197021484, 'auc': 0.6578298211097717} \n",
            "158/689 [=====>........................] - ETA: 30s - loss: 0.6547 - tp: 1395.0000 - fp: 748.0000 - tn: 1762.0000 - fn: 1151.0000 - accuracy: 0.6244 - precision: 0.6510 - recall: 0.5479 - auc: 0.6578\n",
            " For Batch Number 159 the model has a loss of {'loss': 0.6547248959541321, 'tp': 1406.0, 'fp': 755.0, 'tn': 1770.0, 'fn': 1157.0, 'accuracy': 0.6242138147354126, 'precision': 0.650624692440033, 'recall': 0.5485758781433105, 'auc': 0.6576652526855469} \n",
            "159/689 [=====>........................] - ETA: 30s - loss: 0.6547 - tp: 1406.0000 - fp: 755.0000 - tn: 1770.0000 - fn: 1157.0000 - accuracy: 0.6242 - precision: 0.6506 - recall: 0.5486 - auc: 0.6577\n",
            " For Batch Number 160 the model has a loss of {'loss': 0.6551471948623657, 'tp': 1416.0, 'fp': 762.0, 'tn': 1777.0, 'fn': 1165.0, 'accuracy': 0.6236327886581421, 'precision': 0.650137722492218, 'recall': 0.548624575138092, 'auc': 0.6567438840866089} \n",
            "\n",
            " For Batch Number 161 the model has a loss of {'loss': 0.6551678776741028, 'tp': 1426.0, 'fp': 770.0, 'tn': 1785.0, 'fn': 1171.0, 'accuracy': 0.6232531070709229, 'precision': 0.6493625044822693, 'recall': 0.549095094203949, 'auc': 0.656592607498169} \n",
            "161/689 [======>.......................] - ETA: 30s - loss: 0.6552 - tp: 1426.0000 - fp: 770.0000 - tn: 1785.0000 - fn: 1171.0000 - accuracy: 0.6233 - precision: 0.6494 - recall: 0.5491 - auc: 0.6566\n",
            " For Batch Number 162 the model has a loss of {'loss': 0.6548276543617249, 'tp': 1435.0, 'fp': 777.0, 'tn': 1798.0, 'fn': 1174.0, 'accuracy': 0.6236497163772583, 'precision': 0.6487341523170471, 'recall': 0.5500191450119019, 'auc': 0.6568881869316101} \n",
            "162/689 [======>.......................] - ETA: 30s - loss: 0.6548 - tp: 1435.0000 - fp: 777.0000 - tn: 1798.0000 - fn: 1174.0000 - accuracy: 0.6236 - precision: 0.6487 - recall: 0.5500 - auc: 0.6569\n",
            " For Batch Number 163 the model has a loss of {'loss': 0.6547258496284485, 'tp': 1443.0, 'fp': 779.0, 'tn': 1811.0, 'fn': 1183.0, 'accuracy': 0.6238496899604797, 'precision': 0.6494149565696716, 'recall': 0.5495049357414246, 'auc': 0.6571841835975647} \n",
            "163/689 [======>.......................] - ETA: 30s - loss: 0.6547 - tp: 1443.0000 - fp: 779.0000 - tn: 1811.0000 - fn: 1183.0000 - accuracy: 0.6238 - precision: 0.6494 - recall: 0.5495 - auc: 0.6572\n",
            " For Batch Number 164 the model has a loss of {'loss': 0.6561240553855896, 'tp': 1452.0, 'fp': 780.0, 'tn': 1819.0, 'fn': 1197.0, 'accuracy': 0.6232850551605225, 'precision': 0.6505376100540161, 'recall': 0.5481313467025757, 'auc': 0.655458390712738} \n",
            "164/689 [======>.......................] - ETA: 30s - loss: 0.6561 - tp: 1452.0000 - fp: 780.0000 - tn: 1819.0000 - fn: 1197.0000 - accuracy: 0.6233 - precision: 0.6505 - recall: 0.5481 - auc: 0.6555\n",
            " For Batch Number 165 the model has a loss of {'loss': 0.6562022566795349, 'tp': 1460.0, 'fp': 786.0, 'tn': 1830.0, 'fn': 1204.0, 'accuracy': 0.623106062412262, 'precision': 0.6500445008277893, 'recall': 0.5480480194091797, 'auc': 0.6551635265350342} \n",
            "165/689 [======>.......................] - ETA: 30s - loss: 0.6562 - tp: 1460.0000 - fp: 786.0000 - tn: 1830.0000 - fn: 1204.0000 - accuracy: 0.6231 - precision: 0.6500 - recall: 0.5480 - auc: 0.6552\n",
            " For Batch Number 166 the model has a loss of {'loss': 0.6570547819137573, 'tp': 1467.0, 'fp': 796.0, 'tn': 1843.0, 'fn': 1206.0, 'accuracy': 0.6231174468994141, 'precision': 0.6482545137405396, 'recall': 0.5488215684890747, 'auc': 0.6542717218399048} \n",
            "166/689 [======>.......................] - ETA: 30s - loss: 0.6571 - tp: 1467.0000 - fp: 796.0000 - tn: 1843.0000 - fn: 1206.0000 - accuracy: 0.6231 - precision: 0.6483 - recall: 0.5488 - auc: 0.6543\n",
            " For Batch Number 167 the model has a loss of {'loss': 0.6566928625106812, 'tp': 1477.0, 'fp': 801.0, 'tn': 1852.0, 'fn': 1214.0, 'accuracy': 0.6229416131973267, 'precision': 0.6483757495880127, 'recall': 0.5488665699958801, 'auc': 0.6546281576156616} \n",
            "\n",
            " For Batch Number 168 the model has a loss of {'loss': 0.6575590968132019, 'tp': 1483.0, 'fp': 807.0, 'tn': 1860.0, 'fn': 1226.0, 'accuracy': 0.6218377947807312, 'precision': 0.6475982666015625, 'recall': 0.5474344491958618, 'auc': 0.6537714600563049} \n",
            "168/689 [======>.......................] - ETA: 29s - loss: 0.6576 - tp: 1483.0000 - fp: 807.0000 - tn: 1860.0000 - fn: 1226.0000 - accuracy: 0.6218 - precision: 0.6476 - recall: 0.5474 - auc: 0.6538\n",
            " For Batch Number 169 the model has a loss of {'loss': 0.6581441164016724, 'tp': 1489.0, 'fp': 811.0, 'tn': 1869.0, 'fn': 1239.0, 'accuracy': 0.6209319233894348, 'precision': 0.6473913192749023, 'recall': 0.5458211302757263, 'auc': 0.652950644493103} \n",
            "169/689 [======>.......................] - ETA: 29s - loss: 0.6581 - tp: 1489.0000 - fp: 811.0000 - tn: 1869.0000 - fn: 1239.0000 - accuracy: 0.6209 - precision: 0.6474 - recall: 0.5458 - auc: 0.6530\n",
            " For Batch Number 170 the model has a loss of {'loss': 0.6580023765563965, 'tp': 1500.0, 'fp': 818.0, 'tn': 1879.0, 'fn': 1243.0, 'accuracy': 0.6211397051811218, 'precision': 0.6471095681190491, 'recall': 0.5468465089797974, 'auc': 0.6530900597572327} \n",
            "170/689 [======>.......................] - ETA: 29s - loss: 0.6580 - tp: 1500.0000 - fp: 818.0000 - tn: 1879.0000 - fn: 1243.0000 - accuracy: 0.6211 - precision: 0.6471 - recall: 0.5468 - auc: 0.6531\n",
            " For Batch Number 171 the model has a loss of {'loss': 0.6578028798103333, 'tp': 1511.0, 'fp': 822.0, 'tn': 1890.0, 'fn': 1249.0, 'accuracy': 0.6215277910232544, 'precision': 0.647663950920105, 'recall': 0.5474637746810913, 'auc': 0.6534519195556641} \n",
            "171/689 [======>.......................] - ETA: 29s - loss: 0.6578 - tp: 1511.0000 - fp: 822.0000 - tn: 1890.0000 - fn: 1249.0000 - accuracy: 0.6215 - precision: 0.6477 - recall: 0.5475 - auc: 0.6535\n",
            " For Batch Number 172 the model has a loss of {'loss': 0.6577191352844238, 'tp': 1518.0, 'fp': 829.0, 'tn': 1900.0, 'fn': 1257.0, 'accuracy': 0.6210029125213623, 'precision': 0.6467831134796143, 'recall': 0.547027051448822, 'auc': 0.6534119248390198} \n",
            "172/689 [======>.......................] - ETA: 29s - loss: 0.6577 - tp: 1518.0000 - fp: 829.0000 - tn: 1900.0000 - fn: 1257.0000 - accuracy: 0.6210 - precision: 0.6468 - recall: 0.5470 - auc: 0.6534\n",
            " For Batch Number 173 the model has a loss of {'loss': 0.657467246055603, 'tp': 1525.0, 'fp': 833.0, 'tn': 1919.0, 'fn': 1259.0, 'accuracy': 0.6221098303794861, 'precision': 0.6467345356941223, 'recall': 0.547773003578186, 'auc': 0.6535424590110779} \n",
            "173/689 [======>.......................] - ETA: 29s - loss: 0.6575 - tp: 1525.0000 - fp: 833.0000 - tn: 1919.0000 - fn: 1259.0000 - accuracy: 0.6221 - precision: 0.6467 - recall: 0.5478 - auc: 0.6535\n",
            " For Batch Number 174 the model has a loss of {'loss': 0.657452404499054, 'tp': 1531.0, 'fp': 833.0, 'tn': 1934.0, 'fn': 1270.0, 'accuracy': 0.6223060488700867, 'precision': 0.6476311087608337, 'recall': 0.5465905070304871, 'auc': 0.6534770727157593} \n",
            "174/689 [======>.......................] - ETA: 29s - loss: 0.6575 - tp: 1531.0000 - fp: 833.0000 - tn: 1934.0000 - fn: 1270.0000 - accuracy: 0.6223 - precision: 0.6476 - recall: 0.5466 - auc: 0.6535\n",
            " For Batch Number 175 the model has a loss of {'loss': 0.6574433445930481, 'tp': 1534.0, 'fp': 834.0, 'tn': 1949.0, 'fn': 1283.0, 'accuracy': 0.6219642758369446, 'precision': 0.6478040814399719, 'recall': 0.5445509552955627, 'auc': 0.6533432006835938} \n",
            "175/689 [======>.......................] - ETA: 29s - loss: 0.6574 - tp: 1534.0000 - fp: 834.0000 - tn: 1949.0000 - fn: 1283.0000 - accuracy: 0.6220 - precision: 0.6478 - recall: 0.5446 - auc: 0.6533\n",
            " For Batch Number 176 the model has a loss of {'loss': 0.6571530699729919, 'tp': 1540.0, 'fp': 835.0, 'tn': 1965.0, 'fn': 1292.0, 'accuracy': 0.6223366260528564, 'precision': 0.648421049118042, 'recall': 0.5437853336334229, 'auc': 0.6539771556854248} \n",
            "\n",
            " For Batch Number 177 the model has a loss of {'loss': 0.6566848158836365, 'tp': 1547.0, 'fp': 838.0, 'tn': 1980.0, 'fn': 1299.0, 'accuracy': 0.622704803943634, 'precision': 0.6486372947692871, 'recall': 0.5435699224472046, 'auc': 0.6545753479003906} \n",
            "177/689 [======>.......................] - ETA: 29s - loss: 0.6567 - tp: 1547.0000 - fp: 838.0000 - tn: 1980.0000 - fn: 1299.0000 - accuracy: 0.6227 - precision: 0.6486 - recall: 0.5436 - auc: 0.6546\n",
            " For Batch Number 178 the model has a loss of {'loss': 0.6566267609596252, 'tp': 1554.0, 'fp': 842.0, 'tn': 1992.0, 'fn': 1308.0, 'accuracy': 0.622542142868042, 'precision': 0.6485809683799744, 'recall': 0.5429769158363342, 'auc': 0.6544191837310791} \n",
            "178/689 [======>.......................] - ETA: 29s - loss: 0.6566 - tp: 1554.0000 - fp: 842.0000 - tn: 1992.0000 - fn: 1308.0000 - accuracy: 0.6225 - precision: 0.6486 - recall: 0.5430 - auc: 0.6544\n",
            " For Batch Number 179 the model has a loss of {'loss': 0.6567246317863464, 'tp': 1560.0, 'fp': 851.0, 'tn': 2003.0, 'fn': 1314.0, 'accuracy': 0.622032105922699, 'precision': 0.6470344066619873, 'recall': 0.5427975058555603, 'auc': 0.6540048718452454} \n",
            "179/689 [======>.......................] - ETA: 29s - loss: 0.6567 - tp: 1560.0000 - fp: 851.0000 - tn: 2003.0000 - fn: 1314.0000 - accuracy: 0.6220 - precision: 0.6470 - recall: 0.5428 - auc: 0.6540\n",
            " For Batch Number 180 the model has a loss of {'loss': 0.6570338606834412, 'tp': 1568.0, 'fp': 855.0, 'tn': 2012.0, 'fn': 1325.0, 'accuracy': 0.6215277910232544, 'precision': 0.6471316814422607, 'recall': 0.5419979095458984, 'auc': 0.6534063816070557} \n",
            "\n",
            " For Batch Number 181 the model has a loss of {'loss': 0.6571558713912964, 'tp': 1576.0, 'fp': 859.0, 'tn': 2023.0, 'fn': 1334.0, 'accuracy': 0.6213743090629578, 'precision': 0.647227942943573, 'recall': 0.5415807366371155, 'auc': 0.6532856225967407} \n",
            "181/689 [======>.......................] - ETA: 28s - loss: 0.6572 - tp: 1576.0000 - fp: 859.0000 - tn: 2023.0000 - fn: 1334.0000 - accuracy: 0.6214 - precision: 0.6472 - recall: 0.5416 - auc: 0.6533\n",
            " For Batch Number 182 the model has a loss of {'loss': 0.656951367855072, 'tp': 1584.0, 'fp': 865.0, 'tn': 2034.0, 'fn': 1341.0, 'accuracy': 0.6212225556373596, 'precision': 0.6467946171760559, 'recall': 0.5415384769439697, 'auc': 0.6533660888671875} \n",
            "182/689 [======>.......................] - ETA: 28s - loss: 0.6570 - tp: 1584.0000 - fp: 865.0000 - tn: 2034.0000 - fn: 1341.0000 - accuracy: 0.6212 - precision: 0.6468 - recall: 0.5415 - auc: 0.6534\n",
            " For Batch Number 183 the model has a loss of {'loss': 0.6571427583694458, 'tp': 1593.0, 'fp': 871.0, 'tn': 2043.0, 'fn': 1349.0, 'accuracy': 0.6209016442298889, 'precision': 0.6465097665786743, 'recall': 0.5414683818817139, 'auc': 0.6530503630638123} \n",
            "\n",
            " For Batch Number 184 the model has a loss of {'loss': 0.6570139527320862, 'tp': 1600.0, 'fp': 875.0, 'tn': 2054.0, 'fn': 1359.0, 'accuracy': 0.62058424949646, 'precision': 0.6464646458625793, 'recall': 0.5407232046127319, 'auc': 0.6530871391296387} \n",
            "184/689 [=======>......................] - ETA: 28s - loss: 0.6570 - tp: 1600.0000 - fp: 875.0000 - tn: 2054.0000 - fn: 1359.0000 - accuracy: 0.6206 - precision: 0.6465 - recall: 0.5407 - auc: 0.6531\n",
            " For Batch Number 185 the model has a loss of {'loss': 0.6569991111755371, 'tp': 1609.0, 'fp': 880.0, 'tn': 2066.0, 'fn': 1365.0, 'accuracy': 0.6207770109176636, 'precision': 0.6464443802833557, 'recall': 0.5410221815109253, 'auc': 0.6532115340232849} \n",
            "\n",
            " For Batch Number 186 the model has a loss of {'loss': 0.656475305557251, 'tp': 1617.0, 'fp': 883.0, 'tn': 2082.0, 'fn': 1370.0, 'accuracy': 0.6214717626571655, 'precision': 0.6467999815940857, 'recall': 0.5413458347320557, 'auc': 0.6538009643554688} \n",
            "186/689 [=======>......................] - ETA: 28s - loss: 0.6565 - tp: 1617.0000 - fp: 883.0000 - tn: 2082.0000 - fn: 1370.0000 - accuracy: 0.6215 - precision: 0.6468 - recall: 0.5413 - auc: 0.6538\n",
            " For Batch Number 187 the model has a loss of {'loss': 0.6566957831382751, 'tp': 1623.0, 'fp': 887.0, 'tn': 2093.0, 'fn': 1381.0, 'accuracy': 0.6209893226623535, 'precision': 0.6466135382652283, 'recall': 0.5402796268463135, 'auc': 0.6534565091133118} \n",
            "\n",
            " For Batch Number 188 the model has a loss of {'loss': 0.6562798023223877, 'tp': 1634.0, 'fp': 888.0, 'tn': 2104.0, 'fn': 1390.0, 'accuracy': 0.6213430762290955, 'precision': 0.6478984951972961, 'recall': 0.5403439402580261, 'auc': 0.6541324853897095} \n",
            "188/689 [=======>......................] - ETA: 28s - loss: 0.6563 - tp: 1634.0000 - fp: 888.0000 - tn: 2104.0000 - fn: 1390.0000 - accuracy: 0.6213 - precision: 0.6479 - recall: 0.5403 - auc: 0.6541\n",
            " For Batch Number 189 the model has a loss of {'loss': 0.6564432978630066, 'tp': 1641.0, 'fp': 893.0, 'tn': 2116.0, 'fn': 1398.0, 'accuracy': 0.6211971044540405, 'precision': 0.6475927233695984, 'recall': 0.5399802327156067, 'auc': 0.6538743376731873} \n",
            "\n",
            " For Batch Number 190 the model has a loss of {'loss': 0.6563542485237122, 'tp': 1650.0, 'fp': 895.0, 'tn': 2126.0, 'fn': 1409.0, 'accuracy': 0.621052622795105, 'precision': 0.64833003282547, 'recall': 0.5393919348716736, 'auc': 0.6537714600563049} \n",
            "190/689 [=======>......................] - ETA: 28s - loss: 0.6564 - tp: 1650.0000 - fp: 895.0000 - tn: 2126.0000 - fn: 1409.0000 - accuracy: 0.6211 - precision: 0.6483 - recall: 0.5394 - auc: 0.6538\n",
            " For Batch Number 191 the model has a loss of {'loss': 0.656884491443634, 'tp': 1660.0, 'fp': 898.0, 'tn': 2137.0, 'fn': 1417.0, 'accuracy': 0.6212369203567505, 'precision': 0.6489444971084595, 'recall': 0.5394865274429321, 'auc': 0.6535734534263611} \n",
            "191/689 [=======>......................] - ETA: 28s - loss: 0.6569 - tp: 1660.0000 - fp: 898.0000 - tn: 2137.0000 - fn: 1417.0000 - accuracy: 0.6212 - precision: 0.6489 - recall: 0.5395 - auc: 0.6536\n",
            " For Batch Number 192 the model has a loss of {'loss': 0.6562099456787109, 'tp': 1672.0, 'fp': 903.0, 'tn': 2148.0, 'fn': 1421.0, 'accuracy': 0.6217448115348816, 'precision': 0.6493203639984131, 'recall': 0.5405755043029785, 'auc': 0.6542882323265076} \n",
            "\n",
            " For Batch Number 193 the model has a loss of {'loss': 0.6558594107627869, 'tp': 1685.0, 'fp': 906.0, 'tn': 2157.0, 'fn': 1428.0, 'accuracy': 0.6220855116844177, 'precision': 0.6503280401229858, 'recall': 0.5412784814834595, 'auc': 0.6548653841018677} \n",
            "193/689 [=======>......................] - ETA: 27s - loss: 0.6559 - tp: 1685.0000 - fp: 906.0000 - tn: 2157.0000 - fn: 1428.0000 - accuracy: 0.6221 - precision: 0.6503 - recall: 0.5413 - auc: 0.6549\n",
            " For Batch Number 194 the model has a loss of {'loss': 0.6558591723442078, 'tp': 1695.0, 'fp': 912.0, 'tn': 2166.0, 'fn': 1435.0, 'accuracy': 0.6219394207000732, 'precision': 0.6501725912094116, 'recall': 0.5415335297584534, 'auc': 0.6549352407455444} \n",
            "\n",
            " For Batch Number 195 the model has a loss of {'loss': 0.6568724513053894, 'tp': 1701.0, 'fp': 922.0, 'tn': 2176.0, 'fn': 1441.0, 'accuracy': 0.6213141083717346, 'precision': 0.6484940648078918, 'recall': 0.541374921798706, 'auc': 0.6539729237556458} \n",
            "195/689 [=======>......................] - ETA: 27s - loss: 0.6569 - tp: 1701.0000 - fp: 922.0000 - tn: 2176.0000 - fn: 1441.0000 - accuracy: 0.6213 - precision: 0.6485 - recall: 0.5414 - auc: 0.6540\n",
            " For Batch Number 196 the model has a loss of {'loss': 0.6566756367683411, 'tp': 1711.0, 'fp': 925.0, 'tn': 2186.0, 'fn': 1450.0, 'accuracy': 0.6213328838348389, 'precision': 0.649089515209198, 'recall': 0.5412843823432922, 'auc': 0.654255211353302} \n",
            "196/689 [=======>......................] - ETA: 27s - loss: 0.6567 - tp: 1711.0000 - fp: 925.0000 - tn: 2186.0000 - fn: 1450.0000 - accuracy: 0.6213 - precision: 0.6491 - recall: 0.5413 - auc: 0.6543\n",
            " For Batch Number 197 the model has a loss of {'loss': 0.6565079092979431, 'tp': 1722.0, 'fp': 929.0, 'tn': 2196.0, 'fn': 1457.0, 'accuracy': 0.6215101480484009, 'precision': 0.6495661735534668, 'recall': 0.5416797995567322, 'auc': 0.6545055508613586} \n",
            "197/689 [=======>......................] - ETA: 27s - loss: 0.6565 - tp: 1722.0000 - fp: 929.0000 - tn: 2196.0000 - fn: 1457.0000 - accuracy: 0.6215 - precision: 0.6496 - recall: 0.5417 - auc: 0.6545\n",
            " For Batch Number 198 the model has a loss of {'loss': 0.6567202210426331, 'tp': 1730.0, 'fp': 933.0, 'tn': 2207.0, 'fn': 1466.0, 'accuracy': 0.6213699579238892, 'precision': 0.6496432423591614, 'recall': 0.5413016080856323, 'auc': 0.6543232202529907} \n",
            "198/689 [=======>......................] - ETA: 27s - loss: 0.6567 - tp: 1730.0000 - fp: 933.0000 - tn: 2207.0000 - fn: 1466.0000 - accuracy: 0.6214 - precision: 0.6496 - recall: 0.5413 - auc: 0.6543\n",
            " For Batch Number 199 the model has a loss of {'loss': 0.6571829319000244, 'tp': 1737.0, 'fp': 939.0, 'tn': 2217.0, 'fn': 1475.0, 'accuracy': 0.6209170818328857, 'precision': 0.6491031646728516, 'recall': 0.5407845377922058, 'auc': 0.6537427306175232} \n",
            "199/689 [=======>......................] - ETA: 27s - loss: 0.6572 - tp: 1737.0000 - fp: 939.0000 - tn: 2217.0000 - fn: 1475.0000 - accuracy: 0.6209 - precision: 0.6491 - recall: 0.5408 - auc: 0.6537\n",
            " For Batch Number 200 the model has a loss of {'loss': 0.6574402451515198, 'tp': 1741.0, 'fp': 943.0, 'tn': 2228.0, 'fn': 1488.0, 'accuracy': 0.6201562285423279, 'precision': 0.6486586928367615, 'recall': 0.5391762256622314, 'auc': 0.6530396938323975} \n",
            "200/689 [=======>......................] - ETA: 27s - loss: 0.6574 - tp: 1741.0000 - fp: 943.0000 - tn: 2228.0000 - fn: 1488.0000 - accuracy: 0.6202 - precision: 0.6487 - recall: 0.5392 - auc: 0.6530\n",
            " For Batch Number 201 the model has a loss of {'loss': 0.657025933265686, 'tp': 1749.0, 'fp': 944.0, 'tn': 2245.0, 'fn': 1494.0, 'accuracy': 0.6209577322006226, 'precision': 0.649461567401886, 'recall': 0.5393154621124268, 'auc': 0.6536238193511963} \n",
            "201/689 [=======>......................] - ETA: 27s - loss: 0.6570 - tp: 1749.0000 - fp: 944.0000 - tn: 2245.0000 - fn: 1494.0000 - accuracy: 0.6210 - precision: 0.6495 - recall: 0.5393 - auc: 0.6536\n",
            " For Batch Number 202 the model has a loss of {'loss': 0.6566303372383118, 'tp': 1760.0, 'fp': 944.0, 'tn': 2260.0, 'fn': 1500.0, 'accuracy': 0.6219059228897095, 'precision': 0.6508875489234924, 'recall': 0.5398772954940796, 'auc': 0.6543352007865906} \n",
            "202/689 [=======>......................] - ETA: 27s - loss: 0.6566 - tp: 1760.0000 - fp: 944.0000 - tn: 2260.0000 - fn: 1500.0000 - accuracy: 0.6219 - precision: 0.6509 - recall: 0.5399 - auc: 0.6543\n",
            " For Batch Number 203 the model has a loss of {'loss': 0.6565327644348145, 'tp': 1766.0, 'fp': 946.0, 'tn': 2272.0, 'fn': 1512.0, 'accuracy': 0.6216133236885071, 'precision': 0.6511799693107605, 'recall': 0.5387431383132935, 'auc': 0.6545235514640808} \n",
            "203/689 [=======>......................] - ETA: 27s - loss: 0.6565 - tp: 1766.0000 - fp: 946.0000 - tn: 2272.0000 - fn: 1512.0000 - accuracy: 0.6216 - precision: 0.6512 - recall: 0.5387 - auc: 0.6545\n",
            " For Batch Number 204 the model has a loss of {'loss': 0.6563486456871033, 'tp': 1776.0, 'fp': 949.0, 'tn': 2285.0, 'fn': 1518.0, 'accuracy': 0.6220894455909729, 'precision': 0.6517431139945984, 'recall': 0.5391620993614197, 'auc': 0.6547617316246033} \n",
            "204/689 [=======>......................] - ETA: 27s - loss: 0.6563 - tp: 1776.0000 - fp: 949.0000 - tn: 2285.0000 - fn: 1518.0000 - accuracy: 0.6221 - precision: 0.6517 - recall: 0.5392 - auc: 0.6548\n",
            " For Batch Number 205 the model has a loss of {'loss': 0.6561952233314514, 'tp': 1786.0, 'fp': 953.0, 'tn': 2293.0, 'fn': 1528.0, 'accuracy': 0.6217987537384033, 'precision': 0.6520627737045288, 'recall': 0.5389257669448853, 'auc': 0.6550983190536499} \n",
            "205/689 [=======>......................] - ETA: 27s - loss: 0.6562 - tp: 1786.0000 - fp: 953.0000 - tn: 2293.0000 - fn: 1528.0000 - accuracy: 0.6218 - precision: 0.6521 - recall: 0.5389 - auc: 0.6551\n",
            " For Batch Number 206 the model has a loss of {'loss': 0.6561095714569092, 'tp': 1797.0, 'fp': 958.0, 'tn': 2304.0, 'fn': 1533.0, 'accuracy': 0.6221176981925964, 'precision': 0.6522685885429382, 'recall': 0.5396396517753601, 'auc': 0.6552308201789856} \n",
            "206/689 [=======>......................] - ETA: 27s - loss: 0.6561 - tp: 1797.0000 - fp: 958.0000 - tn: 2304.0000 - fn: 1533.0000 - accuracy: 0.6221 - precision: 0.6523 - recall: 0.5396 - auc: 0.6552\n",
            " For Batch Number 207 the model has a loss of {'loss': 0.6560377478599548, 'tp': 1806.0, 'fp': 966.0, 'tn': 2315.0, 'fn': 1537.0, 'accuracy': 0.6221316456794739, 'precision': 0.6515151262283325, 'recall': 0.540233314037323, 'auc': 0.6550848484039307} \n",
            "207/689 [========>.....................] - ETA: 27s - loss: 0.6560 - tp: 1806.0000 - fp: 966.0000 - tn: 2315.0000 - fn: 1537.0000 - accuracy: 0.6221 - precision: 0.6515 - recall: 0.5402 - auc: 0.6551\n",
            " For Batch Number 208 the model has a loss of {'loss': 0.6562700271606445, 'tp': 1814.0, 'fp': 973.0, 'tn': 2329.0, 'fn': 1540.0, 'accuracy': 0.6224459409713745, 'precision': 0.6508790850639343, 'recall': 0.5408467650413513, 'auc': 0.6548555493354797} \n",
            "208/689 [========>.....................] - ETA: 27s - loss: 0.6563 - tp: 1814.0000 - fp: 973.0000 - tn: 2329.0000 - fn: 1540.0000 - accuracy: 0.6224 - precision: 0.6509 - recall: 0.5408 - auc: 0.6549\n",
            " For Batch Number 209 the model has a loss of {'loss': 0.6563320755958557, 'tp': 1819.0, 'fp': 977.0, 'tn': 2343.0, 'fn': 1549.0, 'accuracy': 0.622308611869812, 'precision': 0.6505722403526306, 'recall': 0.540083110332489, 'auc': 0.6547051668167114} \n",
            "209/689 [========>.....................] - ETA: 27s - loss: 0.6563 - tp: 1819.0000 - fp: 977.0000 - tn: 2343.0000 - fn: 1549.0000 - accuracy: 0.6223 - precision: 0.6506 - recall: 0.5401 - auc: 0.6547\n",
            " For Batch Number 210 the model has a loss of {'loss': 0.6566094756126404, 'tp': 1825.0, 'fp': 982.0, 'tn': 2356.0, 'fn': 1557.0, 'accuracy': 0.6221725940704346, 'precision': 0.6501603126525879, 'recall': 0.5396215319633484, 'auc': 0.6544703841209412} \n",
            "210/689 [========>.....................] - ETA: 27s - loss: 0.6566 - tp: 1825.0000 - fp: 982.0000 - tn: 2356.0000 - fn: 1557.0000 - accuracy: 0.6222 - precision: 0.6502 - recall: 0.5396 - auc: 0.6545\n",
            " For Batch Number 211 the model has a loss of {'loss': 0.6565338373184204, 'tp': 1831.0, 'fp': 983.0, 'tn': 2372.0, 'fn': 1566.0, 'accuracy': 0.6224822402000427, 'precision': 0.6506751775741577, 'recall': 0.5390049815177917, 'auc': 0.6547067165374756} \n",
            "211/689 [========>.....................] - ETA: 27s - loss: 0.6565 - tp: 1831.0000 - fp: 983.0000 - tn: 2372.0000 - fn: 1566.0000 - accuracy: 0.6225 - precision: 0.6507 - recall: 0.5390 - auc: 0.6547\n",
            " For Batch Number 212 the model has a loss of {'loss': 0.6566630601882935, 'tp': 1836.0, 'fp': 984.0, 'tn': 2386.0, 'fn': 1578.0, 'accuracy': 0.6223466992378235, 'precision': 0.651063859462738, 'recall': 0.5377855896949768, 'auc': 0.6545758247375488} \n",
            "212/689 [========>.....................] - ETA: 27s - loss: 0.6567 - tp: 1836.0000 - fp: 984.0000 - tn: 2386.0000 - fn: 1578.0000 - accuracy: 0.6223 - precision: 0.6511 - recall: 0.5378 - auc: 0.6546\n",
            " For Batch Number 213 the model has a loss of {'loss': 0.6562600135803223, 'tp': 1843.0, 'fp': 987.0, 'tn': 2402.0, 'fn': 1584.0, 'accuracy': 0.622799277305603, 'precision': 0.6512367725372314, 'recall': 0.5377881526947021, 'auc': 0.6551402807235718} \n",
            "213/689 [========>.....................] - ETA: 27s - loss: 0.6563 - tp: 1843.0000 - fp: 987.0000 - tn: 2402.0000 - fn: 1584.0000 - accuracy: 0.6228 - precision: 0.6512 - recall: 0.5378 - auc: 0.6551\n",
            " For Batch Number 214 the model has a loss of {'loss': 0.6567579507827759, 'tp': 1847.0, 'fp': 996.0, 'tn': 2416.0, 'fn': 1589.0, 'accuracy': 0.6225175261497498, 'precision': 0.6496658325195312, 'recall': 0.5375436544418335, 'auc': 0.6544588208198547} \n",
            "214/689 [========>.....................] - ETA: 27s - loss: 0.6568 - tp: 1847.0000 - fp: 996.0000 - tn: 2416.0000 - fn: 1589.0000 - accuracy: 0.6225 - precision: 0.6497 - recall: 0.5375 - auc: 0.6545\n",
            " For Batch Number 215 the model has a loss of {'loss': 0.6567240953445435, 'tp': 1854.0, 'fp': 1000.0, 'tn': 2429.0, 'fn': 1597.0, 'accuracy': 0.6225290894508362, 'precision': 0.6496145725250244, 'recall': 0.5372355580329895, 'auc': 0.6543223261833191} \n",
            "\n",
            " For Batch Number 216 the model has a loss of {'loss': 0.6566708087921143, 'tp': 1863.0, 'fp': 1003.0, 'tn': 2443.0, 'fn': 1603.0, 'accuracy': 0.6229745149612427, 'precision': 0.6500349044799805, 'recall': 0.5375072360038757, 'auc': 0.6545024514198303} \n",
            "216/689 [========>.....................] - ETA: 27s - loss: 0.6567 - tp: 1863.0000 - fp: 1003.0000 - tn: 2443.0000 - fn: 1603.0000 - accuracy: 0.6230 - precision: 0.6500 - recall: 0.5375 - auc: 0.6545\n",
            " For Batch Number 217 the model has a loss of {'loss': 0.6568261981010437, 'tp': 1870.0, 'fp': 1005.0, 'tn': 2455.0, 'fn': 1614.0, 'accuracy': 0.6228398680686951, 'precision': 0.6504347920417786, 'recall': 0.5367394089698792, 'auc': 0.6541170477867126} \n",
            "217/689 [========>.....................] - ETA: 27s - loss: 0.6568 - tp: 1870.0000 - fp: 1005.0000 - tn: 2455.0000 - fn: 1614.0000 - accuracy: 0.6228 - precision: 0.6504 - recall: 0.5367 - auc: 0.6541\n",
            " For Batch Number 218 the model has a loss of {'loss': 0.657260000705719, 'tp': 1876.0, 'fp': 1009.0, 'tn': 2467.0, 'fn': 1624.0, 'accuracy': 0.6225630640983582, 'precision': 0.6502599716186523, 'recall': 0.5360000133514404, 'auc': 0.6535631418228149} \n",
            "218/689 [========>.....................] - ETA: 27s - loss: 0.6573 - tp: 1876.0000 - fp: 1009.0000 - tn: 2467.0000 - fn: 1624.0000 - accuracy: 0.6226 - precision: 0.6503 - recall: 0.5360 - auc: 0.6536\n",
            " For Batch Number 219 the model has a loss of {'loss': 0.6572850346565247, 'tp': 1884.0, 'fp': 1014.0, 'tn': 2479.0, 'fn': 1631.0, 'accuracy': 0.6225742101669312, 'precision': 0.6501035094261169, 'recall': 0.5359886288642883, 'auc': 0.6533502340316772} \n",
            "219/689 [========>.....................] - ETA: 27s - loss: 0.6573 - tp: 1884.0000 - fp: 1014.0000 - tn: 2479.0000 - fn: 1631.0000 - accuracy: 0.6226 - precision: 0.6501 - recall: 0.5360 - auc: 0.6534\n",
            " For Batch Number 220 the model has a loss of {'loss': 0.6572431325912476, 'tp': 1891.0, 'fp': 1017.0, 'tn': 2492.0, 'fn': 1640.0, 'accuracy': 0.6225852370262146, 'precision': 0.6502751111984253, 'recall': 0.535542368888855, 'auc': 0.653389036655426} \n",
            "220/689 [========>.....................] - ETA: 27s - loss: 0.6572 - tp: 1891.0000 - fp: 1017.0000 - tn: 2492.0000 - fn: 1640.0000 - accuracy: 0.6226 - precision: 0.6503 - recall: 0.5355 - auc: 0.6534\n",
            " For Batch Number 221 the model has a loss of {'loss': 0.6572344899177551, 'tp': 1901.0, 'fp': 1022.0, 'tn': 2502.0, 'fn': 1647.0, 'accuracy': 0.6225961446762085, 'precision': 0.6503592133522034, 'recall': 0.5357947945594788, 'auc': 0.6534308791160583} \n",
            "221/689 [========>.....................] - ETA: 27s - loss: 0.6572 - tp: 1901.0000 - fp: 1022.0000 - tn: 2502.0000 - fn: 1647.0000 - accuracy: 0.6226 - precision: 0.6504 - recall: 0.5358 - auc: 0.6534\n",
            " For Batch Number 222 the model has a loss of {'loss': 0.6573469042778015, 'tp': 1910.0, 'fp': 1027.0, 'tn': 2510.0, 'fn': 1657.0, 'accuracy': 0.622184693813324, 'precision': 0.6503234505653381, 'recall': 0.5354639887809753, 'auc': 0.6533530354499817} \n",
            "222/689 [========>.....................] - ETA: 27s - loss: 0.6573 - tp: 1910.0000 - fp: 1027.0000 - tn: 2510.0000 - fn: 1657.0000 - accuracy: 0.6222 - precision: 0.6503 - recall: 0.5355 - auc: 0.6534\n",
            " For Batch Number 223 the model has a loss of {'loss': 0.6572146415710449, 'tp': 1919.0, 'fp': 1031.0, 'tn': 2522.0, 'fn': 1664.0, 'accuracy': 0.6223374605178833, 'precision': 0.650508463382721, 'recall': 0.5355846881866455, 'auc': 0.6535099744796753} \n",
            "223/689 [========>.....................] - ETA: 27s - loss: 0.6572 - tp: 1919.0000 - fp: 1031.0000 - tn: 2522.0000 - fn: 1664.0000 - accuracy: 0.6223 - precision: 0.6505 - recall: 0.5356 - auc: 0.6535\n",
            " For Batch Number 224 the model has a loss of {'loss': 0.6577064394950867, 'tp': 1927.0, 'fp': 1039.0, 'tn': 2527.0, 'fn': 1675.0, 'accuracy': 0.6213727593421936, 'precision': 0.6496965885162354, 'recall': 0.5349805951118469, 'auc': 0.652862012386322} \n",
            "224/689 [========>.....................] - ETA: 27s - loss: 0.6577 - tp: 1927.0000 - fp: 1039.0000 - tn: 2527.0000 - fn: 1675.0000 - accuracy: 0.6214 - precision: 0.6497 - recall: 0.5350 - auc: 0.6529\n",
            " For Batch Number 225 the model has a loss of {'loss': 0.6579394936561584, 'tp': 1938.0, 'fp': 1046.0, 'tn': 2535.0, 'fn': 1681.0, 'accuracy': 0.6212499737739563, 'precision': 0.6494638323783875, 'recall': 0.5355070233345032, 'auc': 0.6526888608932495} \n",
            "225/689 [========>.....................] - ETA: 27s - loss: 0.6579 - tp: 1938.0000 - fp: 1046.0000 - tn: 2535.0000 - fn: 1681.0000 - accuracy: 0.6212 - precision: 0.6495 - recall: 0.5355 - auc: 0.6527\n",
            " For Batch Number 226 the model has a loss of {'loss': 0.657768189907074, 'tp': 1950.0, 'fp': 1051.0, 'tn': 2544.0, 'fn': 1687.0, 'accuracy': 0.6214048862457275, 'precision': 0.6497834324836731, 'recall': 0.536156177520752, 'auc': 0.652987003326416} \n",
            "226/689 [========>.....................] - ETA: 27s - loss: 0.6578 - tp: 1950.0000 - fp: 1051.0000 - tn: 2544.0000 - fn: 1687.0000 - accuracy: 0.6214 - precision: 0.6498 - recall: 0.5362 - auc: 0.6530\n",
            " For Batch Number 227 the model has a loss of {'loss': 0.6579604148864746, 'tp': 1957.0, 'fp': 1064.0, 'tn': 2553.0, 'fn': 1690.0, 'accuracy': 0.620870053768158, 'precision': 0.6477987170219421, 'recall': 0.5366054177284241, 'auc': 0.6524778008460999} \n",
            "227/689 [========>.....................] - ETA: 27s - loss: 0.6580 - tp: 1957.0000 - fp: 1064.0000 - tn: 2553.0000 - fn: 1690.0000 - accuracy: 0.6209 - precision: 0.6478 - recall: 0.5366 - auc: 0.6525\n",
            " For Batch Number 228 the model has a loss of {'loss': 0.6581530570983887, 'tp': 1965.0, 'fp': 1071.0, 'tn': 2565.0, 'fn': 1695.0, 'accuracy': 0.6208881735801697, 'precision': 0.6472331881523132, 'recall': 0.5368852615356445, 'auc': 0.6521070599555969} \n",
            "228/689 [========>.....................] - ETA: 27s - loss: 0.6582 - tp: 1965.0000 - fp: 1071.0000 - tn: 2565.0000 - fn: 1695.0000 - accuracy: 0.6209 - precision: 0.6472 - recall: 0.5369 - auc: 0.6521\n",
            " For Batch Number 229 the model has a loss of {'loss': 0.6583453416824341, 'tp': 1968.0, 'fp': 1075.0, 'tn': 2581.0, 'fn': 1704.0, 'accuracy': 0.6207696795463562, 'precision': 0.6467301845550537, 'recall': 0.5359477400779724, 'auc': 0.6519083976745605} \n",
            "229/689 [========>.....................] - ETA: 27s - loss: 0.6583 - tp: 1968.0000 - fp: 1075.0000 - tn: 2581.0000 - fn: 1704.0000 - accuracy: 0.6208 - precision: 0.6467 - recall: 0.5359 - auc: 0.6519\n",
            " For Batch Number 230 the model has a loss of {'loss': 0.6583861708641052, 'tp': 1969.0, 'fp': 1077.0, 'tn': 2598.0, 'fn': 1716.0, 'accuracy': 0.620516300201416, 'precision': 0.6464215517044067, 'recall': 0.5343283414840698, 'auc': 0.6518627405166626} \n",
            "230/689 [=========>....................] - ETA: 27s - loss: 0.6584 - tp: 1969.0000 - fp: 1077.0000 - tn: 2598.0000 - fn: 1716.0000 - accuracy: 0.6205 - precision: 0.6464 - recall: 0.5343 - auc: 0.6519\n",
            " For Batch Number 231 the model has a loss of {'loss': 0.6589067578315735, 'tp': 1971.0, 'fp': 1078.0, 'tn': 2612.0, 'fn': 1731.0, 'accuracy': 0.619994580745697, 'precision': 0.6464414596557617, 'recall': 0.5324149131774902, 'auc': 0.6511825323104858} \n",
            "231/689 [=========>....................] - ETA: 27s - loss: 0.6589 - tp: 1971.0000 - fp: 1078.0000 - tn: 2612.0000 - fn: 1731.0000 - accuracy: 0.6200 - precision: 0.6464 - recall: 0.5324 - auc: 0.6512\n",
            " For Batch Number 232 the model has a loss of {'loss': 0.6589673757553101, 'tp': 1972.0, 'fp': 1079.0, 'tn': 2627.0, 'fn': 1746.0, 'accuracy': 0.619477391242981, 'precision': 0.6463454365730286, 'recall': 0.5303927063941956, 'auc': 0.6510640382766724} \n",
            "232/689 [=========>....................] - ETA: 27s - loss: 0.6590 - tp: 1972.0000 - fp: 1079.0000 - tn: 2627.0000 - fn: 1746.0000 - accuracy: 0.6195 - precision: 0.6463 - recall: 0.5304 - auc: 0.6511\n",
            " For Batch Number 233 the model has a loss of {'loss': 0.6588142514228821, 'tp': 1984.0, 'fp': 1080.0, 'tn': 2637.0, 'fn': 1755.0, 'accuracy': 0.6197693347930908, 'precision': 0.647519588470459, 'recall': 0.5306231379508972, 'auc': 0.6514255404472351} \n",
            "233/689 [=========>....................] - ETA: 27s - loss: 0.6588 - tp: 1984.0000 - fp: 1080.0000 - tn: 2637.0000 - fn: 1755.0000 - accuracy: 0.6198 - precision: 0.6475 - recall: 0.5306 - auc: 0.6514\n",
            " For Batch Number 234 the model has a loss of {'loss': 0.6588354706764221, 'tp': 1999.0, 'fp': 1092.0, 'tn': 2642.0, 'fn': 1755.0, 'accuracy': 0.6197916865348816, 'precision': 0.646716296672821, 'recall': 0.5324986577033997, 'auc': 0.6513962745666504} \n",
            "234/689 [=========>....................] - ETA: 27s - loss: 0.6588 - tp: 1999.0000 - fp: 1092.0000 - tn: 2642.0000 - fn: 1755.0000 - accuracy: 0.6198 - precision: 0.6467 - recall: 0.5325 - auc: 0.6514\n",
            " For Batch Number 235 the model has a loss of {'loss': 0.6588693857192993, 'tp': 2016.0, 'fp': 1105.0, 'tn': 2643.0, 'fn': 1756.0, 'accuracy': 0.6195478439331055, 'precision': 0.6459468007087708, 'recall': 0.5344644784927368, 'auc': 0.6514577269554138} \n",
            "235/689 [=========>....................] - ETA: 27s - loss: 0.6589 - tp: 2016.0000 - fp: 1105.0000 - tn: 2643.0000 - fn: 1756.0000 - accuracy: 0.6195 - precision: 0.6459 - recall: 0.5345 - auc: 0.6515\n",
            " For Batch Number 236 the model has a loss of {'loss': 0.6589378118515015, 'tp': 2031.0, 'fp': 1118.0, 'tn': 2646.0, 'fn': 1757.0, 'accuracy': 0.6193061470985413, 'precision': 0.6449666619300842, 'recall': 0.5361668467521667, 'auc': 0.6513836979866028} \n",
            "236/689 [=========>....................] - ETA: 27s - loss: 0.6589 - tp: 2031.0000 - fp: 1118.0000 - tn: 2646.0000 - fn: 1757.0000 - accuracy: 0.6193 - precision: 0.6450 - recall: 0.5362 - auc: 0.6514\n",
            " For Batch Number 237 the model has a loss of {'loss': 0.658816397190094, 'tp': 2040.0, 'fp': 1124.0, 'tn': 2658.0, 'fn': 1762.0, 'accuracy': 0.6194620132446289, 'precision': 0.6447534561157227, 'recall': 0.5365597009658813, 'auc': 0.651464581489563} \n",
            "237/689 [=========>....................] - ETA: 27s - loss: 0.6588 - tp: 2040.0000 - fp: 1124.0000 - tn: 2658.0000 - fn: 1762.0000 - accuracy: 0.6195 - precision: 0.6448 - recall: 0.5366 - auc: 0.6515\n",
            " For Batch Number 238 the model has a loss of {'loss': 0.6590284705162048, 'tp': 2044.0, 'fp': 1126.0, 'tn': 2673.0, 'fn': 1773.0, 'accuracy': 0.6193540096282959, 'precision': 0.6447949409484863, 'recall': 0.535499095916748, 'auc': 0.6512519717216492} \n",
            "\n",
            " For Batch Number 239 the model has a loss of {'loss': 0.659699559211731, 'tp': 2046.0, 'fp': 1127.0, 'tn': 2689.0, 'fn': 1786.0, 'accuracy': 0.6191161274909973, 'precision': 0.6448156237602234, 'recall': 0.5339248180389404, 'auc': 0.650705099105835} \n",
            "239/689 [=========>....................] - ETA: 26s - loss: 0.6597 - tp: 2046.0000 - fp: 1127.0000 - tn: 2689.0000 - fn: 1786.0000 - accuracy: 0.6191 - precision: 0.6448 - recall: 0.5339 - auc: 0.6507\n",
            " For Batch Number 240 the model has a loss of {'loss': 0.6604393124580383, 'tp': 2050.0, 'fp': 1128.0, 'tn': 2703.0, 'fn': 1799.0, 'accuracy': 0.6188802123069763, 'precision': 0.6450597643852234, 'recall': 0.5326058864593506, 'auc': 0.650293231010437} \n",
            "\n",
            " For Batch Number 241 the model has a loss of {'loss': 0.6602898240089417, 'tp': 2057.0, 'fp': 1133.0, 'tn': 2715.0, 'fn': 1807.0, 'accuracy': 0.6187759041786194, 'precision': 0.6448276042938232, 'recall': 0.5323498845100403, 'auc': 0.650547444820404} \n",
            "241/689 [=========>....................] - ETA: 26s - loss: 0.6603 - tp: 2057.0000 - fp: 1133.0000 - tn: 2715.0000 - fn: 1807.0000 - accuracy: 0.6188 - precision: 0.6448 - recall: 0.5323 - auc: 0.6505\n",
            " For Batch Number 242 the model has a loss of {'loss': 0.6604531407356262, 'tp': 2065.0, 'fp': 1139.0, 'tn': 2724.0, 'fn': 1816.0, 'accuracy': 0.6184142827987671, 'precision': 0.6445068717002869, 'recall': 0.5320793390274048, 'auc': 0.6501425504684448} \n",
            "\n",
            " For Batch Number 243 the model has a loss of {'loss': 0.6601575613021851, 'tp': 2081.0, 'fp': 1143.0, 'tn': 2731.0, 'fn': 1821.0, 'accuracy': 0.6188271641731262, 'precision': 0.645471453666687, 'recall': 0.5333162546157837, 'auc': 0.6506827473640442} \n",
            "243/689 [=========>....................] - ETA: 26s - loss: 0.6602 - tp: 2081.0000 - fp: 1143.0000 - tn: 2731.0000 - fn: 1821.0000 - accuracy: 0.6188 - precision: 0.6455 - recall: 0.5333 - auc: 0.6507\n",
            " For Batch Number 244 the model has a loss of {'loss': 0.6601768136024475, 'tp': 2096.0, 'fp': 1156.0, 'tn': 2734.0, 'fn': 1822.0, 'accuracy': 0.6185963153839111, 'precision': 0.6445264220237732, 'recall': 0.5349668264389038, 'auc': 0.6506356596946716} \n",
            "244/689 [=========>....................] - ETA: 26s - loss: 0.6602 - tp: 2096.0000 - fp: 1156.0000 - tn: 2734.0000 - fn: 1822.0000 - accuracy: 0.6186 - precision: 0.6445 - recall: 0.5350 - auc: 0.6506\n",
            " For Batch Number 245 the model has a loss of {'loss': 0.6604124307632446, 'tp': 2108.0, 'fp': 1167.0, 'tn': 2740.0, 'fn': 1825.0, 'accuracy': 0.6183673739433289, 'precision': 0.6436641216278076, 'recall': 0.5359776020050049, 'auc': 0.6503490209579468} \n",
            "245/689 [=========>....................] - ETA: 26s - loss: 0.6604 - tp: 2108.0000 - fp: 1167.0000 - tn: 2740.0000 - fn: 1825.0000 - accuracy: 0.6184 - precision: 0.6437 - recall: 0.5360 - auc: 0.6503\n",
            " For Batch Number 246 the model has a loss of {'loss': 0.660131573677063, 'tp': 2116.0, 'fp': 1170.0, 'tn': 2753.0, 'fn': 1833.0, 'accuracy': 0.6185213327407837, 'precision': 0.6439440250396729, 'recall': 0.535831868648529, 'auc': 0.6508083939552307} \n",
            "246/689 [=========>....................] - ETA: 26s - loss: 0.6601 - tp: 2116.0000 - fp: 1170.0000 - tn: 2753.0000 - fn: 1833.0000 - accuracy: 0.6185 - precision: 0.6439 - recall: 0.5358 - auc: 0.6508\n",
            " For Batch Number 247 the model has a loss of {'loss': 0.6601711511611938, 'tp': 2122.0, 'fp': 1171.0, 'tn': 2767.0, 'fn': 1844.0, 'accuracy': 0.6185475587844849, 'precision': 0.6443971991539001, 'recall': 0.5350478887557983, 'auc': 0.6506822109222412} \n",
            "\n",
            " For Batch Number 248 the model has a loss of {'loss': 0.6600667238235474, 'tp': 2128.0, 'fp': 1172.0, 'tn': 2782.0, 'fn': 1854.0, 'accuracy': 0.6186996102333069, 'precision': 0.6448484659194946, 'recall': 0.5344048142433167, 'auc': 0.650972843170166} \n",
            "248/689 [=========>....................] - ETA: 26s - loss: 0.6601 - tp: 2128.0000 - fp: 1172.0000 - tn: 2782.0000 - fn: 1854.0000 - accuracy: 0.6187 - precision: 0.6448 - recall: 0.5344 - auc: 0.6510\n",
            " For Batch Number 249 the model has a loss of {'loss': 0.6599105596542358, 'tp': 2136.0, 'fp': 1178.0, 'tn': 2795.0, 'fn': 1859.0, 'accuracy': 0.6188504099845886, 'precision': 0.6445383429527283, 'recall': 0.5346683263778687, 'auc': 0.6509561538696289} \n",
            "249/689 [=========>....................] - ETA: 26s - loss: 0.6599 - tp: 2136.0000 - fp: 1178.0000 - tn: 2795.0000 - fn: 1859.0000 - accuracy: 0.6189 - precision: 0.6445 - recall: 0.5347 - auc: 0.6510\n",
            " For Batch Number 250 the model has a loss of {'loss': 0.6599218249320984, 'tp': 2148.0, 'fp': 1183.0, 'tn': 2803.0, 'fn': 1866.0, 'accuracy': 0.6188750267028809, 'precision': 0.6448513865470886, 'recall': 0.5351270437240601, 'auc': 0.6510972380638123} \n",
            "250/689 [=========>....................] - ETA: 25s - loss: 0.6599 - tp: 2148.0000 - fp: 1183.0000 - tn: 2803.0000 - fn: 1866.0000 - accuracy: 0.6189 - precision: 0.6449 - recall: 0.5351 - auc: 0.6511\n",
            " For Batch Number 251 the model has a loss of {'loss': 0.6600801944732666, 'tp': 2160.0, 'fp': 1189.0, 'tn': 2810.0, 'fn': 1873.0, 'accuracy': 0.6187748908996582, 'precision': 0.6449686288833618, 'recall': 0.5355814695358276, 'auc': 0.6511222720146179} \n",
            "\n",
            " For Batch Number 252 the model has a loss of {'loss': 0.6599532961845398, 'tp': 2174.0, 'fp': 1196.0, 'tn': 2817.0, 'fn': 1877.0, 'accuracy': 0.6189236044883728, 'precision': 0.6451038718223572, 'recall': 0.5366576313972473, 'auc': 0.6514641642570496} \n",
            "252/689 [=========>....................] - ETA: 25s - loss: 0.6600 - tp: 2174.0000 - fp: 1196.0000 - tn: 2817.0000 - fn: 1877.0000 - accuracy: 0.6189 - precision: 0.6451 - recall: 0.5367 - auc: 0.6515\n",
            " For Batch Number 253 the model has a loss of {'loss': 0.6610021591186523, 'tp': 2182.0, 'fp': 1207.0, 'tn': 2828.0, 'fn': 1879.0, 'accuracy': 0.6188241243362427, 'precision': 0.6438477635383606, 'recall': 0.5373060703277588, 'auc': 0.6510781049728394} \n",
            "\n",
            " For Batch Number 254 the model has a loss of {'loss': 0.6603840589523315, 'tp': 2187.0, 'fp': 1213.0, 'tn': 2844.0, 'fn': 1884.0, 'accuracy': 0.6189714670181274, 'precision': 0.6432352662086487, 'recall': 0.537214457988739, 'auc': 0.6519589424133301} \n",
            "254/689 [==========>...................] - ETA: 25s - loss: 0.6604 - tp: 2187.0000 - fp: 1213.0000 - tn: 2844.0000 - fn: 1884.0000 - accuracy: 0.6190 - precision: 0.6432 - recall: 0.5372 - auc: 0.6520\n",
            " For Batch Number 255 the model has a loss of {'loss': 0.6620602011680603, 'tp': 2190.0, 'fp': 1213.0, 'tn': 2855.0, 'fn': 1902.0, 'accuracy': 0.6182597875595093, 'precision': 0.6435497999191284, 'recall': 0.5351906418800354, 'auc': 0.6508727669715881} \n",
            "\n",
            " For Batch Number 256 the model has a loss of {'loss': 0.6625796556472778, 'tp': 2195.0, 'fp': 1215.0, 'tn': 2870.0, 'fn': 1912.0, 'accuracy': 0.6182861328125, 'precision': 0.6436949968338013, 'recall': 0.5344533920288086, 'auc': 0.6510129570960999} \n",
            "256/689 [==========>...................] - ETA: 25s - loss: 0.6626 - tp: 2195.0000 - fp: 1215.0000 - tn: 2870.0000 - fn: 1912.0000 - accuracy: 0.6183 - precision: 0.6437 - recall: 0.5345 - auc: 0.6510\n",
            " For Batch Number 257 the model has a loss of {'loss': 0.6628606915473938, 'tp': 2204.0, 'fp': 1219.0, 'tn': 2881.0, 'fn': 1920.0, 'accuracy': 0.6183122396469116, 'precision': 0.6438796520233154, 'recall': 0.534432590007782, 'auc': 0.6509569883346558} \n",
            "257/689 [==========>...................] - ETA: 25s - loss: 0.6629 - tp: 2204.0000 - fp: 1219.0000 - tn: 2881.0000 - fn: 1920.0000 - accuracy: 0.6183 - precision: 0.6439 - recall: 0.5344 - auc: 0.6510\n",
            " For Batch Number 258 the model has a loss of {'loss': 0.6629743576049805, 'tp': 2216.0, 'fp': 1227.0, 'tn': 2888.0, 'fn': 1925.0, 'accuracy': 0.6182170510292053, 'precision': 0.6436247229576111, 'recall': 0.5351364612579346, 'auc': 0.6508502960205078} \n",
            "\n",
            " For Batch Number 259 the model has a loss of {'loss': 0.6633573174476624, 'tp': 2232.0, 'fp': 1241.0, 'tn': 2890.0, 'fn': 1925.0, 'accuracy': 0.6180019378662109, 'precision': 0.642672061920166, 'recall': 0.5369256734848022, 'auc': 0.6507430672645569} \n",
            "259/689 [==========>...................] - ETA: 25s - loss: 0.6634 - tp: 2232.0000 - fp: 1241.0000 - tn: 2890.0000 - fn: 1925.0000 - accuracy: 0.6180 - precision: 0.6427 - recall: 0.5369 - auc: 0.6507\n",
            " For Batch Number 260 the model has a loss of {'loss': 0.6640884876251221, 'tp': 2248.0, 'fp': 1255.0, 'tn': 2892.0, 'fn': 1925.0, 'accuracy': 0.6177884340286255, 'precision': 0.6417356729507446, 'recall': 0.5387011766433716, 'auc': 0.6503946185112} \n",
            "\n",
            " For Batch Number 261 the model has a loss of {'loss': 0.6642764806747437, 'tp': 2260.0, 'fp': 1265.0, 'tn': 2896.0, 'fn': 1931.0, 'accuracy': 0.617337167263031, 'precision': 0.6411347389221191, 'recall': 0.5392507910728455, 'auc': 0.650211751461029} \n",
            "261/689 [==========>...................] - ETA: 25s - loss: 0.6643 - tp: 2260.0000 - fp: 1265.0000 - tn: 2896.0000 - fn: 1931.0000 - accuracy: 0.6173 - precision: 0.6411 - recall: 0.5393 - auc: 0.6502\n",
            " For Batch Number 262 the model has a loss of {'loss': 0.664395809173584, 'tp': 2268.0, 'fp': 1272.0, 'tn': 2908.0, 'fn': 1936.0, 'accuracy': 0.6173664331436157, 'precision': 0.6406779885292053, 'recall': 0.5394862294197083, 'auc': 0.6500502228736877} \n",
            "262/689 [==========>...................] - ETA: 25s - loss: 0.6644 - tp: 2268.0000 - fp: 1272.0000 - tn: 2908.0000 - fn: 1936.0000 - accuracy: 0.6174 - precision: 0.6407 - recall: 0.5395 - auc: 0.6501\n",
            " For Batch Number 263 the model has a loss of {'loss': 0.6643800139427185, 'tp': 2271.0, 'fp': 1273.0, 'tn': 2926.0, 'fn': 1946.0, 'accuracy': 0.6175142526626587, 'precision': 0.6408013701438904, 'recall': 0.5385345220565796, 'auc': 0.650010883808136} \n",
            "\n",
            " For Batch Number 264 the model has a loss of {'loss': 0.6649176478385925, 'tp': 2272.0, 'fp': 1273.0, 'tn': 2942.0, 'fn': 1961.0, 'accuracy': 0.6171875, 'precision': 0.6409026980400085, 'recall': 0.5367351770401001, 'auc': 0.6495525240898132} \n",
            "264/689 [==========>...................] - ETA: 24s - loss: 0.6649 - tp: 2272.0000 - fp: 1273.0000 - tn: 2942.0000 - fn: 1961.0000 - accuracy: 0.6172 - precision: 0.6409 - recall: 0.5367 - auc: 0.6496\n",
            " For Batch Number 265 the model has a loss of {'loss': 0.6653192639350891, 'tp': 2276.0, 'fp': 1274.0, 'tn': 2955.0, 'fn': 1975.0, 'accuracy': 0.6168631911277771, 'precision': 0.6411267518997192, 'recall': 0.5354034304618835, 'auc': 0.6488345861434937} \n",
            "265/689 [==========>...................] - ETA: 24s - loss: 0.6653 - tp: 2276.0000 - fp: 1274.0000 - tn: 2955.0000 - fn: 1975.0000 - accuracy: 0.6169 - precision: 0.6411 - recall: 0.5354 - auc: 0.6488\n",
            " For Batch Number 266 the model has a loss of {'loss': 0.6658074259757996, 'tp': 2287.0, 'fp': 1291.0, 'tn': 2957.0, 'fn': 1977.0, 'accuracy': 0.6160714030265808, 'precision': 0.6391838788986206, 'recall': 0.5363508462905884, 'auc': 0.648160994052887} \n",
            "266/689 [==========>...................] - ETA: 24s - loss: 0.6658 - tp: 2287.0000 - fp: 1291.0000 - tn: 2957.0000 - fn: 1977.0000 - accuracy: 0.6161 - precision: 0.6392 - recall: 0.5364 - auc: 0.6482\n",
            " For Batch Number 267 the model has a loss of {'loss': 0.665891170501709, 'tp': 2307.0, 'fp': 1303.0, 'tn': 2957.0, 'fn': 1977.0, 'accuracy': 0.6161048412322998, 'precision': 0.6390581727027893, 'recall': 0.5385153889656067, 'auc': 0.6483078598976135} \n",
            "\n",
            " For Batch Number 268 the model has a loss of {'loss': 0.6665196418762207, 'tp': 2321.0, 'fp': 1321.0, 'tn': 2957.0, 'fn': 1977.0, 'accuracy': 0.6154384613037109, 'precision': 0.6372871994972229, 'recall': 0.540018618106842, 'auc': 0.6476200222969055} \n",
            "268/689 [==========>...................] - ETA: 24s - loss: 0.6665 - tp: 2321.0000 - fp: 1321.0000 - tn: 2957.0000 - fn: 1977.0000 - accuracy: 0.6154 - precision: 0.6373 - recall: 0.5400 - auc: 0.6476\n",
            " For Batch Number 269 the model has a loss of {'loss': 0.6664109826087952, 'tp': 2336.0, 'fp': 1332.0, 'tn': 2961.0, 'fn': 1979.0, 'accuracy': 0.6153578162193298, 'precision': 0.6368592977523804, 'recall': 0.5413673520088196, 'auc': 0.6477259993553162} \n",
            "269/689 [==========>...................] - ETA: 24s - loss: 0.6664 - tp: 2336.0000 - fp: 1332.0000 - tn: 2961.0000 - fn: 1979.0000 - accuracy: 0.6154 - precision: 0.6369 - recall: 0.5414 - auc: 0.6477\n",
            " For Batch Number 270 the model has a loss of {'loss': 0.6660418510437012, 'tp': 2343.0, 'fp': 1333.0, 'tn': 2980.0, 'fn': 1984.0, 'accuracy': 0.6160879731178284, 'precision': 0.6373775601387024, 'recall': 0.5414837002754211, 'auc': 0.648230254650116} \n",
            "\n",
            " For Batch Number 271 the model has a loss of {'loss': 0.6666629314422607, 'tp': 2346.0, 'fp': 1333.0, 'tn': 2991.0, 'fn': 2002.0, 'accuracy': 0.6154289841651917, 'precision': 0.6376732587814331, 'recall': 0.5395584106445312, 'auc': 0.6470949053764343} \n",
            "271/689 [==========>...................] - ETA: 24s - loss: 0.6667 - tp: 2346.0000 - fp: 1333.0000 - tn: 2991.0000 - fn: 2002.0000 - accuracy: 0.6154 - precision: 0.6377 - recall: 0.5396 - auc: 0.6471\n",
            " For Batch Number 272 the model has a loss of {'loss': 0.6668916940689087, 'tp': 2350.0, 'fp': 1333.0, 'tn': 3003.0, 'fn': 2018.0, 'accuracy': 0.6150045990943909, 'precision': 0.6380667686462402, 'recall': 0.53800368309021, 'auc': 0.6467443704605103} \n",
            "272/689 [==========>...................] - ETA: 24s - loss: 0.6669 - tp: 2350.0000 - fp: 1333.0000 - tn: 3003.0000 - fn: 2018.0000 - accuracy: 0.6150 - precision: 0.6381 - recall: 0.5380 - auc: 0.6467\n",
            " For Batch Number 273 the model has a loss of {'loss': 0.6667515635490417, 'tp': 2363.0, 'fp': 1339.0, 'tn': 3012.0, 'fn': 2022.0, 'accuracy': 0.6152701377868652, 'precision': 0.6383036375045776, 'recall': 0.5388825535774231, 'auc': 0.6470077037811279} \n",
            "\n",
            " For Batch Number 274 the model has a loss of {'loss': 0.666946530342102, 'tp': 2375.0, 'fp': 1348.0, 'tn': 3020.0, 'fn': 2025.0, 'accuracy': 0.6153056621551514, 'precision': 0.6379263997077942, 'recall': 0.5397727489471436, 'auc': 0.6467777490615845} \n",
            "274/689 [==========>...................] - ETA: 24s - loss: 0.6669 - tp: 2375.0000 - fp: 1348.0000 - tn: 3020.0000 - fn: 2025.0000 - accuracy: 0.6153 - precision: 0.6379 - recall: 0.5398 - auc: 0.6468\n",
            " For Batch Number 275 the model has a loss of {'loss': 0.6670681238174438, 'tp': 2390.0, 'fp': 1359.0, 'tn': 3023.0, 'fn': 2028.0, 'accuracy': 0.6151136159896851, 'precision': 0.6375033259391785, 'recall': 0.5409687757492065, 'auc': 0.6467399001121521} \n",
            "275/689 [==========>...................] - ETA: 24s - loss: 0.6671 - tp: 2390.0000 - fp: 1359.0000 - tn: 3023.0000 - fn: 2028.0000 - accuracy: 0.6151 - precision: 0.6375 - recall: 0.5410 - auc: 0.6467\n",
            " For Batch Number 276 the model has a loss of {'loss': 0.6672069430351257, 'tp': 2400.0, 'fp': 1372.0, 'tn': 3032.0, 'fn': 2028.0, 'accuracy': 0.6150362491607666, 'precision': 0.6362672448158264, 'recall': 0.5420054197311401, 'auc': 0.6463580131530762} \n",
            "276/689 [===========>..................] - ETA: 24s - loss: 0.6672 - tp: 2400.0000 - fp: 1372.0000 - tn: 3032.0000 - fn: 2028.0000 - accuracy: 0.6150 - precision: 0.6363 - recall: 0.5420 - auc: 0.6464\n",
            " For Batch Number 277 the model has a loss of {'loss': 0.6669613122940063, 'tp': 2412.0, 'fp': 1377.0, 'tn': 3040.0, 'fn': 2035.0, 'accuracy': 0.6150721907615662, 'precision': 0.6365795731544495, 'recall': 0.5423881411552429, 'auc': 0.6466843485832214} \n",
            "\n",
            " For Batch Number 278 the model has a loss of {'loss': 0.6667687296867371, 'tp': 2419.0, 'fp': 1383.0, 'tn': 3053.0, 'fn': 2041.0, 'accuracy': 0.6151078939437866, 'precision': 0.6362440586090088, 'recall': 0.542376697063446, 'auc': 0.6470105051994324} \n",
            "278/689 [===========>..................] - ETA: 23s - loss: 0.6668 - tp: 2419.0000 - fp: 1383.0000 - tn: 3053.0000 - fn: 2041.0000 - accuracy: 0.6151 - precision: 0.6362 - recall: 0.5424 - auc: 0.6470\n",
            " For Batch Number 279 the model has a loss of {'loss': 0.6667128801345825, 'tp': 2428.0, 'fp': 1386.0, 'tn': 3064.0, 'fn': 2050.0, 'accuracy': 0.615143358707428, 'precision': 0.636601984500885, 'recall': 0.542206346988678, 'auc': 0.6471539735794067} \n",
            "279/689 [===========>..................] - ETA: 23s - loss: 0.6667 - tp: 2428.0000 - fp: 1386.0000 - tn: 3064.0000 - fn: 2050.0000 - accuracy: 0.6151 - precision: 0.6366 - recall: 0.5422 - auc: 0.6472\n",
            " For Batch Number 280 the model has a loss of {'loss': 0.6667323708534241, 'tp': 2434.0, 'fp': 1390.0, 'tn': 3078.0, 'fn': 2058.0, 'accuracy': 0.6151785850524902, 'precision': 0.6365062594413757, 'recall': 0.5418521761894226, 'auc': 0.6472354531288147} \n",
            "\n",
            " For Batch Number 281 the model has a loss of {'loss': 0.6667417883872986, 'tp': 2440.0, 'fp': 1393.0, 'tn': 3094.0, 'fn': 2065.0, 'accuracy': 0.6154359579086304, 'precision': 0.6365770697593689, 'recall': 0.5416204333305359, 'auc': 0.6473580002784729} \n",
            "281/689 [===========>..................] - ETA: 23s - loss: 0.6667 - tp: 2440.0000 - fp: 1393.0000 - tn: 3094.0000 - fn: 2065.0000 - accuracy: 0.6154 - precision: 0.6366 - recall: 0.5416 - auc: 0.6474\n",
            " For Batch Number 282 the model has a loss of {'loss': 0.6668917536735535, 'tp': 2446.0, 'fp': 1398.0, 'tn': 3105.0, 'fn': 2075.0, 'accuracy': 0.6151373982429504, 'precision': 0.6363163590431213, 'recall': 0.541030764579773, 'auc': 0.6472121477127075} \n",
            "\n",
            " For Batch Number 283 the model has a loss of {'loss': 0.6666545271873474, 'tp': 2456.0, 'fp': 1401.0, 'tn': 3116.0, 'fn': 2083.0, 'accuracy': 0.6152827143669128, 'precision': 0.6367643475532532, 'recall': 0.541088342666626, 'auc': 0.6474992632865906} \n",
            "283/689 [===========>..................] - ETA: 23s - loss: 0.6667 - tp: 2456.0000 - fp: 1401.0000 - tn: 3116.0000 - fn: 2083.0000 - accuracy: 0.6153 - precision: 0.6368 - recall: 0.5411 - auc: 0.6475\n",
            " For Batch Number 284 the model has a loss of {'loss': 0.6664840579032898, 'tp': 2467.0, 'fp': 1409.0, 'tn': 3124.0, 'fn': 2088.0, 'accuracy': 0.6152068376541138, 'precision': 0.6364809274673462, 'recall': 0.541602611541748, 'auc': 0.6475826501846313} \n",
            "\n",
            " For Batch Number 285 the model has a loss of {'loss': 0.6666150093078613, 'tp': 2481.0, 'fp': 1419.0, 'tn': 3130.0, 'fn': 2090.0, 'accuracy': 0.6152412295341492, 'precision': 0.6361538171768188, 'recall': 0.5427696108818054, 'auc': 0.6474524736404419} \n",
            "285/689 [===========>..................] - ETA: 23s - loss: 0.6666 - tp: 2481.0000 - fp: 1419.0000 - tn: 3130.0000 - fn: 2090.0000 - accuracy: 0.6152 - precision: 0.6362 - recall: 0.5428 - auc: 0.6475\n",
            " For Batch Number 286 the model has a loss of {'loss': 0.6665341258049011, 'tp': 2494.0, 'fp': 1426.0, 'tn': 3138.0, 'fn': 2094.0, 'accuracy': 0.6153846383094788, 'precision': 0.6362245082855225, 'recall': 0.5435919761657715, 'auc': 0.6475762128829956} \n",
            "\n",
            " For Batch Number 287 the model has a loss of {'loss': 0.666387140750885, 'tp': 2502.0, 'fp': 1433.0, 'tn': 3148.0, 'fn': 2101.0, 'accuracy': 0.6152003407478333, 'precision': 0.6358322501182556, 'recall': 0.5435585379600525, 'auc': 0.6476198434829712} \n",
            "287/689 [===========>..................] - ETA: 23s - loss: 0.6664 - tp: 2502.0000 - fp: 1433.0000 - tn: 3148.0000 - fn: 2101.0000 - accuracy: 0.6152 - precision: 0.6358 - recall: 0.5436 - auc: 0.6476\n",
            " For Batch Number 288 the model has a loss of {'loss': 0.6662106513977051, 'tp': 2510.0, 'fp': 1434.0, 'tn': 3162.0, 'fn': 2110.0, 'accuracy': 0.6154513955116272, 'precision': 0.6364097595214844, 'recall': 0.5432900190353394, 'auc': 0.6478903889656067} \n",
            "288/689 [===========>..................] - ETA: 23s - loss: 0.6662 - tp: 2510.0000 - fp: 1434.0000 - tn: 3162.0000 - fn: 2110.0000 - accuracy: 0.6155 - precision: 0.6364 - recall: 0.5433 - auc: 0.6479\n",
            " For Batch Number 289 the model has a loss of {'loss': 0.666235625743866, 'tp': 2517.0, 'fp': 1436.0, 'tn': 3176.0, 'fn': 2119.0, 'accuracy': 0.6155925393104553, 'precision': 0.6367316246032715, 'recall': 0.5429249405860901, 'auc': 0.6478174328804016} \n",
            "\n",
            " For Batch Number 290 the model has a loss of {'loss': 0.665770411491394, 'tp': 2524.0, 'fp': 1439.0, 'tn': 3194.0, 'fn': 2123.0, 'accuracy': 0.6161637902259827, 'precision': 0.63689124584198, 'recall': 0.5431461334228516, 'auc': 0.6485623121261597} \n",
            "290/689 [===========>..................] - ETA: 23s - loss: 0.6658 - tp: 2524.0000 - fp: 1439.0000 - tn: 3194.0000 - fn: 2123.0000 - accuracy: 0.6162 - precision: 0.6369 - recall: 0.5431 - auc: 0.6486\n",
            " For Batch Number 291 the model has a loss of {'loss': 0.665587306022644, 'tp': 2530.0, 'fp': 1443.0, 'tn': 3209.0, 'fn': 2130.0, 'accuracy': 0.6163015365600586, 'precision': 0.6367983818054199, 'recall': 0.5429184436798096, 'auc': 0.6488358378410339} \n",
            "291/689 [===========>..................] - ETA: 22s - loss: 0.6656 - tp: 2530.0000 - fp: 1443.0000 - tn: 3209.0000 - fn: 2130.0000 - accuracy: 0.6163 - precision: 0.6368 - recall: 0.5429 - auc: 0.6488\n",
            " For Batch Number 292 the model has a loss of {'loss': 0.6655737161636353, 'tp': 2536.0, 'fp': 1445.0, 'tn': 3223.0, 'fn': 2140.0, 'accuracy': 0.6163313388824463, 'precision': 0.6370258927345276, 'recall': 0.5423438549041748, 'auc': 0.6487651467323303} \n",
            "\n",
            " For Batch Number 293 the model has a loss of {'loss': 0.6654379367828369, 'tp': 2543.0, 'fp': 1446.0, 'tn': 3235.0, 'fn': 2152.0, 'accuracy': 0.6162542700767517, 'precision': 0.6375031471252441, 'recall': 0.541640043258667, 'auc': 0.6489193439483643} \n",
            "293/689 [===========>..................] - ETA: 22s - loss: 0.6654 - tp: 2543.0000 - fp: 1446.0000 - tn: 3235.0000 - fn: 2152.0000 - accuracy: 0.6163 - precision: 0.6375 - recall: 0.5416 - auc: 0.6489\n",
            " For Batch Number 294 the model has a loss of {'loss': 0.6657766103744507, 'tp': 2550.0, 'fp': 1453.0, 'tn': 3243.0, 'fn': 2162.0, 'accuracy': 0.6157525777816772, 'precision': 0.6370222568511963, 'recall': 0.5411714911460876, 'auc': 0.6484418511390686} \n",
            "294/689 [===========>..................] - ETA: 22s - loss: 0.6658 - tp: 2550.0000 - fp: 1453.0000 - tn: 3243.0000 - fn: 2162.0000 - accuracy: 0.6158 - precision: 0.6370 - recall: 0.5412 - auc: 0.6484\n",
            " For Batch Number 295 the model has a loss of {'loss': 0.6658511161804199, 'tp': 2561.0, 'fp': 1464.0, 'tn': 3252.0, 'fn': 2163.0, 'accuracy': 0.6157838702201843, 'precision': 0.6362732648849487, 'recall': 0.5421253442764282, 'auc': 0.6481995582580566} \n",
            "295/689 [===========>..................] - ETA: 22s - loss: 0.6659 - tp: 2561.0000 - fp: 1464.0000 - tn: 3252.0000 - fn: 2163.0000 - accuracy: 0.6158 - precision: 0.6363 - recall: 0.5421 - auc: 0.6482\n",
            " For Batch Number 296 the model has a loss of {'loss': 0.6659728288650513, 'tp': 2571.0, 'fp': 1472.0, 'tn': 3260.0, 'fn': 2169.0, 'accuracy': 0.6156038641929626, 'precision': 0.6359139084815979, 'recall': 0.5424050688743591, 'auc': 0.6480057239532471} \n",
            "296/689 [===========>..................] - ETA: 22s - loss: 0.6660 - tp: 2571.0000 - fp: 1472.0000 - tn: 3260.0000 - fn: 2169.0000 - accuracy: 0.6156 - precision: 0.6359 - recall: 0.5424 - auc: 0.6480\n",
            " For Batch Number 297 the model has a loss of {'loss': 0.6660377979278564, 'tp': 2579.0, 'fp': 1476.0, 'tn': 3272.0, 'fn': 2177.0, 'accuracy': 0.6156355142593384, 'precision': 0.6360049247741699, 'recall': 0.5422624349594116, 'auc': 0.6479055881500244} \n",
            "\n",
            " For Batch Number 298 the model has a loss of {'loss': 0.6657595038414001, 'tp': 2585.0, 'fp': 1479.0, 'tn': 3288.0, 'fn': 2184.0, 'accuracy': 0.6158766746520996, 'precision': 0.6360728144645691, 'recall': 0.5420423746109009, 'auc': 0.6482219099998474} \n",
            "298/689 [===========>..................] - ETA: 22s - loss: 0.6658 - tp: 2585.0000 - fp: 1479.0000 - tn: 3288.0000 - fn: 2184.0000 - accuracy: 0.6159 - precision: 0.6361 - recall: 0.5420 - auc: 0.6482\n",
            " For Batch Number 299 the model has a loss of {'loss': 0.6659258604049683, 'tp': 2590.0, 'fp': 1480.0, 'tn': 3300.0, 'fn': 2198.0, 'accuracy': 0.615593671798706, 'precision': 0.6363636255264282, 'recall': 0.5409356951713562, 'auc': 0.647810697555542} \n",
            "299/689 [============>.................] - ETA: 22s - loss: 0.6659 - tp: 2590.0000 - fp: 1480.0000 - tn: 3300.0000 - fn: 2198.0000 - accuracy: 0.6156 - precision: 0.6364 - recall: 0.5409 - auc: 0.6478\n",
            " For Batch Number 300 the model has a loss of {'loss': 0.6666374206542969, 'tp': 2595.0, 'fp': 1483.0, 'tn': 3309.0, 'fn': 2213.0, 'accuracy': 0.6150000095367432, 'precision': 0.6363413333892822, 'recall': 0.5397254824638367, 'auc': 0.6467088460922241} \n",
            "300/689 [============>.................] - ETA: 22s - loss: 0.6666 - tp: 2595.0000 - fp: 1483.0000 - tn: 3309.0000 - fn: 2213.0000 - accuracy: 0.6150 - precision: 0.6363 - recall: 0.5397 - auc: 0.6467\n",
            " For Batch Number 301 the model has a loss of {'loss': 0.6667724251747131, 'tp': 2603.0, 'fp': 1485.0, 'tn': 3320.0, 'fn': 2224.0, 'accuracy': 0.6149293780326843, 'precision': 0.6367416977882385, 'recall': 0.5392583608627319, 'auc': 0.6465600728988647} \n",
            "301/689 [============>.................] - ETA: 22s - loss: 0.6668 - tp: 2603.0000 - fp: 1485.0000 - tn: 3320.0000 - fn: 2224.0000 - accuracy: 0.6149 - precision: 0.6367 - recall: 0.5393 - auc: 0.6466\n",
            " For Batch Number 302 the model has a loss of {'loss': 0.6665835976600647, 'tp': 2613.0, 'fp': 1487.0, 'tn': 3334.0, 'fn': 2230.0, 'accuracy': 0.6153766512870789, 'precision': 0.6373170614242554, 'recall': 0.5395416021347046, 'auc': 0.6467890739440918} \n",
            "\n",
            " For Batch Number 303 the model has a loss of {'loss': 0.6670517325401306, 'tp': 2621.0, 'fp': 1495.0, 'tn': 3345.0, 'fn': 2235.0, 'accuracy': 0.6153053045272827, 'precision': 0.6367833018302917, 'recall': 0.5397446751594543, 'auc': 0.646278440952301} \n",
            "303/689 [============>.................] - ETA: 22s - loss: 0.6671 - tp: 2621.0000 - fp: 1495.0000 - tn: 3345.0000 - fn: 2235.0000 - accuracy: 0.6153 - precision: 0.6368 - recall: 0.5397 - auc: 0.6463\n",
            " For Batch Number 304 the model has a loss of {'loss': 0.6668005585670471, 'tp': 2633.0, 'fp': 1498.0, 'tn': 3356.0, 'fn': 2241.0, 'accuracy': 0.6156455874443054, 'precision': 0.6373759508132935, 'recall': 0.540213406085968, 'auc': 0.646605908870697} \n",
            "\n",
            " For Batch Number 305 the model has a loss of {'loss': 0.6667357683181763, 'tp': 2644.0, 'fp': 1503.0, 'tn': 3367.0, 'fn': 2246.0, 'accuracy': 0.6158811450004578, 'precision': 0.6375693082809448, 'recall': 0.540695309638977, 'auc': 0.6466640830039978} \n",
            "305/689 [============>.................] - ETA: 22s - loss: 0.6667 - tp: 2644.0000 - fp: 1503.0000 - tn: 3367.0000 - fn: 2246.0000 - accuracy: 0.6159 - precision: 0.6376 - recall: 0.5407 - auc: 0.6467\n",
            " For Batch Number 306 the model has a loss of {'loss': 0.6665284633636475, 'tp': 2651.0, 'fp': 1511.0, 'tn': 3382.0, 'fn': 2248.0, 'accuracy': 0.6161152124404907, 'precision': 0.6369534134864807, 'recall': 0.5411308407783508, 'auc': 0.6467344760894775} \n",
            "306/689 [============>.................] - ETA: 21s - loss: 0.6665 - tp: 2651.0000 - fp: 1511.0000 - tn: 3382.0000 - fn: 2248.0000 - accuracy: 0.6161 - precision: 0.6370 - recall: 0.5411 - auc: 0.6467\n",
            " For Batch Number 307 the model has a loss of {'loss': 0.6664571166038513, 'tp': 2657.0, 'fp': 1515.0, 'tn': 3399.0, 'fn': 2253.0, 'accuracy': 0.6164495348930359, 'precision': 0.6368648409843445, 'recall': 0.5411405563354492, 'auc': 0.6467724442481995} \n",
            "307/689 [============>.................] - ETA: 21s - loss: 0.6665 - tp: 2657.0000 - fp: 1515.0000 - tn: 3399.0000 - fn: 2253.0000 - accuracy: 0.6164 - precision: 0.6369 - recall: 0.5411 - auc: 0.6468\n",
            " For Batch Number 308 the model has a loss of {'loss': 0.6666660308837891, 'tp': 2662.0, 'fp': 1517.0, 'tn': 3412.0, 'fn': 2265.0, 'accuracy': 0.616274356842041, 'precision': 0.636994481086731, 'recall': 0.5402882099151611, 'auc': 0.6462931036949158} \n",
            "308/689 [============>.................] - ETA: 21s - loss: 0.6667 - tp: 2662.0000 - fp: 1517.0000 - tn: 3412.0000 - fn: 2265.0000 - accuracy: 0.6163 - precision: 0.6370 - recall: 0.5403 - auc: 0.6463\n",
            " For Batch Number 309 the model has a loss of {'loss': 0.6668651700019836, 'tp': 2665.0, 'fp': 1519.0, 'tn': 3425.0, 'fn': 2279.0, 'accuracy': 0.615898072719574, 'precision': 0.6369503140449524, 'recall': 0.5390372276306152, 'auc': 0.645858108997345} \n",
            "\n",
            " For Batch Number 310 the model has a loss of {'loss': 0.666778564453125, 'tp': 2669.0, 'fp': 1522.0, 'tn': 3441.0, 'fn': 2288.0, 'accuracy': 0.6159273982048035, 'precision': 0.6368408203125, 'recall': 0.5384305119514465, 'auc': 0.6459331512451172} \n",
            "310/689 [============>.................] - ETA: 21s - loss: 0.6668 - tp: 2669.0000 - fp: 1522.0000 - tn: 3441.0000 - fn: 2288.0000 - accuracy: 0.6159 - precision: 0.6368 - recall: 0.5384 - auc: 0.6459\n",
            " For Batch Number 311 the model has a loss of {'loss': 0.6666985154151917, 'tp': 2679.0, 'fp': 1523.0, 'tn': 3449.0, 'fn': 2301.0, 'accuracy': 0.6157556176185608, 'precision': 0.6375535726547241, 'recall': 0.5379518270492554, 'auc': 0.6460778713226318} \n",
            "311/689 [============>.................] - ETA: 21s - loss: 0.6667 - tp: 2679.0000 - fp: 1523.0000 - tn: 3449.0000 - fn: 2301.0000 - accuracy: 0.6158 - precision: 0.6376 - recall: 0.5380 - auc: 0.6461\n",
            " For Batch Number 312 the model has a loss of {'loss': 0.6668391227722168, 'tp': 2693.0, 'fp': 1541.0, 'tn': 3449.0, 'fn': 2301.0, 'accuracy': 0.6151843070983887, 'precision': 0.6360415816307068, 'recall': 0.5392470955848694, 'auc': 0.6458011865615845} \n",
            "\n",
            " For Batch Number 313 the model has a loss of {'loss': 0.6663862466812134, 'tp': 2716.0, 'fp': 1550.0, 'tn': 3449.0, 'fn': 2301.0, 'accuracy': 0.6155151724815369, 'precision': 0.6366620063781738, 'recall': 0.5413593649864197, 'auc': 0.6464925408363342} \n",
            "313/689 [============>.................] - ETA: 21s - loss: 0.6664 - tp: 2716.0000 - fp: 1550.0000 - tn: 3449.0000 - fn: 2301.0000 - accuracy: 0.6155 - precision: 0.6367 - recall: 0.5414 - auc: 0.6465\n",
            " For Batch Number 314 the model has a loss of {'loss': 0.6667837500572205, 'tp': 2729.0, 'fp': 1569.0, 'tn': 3449.0, 'fn': 2301.0, 'accuracy': 0.6148487329483032, 'precision': 0.6349464654922485, 'recall': 0.5425447225570679, 'auc': 0.6459662914276123} \n",
            "314/689 [============>.................] - ETA: 21s - loss: 0.6668 - tp: 2729.0000 - fp: 1569.0000 - tn: 3449.0000 - fn: 2301.0000 - accuracy: 0.6148 - precision: 0.6349 - recall: 0.5425 - auc: 0.6460\n",
            " For Batch Number 315 the model has a loss of {'loss': 0.666683554649353, 'tp': 2739.0, 'fp': 1578.0, 'tn': 3459.0, 'fn': 2304.0, 'accuracy': 0.6148809790611267, 'precision': 0.6344683766365051, 'recall': 0.5431290864944458, 'auc': 0.6459510326385498} \n",
            "315/689 [============>.................] - ETA: 21s - loss: 0.6667 - tp: 2739.0000 - fp: 1578.0000 - tn: 3459.0000 - fn: 2304.0000 - accuracy: 0.6149 - precision: 0.6345 - recall: 0.5431 - auc: 0.6460\n",
            " For Batch Number 316 the model has a loss of {'loss': 0.6668254733085632, 'tp': 2744.0, 'fp': 1580.0, 'tn': 3472.0, 'fn': 2316.0, 'accuracy': 0.6147152185440063, 'precision': 0.6345975995063782, 'recall': 0.5422924757003784, 'auc': 0.6456478238105774} \n",
            "316/689 [============>.................] - ETA: 21s - loss: 0.6668 - tp: 2744.0000 - fp: 1580.0000 - tn: 3472.0000 - fn: 2316.0000 - accuracy: 0.6147 - precision: 0.6346 - recall: 0.5423 - auc: 0.6456\n",
            " For Batch Number 317 the model has a loss of {'loss': 0.6666644215583801, 'tp': 2750.0, 'fp': 1580.0, 'tn': 3487.0, 'fn': 2327.0, 'accuracy': 0.6148462295532227, 'precision': 0.6351039409637451, 'recall': 0.5416584610939026, 'auc': 0.6460249423980713} \n",
            "\n",
            " For Batch Number 318 the model has a loss of {'loss': 0.6666157245635986, 'tp': 2756.0, 'fp': 1582.0, 'tn': 3501.0, 'fn': 2337.0, 'accuracy': 0.6148781180381775, 'precision': 0.6353158354759216, 'recall': 0.5411348938941956, 'auc': 0.6462081074714661} \n",
            "318/689 [============>.................] - ETA: 21s - loss: 0.6666 - tp: 2756.0000 - fp: 1582.0000 - tn: 3501.0000 - fn: 2337.0000 - accuracy: 0.6149 - precision: 0.6353 - recall: 0.5411 - auc: 0.6462\n",
            " For Batch Number 319 the model has a loss of {'loss': 0.6665889620780945, 'tp': 2765.0, 'fp': 1583.0, 'tn': 3514.0, 'fn': 2346.0, 'accuracy': 0.6151058077812195, 'precision': 0.6359245777130127, 'recall': 0.5409899950027466, 'auc': 0.6463371515274048} \n",
            "319/689 [============>.................] - ETA: 21s - loss: 0.6666 - tp: 2765.0000 - fp: 1583.0000 - tn: 3514.0000 - fn: 2346.0000 - accuracy: 0.6151 - precision: 0.6359 - recall: 0.5410 - auc: 0.6463\n",
            " For Batch Number 320 the model has a loss of {'loss': 0.6666189432144165, 'tp': 2776.0, 'fp': 1587.0, 'tn': 3526.0, 'fn': 2351.0, 'accuracy': 0.615429699420929, 'precision': 0.6362594366073608, 'recall': 0.5414472222328186, 'auc': 0.6464172601699829} \n",
            "320/689 [============>.................] - ETA: 21s - loss: 0.6666 - tp: 2776.0000 - fp: 1587.0000 - tn: 3526.0000 - fn: 2351.0000 - accuracy: 0.6154 - precision: 0.6363 - recall: 0.5414 - auc: 0.6464\n",
            " For Batch Number 321 the model has a loss of {'loss': 0.6665448546409607, 'tp': 2788.0, 'fp': 1595.0, 'tn': 3533.0, 'fn': 2356.0, 'accuracy': 0.6153621673583984, 'precision': 0.6360939741134644, 'recall': 0.5419906973838806, 'auc': 0.6465297341346741} \n",
            "\n",
            " For Batch Number 322 the model has a loss of {'loss': 0.6666311621665955, 'tp': 2798.0, 'fp': 1604.0, 'tn': 3542.0, 'fn': 2360.0, 'accuracy': 0.6152950525283813, 'precision': 0.6356201767921448, 'recall': 0.5424582958221436, 'auc': 0.6463416814804077} \n",
            "322/689 [=============>................] - ETA: 20s - loss: 0.6666 - tp: 2798.0000 - fp: 1604.0000 - tn: 3542.0000 - fn: 2360.0000 - accuracy: 0.6153 - precision: 0.6356 - recall: 0.5425 - auc: 0.6463\n",
            " For Batch Number 323 the model has a loss of {'loss': 0.6666996479034424, 'tp': 2808.0, 'fp': 1610.0, 'tn': 3553.0, 'fn': 2365.0, 'accuracy': 0.6154218316078186, 'precision': 0.6355817317962646, 'recall': 0.5428184866905212, 'auc': 0.6464309096336365} \n",
            "323/689 [=============>................] - ETA: 20s - loss: 0.6667 - tp: 2808.0000 - fp: 1610.0000 - tn: 3553.0000 - fn: 2365.0000 - accuracy: 0.6154 - precision: 0.6356 - recall: 0.5428 - auc: 0.6464\n",
            " For Batch Number 324 the model has a loss of {'loss': 0.6665363311767578, 'tp': 2820.0, 'fp': 1616.0, 'tn': 3564.0, 'fn': 2368.0, 'accuracy': 0.6157407164573669, 'precision': 0.6357078552246094, 'recall': 0.5435620546340942, 'auc': 0.6468899846076965} \n",
            "324/689 [=============>................] - ETA: 20s - loss: 0.6665 - tp: 2820.0000 - fp: 1616.0000 - tn: 3564.0000 - fn: 2368.0000 - accuracy: 0.6157 - precision: 0.6357 - recall: 0.5436 - auc: 0.6469\n",
            " For Batch Number 325 the model has a loss of {'loss': 0.6662017703056335, 'tp': 2830.0, 'fp': 1618.0, 'tn': 3578.0, 'fn': 2374.0, 'accuracy': 0.6161538362503052, 'precision': 0.6362410187721252, 'recall': 0.5438124537467957, 'auc': 0.6473531723022461} \n",
            "325/689 [=============>................] - ETA: 20s - loss: 0.6662 - tp: 2830.0000 - fp: 1618.0000 - tn: 3578.0000 - fn: 2374.0000 - accuracy: 0.6162 - precision: 0.6362 - recall: 0.5438 - auc: 0.6474\n",
            " For Batch Number 326 the model has a loss of {'loss': 0.6666390895843506, 'tp': 2837.0, 'fp': 1623.0, 'tn': 3587.0, 'fn': 2385.0, 'accuracy': 0.6157975196838379, 'precision': 0.6360986828804016, 'recall': 0.5432784557342529, 'auc': 0.6467992663383484} \n",
            "\n",
            " For Batch Number 327 the model has a loss of {'loss': 0.6662633419036865, 'tp': 2843.0, 'fp': 1627.0, 'tn': 3605.0, 'fn': 2389.0, 'accuracy': 0.6162079572677612, 'precision': 0.636017918586731, 'recall': 0.5433868765830994, 'auc': 0.6473252773284912} \n",
            "327/689 [=============>................] - ETA: 20s - loss: 0.6663 - tp: 2843.0000 - fp: 1627.0000 - tn: 3605.0000 - fn: 2389.0000 - accuracy: 0.6162 - precision: 0.6360 - recall: 0.5434 - auc: 0.6473\n",
            " For Batch Number 328 the model has a loss of {'loss': 0.6660676002502441, 'tp': 2849.0, 'fp': 1630.0, 'tn': 3620.0, 'fn': 2397.0, 'accuracy': 0.6163300275802612, 'precision': 0.6360794901847839, 'recall': 0.5430804491043091, 'auc': 0.6476138830184937} \n",
            "\n",
            " For Batch Number 329 the model has a loss of {'loss': 0.6661392450332642, 'tp': 2858.0, 'fp': 1631.0, 'tn': 3633.0, 'fn': 2406.0, 'accuracy': 0.6165463328361511, 'precision': 0.6366674304008484, 'recall': 0.5429331064224243, 'auc': 0.6476740837097168} \n",
            "329/689 [=============>................] - ETA: 20s - loss: 0.6661 - tp: 2858.0000 - fp: 1631.0000 - tn: 3633.0000 - fn: 2406.0000 - accuracy: 0.6165 - precision: 0.6367 - recall: 0.5429 - auc: 0.6477\n",
            " For Batch Number 330 the model has a loss of {'loss': 0.6661711931228638, 'tp': 2862.0, 'fp': 1638.0, 'tn': 3649.0, 'fn': 2411.0, 'accuracy': 0.6165719628334045, 'precision': 0.6359999775886536, 'recall': 0.5427650213241577, 'auc': 0.6478157043457031} \n",
            "\n",
            " For Batch Number 331 the model has a loss of {'loss': 0.6661815643310547, 'tp': 2867.0, 'fp': 1642.0, 'tn': 3664.0, 'fn': 2419.0, 'accuracy': 0.6165974140167236, 'precision': 0.6358394026756287, 'recall': 0.5423761010169983, 'auc': 0.6477362513542175} \n",
            "331/689 [=============>................] - ETA: 20s - loss: 0.6662 - tp: 2867.0000 - fp: 1642.0000 - tn: 3664.0000 - fn: 2419.0000 - accuracy: 0.6166 - precision: 0.6358 - recall: 0.5424 - auc: 0.6477\n",
            " For Batch Number 332 the model has a loss of {'loss': 0.666130542755127, 'tp': 2876.0, 'fp': 1643.0, 'tn': 3674.0, 'fn': 2431.0, 'accuracy': 0.6165286302566528, 'precision': 0.6364240050315857, 'recall': 0.5419257879257202, 'auc': 0.6478040814399719} \n",
            "332/689 [=============>................] - ETA: 20s - loss: 0.6661 - tp: 2876.0000 - fp: 1643.0000 - tn: 3674.0000 - fn: 2431.0000 - accuracy: 0.6165 - precision: 0.6364 - recall: 0.5419 - auc: 0.6478\n",
            " For Batch Number 333 the model has a loss of {'loss': 0.6663435101509094, 'tp': 2885.0, 'fp': 1648.0, 'tn': 3682.0, 'fn': 2441.0, 'accuracy': 0.616272509098053, 'precision': 0.6364438533782959, 'recall': 0.5416823029518127, 'auc': 0.6474674344062805} \n",
            "333/689 [=============>................] - ETA: 20s - loss: 0.6663 - tp: 2885.0000 - fp: 1648.0000 - tn: 3682.0000 - fn: 2441.0000 - accuracy: 0.6163 - precision: 0.6364 - recall: 0.5417 - auc: 0.6475\n",
            " For Batch Number 334 the model has a loss of {'loss': 0.666414201259613, 'tp': 2900.0, 'fp': 1662.0, 'tn': 3685.0, 'fn': 2441.0, 'accuracy': 0.6161115169525146, 'precision': 0.6356860995292664, 'recall': 0.5429694652557373, 'auc': 0.6473094820976257} \n",
            "334/689 [=============>................] - ETA: 20s - loss: 0.6664 - tp: 2900.0000 - fp: 1662.0000 - tn: 3685.0000 - fn: 2441.0000 - accuracy: 0.6161 - precision: 0.6357 - recall: 0.5430 - auc: 0.6473\n",
            " For Batch Number 335 the model has a loss of {'loss': 0.6663700938224792, 'tp': 2920.0, 'fp': 1673.0, 'tn': 3685.0, 'fn': 2442.0, 'accuracy': 0.6161380410194397, 'precision': 0.6357500553131104, 'recall': 0.5445729494094849, 'auc': 0.6474746465682983} \n",
            "\n",
            " For Batch Number 336 the model has a loss of {'loss': 0.6668309569358826, 'tp': 2934.0, 'fp': 1691.0, 'tn': 3685.0, 'fn': 2442.0, 'accuracy': 0.615606427192688, 'precision': 0.6343783736228943, 'recall': 0.5457589030265808, 'auc': 0.6469736099243164} \n",
            "336/689 [=============>................] - ETA: 19s - loss: 0.6668 - tp: 2934.0000 - fp: 1691.0000 - tn: 3685.0000 - fn: 2442.0000 - accuracy: 0.6156 - precision: 0.6344 - recall: 0.5458 - auc: 0.6470\n",
            " For Batch Number 337 the model has a loss of {'loss': 0.6669107675552368, 'tp': 2950.0, 'fp': 1706.0, 'tn': 3686.0, 'fn': 2442.0, 'accuracy': 0.6153560876846313, 'precision': 0.6335910558700562, 'recall': 0.5471068024635315, 'auc': 0.6468833684921265} \n",
            "\n",
            " For Batch Number 338 the model has a loss of {'loss': 0.666910707950592, 'tp': 2957.0, 'fp': 1715.0, 'tn': 3697.0, 'fn': 2447.0, 'accuracy': 0.6151996850967407, 'precision': 0.6329195499420166, 'recall': 0.5471872687339783, 'auc': 0.6467333436012268} \n",
            "338/689 [=============>................] - ETA: 19s - loss: 0.6669 - tp: 2957.0000 - fp: 1715.0000 - tn: 3697.0000 - fn: 2447.0000 - accuracy: 0.6152 - precision: 0.6329 - recall: 0.5472 - auc: 0.6467\n",
            " For Batch Number 339 the model has a loss of {'loss': 0.6671009063720703, 'tp': 2960.0, 'fp': 1719.0, 'tn': 3708.0, 'fn': 2461.0, 'accuracy': 0.6146755218505859, 'precision': 0.6326137781143188, 'recall': 0.546024739742279, 'auc': 0.6462613940238953} \n",
            "339/689 [=============>................] - ETA: 19s - loss: 0.6671 - tp: 2960.0000 - fp: 1719.0000 - tn: 3708.0000 - fn: 2461.0000 - accuracy: 0.6147 - precision: 0.6326 - recall: 0.5460 - auc: 0.6463\n",
            " For Batch Number 340 the model has a loss of {'loss': 0.6674240231513977, 'tp': 2962.0, 'fp': 1721.0, 'tn': 3719.0, 'fn': 2478.0, 'accuracy': 0.614062488079071, 'precision': 0.6325005292892456, 'recall': 0.5444852709770203, 'auc': 0.6455230712890625} \n",
            "340/689 [=============>................] - ETA: 19s - loss: 0.6674 - tp: 2962.0000 - fp: 1721.0000 - tn: 3719.0000 - fn: 2478.0000 - accuracy: 0.6141 - precision: 0.6325 - recall: 0.5445 - auc: 0.6455\n",
            " For Batch Number 341 the model has a loss of {'loss': 0.6672360301017761, 'tp': 2967.0, 'fp': 1722.0, 'tn': 3738.0, 'fn': 2485.0, 'accuracy': 0.6144611239433289, 'precision': 0.6327575445175171, 'recall': 0.5442039370536804, 'auc': 0.6457812190055847} \n",
            "341/689 [=============>................] - ETA: 19s - loss: 0.6672 - tp: 2967.0000 - fp: 1722.0000 - tn: 3738.0000 - fn: 2485.0000 - accuracy: 0.6145 - precision: 0.6328 - recall: 0.5442 - auc: 0.6458\n",
            " For Batch Number 342 the model has a loss of {'loss': 0.6676816940307617, 'tp': 2971.0, 'fp': 1726.0, 'tn': 3745.0, 'fn': 2502.0, 'accuracy': 0.6136695742607117, 'precision': 0.6325314044952393, 'recall': 0.5428466796875, 'auc': 0.6449123024940491} \n",
            "\n",
            " For Batch Number 343 the model has a loss of {'loss': 0.6678267121315002, 'tp': 2974.0, 'fp': 1731.0, 'tn': 3758.0, 'fn': 2513.0, 'accuracy': 0.6133381724357605, 'precision': 0.6320934891700745, 'recall': 0.5420083999633789, 'auc': 0.6446317434310913} \n",
            "343/689 [=============>................] - ETA: 19s - loss: 0.6678 - tp: 2974.0000 - fp: 1731.0000 - tn: 3758.0000 - fn: 2513.0000 - accuracy: 0.6133 - precision: 0.6321 - recall: 0.5420 - auc: 0.6446\n",
            " For Batch Number 344 the model has a loss of {'loss': 0.6676965951919556, 'tp': 2983.0, 'fp': 1736.0, 'tn': 3770.0, 'fn': 2519.0, 'accuracy': 0.6134629249572754, 'precision': 0.6321254372596741, 'recall': 0.5421664714813232, 'auc': 0.6447515487670898} \n",
            "\n",
            " For Batch Number 345 the model has a loss of {'loss': 0.6677421927452087, 'tp': 2992.0, 'fp': 1747.0, 'tn': 3779.0, 'fn': 2522.0, 'accuracy': 0.613315224647522, 'precision': 0.6313568353652954, 'recall': 0.5426188111305237, 'auc': 0.6445372700691223} \n",
            "345/689 [==============>...............] - ETA: 19s - loss: 0.6677 - tp: 2992.0000 - fp: 1747.0000 - tn: 3779.0000 - fn: 2522.0000 - accuracy: 0.6133 - precision: 0.6314 - recall: 0.5426 - auc: 0.6445\n",
            " For Batch Number 346 the model has a loss of {'loss': 0.6676989197731018, 'tp': 3003.0, 'fp': 1757.0, 'tn': 3787.0, 'fn': 2525.0, 'accuracy': 0.6132586598396301, 'precision': 0.6308823823928833, 'recall': 0.5432344675064087, 'auc': 0.644507110118866} \n",
            "\n",
            " For Batch Number 347 the model has a loss of {'loss': 0.6675759553909302, 'tp': 3012.0, 'fp': 1767.0, 'tn': 3798.0, 'fn': 2527.0, 'accuracy': 0.6132925152778625, 'precision': 0.6302573680877686, 'recall': 0.5437804460525513, 'auc': 0.6445392966270447} \n",
            "347/689 [==============>...............] - ETA: 19s - loss: 0.6676 - tp: 3012.0000 - fp: 1767.0000 - tn: 3798.0000 - fn: 2527.0000 - accuracy: 0.6133 - precision: 0.6303 - recall: 0.5438 - auc: 0.6445\n",
            " For Batch Number 348 the model has a loss of {'loss': 0.6675494313240051, 'tp': 3017.0, 'fp': 1769.0, 'tn': 3816.0, 'fn': 2534.0, 'accuracy': 0.6135955452919006, 'precision': 0.6303802728652954, 'recall': 0.5435056686401367, 'auc': 0.644637405872345} \n",
            "348/689 [==============>...............] - ETA: 19s - loss: 0.6675 - tp: 3017.0000 - fp: 1769.0000 - tn: 3816.0000 - fn: 2534.0000 - accuracy: 0.6136 - precision: 0.6304 - recall: 0.5435 - auc: 0.6446\n",
            " For Batch Number 349 the model has a loss of {'loss': 0.6675774455070496, 'tp': 3020.0, 'fp': 1770.0, 'tn': 3833.0, 'fn': 2545.0, 'accuracy': 0.6136282086372375, 'precision': 0.630480170249939, 'recall': 0.5426774621009827, 'auc': 0.6446611881256104} \n",
            "349/689 [==============>...............] - ETA: 19s - loss: 0.6676 - tp: 3020.0000 - fp: 1770.0000 - tn: 3833.0000 - fn: 2545.0000 - accuracy: 0.6136 - precision: 0.6305 - recall: 0.5427 - auc: 0.6447\n",
            " For Batch Number 350 the model has a loss of {'loss': 0.6679558157920837, 'tp': 3023.0, 'fp': 1770.0, 'tn': 3848.0, 'fn': 2559.0, 'accuracy': 0.6134821176528931, 'precision': 0.6307114362716675, 'recall': 0.5415621399879456, 'auc': 0.6441589593887329} \n",
            "350/689 [==============>...............] - ETA: 19s - loss: 0.6680 - tp: 3023.0000 - fp: 1770.0000 - tn: 3848.0000 - fn: 2559.0000 - accuracy: 0.6135 - precision: 0.6307 - recall: 0.5416 - auc: 0.6442\n",
            " For Batch Number 351 the model has a loss of {'loss': 0.6683104634284973, 'tp': 3026.0, 'fp': 1770.0, 'tn': 3862.0, 'fn': 2574.0, 'accuracy': 0.6132478713989258, 'precision': 0.6309424638748169, 'recall': 0.5403571724891663, 'auc': 0.6437118053436279} \n",
            "351/689 [==============>...............] - ETA: 19s - loss: 0.6683 - tp: 3026.0000 - fp: 1770.0000 - tn: 3862.0000 - fn: 2574.0000 - accuracy: 0.6132 - precision: 0.6309 - recall: 0.5404 - auc: 0.6437\n",
            " For Batch Number 352 the model has a loss of {'loss': 0.6684336066246033, 'tp': 3029.0, 'fp': 1770.0, 'tn': 3877.0, 'fn': 2588.0, 'accuracy': 0.6131036877632141, 'precision': 0.6311731338500977, 'recall': 0.5392558574676514, 'auc': 0.6434336304664612} \n",
            "\n",
            " For Batch Number 353 the model has a loss of {'loss': 0.6681970357894897, 'tp': 3037.0, 'fp': 1770.0, 'tn': 3895.0, 'fn': 2594.0, 'accuracy': 0.6136685609817505, 'precision': 0.6317870020866394, 'recall': 0.5393358469009399, 'auc': 0.6437363028526306} \n",
            "353/689 [==============>...............] - ETA: 18s - loss: 0.6682 - tp: 3037.0000 - fp: 1770.0000 - tn: 3895.0000 - fn: 2594.0000 - accuracy: 0.6137 - precision: 0.6318 - recall: 0.5393 - auc: 0.6437\n",
            " For Batch Number 354 the model has a loss of {'loss': 0.6681448817253113, 'tp': 3047.0, 'fp': 1774.0, 'tn': 3905.0, 'fn': 2602.0, 'accuracy': 0.6137005686759949, 'precision': 0.6320265531539917, 'recall': 0.5393875241279602, 'auc': 0.643744170665741} \n",
            "354/689 [==============>...............] - ETA: 18s - loss: 0.6681 - tp: 3047.0000 - fp: 1774.0000 - tn: 3905.0000 - fn: 2602.0000 - accuracy: 0.6137 - precision: 0.6320 - recall: 0.5394 - auc: 0.6437\n",
            " For Batch Number 355 the model has a loss of {'loss': 0.6679629683494568, 'tp': 3060.0, 'fp': 1776.0, 'tn': 3915.0, 'fn': 2609.0, 'accuracy': 0.6139965057373047, 'precision': 0.6327543258666992, 'recall': 0.5397777557373047, 'auc': 0.6440249085426331} \n",
            "355/689 [==============>...............] - ETA: 18s - loss: 0.6680 - tp: 3060.0000 - fp: 1776.0000 - tn: 3915.0000 - fn: 2609.0000 - accuracy: 0.6140 - precision: 0.6328 - recall: 0.5398 - auc: 0.6440\n",
            " For Batch Number 356 the model has a loss of {'loss': 0.6679088473320007, 'tp': 3076.0, 'fp': 1789.0, 'tn': 3917.0, 'fn': 2610.0, 'accuracy': 0.6138518452644348, 'precision': 0.6322713494300842, 'recall': 0.5409778356552124, 'auc': 0.6440584659576416} \n",
            "356/689 [==============>...............] - ETA: 18s - loss: 0.6679 - tp: 3076.0000 - fp: 1789.0000 - tn: 3917.0000 - fn: 2610.0000 - accuracy: 0.6139 - precision: 0.6323 - recall: 0.5410 - auc: 0.6441\n",
            " For Batch Number 357 the model has a loss of {'loss': 0.6677582263946533, 'tp': 3094.0, 'fp': 1802.0, 'tn': 3918.0, 'fn': 2610.0, 'accuracy': 0.6137955188751221, 'precision': 0.6319444179534912, 'recall': 0.542426347732544, 'auc': 0.6442615985870361} \n",
            "357/689 [==============>...............] - ETA: 18s - loss: 0.6678 - tp: 3094.0000 - fp: 1802.0000 - tn: 3918.0000 - fn: 2610.0000 - accuracy: 0.6138 - precision: 0.6319 - recall: 0.5424 - auc: 0.6443\n",
            " For Batch Number 358 the model has a loss of {'loss': 0.6678587198257446, 'tp': 3107.0, 'fp': 1818.0, 'tn': 3920.0, 'fn': 2611.0, 'accuracy': 0.6133903861045837, 'precision': 0.6308629512786865, 'recall': 0.5433717966079712, 'auc': 0.6440785527229309} \n",
            "358/689 [==============>...............] - ETA: 18s - loss: 0.6679 - tp: 3107.0000 - fp: 1818.0000 - tn: 3920.0000 - fn: 2611.0000 - accuracy: 0.6134 - precision: 0.6309 - recall: 0.5434 - auc: 0.6441\n",
            " For Batch Number 359 the model has a loss of {'loss': 0.6676058769226074, 'tp': 3119.0, 'fp': 1823.0, 'tn': 3928.0, 'fn': 2618.0, 'accuracy': 0.613422691822052, 'precision': 0.6311209797859192, 'recall': 0.5436639189720154, 'auc': 0.6443184614181519} \n",
            "359/689 [==============>...............] - ETA: 18s - loss: 0.6676 - tp: 3119.0000 - fp: 1823.0000 - tn: 3928.0000 - fn: 2618.0000 - accuracy: 0.6134 - precision: 0.6311 - recall: 0.5437 - auc: 0.6443\n",
            " For Batch Number 360 the model has a loss of {'loss': 0.6676008105278015, 'tp': 3128.0, 'fp': 1827.0, 'tn': 3934.0, 'fn': 2631.0, 'accuracy': 0.6130208373069763, 'precision': 0.6312815546989441, 'recall': 0.5431498289108276, 'auc': 0.6442662477493286} \n",
            "\n",
            " For Batch Number 361 the model has a loss of {'loss': 0.6675657629966736, 'tp': 3134.0, 'fp': 1834.0, 'tn': 3949.0, 'fn': 2635.0, 'accuracy': 0.6131405830383301, 'precision': 0.6308373808860779, 'recall': 0.5432484149932861, 'auc': 0.6442692875862122} \n",
            "361/689 [==============>...............] - ETA: 18s - loss: 0.6676 - tp: 3134.0000 - fp: 1834.0000 - tn: 3949.0000 - fn: 2635.0000 - accuracy: 0.6131 - precision: 0.6308 - recall: 0.5432 - auc: 0.6443\n",
            " For Batch Number 362 the model has a loss of {'loss': 0.6675302386283875, 'tp': 3143.0, 'fp': 1835.0, 'tn': 3961.0, 'fn': 2645.0, 'accuracy': 0.6132596731185913, 'precision': 0.6313780546188354, 'recall': 0.5430200695991516, 'auc': 0.6442421078681946} \n",
            "\n",
            " For Batch Number 363 the model has a loss of {'loss': 0.6677770018577576, 'tp': 3148.0, 'fp': 1840.0, 'tn': 3971.0, 'fn': 2657.0, 'accuracy': 0.6128615736961365, 'precision': 0.631114661693573, 'recall': 0.5422911047935486, 'auc': 0.6437463164329529} \n",
            "363/689 [==============>...............] - ETA: 18s - loss: 0.6678 - tp: 3148.0000 - fp: 1840.0000 - tn: 3971.0000 - fn: 2657.0000 - accuracy: 0.6129 - precision: 0.6311 - recall: 0.5423 - auc: 0.6437\n",
            " For Batch Number 364 the model has a loss of {'loss': 0.6675729155540466, 'tp': 3156.0, 'fp': 1842.0, 'tn': 3985.0, 'fn': 2665.0, 'accuracy': 0.6130666136741638, 'precision': 0.6314525604248047, 'recall': 0.5421748757362366, 'auc': 0.6440216302871704} \n",
            "\n",
            " For Batch Number 365 the model has a loss of {'loss': 0.667400062084198, 'tp': 3162.0, 'fp': 1845.0, 'tn': 3999.0, 'fn': 2674.0, 'accuracy': 0.6130993366241455, 'precision': 0.6315158605575562, 'recall': 0.5418094396591187, 'auc': 0.6441916227340698} \n",
            "365/689 [==============>...............] - ETA: 18s - loss: 0.6674 - tp: 3162.0000 - fp: 1845.0000 - tn: 3999.0000 - fn: 2674.0000 - accuracy: 0.6131 - precision: 0.6315 - recall: 0.5418 - auc: 0.6442\n",
            " For Batch Number 366 the model has a loss of {'loss': 0.6678591370582581, 'tp': 3164.0, 'fp': 1854.0, 'tn': 4012.0, 'fn': 2682.0, 'accuracy': 0.6127049326896667, 'precision': 0.6305301189422607, 'recall': 0.5412247776985168, 'auc': 0.6436156630516052} \n",
            "\n",
            " For Batch Number 367 the model has a loss of {'loss': 0.6678959131240845, 'tp': 3170.0, 'fp': 1857.0, 'tn': 4023.0, 'fn': 2694.0, 'accuracy': 0.6124829649925232, 'precision': 0.630594789981842, 'recall': 0.5405866503715515, 'auc': 0.6436105966567993} \n",
            "367/689 [==============>...............] - ETA: 18s - loss: 0.6679 - tp: 3170.0000 - fp: 1857.0000 - tn: 4023.0000 - fn: 2694.0000 - accuracy: 0.6125 - precision: 0.6306 - recall: 0.5406 - auc: 0.6436\n",
            " For Batch Number 368 the model has a loss of {'loss': 0.6679726839065552, 'tp': 3176.0, 'fp': 1860.0, 'tn': 4037.0, 'fn': 2703.0, 'accuracy': 0.6125169992446899, 'precision': 0.630659282207489, 'recall': 0.5402279496192932, 'auc': 0.6433997750282288} \n",
            "368/689 [===============>..............] - ETA: 18s - loss: 0.6680 - tp: 3176.0000 - fp: 1860.0000 - tn: 4037.0000 - fn: 2703.0000 - accuracy: 0.6125 - precision: 0.6307 - recall: 0.5402 - auc: 0.6434\n",
            " For Batch Number 369 the model has a loss of {'loss': 0.66815185546875, 'tp': 3181.0, 'fp': 1864.0, 'tn': 4046.0, 'fn': 2717.0, 'accuracy': 0.6120426654815674, 'precision': 0.6305252909660339, 'recall': 0.5393353700637817, 'auc': 0.6430341601371765} \n",
            "369/689 [===============>..............] - ETA: 17s - loss: 0.6682 - tp: 3181.0000 - fp: 1864.0000 - tn: 4046.0000 - fn: 2717.0000 - accuracy: 0.6120 - precision: 0.6305 - recall: 0.5393 - auc: 0.6430\n",
            " For Batch Number 370 the model has a loss of {'loss': 0.6682485342025757, 'tp': 3186.0, 'fp': 1869.0, 'tn': 4057.0, 'fn': 2728.0, 'accuracy': 0.6117398738861084, 'precision': 0.6302670836448669, 'recall': 0.5387216806411743, 'auc': 0.6429369449615479} \n",
            "370/689 [===============>..............] - ETA: 17s - loss: 0.6682 - tp: 3186.0000 - fp: 1869.0000 - tn: 4057.0000 - fn: 2728.0000 - accuracy: 0.6117 - precision: 0.6303 - recall: 0.5387 - auc: 0.6429\n",
            " For Batch Number 371 the model has a loss of {'loss': 0.6682665348052979, 'tp': 3198.0, 'fp': 1879.0, 'tn': 4064.0, 'fn': 2731.0, 'accuracy': 0.6116913557052612, 'precision': 0.6298995614051819, 'recall': 0.5393826961517334, 'auc': 0.6428828835487366} \n",
            "\n",
            " For Batch Number 372 the model has a loss of {'loss': 0.6684478521347046, 'tp': 3211.0, 'fp': 1893.0, 'tn': 4068.0, 'fn': 2732.0, 'accuracy': 0.6114751100540161, 'precision': 0.6291144490242004, 'recall': 0.5402995347976685, 'auc': 0.6425862908363342} \n",
            "372/689 [===============>..............] - ETA: 17s - loss: 0.6684 - tp: 3211.0000 - fp: 1893.0000 - tn: 4068.0000 - fn: 2732.0000 - accuracy: 0.6115 - precision: 0.6291 - recall: 0.5403 - auc: 0.6426\n",
            " For Batch Number 373 the model has a loss of {'loss': 0.6685065031051636, 'tp': 3223.0, 'fp': 1903.0, 'tn': 4075.0, 'fn': 2735.0, 'accuracy': 0.6114276051521301, 'precision': 0.6287553906440735, 'recall': 0.5409533381462097, 'auc': 0.6425270438194275} \n",
            "\n",
            " For Batch Number 374 the model has a loss of {'loss': 0.6684266924858093, 'tp': 3231.0, 'fp': 1909.0, 'tn': 4086.0, 'fn': 2742.0, 'accuracy': 0.6113803386688232, 'precision': 0.628599226474762, 'recall': 0.5409342050552368, 'auc': 0.6425634622573853} \n",
            "374/689 [===============>..............] - ETA: 17s - loss: 0.6684 - tp: 3231.0000 - fp: 1909.0000 - tn: 4086.0000 - fn: 2742.0000 - accuracy: 0.6114 - precision: 0.6286 - recall: 0.5409 - auc: 0.6426\n",
            " For Batch Number 375 the model has a loss of {'loss': 0.6682186126708984, 'tp': 3240.0, 'fp': 1910.0, 'tn': 4099.0, 'fn': 2751.0, 'accuracy': 0.6115833520889282, 'precision': 0.6291261911392212, 'recall': 0.5408112406730652, 'auc': 0.6428707838058472} \n",
            "375/689 [===============>..............] - ETA: 17s - loss: 0.6682 - tp: 3240.0000 - fp: 1910.0000 - tn: 4099.0000 - fn: 2751.0000 - accuracy: 0.6116 - precision: 0.6291 - recall: 0.5408 - auc: 0.6429\n",
            " For Batch Number 376 the model has a loss of {'loss': 0.6684738397598267, 'tp': 3245.0, 'fp': 1912.0, 'tn': 4107.0, 'fn': 2768.0, 'accuracy': 0.6110372543334961, 'precision': 0.6292418241500854, 'recall': 0.539664089679718, 'auc': 0.6423680782318115} \n",
            "376/689 [===============>..............] - ETA: 17s - loss: 0.6685 - tp: 3245.0000 - fp: 1912.0000 - tn: 4107.0000 - fn: 2768.0000 - accuracy: 0.6110 - precision: 0.6292 - recall: 0.5397 - auc: 0.6424\n",
            " For Batch Number 377 the model has a loss of {'loss': 0.6683690547943115, 'tp': 3253.0, 'fp': 1916.0, 'tn': 4119.0, 'fn': 2776.0, 'accuracy': 0.6110742688179016, 'precision': 0.6293286681175232, 'recall': 0.5395588278770447, 'auc': 0.642478883266449} \n",
            "\n",
            " For Batch Number 378 the model has a loss of {'loss': 0.6685396432876587, 'tp': 3261.0, 'fp': 1924.0, 'tn': 4131.0, 'fn': 2780.0, 'accuracy': 0.6111111044883728, 'precision': 0.628929615020752, 'recall': 0.5398113131523132, 'auc': 0.6422703266143799} \n",
            "378/689 [===============>..............] - ETA: 17s - loss: 0.6685 - tp: 3261.0000 - fp: 1924.0000 - tn: 4131.0000 - fn: 2780.0000 - accuracy: 0.6111 - precision: 0.6289 - recall: 0.5398 - auc: 0.6423\n",
            " For Batch Number 379 the model has a loss of {'loss': 0.6685786843299866, 'tp': 3272.0, 'fp': 1932.0, 'tn': 4140.0, 'fn': 2784.0, 'accuracy': 0.6111477613449097, 'precision': 0.6287471055984497, 'recall': 0.5402905941009521, 'auc': 0.6421462297439575} \n",
            "\n",
            " For Batch Number 380 the model has a loss of {'loss': 0.6684200167655945, 'tp': 3286.0, 'fp': 1937.0, 'tn': 4149.0, 'fn': 2788.0, 'accuracy': 0.6114309430122375, 'precision': 0.629140317440033, 'recall': 0.54099440574646, 'auc': 0.6422886848449707} \n",
            "380/689 [===============>..............] - ETA: 17s - loss: 0.6684 - tp: 3286.0000 - fp: 1937.0000 - tn: 4149.0000 - fn: 2788.0000 - accuracy: 0.6114 - precision: 0.6291 - recall: 0.5410 - auc: 0.6423\n",
            " For Batch Number 381 the model has a loss of {'loss': 0.6687219142913818, 'tp': 3293.0, 'fp': 1948.0, 'tn': 4156.0, 'fn': 2795.0, 'accuracy': 0.6109744310379028, 'precision': 0.6283152103424072, 'recall': 0.5409001111984253, 'auc': 0.6418415904045105} \n",
            "381/689 [===============>..............] - ETA: 17s - loss: 0.6687 - tp: 3293.0000 - fp: 1948.0000 - tn: 4156.0000 - fn: 2795.0000 - accuracy: 0.6110 - precision: 0.6283 - recall: 0.5409 - auc: 0.6418\n",
            " For Batch Number 382 the model has a loss of {'loss': 0.6684600114822388, 'tp': 3304.0, 'fp': 1950.0, 'tn': 4169.0, 'fn': 2801.0, 'accuracy': 0.6113383769989014, 'precision': 0.6288542151451111, 'recall': 0.5411957502365112, 'auc': 0.6422127485275269} \n",
            "382/689 [===============>..............] - ETA: 17s - loss: 0.6685 - tp: 3304.0000 - fp: 1950.0000 - tn: 4169.0000 - fn: 2801.0000 - accuracy: 0.6113 - precision: 0.6289 - recall: 0.5412 - auc: 0.6422\n",
            " For Batch Number 383 the model has a loss of {'loss': 0.6681471467018127, 'tp': 3312.0, 'fp': 1956.0, 'tn': 4184.0, 'fn': 2804.0, 'accuracy': 0.6116188168525696, 'precision': 0.6287015676498413, 'recall': 0.541530430316925, 'auc': 0.6425678730010986} \n",
            "383/689 [===============>..............] - ETA: 17s - loss: 0.6681 - tp: 3312.0000 - fp: 1956.0000 - tn: 4184.0000 - fn: 2804.0000 - accuracy: 0.6116 - precision: 0.6287 - recall: 0.5415 - auc: 0.6426\n",
            " For Batch Number 384 the model has a loss of {'loss': 0.6680993437767029, 'tp': 3320.0, 'fp': 1958.0, 'tn': 4196.0, 'fn': 2814.0, 'accuracy': 0.6116536259651184, 'precision': 0.6290261745452881, 'recall': 0.5412455201148987, 'auc': 0.6425763964653015} \n",
            "384/689 [===============>..............] - ETA: 17s - loss: 0.6681 - tp: 3320.0000 - fp: 1958.0000 - tn: 4196.0000 - fn: 2814.0000 - accuracy: 0.6117 - precision: 0.6290 - recall: 0.5412 - auc: 0.6426\n",
            " For Batch Number 385 the model has a loss of {'loss': 0.6680871844291687, 'tp': 3326.0, 'fp': 1960.0, 'tn': 4212.0, 'fn': 2822.0, 'accuracy': 0.6118506789207458, 'precision': 0.6292092204093933, 'recall': 0.5409889221191406, 'auc': 0.6426078081130981} \n",
            "385/689 [===============>..............] - ETA: 17s - loss: 0.6681 - tp: 3326.0000 - fp: 1960.0000 - tn: 4212.0000 - fn: 2822.0000 - accuracy: 0.6119 - precision: 0.6292 - recall: 0.5410 - auc: 0.6426\n",
            " For Batch Number 386 the model has a loss of {'loss': 0.6681017279624939, 'tp': 3332.0, 'fp': 1960.0, 'tn': 4224.0, 'fn': 2836.0, 'accuracy': 0.6117228269577026, 'precision': 0.6296296119689941, 'recall': 0.5402075052261353, 'auc': 0.6425166726112366} \n",
            "386/689 [===============>..............] - ETA: 16s - loss: 0.6681 - tp: 3332.0000 - fp: 1960.0000 - tn: 4224.0000 - fn: 2836.0000 - accuracy: 0.6117 - precision: 0.6296 - recall: 0.5402 - auc: 0.6425\n",
            " For Batch Number 387 the model has a loss of {'loss': 0.6683696508407593, 'tp': 3334.0, 'fp': 1964.0, 'tn': 4239.0, 'fn': 2847.0, 'accuracy': 0.6115148663520813, 'precision': 0.6292940974235535, 'recall': 0.5393949151039124, 'auc': 0.642177164554596} \n",
            "387/689 [===============>..............] - ETA: 16s - loss: 0.6684 - tp: 3334.0000 - fp: 1964.0000 - tn: 4239.0000 - fn: 2847.0000 - accuracy: 0.6115 - precision: 0.6293 - recall: 0.5394 - auc: 0.6422\n",
            " For Batch Number 388 the model has a loss of {'loss': 0.6683934926986694, 'tp': 3341.0, 'fp': 1969.0, 'tn': 4251.0, 'fn': 2855.0, 'accuracy': 0.6114690899848938, 'precision': 0.62919020652771, 'recall': 0.5392188429832458, 'auc': 0.6420944929122925} \n",
            "388/689 [===============>..............] - ETA: 16s - loss: 0.6684 - tp: 3341.0000 - fp: 1969.0000 - tn: 4251.0000 - fn: 2855.0000 - accuracy: 0.6115 - precision: 0.6292 - recall: 0.5392 - auc: 0.6421\n",
            " For Batch Number 389 the model has a loss of {'loss': 0.668359100818634, 'tp': 3348.0, 'fp': 1976.0, 'tn': 4264.0, 'fn': 2860.0, 'accuracy': 0.6115038394927979, 'precision': 0.6288504600524902, 'recall': 0.5393041372299194, 'auc': 0.6419726610183716} \n",
            "389/689 [===============>..............] - ETA: 16s - loss: 0.6684 - tp: 3348.0000 - fp: 1976.0000 - tn: 4264.0000 - fn: 2860.0000 - accuracy: 0.6115 - precision: 0.6289 - recall: 0.5393 - auc: 0.6420\n",
            " For Batch Number 390 the model has a loss of {'loss': 0.6682918667793274, 'tp': 3356.0, 'fp': 1979.0, 'tn': 4278.0, 'fn': 2867.0, 'accuracy': 0.6116987466812134, 'precision': 0.6290534138679504, 'recall': 0.5392897129058838, 'auc': 0.6420342326164246} \n",
            "390/689 [===============>..............] - ETA: 16s - loss: 0.6683 - tp: 3356.0000 - fp: 1979.0000 - tn: 4278.0000 - fn: 2867.0000 - accuracy: 0.6117 - precision: 0.6291 - recall: 0.5393 - auc: 0.6420\n",
            " For Batch Number 391 the model has a loss of {'loss': 0.6683457493782043, 'tp': 3360.0, 'fp': 1984.0, 'tn': 4290.0, 'fn': 2878.0, 'accuracy': 0.6114130616188049, 'precision': 0.628742516040802, 'recall': 0.538634181022644, 'auc': 0.6418329477310181} \n",
            "391/689 [================>.............] - ETA: 16s - loss: 0.6683 - tp: 3360.0000 - fp: 1984.0000 - tn: 4290.0000 - fn: 2878.0000 - accuracy: 0.6114 - precision: 0.6287 - recall: 0.5386 - auc: 0.6418\n",
            " For Batch Number 392 the model has a loss of {'loss': 0.6684281229972839, 'tp': 3367.0, 'fp': 1985.0, 'tn': 4301.0, 'fn': 2891.0, 'accuracy': 0.6112882494926453, 'precision': 0.6291106343269348, 'recall': 0.5380313396453857, 'auc': 0.6415562033653259} \n",
            "\n",
            " For Batch Number 393 the model has a loss of {'loss': 0.6684824228286743, 'tp': 3372.0, 'fp': 1988.0, 'tn': 4313.0, 'fn': 2903.0, 'accuracy': 0.6110845804214478, 'precision': 0.629104495048523, 'recall': 0.537370502948761, 'auc': 0.6412572860717773} \n",
            "393/689 [================>.............] - ETA: 16s - loss: 0.6685 - tp: 3372.0000 - fp: 1988.0000 - tn: 4313.0000 - fn: 2903.0000 - accuracy: 0.6111 - precision: 0.6291 - recall: 0.5374 - auc: 0.6413\n",
            " For Batch Number 394 the model has a loss of {'loss': 0.6685059070587158, 'tp': 3378.0, 'fp': 1988.0, 'tn': 4324.0, 'fn': 2918.0, 'accuracy': 0.6108819842338562, 'precision': 0.6295192241668701, 'recall': 0.5365311503410339, 'auc': 0.6410508155822754} \n",
            "394/689 [================>.............] - ETA: 16s - loss: 0.6685 - tp: 3378.0000 - fp: 1988.0000 - tn: 4324.0000 - fn: 2918.0000 - accuracy: 0.6109 - precision: 0.6295 - recall: 0.5365 - auc: 0.6411\n",
            " For Batch Number 395 the model has a loss of {'loss': 0.6680673360824585, 'tp': 3389.0, 'fp': 1988.0, 'tn': 4338.0, 'fn': 2925.0, 'accuracy': 0.6113132834434509, 'precision': 0.6302770972251892, 'recall': 0.5367437601089478, 'auc': 0.6415805816650391} \n",
            "\n",
            " For Batch Number 396 the model has a loss of {'loss': 0.6684039831161499, 'tp': 3399.0, 'fp': 1998.0, 'tn': 4344.0, 'fn': 2931.0, 'accuracy': 0.6110321879386902, 'precision': 0.6297943592071533, 'recall': 0.5369668006896973, 'auc': 0.6413595080375671} \n",
            "396/689 [================>.............] - ETA: 16s - loss: 0.6684 - tp: 3399.0000 - fp: 1998.0000 - tn: 4344.0000 - fn: 2931.0000 - accuracy: 0.6110 - precision: 0.6298 - recall: 0.5370 - auc: 0.6414\n",
            " For Batch Number 397 the model has a loss of {'loss': 0.6681462526321411, 'tp': 3415.0, 'fp': 2006.0, 'tn': 4350.0, 'fn': 2933.0, 'accuracy': 0.6112248301506042, 'precision': 0.6299575567245483, 'recall': 0.5379647016525269, 'auc': 0.6416532397270203} \n",
            "397/689 [================>.............] - ETA: 16s - loss: 0.6681 - tp: 3415.0000 - fp: 2006.0000 - tn: 4350.0000 - fn: 2933.0000 - accuracy: 0.6112 - precision: 0.6300 - recall: 0.5380 - auc: 0.6417\n",
            " For Batch Number 398 the model has a loss of {'loss': 0.6680972576141357, 'tp': 3430.0, 'fp': 2014.0, 'tn': 4353.0, 'fn': 2939.0, 'accuracy': 0.6111024022102356, 'precision': 0.6300514340400696, 'recall': 0.538546085357666, 'auc': 0.6418271064758301} \n",
            "398/689 [================>.............] - ETA: 16s - loss: 0.6681 - tp: 3430.0000 - fp: 2014.0000 - tn: 4353.0000 - fn: 2939.0000 - accuracy: 0.6111 - precision: 0.6301 - recall: 0.5385 - auc: 0.6418\n",
            " For Batch Number 399 the model has a loss of {'loss': 0.6679703593254089, 'tp': 3443.0, 'fp': 2029.0, 'tn': 4354.0, 'fn': 2942.0, 'accuracy': 0.6106672883033752, 'precision': 0.629203200340271, 'recall': 0.5392325520515442, 'auc': 0.64178866147995} \n",
            "\n",
            " For Batch Number 400 the model has a loss of {'loss': 0.6679875254631042, 'tp': 3458.0, 'fp': 2042.0, 'tn': 4356.0, 'fn': 2944.0, 'accuracy': 0.6104687452316284, 'precision': 0.6287272572517395, 'recall': 0.5401437282562256, 'auc': 0.6417364478111267} \n",
            "400/689 [================>.............] - ETA: 16s - loss: 0.6680 - tp: 3458.0000 - fp: 2042.0000 - tn: 4356.0000 - fn: 2944.0000 - accuracy: 0.6105 - precision: 0.6287 - recall: 0.5401 - auc: 0.6417\n",
            " For Batch Number 401 the model has a loss of {'loss': 0.6678516268730164, 'tp': 3468.0, 'fp': 2050.0, 'tn': 4365.0, 'fn': 2949.0, 'accuracy': 0.6104270815849304, 'precision': 0.6284886002540588, 'recall': 0.5404394865036011, 'auc': 0.6417742967605591} \n",
            "401/689 [================>.............] - ETA: 16s - loss: 0.6679 - tp: 3468.0000 - fp: 2050.0000 - tn: 4365.0000 - fn: 2949.0000 - accuracy: 0.6104 - precision: 0.6285 - recall: 0.5404 - auc: 0.6418\n",
            " For Batch Number 402 the model has a loss of {'loss': 0.6679660081863403, 'tp': 3474.0, 'fp': 2055.0, 'tn': 4379.0, 'fn': 2956.0, 'accuracy': 0.6104633212089539, 'precision': 0.6283233761787415, 'recall': 0.5402799248695374, 'auc': 0.6416481137275696} \n",
            "402/689 [================>.............] - ETA: 16s - loss: 0.6680 - tp: 3474.0000 - fp: 2055.0000 - tn: 4379.0000 - fn: 2956.0000 - accuracy: 0.6105 - precision: 0.6283 - recall: 0.5403 - auc: 0.6416\n",
            " For Batch Number 403 the model has a loss of {'loss': 0.6680518388748169, 'tp': 3478.0, 'fp': 2057.0, 'tn': 4390.0, 'fn': 2971.0, 'accuracy': 0.610111653804779, 'precision': 0.6283649206161499, 'recall': 0.5393084287643433, 'auc': 0.64140784740448} \n",
            "\n",
            " For Batch Number 404 the model has a loss of {'loss': 0.668129563331604, 'tp': 3482.0, 'fp': 2061.0, 'tn': 4403.0, 'fn': 2982.0, 'accuracy': 0.6099164485931396, 'precision': 0.628179669380188, 'recall': 0.5386757254600525, 'auc': 0.6412029266357422} \n",
            "404/689 [================>.............] - ETA: 15s - loss: 0.6681 - tp: 3482.0000 - fp: 2061.0000 - tn: 4403.0000 - fn: 2982.0000 - accuracy: 0.6099 - precision: 0.6282 - recall: 0.5387 - auc: 0.6412\n",
            " For Batch Number 405 the model has a loss of {'loss': 0.6681632399559021, 'tp': 3488.0, 'fp': 2063.0, 'tn': 4416.0, 'fn': 2993.0, 'accuracy': 0.6098765134811401, 'precision': 0.6283552646636963, 'recall': 0.5381885766983032, 'auc': 0.6411154270172119} \n",
            "405/689 [================>.............] - ETA: 15s - loss: 0.6682 - tp: 3488.0000 - fp: 2063.0000 - tn: 4416.0000 - fn: 2993.0000 - accuracy: 0.6099 - precision: 0.6284 - recall: 0.5382 - auc: 0.6411\n",
            " For Batch Number 406 the model has a loss of {'loss': 0.6682393550872803, 'tp': 3491.0, 'fp': 2068.0, 'tn': 4434.0, 'fn': 2999.0, 'accuracy': 0.6099907755851746, 'precision': 0.6279906630516052, 'recall': 0.5379044413566589, 'auc': 0.6410396695137024} \n",
            "\n",
            " For Batch Number 407 the model has a loss of {'loss': 0.6683602333068848, 'tp': 3496.0, 'fp': 2069.0, 'tn': 4445.0, 'fn': 3014.0, 'accuracy': 0.6097205281257629, 'precision': 0.628212034702301, 'recall': 0.5370199680328369, 'auc': 0.6407075524330139} \n",
            "407/689 [================>.............] - ETA: 15s - loss: 0.6684 - tp: 3496.0000 - fp: 2069.0000 - tn: 4445.0000 - fn: 3014.0000 - accuracy: 0.6097 - precision: 0.6282 - recall: 0.5370 - auc: 0.6407\n",
            " For Batch Number 408 the model has a loss of {'loss': 0.6683576107025146, 'tp': 3499.0, 'fp': 2074.0, 'tn': 4459.0, 'fn': 3024.0, 'accuracy': 0.6095281839370728, 'precision': 0.6278485655784607, 'recall': 0.5364096164703369, 'auc': 0.6406497359275818} \n",
            "\n",
            " For Batch Number 409 the model has a loss of {'loss': 0.6681439280509949, 'tp': 3509.0, 'fp': 2075.0, 'tn': 4475.0, 'fn': 3029.0, 'accuracy': 0.6100244522094727, 'precision': 0.628402590751648, 'recall': 0.5367084741592407, 'auc': 0.6409780979156494} \n",
            "409/689 [================>.............] - ETA: 15s - loss: 0.6681 - tp: 3509.0000 - fp: 2075.0000 - tn: 4475.0000 - fn: 3029.0000 - accuracy: 0.6100 - precision: 0.6284 - recall: 0.5367 - auc: 0.6410\n",
            " For Batch Number 410 the model has a loss of {'loss': 0.6680208444595337, 'tp': 3517.0, 'fp': 2079.0, 'tn': 4488.0, 'fn': 3036.0, 'accuracy': 0.6101372241973877, 'precision': 0.6284846067428589, 'recall': 0.5367007255554199, 'auc': 0.6410855650901794} \n",
            "410/689 [================>.............] - ETA: 15s - loss: 0.6680 - tp: 3517.0000 - fp: 2079.0000 - tn: 4488.0000 - fn: 3036.0000 - accuracy: 0.6101 - precision: 0.6285 - recall: 0.5367 - auc: 0.6411\n",
            " For Batch Number 411 the model has a loss of {'loss': 0.6679899096488953, 'tp': 3528.0, 'fp': 2081.0, 'tn': 4496.0, 'fn': 3047.0, 'accuracy': 0.610097348690033, 'precision': 0.6289891004562378, 'recall': 0.5365779399871826, 'auc': 0.6411687135696411} \n",
            "411/689 [================>.............] - ETA: 15s - loss: 0.6680 - tp: 3528.0000 - fp: 2081.0000 - tn: 4496.0000 - fn: 3047.0000 - accuracy: 0.6101 - precision: 0.6290 - recall: 0.5366 - auc: 0.6412\n",
            " For Batch Number 412 the model has a loss of {'loss': 0.66802579164505, 'tp': 3537.0, 'fp': 2087.0, 'tn': 4508.0, 'fn': 3052.0, 'accuracy': 0.6102093458175659, 'precision': 0.6289117932319641, 'recall': 0.5368037819862366, 'auc': 0.6411215662956238} \n",
            "\n",
            " For Batch Number 413 the model has a loss of {'loss': 0.6678386330604553, 'tp': 3548.0, 'fp': 2094.0, 'tn': 4519.0, 'fn': 3055.0, 'accuracy': 0.6103965044021606, 'precision': 0.6288549900054932, 'recall': 0.5373315215110779, 'auc': 0.6412451863288879} \n",
            "413/689 [================>.............] - ETA: 15s - loss: 0.6678 - tp: 3548.0000 - fp: 2094.0000 - tn: 4519.0000 - fn: 3055.0000 - accuracy: 0.6104 - precision: 0.6289 - recall: 0.5373 - auc: 0.6412\n",
            " For Batch Number 414 the model has a loss of {'loss': 0.6677477359771729, 'tp': 3559.0, 'fp': 2099.0, 'tn': 4528.0, 'fn': 3062.0, 'accuracy': 0.6104317903518677, 'precision': 0.6290208697319031, 'recall': 0.5375320911407471, 'auc': 0.6413193941116333} \n",
            "414/689 [=================>............] - ETA: 15s - loss: 0.6677 - tp: 3559.0000 - fp: 2099.0000 - tn: 4528.0000 - fn: 3062.0000 - accuracy: 0.6104 - precision: 0.6290 - recall: 0.5375 - auc: 0.6413\n",
            " For Batch Number 415 the model has a loss of {'loss': 0.6675220727920532, 'tp': 3570.0, 'fp': 2104.0, 'tn': 4538.0, 'fn': 3068.0, 'accuracy': 0.6105421781539917, 'precision': 0.6291857361793518, 'recall': 0.5378125905990601, 'auc': 0.6415981650352478} \n",
            "\n",
            " For Batch Number 416 the model has a loss of {'loss': 0.6671792268753052, 'tp': 3581.0, 'fp': 2108.0, 'tn': 4550.0, 'fn': 3073.0, 'accuracy': 0.6108022928237915, 'precision': 0.629460334777832, 'recall': 0.5381725430488586, 'auc': 0.6420958042144775} \n",
            "416/689 [=================>............] - ETA: 15s - loss: 0.6672 - tp: 3581.0000 - fp: 2108.0000 - tn: 4550.0000 - fn: 3073.0000 - accuracy: 0.6108 - precision: 0.6295 - recall: 0.5382 - auc: 0.6421\n",
            " For Batch Number 417 the model has a loss of {'loss': 0.6670400500297546, 'tp': 3589.0, 'fp': 2113.0, 'tn': 4564.0, 'fn': 3078.0, 'accuracy': 0.6109862327575684, 'precision': 0.6294282674789429, 'recall': 0.5383231043815613, 'auc': 0.6423981785774231} \n",
            "417/689 [=================>............] - ETA: 15s - loss: 0.6670 - tp: 3589.0000 - fp: 2113.0000 - tn: 4564.0000 - fn: 3078.0000 - accuracy: 0.6110 - precision: 0.6294 - recall: 0.5383 - auc: 0.6424\n",
            " For Batch Number 418 the model has a loss of {'loss': 0.6669016480445862, 'tp': 3596.0, 'fp': 2118.0, 'tn': 4579.0, 'fn': 3083.0, 'accuracy': 0.6111692786216736, 'precision': 0.6293314695358276, 'recall': 0.5384039282798767, 'auc': 0.642711877822876} \n",
            "418/689 [=================>............] - ETA: 15s - loss: 0.6669 - tp: 3596.0000 - fp: 2118.0000 - tn: 4579.0000 - fn: 3083.0000 - accuracy: 0.6112 - precision: 0.6293 - recall: 0.5384 - auc: 0.6427\n",
            " For Batch Number 419 the model has a loss of {'loss': 0.6667671203613281, 'tp': 3606.0, 'fp': 2119.0, 'tn': 4594.0, 'fn': 3089.0, 'accuracy': 0.611575186252594, 'precision': 0.6298689842224121, 'recall': 0.5386108756065369, 'auc': 0.6430987119674683} \n",
            "419/689 [=================>............] - ETA: 15s - loss: 0.6668 - tp: 3606.0000 - fp: 2119.0000 - tn: 4594.0000 - fn: 3089.0000 - accuracy: 0.6116 - precision: 0.6299 - recall: 0.5386 - auc: 0.6431\n",
            " For Batch Number 420 the model has a loss of {'loss': 0.6675478219985962, 'tp': 3615.0, 'fp': 2120.0, 'tn': 4601.0, 'fn': 3104.0, 'accuracy': 0.6113095283508301, 'precision': 0.630340039730072, 'recall': 0.5380265116691589, 'auc': 0.6424176096916199} \n",
            "420/689 [=================>............] - ETA: 14s - loss: 0.6675 - tp: 3615.0000 - fp: 2120.0000 - tn: 4601.0000 - fn: 3104.0000 - accuracy: 0.6113 - precision: 0.6303 - recall: 0.5380 - auc: 0.6424\n",
            " For Batch Number 421 the model has a loss of {'loss': 0.6671288013458252, 'tp': 3622.0, 'fp': 2123.0, 'tn': 4618.0, 'fn': 3109.0, 'accuracy': 0.6116389632225037, 'precision': 0.6304612755775452, 'recall': 0.5381072759628296, 'auc': 0.6429170966148376} \n",
            "\n",
            " For Batch Number 422 the model has a loss of {'loss': 0.6667484045028687, 'tp': 3631.0, 'fp': 2127.0, 'tn': 4632.0, 'fn': 3114.0, 'accuracy': 0.6118927597999573, 'precision': 0.6306009292602539, 'recall': 0.5383247137069702, 'auc': 0.6434257626533508} \n",
            "422/689 [=================>............] - ETA: 14s - loss: 0.6667 - tp: 3631.0000 - fp: 2127.0000 - tn: 4632.0000 - fn: 3114.0000 - accuracy: 0.6119 - precision: 0.6306 - recall: 0.5383 - auc: 0.6434\n",
            " For Batch Number 423 the model has a loss of {'loss': 0.666718602180481, 'tp': 3641.0, 'fp': 2134.0, 'tn': 4643.0, 'fn': 3118.0, 'accuracy': 0.611997663974762, 'precision': 0.630476176738739, 'recall': 0.538689136505127, 'auc': 0.6434046626091003} \n",
            "423/689 [=================>............] - ETA: 14s - loss: 0.6667 - tp: 3641.0000 - fp: 2134.0000 - tn: 4643.0000 - fn: 3118.0000 - accuracy: 0.6120 - precision: 0.6305 - recall: 0.5387 - auc: 0.6434\n",
            " For Batch Number 424 the model has a loss of {'loss': 0.6665427088737488, 'tp': 3654.0, 'fp': 2136.0, 'tn': 4650.0, 'fn': 3128.0, 'accuracy': 0.6120283007621765, 'precision': 0.6310880780220032, 'recall': 0.5387791395187378, 'auc': 0.6436635255813599} \n",
            "\n",
            " For Batch Number 425 the model has a loss of {'loss': 0.6665075421333313, 'tp': 3665.0, 'fp': 2142.0, 'tn': 4657.0, 'fn': 3136.0, 'accuracy': 0.6119117736816406, 'precision': 0.6311348080635071, 'recall': 0.5388913154602051, 'auc': 0.6436965465545654} \n",
            "425/689 [=================>............] - ETA: 14s - loss: 0.6665 - tp: 3665.0000 - fp: 2142.0000 - tn: 4657.0000 - fn: 3136.0000 - accuracy: 0.6119 - precision: 0.6311 - recall: 0.5389 - auc: 0.6437\n",
            " For Batch Number 426 the model has a loss of {'loss': 0.666370153427124, 'tp': 3677.0, 'fp': 2149.0, 'tn': 4668.0, 'fn': 3138.0, 'accuracy': 0.6121625304222107, 'precision': 0.6311362981796265, 'recall': 0.5395451188087463, 'auc': 0.6439159512519836} \n",
            "426/689 [=================>............] - ETA: 14s - loss: 0.6664 - tp: 3677.0000 - fp: 2149.0000 - tn: 4668.0000 - fn: 3138.0000 - accuracy: 0.6122 - precision: 0.6311 - recall: 0.5395 - auc: 0.6439\n",
            " For Batch Number 427 the model has a loss of {'loss': 0.6664180755615234, 'tp': 3690.0, 'fp': 2158.0, 'tn': 4673.0, 'fn': 3143.0, 'accuracy': 0.6120462417602539, 'precision': 0.6309849619865417, 'recall': 0.5400263667106628, 'auc': 0.6439202427864075} \n",
            "\n",
            " For Batch Number 428 the model has a loss of {'loss': 0.6667160391807556, 'tp': 3699.0, 'fp': 2170.0, 'tn': 4677.0, 'fn': 3150.0, 'accuracy': 0.6115654110908508, 'precision': 0.630260705947876, 'recall': 0.5400788187980652, 'auc': 0.6434581279754639} \n",
            "428/689 [=================>............] - ETA: 14s - loss: 0.6667 - tp: 3699.0000 - fp: 2170.0000 - tn: 4677.0000 - fn: 3150.0000 - accuracy: 0.6116 - precision: 0.6303 - recall: 0.5401 - auc: 0.6435\n",
            " For Batch Number 429 the model has a loss of {'loss': 0.6668829321861267, 'tp': 3709.0, 'fp': 2179.0, 'tn': 4683.0, 'fn': 3157.0, 'accuracy': 0.6113053560256958, 'precision': 0.6299252510070801, 'recall': 0.5401980876922607, 'auc': 0.6431763768196106} \n",
            "429/689 [=================>............] - ETA: 14s - loss: 0.6669 - tp: 3709.0000 - fp: 2179.0000 - tn: 4683.0000 - fn: 3157.0000 - accuracy: 0.6113 - precision: 0.6299 - recall: 0.5402 - auc: 0.6432\n",
            " For Batch Number 430 the model has a loss of {'loss': 0.6668928861618042, 'tp': 3722.0, 'fp': 2184.0, 'tn': 4692.0, 'fn': 3162.0, 'accuracy': 0.611482560634613, 'precision': 0.6302065849304199, 'recall': 0.5406740307807922, 'auc': 0.6432904601097107} \n",
            "430/689 [=================>............] - ETA: 14s - loss: 0.6669 - tp: 3722.0000 - fp: 2184.0000 - tn: 4692.0000 - fn: 3162.0000 - accuracy: 0.6115 - precision: 0.6302 - recall: 0.5407 - auc: 0.6433\n",
            " For Batch Number 431 the model has a loss of {'loss': 0.6667304039001465, 'tp': 3730.0, 'fp': 2189.0, 'tn': 4703.0, 'fn': 3170.0, 'accuracy': 0.611441433429718, 'precision': 0.6301740407943726, 'recall': 0.5405797362327576, 'auc': 0.6434579491615295} \n",
            "431/689 [=================>............] - ETA: 14s - loss: 0.6667 - tp: 3730.0000 - fp: 2189.0000 - tn: 4703.0000 - fn: 3170.0000 - accuracy: 0.6114 - precision: 0.6302 - recall: 0.5406 - auc: 0.6435\n",
            " For Batch Number 432 the model has a loss of {'loss': 0.6667388081550598, 'tp': 3740.0, 'fp': 2193.0, 'tn': 4714.0, 'fn': 3177.0, 'accuracy': 0.6115451455116272, 'precision': 0.6303724646568298, 'recall': 0.5406968593597412, 'auc': 0.6434118151664734} \n",
            "\n",
            " For Batch Number 433 the model has a loss of {'loss': 0.6667735576629639, 'tp': 3751.0, 'fp': 2196.0, 'tn': 4724.0, 'fn': 3185.0, 'accuracy': 0.6116483807563782, 'precision': 0.6307381987571716, 'recall': 0.5408016443252563, 'auc': 0.6433408856391907} \n",
            "433/689 [=================>............] - ETA: 14s - loss: 0.6668 - tp: 3751.0000 - fp: 2196.0000 - tn: 4724.0000 - fn: 3185.0000 - accuracy: 0.6116 - precision: 0.6307 - recall: 0.5408 - auc: 0.6433\n",
            " For Batch Number 434 the model has a loss of {'loss': 0.6668816208839417, 'tp': 3757.0, 'fp': 2201.0, 'tn': 4734.0, 'fn': 3196.0, 'accuracy': 0.6113911271095276, 'precision': 0.630580723285675, 'recall': 0.5403422713279724, 'auc': 0.64308100938797} \n",
            "434/689 [=================>............] - ETA: 14s - loss: 0.6669 - tp: 3757.0000 - fp: 2201.0000 - tn: 4734.0000 - fn: 3196.0000 - accuracy: 0.6114 - precision: 0.6306 - recall: 0.5403 - auc: 0.6431\n",
            " For Batch Number 435 the model has a loss of {'loss': 0.6667753458023071, 'tp': 3765.0, 'fp': 2204.0, 'tn': 4748.0, 'fn': 3203.0, 'accuracy': 0.6115660667419434, 'precision': 0.6307589411735535, 'recall': 0.5403271913528442, 'auc': 0.6432068943977356} \n",
            "435/689 [=================>............] - ETA: 14s - loss: 0.6668 - tp: 3765.0000 - fp: 2204.0000 - tn: 4748.0000 - fn: 3203.0000 - accuracy: 0.6116 - precision: 0.6308 - recall: 0.5403 - auc: 0.6432\n",
            " For Batch Number 436 the model has a loss of {'loss': 0.666824221611023, 'tp': 3772.0, 'fp': 2211.0, 'tn': 4757.0, 'fn': 3212.0, 'accuracy': 0.6113101840019226, 'precision': 0.6304529309272766, 'recall': 0.5400916337966919, 'auc': 0.6430914998054504} \n",
            "436/689 [=================>............] - ETA: 14s - loss: 0.6668 - tp: 3772.0000 - fp: 2211.0000 - tn: 4757.0000 - fn: 3212.0000 - accuracy: 0.6113 - precision: 0.6305 - recall: 0.5401 - auc: 0.6431\n",
            " For Batch Number 437 the model has a loss of {'loss': 0.6667515635490417, 'tp': 3780.0, 'fp': 2219.0, 'tn': 4769.0, 'fn': 3216.0, 'accuracy': 0.6113415360450745, 'precision': 0.6301050186157227, 'recall': 0.5403087735176086, 'auc': 0.6431400775909424} \n",
            "437/689 [==================>...........] - ETA: 14s - loss: 0.6668 - tp: 3780.0000 - fp: 2219.0000 - tn: 4769.0000 - fn: 3216.0000 - accuracy: 0.6113 - precision: 0.6301 - recall: 0.5403 - auc: 0.6431\n",
            " For Batch Number 438 the model has a loss of {'loss': 0.6666392683982849, 'tp': 3790.0, 'fp': 2222.0, 'tn': 4781.0, 'fn': 3223.0, 'accuracy': 0.6115154027938843, 'precision': 0.630405843257904, 'recall': 0.5404249429702759, 'auc': 0.643292248249054} \n",
            "438/689 [==================>...........] - ETA: 13s - loss: 0.6666 - tp: 3790.0000 - fp: 2222.0000 - tn: 4781.0000 - fn: 3223.0000 - accuracy: 0.6115 - precision: 0.6304 - recall: 0.5404 - auc: 0.6433\n",
            " For Batch Number 439 the model has a loss of {'loss': 0.6664324998855591, 'tp': 3801.0, 'fp': 2224.0, 'tn': 4794.0, 'fn': 3229.0, 'accuracy': 0.6118308901786804, 'precision': 0.6308713555335999, 'recall': 0.5406827926635742, 'auc': 0.6436029076576233} \n",
            "439/689 [==================>...........] - ETA: 13s - loss: 0.6664 - tp: 3801.0000 - fp: 2224.0000 - tn: 4794.0000 - fn: 3229.0000 - accuracy: 0.6118 - precision: 0.6309 - recall: 0.5407 - auc: 0.6436\n",
            " For Batch Number 440 the model has a loss of {'loss': 0.6664345264434814, 'tp': 3811.0, 'fp': 2229.0, 'tn': 4802.0, 'fn': 3238.0, 'accuracy': 0.6117187738418579, 'precision': 0.6309602856636047, 'recall': 0.5406440496444702, 'auc': 0.6435568928718567} \n",
            "440/689 [==================>...........] - ETA: 13s - loss: 0.6664 - tp: 3811.0000 - fp: 2229.0000 - tn: 4802.0000 - fn: 3238.0000 - accuracy: 0.6117 - precision: 0.6310 - recall: 0.5406 - auc: 0.6436\n",
            " For Batch Number 441 the model has a loss of {'loss': 0.6663995385169983, 'tp': 3819.0, 'fp': 2237.0, 'tn': 4813.0, 'fn': 3243.0, 'accuracy': 0.6116780042648315, 'precision': 0.6306142807006836, 'recall': 0.5407816767692566, 'auc': 0.64357590675354} \n",
            "441/689 [==================>...........] - ETA: 13s - loss: 0.6664 - tp: 3819.0000 - fp: 2237.0000 - tn: 4813.0000 - fn: 3243.0000 - accuracy: 0.6117 - precision: 0.6306 - recall: 0.5408 - auc: 0.6436\n",
            " For Batch Number 442 the model has a loss of {'loss': 0.666498601436615, 'tp': 3827.0, 'fp': 2243.0, 'tn': 4824.0, 'fn': 3250.0, 'accuracy': 0.6116374731063843, 'precision': 0.630477786064148, 'recall': 0.5407658815383911, 'auc': 0.6433748006820679} \n",
            "442/689 [==================>...........] - ETA: 13s - loss: 0.6665 - tp: 3827.0000 - fp: 2243.0000 - tn: 4824.0000 - fn: 3250.0000 - accuracy: 0.6116 - precision: 0.6305 - recall: 0.5408 - auc: 0.6434\n",
            " For Batch Number 443 the model has a loss of {'loss': 0.6665337085723877, 'tp': 3835.0, 'fp': 2249.0, 'tn': 4836.0, 'fn': 3256.0, 'accuracy': 0.6116676330566406, 'precision': 0.6303418874740601, 'recall': 0.5408263802528381, 'auc': 0.6433379054069519} \n",
            "443/689 [==================>...........] - ETA: 13s - loss: 0.6665 - tp: 3835.0000 - fp: 2249.0000 - tn: 4836.0000 - fn: 3256.0000 - accuracy: 0.6117 - precision: 0.6303 - recall: 0.5408 - auc: 0.6433\n",
            " For Batch Number 444 the model has a loss of {'loss': 0.6665810942649841, 'tp': 3843.0, 'fp': 2255.0, 'tn': 4848.0, 'fn': 3262.0, 'accuracy': 0.6116976141929626, 'precision': 0.6302066445350647, 'recall': 0.5408867001533508, 'auc': 0.6432251930236816} \n",
            "444/689 [==================>...........] - ETA: 13s - loss: 0.6666 - tp: 3843.0000 - fp: 2255.0000 - tn: 4848.0000 - fn: 3262.0000 - accuracy: 0.6117 - precision: 0.6302 - recall: 0.5409 - auc: 0.6432\n",
            " For Batch Number 445 the model has a loss of {'loss': 0.6663655042648315, 'tp': 3853.0, 'fp': 2256.0, 'tn': 4861.0, 'fn': 3270.0, 'accuracy': 0.6119381785392761, 'precision': 0.6307088136672974, 'recall': 0.5409237742424011, 'auc': 0.6435619592666626} \n",
            "445/689 [==================>...........] - ETA: 13s - loss: 0.6664 - tp: 3853.0000 - fp: 2256.0000 - tn: 4861.0000 - fn: 3270.0000 - accuracy: 0.6119 - precision: 0.6307 - recall: 0.5409 - auc: 0.6436\n",
            " For Batch Number 446 the model has a loss of {'loss': 0.6661678552627563, 'tp': 3862.0, 'fp': 2260.0, 'tn': 4874.0, 'fn': 3276.0, 'accuracy': 0.6121076345443726, 'precision': 0.6308395862579346, 'recall': 0.5410479307174683, 'auc': 0.6438499689102173} \n",
            "446/689 [==================>...........] - ETA: 13s - loss: 0.6662 - tp: 3862.0000 - fp: 2260.0000 - tn: 4874.0000 - fn: 3276.0000 - accuracy: 0.6121 - precision: 0.6308 - recall: 0.5410 - auc: 0.6438\n",
            " For Batch Number 447 the model has a loss of {'loss': 0.6661344766616821, 'tp': 3867.0, 'fp': 2264.0, 'tn': 4888.0, 'fn': 3285.0, 'accuracy': 0.6120665669441223, 'precision': 0.630729079246521, 'recall': 0.5406879186630249, 'auc': 0.6438122391700745} \n",
            "447/689 [==================>...........] - ETA: 13s - loss: 0.6661 - tp: 3867.0000 - fp: 2264.0000 - tn: 4888.0000 - fn: 3285.0000 - accuracy: 0.6121 - precision: 0.6307 - recall: 0.5407 - auc: 0.6438\n",
            " For Batch Number 448 the model has a loss of {'loss': 0.6664009690284729, 'tp': 3874.0, 'fp': 2271.0, 'tn': 4895.0, 'fn': 3296.0, 'accuracy': 0.6116768717765808, 'precision': 0.6304312348365784, 'recall': 0.540306806564331, 'auc': 0.6434193849563599} \n",
            "448/689 [==================>...........] - ETA: 13s - loss: 0.6664 - tp: 3874.0000 - fp: 2271.0000 - tn: 4895.0000 - fn: 3296.0000 - accuracy: 0.6117 - precision: 0.6304 - recall: 0.5403 - auc: 0.6434\n",
            " For Batch Number 449 the model has a loss of {'loss': 0.666524350643158, 'tp': 3878.0, 'fp': 2278.0, 'tn': 4908.0, 'fn': 3304.0, 'accuracy': 0.6114977598190308, 'precision': 0.6299545168876648, 'recall': 0.539961040019989, 'auc': 0.6431395411491394} \n",
            "449/689 [==================>...........] - ETA: 13s - loss: 0.6665 - tp: 3878.0000 - fp: 2278.0000 - tn: 4908.0000 - fn: 3304.0000 - accuracy: 0.6115 - precision: 0.6300 - recall: 0.5400 - auc: 0.6431\n",
            " For Batch Number 450 the model has a loss of {'loss': 0.6665764451026917, 'tp': 3885.0, 'fp': 2282.0, 'tn': 4917.0, 'fn': 3316.0, 'accuracy': 0.6112499833106995, 'precision': 0.6299659609794617, 'recall': 0.5395084023475647, 'auc': 0.6429868340492249} \n",
            "450/689 [==================>...........] - ETA: 13s - loss: 0.6666 - tp: 3885.0000 - fp: 2282.0000 - tn: 4917.0000 - fn: 3316.0000 - accuracy: 0.6112 - precision: 0.6300 - recall: 0.5395 - auc: 0.6430\n",
            " For Batch Number 451 the model has a loss of {'loss': 0.666289746761322, 'tp': 3896.0, 'fp': 2284.0, 'tn': 4932.0, 'fn': 3320.0, 'accuracy': 0.6116962432861328, 'precision': 0.6304206848144531, 'recall': 0.5399113297462463, 'auc': 0.643487274646759} \n",
            "451/689 [==================>...........] - ETA: 13s - loss: 0.6663 - tp: 3896.0000 - fp: 2284.0000 - tn: 4932.0000 - fn: 3320.0000 - accuracy: 0.6117 - precision: 0.6304 - recall: 0.5399 - auc: 0.6435\n",
            " For Batch Number 452 the model has a loss of {'loss': 0.666252613067627, 'tp': 3902.0, 'fp': 2290.0, 'tn': 4944.0, 'fn': 3328.0, 'accuracy': 0.611587405204773, 'precision': 0.6301679611206055, 'recall': 0.5396957397460938, 'auc': 0.6434664726257324} \n",
            "452/689 [==================>...........] - ETA: 13s - loss: 0.6663 - tp: 3902.0000 - fp: 2290.0000 - tn: 4944.0000 - fn: 3328.0000 - accuracy: 0.6116 - precision: 0.6302 - recall: 0.5397 - auc: 0.6435\n",
            " For Batch Number 453 the model has a loss of {'loss': 0.6662563681602478, 'tp': 3914.0, 'fp': 2292.0, 'tn': 4950.0, 'fn': 3340.0, 'accuracy': 0.6114790439605713, 'precision': 0.6306799650192261, 'recall': 0.5395643711090088, 'auc': 0.6434670090675354} \n",
            "453/689 [==================>...........] - ETA: 13s - loss: 0.6663 - tp: 3914.0000 - fp: 2292.0000 - tn: 4950.0000 - fn: 3340.0000 - accuracy: 0.6115 - precision: 0.6307 - recall: 0.5396 - auc: 0.6435\n",
            " For Batch Number 454 the model has a loss of {'loss': 0.6661792993545532, 'tp': 3924.0, 'fp': 2297.0, 'tn': 4962.0, 'fn': 3345.0, 'accuracy': 0.6116464734077454, 'precision': 0.630766749382019, 'recall': 0.5398266315460205, 'auc': 0.6435332894325256} \n",
            "454/689 [==================>...........] - ETA: 13s - loss: 0.6662 - tp: 3924.0000 - fp: 2297.0000 - tn: 4962.0000 - fn: 3345.0000 - accuracy: 0.6116 - precision: 0.6308 - recall: 0.5398 - auc: 0.6435\n",
            " For Batch Number 455 the model has a loss of {'loss': 0.6661968231201172, 'tp': 3933.0, 'fp': 2304.0, 'tn': 4969.0, 'fn': 3354.0, 'accuracy': 0.6114010810852051, 'precision': 0.630591630935669, 'recall': 0.5397282838821411, 'auc': 0.6434682607650757} \n",
            "455/689 [==================>...........] - ETA: 13s - loss: 0.6662 - tp: 3933.0000 - fp: 2304.0000 - tn: 4969.0000 - fn: 3354.0000 - accuracy: 0.6114 - precision: 0.6306 - recall: 0.5397 - auc: 0.6435\n",
            " For Batch Number 456 the model has a loss of {'loss': 0.6661260724067688, 'tp': 3946.0, 'fp': 2309.0, 'tn': 4977.0, 'fn': 3360.0, 'accuracy': 0.6114994287490845, 'precision': 0.6308553218841553, 'recall': 0.5401040315628052, 'auc': 0.6435795426368713} \n",
            "456/689 [==================>...........] - ETA: 13s - loss: 0.6661 - tp: 3946.0000 - fp: 2309.0000 - tn: 4977.0000 - fn: 3360.0000 - accuracy: 0.6115 - precision: 0.6309 - recall: 0.5401 - auc: 0.6436\n",
            " For Batch Number 457 the model has a loss of {'loss': 0.6659007668495178, 'tp': 3962.0, 'fp': 2314.0, 'tn': 4985.0, 'fn': 3363.0, 'accuracy': 0.6118025183677673, 'precision': 0.6312938332557678, 'recall': 0.5408873558044434, 'auc': 0.6439201831817627} \n",
            "457/689 [==================>...........] - ETA: 13s - loss: 0.6659 - tp: 3962.0000 - fp: 2314.0000 - tn: 4985.0000 - fn: 3363.0000 - accuracy: 0.6118 - precision: 0.6313 - recall: 0.5409 - auc: 0.6439\n",
            " For Batch Number 458 the model has a loss of {'loss': 0.6660467386245728, 'tp': 3970.0, 'fp': 2325.0, 'tn': 4994.0, 'fn': 3367.0, 'accuracy': 0.6116266250610352, 'precision': 0.630659282207489, 'recall': 0.541093111038208, 'auc': 0.6437134742736816} \n",
            "458/689 [==================>...........] - ETA: 13s - loss: 0.6660 - tp: 3970.0000 - fp: 2325.0000 - tn: 4994.0000 - fn: 3367.0000 - accuracy: 0.6116 - precision: 0.6307 - recall: 0.5411 - auc: 0.6437\n",
            " For Batch Number 459 the model has a loss of {'loss': 0.6657894253730774, 'tp': 3983.0, 'fp': 2329.0, 'tn': 5006.0, 'fn': 3370.0, 'accuracy': 0.6119961738586426, 'precision': 0.6310203075408936, 'recall': 0.5416836738586426, 'auc': 0.6440315246582031} \n",
            "459/689 [==================>...........] - ETA: 13s - loss: 0.6658 - tp: 3983.0000 - fp: 2329.0000 - tn: 5006.0000 - fn: 3370.0000 - accuracy: 0.6120 - precision: 0.6310 - recall: 0.5417 - auc: 0.6440\n",
            " For Batch Number 460 the model has a loss of {'loss': 0.6656606793403625, 'tp': 3994.0, 'fp': 2335.0, 'tn': 5019.0, 'fn': 3372.0, 'accuracy': 0.6122962236404419, 'precision': 0.6310633420944214, 'recall': 0.5422210097312927, 'auc': 0.6442705392837524} \n",
            "460/689 [===================>..........] - ETA: 12s - loss: 0.6657 - tp: 3994.0000 - fp: 2335.0000 - tn: 5019.0000 - fn: 3372.0000 - accuracy: 0.6123 - precision: 0.6311 - recall: 0.5422 - auc: 0.6443\n",
            " For Batch Number 461 the model has a loss of {'loss': 0.6658912301063538, 'tp': 4000.0, 'fp': 2345.0, 'tn': 5028.0, 'fn': 3379.0, 'accuracy': 0.6119847893714905, 'precision': 0.6304176449775696, 'recall': 0.5420788526535034, 'auc': 0.6438699960708618} \n",
            "461/689 [===================>..........] - ETA: 12s - loss: 0.6659 - tp: 4000.0000 - fp: 2345.0000 - tn: 5028.0000 - fn: 3379.0000 - accuracy: 0.6120 - precision: 0.6304 - recall: 0.5421 - auc: 0.6439\n",
            " For Batch Number 462 the model has a loss of {'loss': 0.6656086444854736, 'tp': 4012.0, 'fp': 2347.0, 'tn': 5042.0, 'fn': 3383.0, 'accuracy': 0.6124188303947449, 'precision': 0.6309168338775635, 'recall': 0.5425287485122681, 'auc': 0.6443530321121216} \n",
            "462/689 [===================>..........] - ETA: 12s - loss: 0.6656 - tp: 4012.0000 - fp: 2347.0000 - tn: 5042.0000 - fn: 3383.0000 - accuracy: 0.6124 - precision: 0.6309 - recall: 0.5425 - auc: 0.6444\n",
            " For Batch Number 463 the model has a loss of {'loss': 0.6656561493873596, 'tp': 4019.0, 'fp': 2350.0, 'tn': 5056.0, 'fn': 3391.0, 'accuracy': 0.6125134825706482, 'precision': 0.6310252547264099, 'recall': 0.5423751473426819, 'auc': 0.6443692445755005} \n",
            "463/689 [===================>..........] - ETA: 12s - loss: 0.6657 - tp: 4019.0000 - fp: 2350.0000 - tn: 5056.0000 - fn: 3391.0000 - accuracy: 0.6125 - precision: 0.6310 - recall: 0.5424 - auc: 0.6444\n",
            " For Batch Number 464 the model has a loss of {'loss': 0.6653213500976562, 'tp': 4026.0, 'fp': 2352.0, 'tn': 5072.0, 'fn': 3398.0, 'accuracy': 0.6127424836158752, 'precision': 0.6312323808670044, 'recall': 0.5422952771186829, 'auc': 0.644916832447052} \n",
            "464/689 [===================>..........] - ETA: 12s - loss: 0.6653 - tp: 4026.0000 - fp: 2352.0000 - tn: 5072.0000 - fn: 3398.0000 - accuracy: 0.6127 - precision: 0.6312 - recall: 0.5423 - auc: 0.6449\n",
            " For Batch Number 465 the model has a loss of {'loss': 0.665186882019043, 'tp': 4033.0, 'fp': 2354.0, 'tn': 5086.0, 'fn': 3407.0, 'accuracy': 0.6128360033035278, 'precision': 0.6314388513565063, 'recall': 0.5420699119567871, 'auc': 0.645144522190094} \n",
            "465/689 [===================>..........] - ETA: 12s - loss: 0.6652 - tp: 4033.0000 - fp: 2354.0000 - tn: 5086.0000 - fn: 3407.0000 - accuracy: 0.6128 - precision: 0.6314 - recall: 0.5421 - auc: 0.6451\n",
            " For Batch Number 466 the model has a loss of {'loss': 0.6651650667190552, 'tp': 4042.0, 'fp': 2357.0, 'tn': 5097.0, 'fn': 3416.0, 'accuracy': 0.6128621101379395, 'precision': 0.6316611766815186, 'recall': 0.5419683456420898, 'auc': 0.6452043056488037} \n",
            "466/689 [===================>..........] - ETA: 12s - loss: 0.6652 - tp: 4042.0000 - fp: 2357.0000 - tn: 5097.0000 - fn: 3416.0000 - accuracy: 0.6129 - precision: 0.6317 - recall: 0.5420 - auc: 0.6452\n",
            " For Batch Number 467 the model has a loss of {'loss': 0.6649062037467957, 'tp': 4057.0, 'fp': 2360.0, 'tn': 5109.0, 'fn': 3418.0, 'accuracy': 0.6133565306663513, 'precision': 0.6322268843650818, 'recall': 0.5427424907684326, 'auc': 0.6456692814826965} \n",
            "467/689 [===================>..........] - ETA: 12s - loss: 0.6649 - tp: 4057.0000 - fp: 2360.0000 - tn: 5109.0000 - fn: 3418.0000 - accuracy: 0.6134 - precision: 0.6322 - recall: 0.5427 - auc: 0.6457\n",
            " For Batch Number 468 the model has a loss of {'loss': 0.6650969386100769, 'tp': 4064.0, 'fp': 2366.0, 'tn': 5119.0, 'fn': 3427.0, 'accuracy': 0.6131811141967773, 'precision': 0.632037341594696, 'recall': 0.5425176620483398, 'auc': 0.645456850528717} \n",
            "468/689 [===================>..........] - ETA: 12s - loss: 0.6651 - tp: 4064.0000 - fp: 2366.0000 - tn: 5119.0000 - fn: 3427.0000 - accuracy: 0.6132 - precision: 0.6320 - recall: 0.5425 - auc: 0.6455\n",
            " For Batch Number 469 the model has a loss of {'loss': 0.6649155020713806, 'tp': 4075.0, 'fp': 2371.0, 'tn': 5130.0, 'fn': 3432.0, 'accuracy': 0.6133395433425903, 'precision': 0.6321749687194824, 'recall': 0.5428267121315002, 'auc': 0.6456578373908997} \n",
            "469/689 [===================>..........] - ETA: 12s - loss: 0.6649 - tp: 4075.0000 - fp: 2371.0000 - tn: 5130.0000 - fn: 3432.0000 - accuracy: 0.6133 - precision: 0.6322 - recall: 0.5428 - auc: 0.6457\n",
            " For Batch Number 470 the model has a loss of {'loss': 0.6651409864425659, 'tp': 4082.0, 'fp': 2380.0, 'tn': 5138.0, 'fn': 3440.0, 'accuracy': 0.6130319237709045, 'precision': 0.6316929459571838, 'recall': 0.5426748394966125, 'auc': 0.6453601717948914} \n",
            "470/689 [===================>..........] - ETA: 12s - loss: 0.6651 - tp: 4082.0000 - fp: 2380.0000 - tn: 5138.0000 - fn: 3440.0000 - accuracy: 0.6130 - precision: 0.6317 - recall: 0.5427 - auc: 0.6454\n",
            " For Batch Number 471 the model has a loss of {'loss': 0.6647562980651855, 'tp': 4094.0, 'fp': 2383.0, 'tn': 5150.0, 'fn': 3445.0, 'accuracy': 0.6133227348327637, 'precision': 0.6320827603340149, 'recall': 0.5430428385734558, 'auc': 0.6458683013916016} \n",
            "471/689 [===================>..........] - ETA: 12s - loss: 0.6648 - tp: 4094.0000 - fp: 2383.0000 - tn: 5150.0000 - fn: 3445.0000 - accuracy: 0.6133 - precision: 0.6321 - recall: 0.5430 - auc: 0.6459\n",
            " For Batch Number 472 the model has a loss of {'loss': 0.6644194722175598, 'tp': 4105.0, 'fp': 2386.0, 'tn': 5164.0, 'fn': 3449.0, 'accuracy': 0.613678514957428, 'precision': 0.6324141025543213, 'recall': 0.5434207320213318, 'auc': 0.6463208794593811} \n",
            "472/689 [===================>..........] - ETA: 12s - loss: 0.6644 - tp: 4105.0000 - fp: 2386.0000 - tn: 5164.0000 - fn: 3449.0000 - accuracy: 0.6137 - precision: 0.6324 - recall: 0.5434 - auc: 0.6463\n",
            " For Batch Number 473 the model has a loss of {'loss': 0.66461580991745, 'tp': 4110.0, 'fp': 2394.0, 'tn': 5176.0, 'fn': 3456.0, 'accuracy': 0.6135042309761047, 'precision': 0.6319188475608826, 'recall': 0.5432196855545044, 'auc': 0.6461774706840515} \n",
            "473/689 [===================>..........] - ETA: 12s - loss: 0.6646 - tp: 4110.0000 - fp: 2394.0000 - tn: 5176.0000 - fn: 3456.0000 - accuracy: 0.6135 - precision: 0.6319 - recall: 0.5432 - auc: 0.6462\n",
            " For Batch Number 474 the model has a loss of {'loss': 0.6648254990577698, 'tp': 4117.0, 'fp': 2397.0, 'tn': 5189.0, 'fn': 3465.0, 'accuracy': 0.6135284900665283, 'precision': 0.6320233345031738, 'recall': 0.5429965853691101, 'auc': 0.6459841728210449} \n",
            "474/689 [===================>..........] - ETA: 12s - loss: 0.6648 - tp: 4117.0000 - fp: 2397.0000 - tn: 5189.0000 - fn: 3465.0000 - accuracy: 0.6135 - precision: 0.6320 - recall: 0.5430 - auc: 0.6460\n",
            " For Batch Number 475 the model has a loss of {'loss': 0.6644988656044006, 'tp': 4125.0, 'fp': 2399.0, 'tn': 5207.0, 'fn': 3469.0, 'accuracy': 0.6139473915100098, 'precision': 0.6322808265686035, 'recall': 0.5431919693946838, 'auc': 0.6465771794319153} \n",
            "475/689 [===================>..........] - ETA: 12s - loss: 0.6645 - tp: 4125.0000 - fp: 2399.0000 - tn: 5207.0000 - fn: 3469.0000 - accuracy: 0.6139 - precision: 0.6323 - recall: 0.5432 - auc: 0.6466\n",
            " For Batch Number 476 the model has a loss of {'loss': 0.6649737358093262, 'tp': 4130.0, 'fp': 2402.0, 'tn': 5218.0, 'fn': 3482.0, 'accuracy': 0.613707959651947, 'precision': 0.6322718858718872, 'recall': 0.5425643920898438, 'auc': 0.6460731625556946} \n",
            "476/689 [===================>..........] - ETA: 12s - loss: 0.6650 - tp: 4130.0000 - fp: 2402.0000 - tn: 5218.0000 - fn: 3482.0000 - accuracy: 0.6137 - precision: 0.6323 - recall: 0.5426 - auc: 0.6461\n",
            " For Batch Number 477 the model has a loss of {'loss': 0.6653156280517578, 'tp': 4139.0, 'fp': 2404.0, 'tn': 5228.0, 'fn': 3493.0, 'accuracy': 0.6136661171913147, 'precision': 0.6325844526290894, 'recall': 0.5423218011856079, 'auc': 0.645742654800415} \n",
            "477/689 [===================>..........] - ETA: 12s - loss: 0.6653 - tp: 4139.0000 - fp: 2404.0000 - tn: 5228.0000 - fn: 3493.0000 - accuracy: 0.6137 - precision: 0.6326 - recall: 0.5423 - auc: 0.6457\n",
            " For Batch Number 478 the model has a loss of {'loss': 0.6651868224143982, 'tp': 4149.0, 'fp': 2410.0, 'tn': 5238.0, 'fn': 3499.0, 'accuracy': 0.6136898398399353, 'precision': 0.6325659155845642, 'recall': 0.5424947738647461, 'auc': 0.6459344029426575} \n",
            "478/689 [===================>..........] - ETA: 12s - loss: 0.6652 - tp: 4149.0000 - fp: 2410.0000 - tn: 5238.0000 - fn: 3499.0000 - accuracy: 0.6137 - precision: 0.6326 - recall: 0.5425 - auc: 0.6459\n",
            " For Batch Number 479 the model has a loss of {'loss': 0.6651247143745422, 'tp': 4164.0, 'fp': 2417.0, 'tn': 5245.0, 'fn': 3502.0, 'accuracy': 0.6138439178466797, 'precision': 0.6327306032180786, 'recall': 0.5431776642799377, 'auc': 0.6460350155830383} \n",
            "479/689 [===================>..........] - ETA: 12s - loss: 0.6651 - tp: 4164.0000 - fp: 2417.0000 - tn: 5245.0000 - fn: 3502.0000 - accuracy: 0.6138 - precision: 0.6327 - recall: 0.5432 - auc: 0.6460\n",
            " For Batch Number 480 the model has a loss of {'loss': 0.6652084589004517, 'tp': 4173.0, 'fp': 2431.0, 'tn': 5254.0, 'fn': 3502.0, 'accuracy': 0.6137369871139526, 'precision': 0.6318897604942322, 'recall': 0.5437133312225342, 'auc': 0.6458266377449036} \n",
            "480/689 [===================>..........] - ETA: 12s - loss: 0.6652 - tp: 4173.0000 - fp: 2431.0000 - tn: 5254.0000 - fn: 3502.0000 - accuracy: 0.6137 - precision: 0.6319 - recall: 0.5437 - auc: 0.6458\n",
            " For Batch Number 481 the model has a loss of {'loss': 0.665213406085968, 'tp': 4181.0, 'fp': 2437.0, 'tn': 5266.0, 'fn': 3508.0, 'accuracy': 0.6137604117393494, 'precision': 0.6317618489265442, 'recall': 0.5437638163566589, 'auc': 0.6457332372665405} \n",
            "481/689 [===================>..........] - ETA: 11s - loss: 0.6652 - tp: 4181.0000 - fp: 2437.0000 - tn: 5266.0000 - fn: 3508.0000 - accuracy: 0.6138 - precision: 0.6318 - recall: 0.5438 - auc: 0.6457\n",
            " For Batch Number 482 the model has a loss of {'loss': 0.6654064059257507, 'tp': 4181.0, 'fp': 2440.0, 'tn': 5278.0, 'fn': 3525.0, 'accuracy': 0.6132650375366211, 'precision': 0.6314756274223328, 'recall': 0.5425642132759094, 'auc': 0.6453726887702942} \n",
            "482/689 [===================>..........] - ETA: 11s - loss: 0.6654 - tp: 4181.0000 - fp: 2440.0000 - tn: 5278.0000 - fn: 3525.0000 - accuracy: 0.6133 - precision: 0.6315 - recall: 0.5426 - auc: 0.6454\n",
            " For Batch Number 483 the model has a loss of {'loss': 0.6653926372528076, 'tp': 4183.0, 'fp': 2440.0, 'tn': 5294.0, 'fn': 3539.0, 'accuracy': 0.6131599545478821, 'precision': 0.6315869092941284, 'recall': 0.5416990518569946, 'auc': 0.6454160213470459} \n",
            "483/689 [====================>.........] - ETA: 11s - loss: 0.6654 - tp: 4183.0000 - fp: 2440.0000 - tn: 5294.0000 - fn: 3539.0000 - accuracy: 0.6132 - precision: 0.6316 - recall: 0.5417 - auc: 0.6454\n",
            " For Batch Number 484 the model has a loss of {'loss': 0.6654520034790039, 'tp': 4187.0, 'fp': 2442.0, 'tn': 5308.0, 'fn': 3551.0, 'accuracy': 0.6130552887916565, 'precision': 0.6316186189651489, 'recall': 0.5410959124565125, 'auc': 0.6452908515930176} \n",
            "484/689 [====================>.........] - ETA: 11s - loss: 0.6655 - tp: 4187.0000 - fp: 2442.0000 - tn: 5308.0000 - fn: 3551.0000 - accuracy: 0.6131 - precision: 0.6316 - recall: 0.5411 - auc: 0.6453\n",
            " For Batch Number 485 the model has a loss of {'loss': 0.6653741002082825, 'tp': 4197.0, 'fp': 2444.0, 'tn': 5318.0, 'fn': 3561.0, 'accuracy': 0.6130799055099487, 'precision': 0.6319831609725952, 'recall': 0.5409899353981018, 'auc': 0.6454426050186157} \n",
            "485/689 [====================>.........] - ETA: 11s - loss: 0.6654 - tp: 4197.0000 - fp: 2444.0000 - tn: 5318.0000 - fn: 3561.0000 - accuracy: 0.6131 - precision: 0.6320 - recall: 0.5410 - auc: 0.6454\n",
            " For Batch Number 486 the model has a loss of {'loss': 0.6655406355857849, 'tp': 4210.0, 'fp': 2455.0, 'tn': 5322.0, 'fn': 3565.0, 'accuracy': 0.6129115223884583, 'precision': 0.6316578984260559, 'recall': 0.5414791107177734, 'auc': 0.6452784538269043} \n",
            "486/689 [====================>.........] - ETA: 11s - loss: 0.6655 - tp: 4210.0000 - fp: 2455.0000 - tn: 5322.0000 - fn: 3565.0000 - accuracy: 0.6129 - precision: 0.6317 - recall: 0.5415 - auc: 0.6453\n",
            " For Batch Number 487 the model has a loss of {'loss': 0.6656385064125061, 'tp': 4222.0, 'fp': 2473.0, 'tn': 5324.0, 'fn': 3565.0, 'accuracy': 0.6125513315200806, 'precision': 0.6306198835372925, 'recall': 0.5421857237815857, 'auc': 0.645031750202179} \n",
            "487/689 [====================>.........] - ETA: 11s - loss: 0.6656 - tp: 4222.0000 - fp: 2473.0000 - tn: 5324.0000 - fn: 3565.0000 - accuracy: 0.6126 - precision: 0.6306 - recall: 0.5422 - auc: 0.6450\n",
            " For Batch Number 488 the model has a loss of {'loss': 0.6656312346458435, 'tp': 4235.0, 'fp': 2485.0, 'tn': 5329.0, 'fn': 3567.0, 'accuracy': 0.6124487519264221, 'precision': 0.6302083134651184, 'recall': 0.5428095459938049, 'auc': 0.6450046300888062} \n",
            "488/689 [====================>.........] - ETA: 11s - loss: 0.6656 - tp: 4235.0000 - fp: 2485.0000 - tn: 5329.0000 - fn: 3567.0000 - accuracy: 0.6124 - precision: 0.6302 - recall: 0.5428 - auc: 0.6450\n",
            " For Batch Number 489 the model has a loss of {'loss': 0.6656338572502136, 'tp': 4249.0, 'fp': 2495.0, 'tn': 5332.0, 'fn': 3572.0, 'accuracy': 0.6122826933860779, 'precision': 0.6300415396690369, 'recall': 0.5432808995246887, 'auc': 0.6450177431106567} \n",
            "489/689 [====================>.........] - ETA: 11s - loss: 0.6656 - tp: 4249.0000 - fp: 2495.0000 - tn: 5332.0000 - fn: 3572.0000 - accuracy: 0.6123 - precision: 0.6300 - recall: 0.5433 - auc: 0.6450\n",
            " For Batch Number 490 the model has a loss of {'loss': 0.6656504273414612, 'tp': 4263.0, 'fp': 2501.0, 'tn': 5337.0, 'fn': 3579.0, 'accuracy': 0.6122449040412903, 'precision': 0.6302483677864075, 'recall': 0.5436113476753235, 'auc': 0.6450023651123047} \n",
            "490/689 [====================>.........] - ETA: 11s - loss: 0.6657 - tp: 4263.0000 - fp: 2501.0000 - tn: 5337.0000 - fn: 3579.0000 - accuracy: 0.6122 - precision: 0.6302 - recall: 0.5436 - auc: 0.6450\n",
            " For Batch Number 491 the model has a loss of {'loss': 0.6655028462409973, 'tp': 4275.0, 'fp': 2508.0, 'tn': 5346.0, 'fn': 3583.0, 'accuracy': 0.6123345494270325, 'precision': 0.6302521228790283, 'recall': 0.54403156042099, 'auc': 0.645205020904541} \n",
            "\n",
            " For Batch Number 492 the model has a loss of {'loss': 0.6654809713363647, 'tp': 4284.0, 'fp': 2513.0, 'tn': 5356.0, 'fn': 3591.0, 'accuracy': 0.6122967600822449, 'precision': 0.6302780508995056, 'recall': 0.5440000295639038, 'auc': 0.6451720595359802} \n",
            "492/689 [====================>.........] - ETA: 11s - loss: 0.6655 - tp: 4284.0000 - fp: 2513.0000 - tn: 5356.0000 - fn: 3591.0000 - accuracy: 0.6123 - precision: 0.6303 - recall: 0.5440 - auc: 0.6452\n",
            " For Batch Number 493 the model has a loss of {'loss': 0.6655104160308838, 'tp': 4291.0, 'fp': 2517.0, 'tn': 5371.0, 'fn': 3597.0, 'accuracy': 0.6124492883682251, 'precision': 0.6302878856658936, 'recall': 0.5439908504486084, 'auc': 0.6450331211090088} \n",
            "\n",
            " For Batch Number 494 the model has a loss of {'loss': 0.6654150485992432, 'tp': 4298.0, 'fp': 2519.0, 'tn': 5383.0, 'fn': 3608.0, 'accuracy': 0.6124114394187927, 'precision': 0.6304826140403748, 'recall': 0.543637752532959, 'auc': 0.6451964974403381} \n",
            "494/689 [====================>.........] - ETA: 11s - loss: 0.6654 - tp: 4298.0000 - fp: 2519.0000 - tn: 5383.0000 - fn: 3608.0000 - accuracy: 0.6124 - precision: 0.6305 - recall: 0.5436 - auc: 0.6452\n",
            " For Batch Number 495 the model has a loss of {'loss': 0.6654373407363892, 'tp': 4303.0, 'fp': 2523.0, 'tn': 5396.0, 'fn': 3618.0, 'accuracy': 0.6123105883598328, 'precision': 0.6303838491439819, 'recall': 0.5432394742965698, 'auc': 0.6451302766799927} \n",
            "495/689 [====================>.........] - ETA: 11s - loss: 0.6654 - tp: 4303.0000 - fp: 2523.0000 - tn: 5396.0000 - fn: 3618.0000 - accuracy: 0.6123 - precision: 0.6304 - recall: 0.5432 - auc: 0.6451\n",
            " For Batch Number 496 the model has a loss of {'loss': 0.6653907299041748, 'tp': 4309.0, 'fp': 2526.0, 'tn': 5411.0, 'fn': 3626.0, 'accuracy': 0.6123992204666138, 'precision': 0.630431592464447, 'recall': 0.5430371761322021, 'auc': 0.6451622843742371} \n",
            "496/689 [====================>.........] - ETA: 11s - loss: 0.6654 - tp: 4309.0000 - fp: 2526.0000 - tn: 5411.0000 - fn: 3626.0000 - accuracy: 0.6124 - precision: 0.6304 - recall: 0.5430 - auc: 0.6452\n",
            " For Batch Number 497 the model has a loss of {'loss': 0.6653759479522705, 'tp': 4316.0, 'fp': 2529.0, 'tn': 5426.0, 'fn': 3633.0, 'accuracy': 0.6125503182411194, 'precision': 0.6305332183837891, 'recall': 0.5429613590240479, 'auc': 0.6451937556266785} \n",
            "497/689 [====================>.........] - ETA: 11s - loss: 0.6654 - tp: 4316.0000 - fp: 2529.0000 - tn: 5426.0000 - fn: 3633.0000 - accuracy: 0.6126 - precision: 0.6305 - recall: 0.5430 - auc: 0.6452\n",
            " For Batch Number 498 the model has a loss of {'loss': 0.6653308868408203, 'tp': 4324.0, 'fp': 2534.0, 'tn': 5439.0, 'fn': 3639.0, 'accuracy': 0.6126380562782288, 'precision': 0.6305045485496521, 'recall': 0.5430114269256592, 'auc': 0.6452363133430481} \n",
            "498/689 [====================>.........] - ETA: 11s - loss: 0.6653 - tp: 4324.0000 - fp: 2534.0000 - tn: 5439.0000 - fn: 3639.0000 - accuracy: 0.6126 - precision: 0.6305 - recall: 0.5430 - auc: 0.6452\n",
            " For Batch Number 499 the model has a loss of {'loss': 0.6654472351074219, 'tp': 4331.0, 'fp': 2536.0, 'tn': 5448.0, 'fn': 3653.0, 'accuracy': 0.6124123334884644, 'precision': 0.6306975483894348, 'recall': 0.5424599051475525, 'auc': 0.645032525062561} \n",
            "499/689 [====================>.........] - ETA: 10s - loss: 0.6654 - tp: 4331.0000 - fp: 2536.0000 - tn: 5448.0000 - fn: 3653.0000 - accuracy: 0.6124 - precision: 0.6307 - recall: 0.5425 - auc: 0.6450\n",
            " For Batch Number 500 the model has a loss of {'loss': 0.6653680801391602, 'tp': 4340.0, 'fp': 2539.0, 'tn': 5460.0, 'fn': 3661.0, 'accuracy': 0.612500011920929, 'precision': 0.6309056282043457, 'recall': 0.5424321889877319, 'auc': 0.6452166438102722} \n",
            "\n",
            " For Batch Number 501 the model has a loss of {'loss': 0.6653284430503845, 'tp': 4351.0, 'fp': 2543.0, 'tn': 5469.0, 'fn': 3669.0, 'accuracy': 0.6125249266624451, 'precision': 0.6311284899711609, 'recall': 0.542518675327301, 'auc': 0.645226240158081} \n",
            "501/689 [====================>.........] - ETA: 10s - loss: 0.6653 - tp: 4351.0000 - fp: 2543.0000 - tn: 5469.0000 - fn: 3669.0000 - accuracy: 0.6125 - precision: 0.6311 - recall: 0.5425 - auc: 0.6452\n",
            " For Batch Number 502 the model has a loss of {'loss': 0.665520966053009, 'tp': 4362.0, 'fp': 2555.0, 'tn': 5475.0, 'fn': 3672.0, 'accuracy': 0.6123630404472351, 'precision': 0.6306201815605164, 'recall': 0.5429425239562988, 'auc': 0.6450210213661194} \n",
            "502/689 [====================>.........] - ETA: 10s - loss: 0.6655 - tp: 4362.0000 - fp: 2555.0000 - tn: 5475.0000 - fn: 3672.0000 - accuracy: 0.6124 - precision: 0.6306 - recall: 0.5429 - auc: 0.6450\n",
            " For Batch Number 503 the model has a loss of {'loss': 0.6655258536338806, 'tp': 4374.0, 'fp': 2565.0, 'tn': 5480.0, 'fn': 3677.0, 'accuracy': 0.6122018098831177, 'precision': 0.6303501725196838, 'recall': 0.5432865619659424, 'auc': 0.6450089812278748} \n",
            "503/689 [====================>.........] - ETA: 10s - loss: 0.6655 - tp: 4374.0000 - fp: 2565.0000 - tn: 5480.0000 - fn: 3677.0000 - accuracy: 0.6122 - precision: 0.6304 - recall: 0.5433 - auc: 0.6450\n",
            " For Batch Number 504 the model has a loss of {'loss': 0.6657869815826416, 'tp': 4385.0, 'fp': 2577.0, 'tn': 5485.0, 'fn': 3681.0, 'accuracy': 0.6119791865348816, 'precision': 0.6298477649688721, 'recall': 0.5436399579048157, 'auc': 0.6447467803955078} \n",
            "504/689 [====================>.........] - ETA: 10s - loss: 0.6658 - tp: 4385.0000 - fp: 2577.0000 - tn: 5485.0000 - fn: 3681.0000 - accuracy: 0.6120 - precision: 0.6298 - recall: 0.5436 - auc: 0.6447\n",
            " For Batch Number 505 the model has a loss of {'loss': 0.6659709215164185, 'tp': 4395.0, 'fp': 2588.0, 'tn': 5490.0, 'fn': 3687.0, 'accuracy': 0.6116955280303955, 'precision': 0.6293856501579285, 'recall': 0.5438010096549988, 'auc': 0.6444502472877502} \n",
            "\n",
            " For Batch Number 506 the model has a loss of {'loss': 0.6660022139549255, 'tp': 4405.0, 'fp': 2596.0, 'tn': 5499.0, 'fn': 3692.0, 'accuracy': 0.6116600632667542, 'precision': 0.6291958093643188, 'recall': 0.544028639793396, 'auc': 0.6443765163421631} \n",
            "506/689 [=====================>........] - ETA: 10s - loss: 0.6660 - tp: 4405.0000 - fp: 2596.0000 - tn: 5499.0000 - fn: 3692.0000 - accuracy: 0.6117 - precision: 0.6292 - recall: 0.5440 - auc: 0.6444\n",
            " For Batch Number 507 the model has a loss of {'loss': 0.6660171151161194, 'tp': 4413.0, 'fp': 2601.0, 'tn': 5507.0, 'fn': 3703.0, 'accuracy': 0.6114398241043091, 'precision': 0.6291702389717102, 'recall': 0.5437407493591309, 'auc': 0.6443074345588684} \n",
            "507/689 [=====================>........] - ETA: 10s - loss: 0.6660 - tp: 4413.0000 - fp: 2601.0000 - tn: 5507.0000 - fn: 3703.0000 - accuracy: 0.6114 - precision: 0.6292 - recall: 0.5437 - auc: 0.6443\n",
            " For Batch Number 508 the model has a loss of {'loss': 0.6660679578781128, 'tp': 4424.0, 'fp': 2604.0, 'tn': 5514.0, 'fn': 3714.0, 'accuracy': 0.611343502998352, 'precision': 0.629482090473175, 'recall': 0.5436224937438965, 'auc': 0.6442009210586548} \n",
            "508/689 [=====================>........] - ETA: 10s - loss: 0.6661 - tp: 4424.0000 - fp: 2604.0000 - tn: 5514.0000 - fn: 3714.0000 - accuracy: 0.6113 - precision: 0.6295 - recall: 0.5436 - auc: 0.6442\n",
            " For Batch Number 509 the model has a loss of {'loss': 0.6660042405128479, 'tp': 4432.0, 'fp': 2611.0, 'tn': 5526.0, 'fn': 3719.0, 'accuracy': 0.611370325088501, 'precision': 0.6292772889137268, 'recall': 0.54373699426651, 'auc': 0.6442410945892334} \n",
            "509/689 [=====================>........] - ETA: 10s - loss: 0.6660 - tp: 4432.0000 - fp: 2611.0000 - tn: 5526.0000 - fn: 3719.0000 - accuracy: 0.6114 - precision: 0.6293 - recall: 0.5437 - auc: 0.6442\n",
            " For Batch Number 510 the model has a loss of {'loss': 0.666022002696991, 'tp': 4441.0, 'fp': 2617.0, 'tn': 5536.0, 'fn': 3726.0, 'accuracy': 0.611335813999176, 'precision': 0.6292150616645813, 'recall': 0.5437737107276917, 'auc': 0.6441372632980347} \n",
            "510/689 [=====================>........] - ETA: 10s - loss: 0.6660 - tp: 4441.0000 - fp: 2617.0000 - tn: 5536.0000 - fn: 3726.0000 - accuracy: 0.6113 - precision: 0.6292 - recall: 0.5438 - auc: 0.6441\n",
            " For Batch Number 511 the model has a loss of {'loss': 0.6662049293518066, 'tp': 4446.0, 'fp': 2627.0, 'tn': 5545.0, 'fn': 3734.0, 'accuracy': 0.6109955906867981, 'precision': 0.6285876035690308, 'recall': 0.5435208082199097, 'auc': 0.6437684893608093} \n",
            "511/689 [=====================>........] - ETA: 10s - loss: 0.6662 - tp: 4446.0000 - fp: 2627.0000 - tn: 5545.0000 - fn: 3734.0000 - accuracy: 0.6110 - precision: 0.6286 - recall: 0.5435 - auc: 0.6438\n",
            " For Batch Number 512 the model has a loss of {'loss': 0.666243851184845, 'tp': 4455.0, 'fp': 2632.0, 'tn': 5552.0, 'fn': 3745.0, 'accuracy': 0.61077880859375, 'precision': 0.6286157965660095, 'recall': 0.5432927012443542, 'auc': 0.6437026858329773} \n",
            "512/689 [=====================>........] - ETA: 10s - loss: 0.6662 - tp: 4455.0000 - fp: 2632.0000 - tn: 5552.0000 - fn: 3745.0000 - accuracy: 0.6108 - precision: 0.6286 - recall: 0.5433 - auc: 0.6437\n",
            " For Batch Number 513 the model has a loss of {'loss': 0.666207492351532, 'tp': 4464.0, 'fp': 2639.0, 'tn': 5563.0, 'fn': 3750.0, 'accuracy': 0.6108065247535706, 'precision': 0.6284668445587158, 'recall': 0.5434623956680298, 'auc': 0.6437110900878906} \n",
            "513/689 [=====================>........] - ETA: 10s - loss: 0.6662 - tp: 4464.0000 - fp: 2639.0000 - tn: 5563.0000 - fn: 3750.0000 - accuracy: 0.6108 - precision: 0.6285 - recall: 0.5435 - auc: 0.6437\n",
            " For Batch Number 514 the model has a loss of {'loss': 0.6661350727081299, 'tp': 4474.0, 'fp': 2645.0, 'tn': 5574.0, 'fn': 3755.0, 'accuracy': 0.6108949184417725, 'precision': 0.6284590363502502, 'recall': 0.5436869859695435, 'auc': 0.6437844038009644} \n",
            "514/689 [=====================>........] - ETA: 10s - loss: 0.6661 - tp: 4474.0000 - fp: 2645.0000 - tn: 5574.0000 - fn: 3755.0000 - accuracy: 0.6109 - precision: 0.6285 - recall: 0.5437 - auc: 0.6438\n",
            " For Batch Number 515 the model has a loss of {'loss': 0.6660693287849426, 'tp': 4484.0, 'fp': 2650.0, 'tn': 5585.0, 'fn': 3761.0, 'accuracy': 0.6109830141067505, 'precision': 0.6285393834114075, 'recall': 0.5438447594642639, 'auc': 0.6438661217689514} \n",
            "\n",
            " For Batch Number 516 the model has a loss of {'loss': 0.6661436557769775, 'tp': 4487.0, 'fp': 2660.0, 'tn': 5598.0, 'fn': 3767.0, 'accuracy': 0.6107679009437561, 'precision': 0.627815842628479, 'recall': 0.5436152219772339, 'auc': 0.6436048746109009} \n",
            "516/689 [=====================>........] - ETA: 9s - loss: 0.6661 - tp: 4487.0000 - fp: 2660.0000 - tn: 5598.0000 - fn: 3767.0000 - accuracy: 0.6108 - precision: 0.6278 - recall: 0.5436 - auc: 0.6436 \n",
            " For Batch Number 517 the model has a loss of {'loss': 0.6660881042480469, 'tp': 4489.0, 'fp': 2664.0, 'tn': 5615.0, 'fn': 3776.0, 'accuracy': 0.6107349991798401, 'precision': 0.6275688409805298, 'recall': 0.5431336760520935, 'auc': 0.6435993909835815} \n",
            "517/689 [=====================>........] - ETA: 9s - loss: 0.6661 - tp: 4489.0000 - fp: 2664.0000 - tn: 5615.0000 - fn: 3776.0000 - accuracy: 0.6107 - precision: 0.6276 - recall: 0.5431 - auc: 0.6436\n",
            " For Batch Number 518 the model has a loss of {'loss': 0.6661161184310913, 'tp': 4491.0, 'fp': 2665.0, 'tn': 5633.0, 'fn': 3787.0, 'accuracy': 0.6107625365257263, 'precision': 0.627585232257843, 'recall': 0.5425223708152771, 'auc': 0.6434702277183533} \n",
            "518/689 [=====================>........] - ETA: 9s - loss: 0.6661 - tp: 4491.0000 - fp: 2665.0000 - tn: 5633.0000 - fn: 3787.0000 - accuracy: 0.6108 - precision: 0.6276 - recall: 0.5425 - auc: 0.6435\n",
            " For Batch Number 519 the model has a loss of {'loss': 0.6663026213645935, 'tp': 4493.0, 'fp': 2665.0, 'tn': 5649.0, 'fn': 3801.0, 'accuracy': 0.6106695532798767, 'precision': 0.6276893019676208, 'recall': 0.5417169332504272, 'auc': 0.6431275606155396} \n",
            "\n",
            " For Batch Number 520 the model has a loss of {'loss': 0.6662284135818481, 'tp': 4493.0, 'fp': 2665.0, 'tn': 5669.0, 'fn': 3813.0, 'accuracy': 0.6106970906257629, 'precision': 0.6276893019676208, 'recall': 0.5409342646598816, 'auc': 0.6432235240936279} \n",
            "520/689 [=====================>........] - ETA: 9s - loss: 0.6662 - tp: 4493.0000 - fp: 2665.0000 - tn: 5669.0000 - fn: 3813.0000 - accuracy: 0.6107 - precision: 0.6277 - recall: 0.5409 - auc: 0.6432\n",
            " For Batch Number 521 the model has a loss of {'loss': 0.6662705540657043, 'tp': 4494.0, 'fp': 2665.0, 'tn': 5685.0, 'fn': 3828.0, 'accuracy': 0.6105446219444275, 'precision': 0.627741277217865, 'recall': 0.5400144457817078, 'auc': 0.6431038975715637} \n",
            "521/689 [=====================>........] - ETA: 9s - loss: 0.6663 - tp: 4494.0000 - fp: 2665.0000 - tn: 5685.0000 - fn: 3828.0000 - accuracy: 0.6105 - precision: 0.6277 - recall: 0.5400 - auc: 0.6431\n",
            " For Batch Number 522 the model has a loss of {'loss': 0.6664535999298096, 'tp': 4496.0, 'fp': 2665.0, 'tn': 5695.0, 'fn': 3848.0, 'accuracy': 0.6100934147834778, 'precision': 0.627845287322998, 'recall': 0.5388302803039551, 'auc': 0.6427385807037354} \n",
            "522/689 [=====================>........] - ETA: 9s - loss: 0.6665 - tp: 4496.0000 - fp: 2665.0000 - tn: 5695.0000 - fn: 3848.0000 - accuracy: 0.6101 - precision: 0.6278 - recall: 0.5388 - auc: 0.6427\n",
            " For Batch Number 523 the model has a loss of {'loss': 0.666370689868927, 'tp': 4506.0, 'fp': 2670.0, 'tn': 5709.0, 'fn': 3851.0, 'accuracy': 0.6103609204292297, 'precision': 0.6279264092445374, 'recall': 0.5391886830329895, 'auc': 0.6427936553955078} \n",
            "\n",
            " For Batch Number 524 the model has a loss of {'loss': 0.666476845741272, 'tp': 4514.0, 'fp': 2689.0, 'tn': 5713.0, 'fn': 3852.0, 'accuracy': 0.6099117398262024, 'precision': 0.6266833543777466, 'recall': 0.5395649075508118, 'auc': 0.6424732208251953} \n",
            "524/689 [=====================>........] - ETA: 9s - loss: 0.6665 - tp: 4514.0000 - fp: 2689.0000 - tn: 5713.0000 - fn: 3852.0000 - accuracy: 0.6099 - precision: 0.6267 - recall: 0.5396 - auc: 0.6425\n",
            " For Batch Number 525 the model has a loss of {'loss': 0.6665806770324707, 'tp': 4527.0, 'fp': 2702.0, 'tn': 5716.0, 'fn': 3855.0, 'accuracy': 0.6097024083137512, 'precision': 0.6262276768684387, 'recall': 0.5400859117507935, 'auc': 0.6423619985580444} \n",
            "525/689 [=====================>........] - ETA: 9s - loss: 0.6666 - tp: 4527.0000 - fp: 2702.0000 - tn: 5716.0000 - fn: 3855.0000 - accuracy: 0.6097 - precision: 0.6262 - recall: 0.5401 - auc: 0.6424\n",
            " For Batch Number 526 the model has a loss of {'loss': 0.666571855545044, 'tp': 4539.0, 'fp': 2712.0, 'tn': 5723.0, 'fn': 3858.0, 'accuracy': 0.6096720695495605, 'precision': 0.6259826421737671, 'recall': 0.540550172328949, 'auc': 0.6423117518424988} \n",
            "526/689 [=====================>........] - ETA: 9s - loss: 0.6666 - tp: 4539.0000 - fp: 2712.0000 - tn: 5723.0000 - fn: 3858.0000 - accuracy: 0.6097 - precision: 0.6260 - recall: 0.5406 - auc: 0.6423\n",
            " For Batch Number 527 the model has a loss of {'loss': 0.6665022969245911, 'tp': 4550.0, 'fp': 2719.0, 'tn': 5733.0, 'fn': 3862.0, 'accuracy': 0.6097604632377625, 'precision': 0.6259458065032959, 'recall': 0.5408939719200134, 'auc': 0.6423641443252563} \n",
            "527/689 [=====================>........] - ETA: 9s - loss: 0.6665 - tp: 4550.0000 - fp: 2719.0000 - tn: 5733.0000 - fn: 3862.0000 - accuracy: 0.6098 - precision: 0.6259 - recall: 0.5409 - auc: 0.6424\n",
            " For Batch Number 528 the model has a loss of {'loss': 0.666379451751709, 'tp': 4558.0, 'fp': 2721.0, 'tn': 5745.0, 'fn': 3872.0, 'accuracy': 0.6097893118858337, 'precision': 0.6261849403381348, 'recall': 0.5406880378723145, 'auc': 0.6425122618675232} \n",
            "\n",
            " For Batch Number 529 the model has a loss of {'loss': 0.6661673784255981, 'tp': 4567.0, 'fp': 2723.0, 'tn': 5762.0, 'fn': 3876.0, 'accuracy': 0.6101725101470947, 'precision': 0.6264746189117432, 'recall': 0.5409214496612549, 'auc': 0.64276522397995} \n",
            "529/689 [======================>.......] - ETA: 9s - loss: 0.6662 - tp: 4567.0000 - fp: 2723.0000 - tn: 5762.0000 - fn: 3876.0000 - accuracy: 0.6102 - precision: 0.6265 - recall: 0.5409 - auc: 0.6428\n",
            " For Batch Number 530 the model has a loss of {'loss': 0.6661268472671509, 'tp': 4578.0, 'fp': 2727.0, 'tn': 5770.0, 'fn': 3885.0, 'accuracy': 0.6101415157318115, 'precision': 0.6266940236091614, 'recall': 0.540942907333374, 'auc': 0.6428073048591614} \n",
            "\n",
            " For Batch Number 531 the model has a loss of {'loss': 0.6661026477813721, 'tp': 4584.0, 'fp': 2730.0, 'tn': 5785.0, 'fn': 3893.0, 'accuracy': 0.6102283596992493, 'precision': 0.6267432570457458, 'recall': 0.5407573580741882, 'auc': 0.6428959965705872} \n",
            "531/689 [======================>.......] - ETA: 9s - loss: 0.6661 - tp: 4584.0000 - fp: 2730.0000 - tn: 5785.0000 - fn: 3893.0000 - accuracy: 0.6102 - precision: 0.6267 - recall: 0.5408 - auc: 0.6429\n",
            " For Batch Number 532 the model has a loss of {'loss': 0.6661266684532166, 'tp': 4591.0, 'fp': 2733.0, 'tn': 5796.0, 'fn': 3904.0, 'accuracy': 0.6101386547088623, 'precision': 0.626843273639679, 'recall': 0.5404355525970459, 'auc': 0.6428676843643188} \n",
            "532/689 [======================>.......] - ETA: 9s - loss: 0.6661 - tp: 4591.0000 - fp: 2733.0000 - tn: 5796.0000 - fn: 3904.0000 - accuracy: 0.6101 - precision: 0.6268 - recall: 0.5404 - auc: 0.6429\n",
            " For Batch Number 533 the model has a loss of {'loss': 0.6660991311073303, 'tp': 4601.0, 'fp': 2737.0, 'tn': 5807.0, 'fn': 3911.0, 'accuracy': 0.6102251410484314, 'precision': 0.6270101070404053, 'recall': 0.5405310392379761, 'auc': 0.6428689956665039} \n",
            "533/689 [======================>.......] - ETA: 8s - loss: 0.6661 - tp: 4601.0000 - fp: 2737.0000 - tn: 5807.0000 - fn: 3911.0000 - accuracy: 0.6102 - precision: 0.6270 - recall: 0.5405 - auc: 0.6429\n",
            " For Batch Number 534 the model has a loss of {'loss': 0.6661859154701233, 'tp': 4610.0, 'fp': 2744.0, 'tn': 5814.0, 'fn': 3920.0, 'accuracy': 0.6100187301635742, 'precision': 0.6268697381019592, 'recall': 0.5404455065727234, 'auc': 0.6427604556083679} \n",
            "534/689 [======================>.......] - ETA: 8s - loss: 0.6662 - tp: 4610.0000 - fp: 2744.0000 - tn: 5814.0000 - fn: 3920.0000 - accuracy: 0.6100 - precision: 0.6269 - recall: 0.5404 - auc: 0.6428\n",
            " For Batch Number 535 the model has a loss of {'loss': 0.6661140322685242, 'tp': 4623.0, 'fp': 2749.0, 'tn': 5824.0, 'fn': 3924.0, 'accuracy': 0.6102219820022583, 'precision': 0.6271025538444519, 'recall': 0.5408915281295776, 'auc': 0.6429429054260254} \n",
            "535/689 [======================>.......] - ETA: 8s - loss: 0.6661 - tp: 4623.0000 - fp: 2749.0000 - tn: 5824.0000 - fn: 3924.0000 - accuracy: 0.6102 - precision: 0.6271 - recall: 0.5409 - auc: 0.6429\n",
            " For Batch Number 536 the model has a loss of {'loss': 0.6662633419036865, 'tp': 4630.0, 'fp': 2760.0, 'tn': 5834.0, 'fn': 3928.0, 'accuracy': 0.6100746393203735, 'precision': 0.6265223026275635, 'recall': 0.5410142540931702, 'auc': 0.6427554488182068} \n",
            "\n",
            " For Batch Number 537 the model has a loss of {'loss': 0.6660785675048828, 'tp': 4640.0, 'fp': 2762.0, 'tn': 5848.0, 'fn': 3934.0, 'accuracy': 0.6103351712226868, 'precision': 0.626857578754425, 'recall': 0.5411709547042847, 'auc': 0.6430253982543945} \n",
            "537/689 [======================>.......] - ETA: 8s - loss: 0.6661 - tp: 4640.0000 - fp: 2762.0000 - tn: 5848.0000 - fn: 3934.0000 - accuracy: 0.6103 - precision: 0.6269 - recall: 0.5412 - auc: 0.6430\n",
            " For Batch Number 538 the model has a loss of {'loss': 0.6659256219863892, 'tp': 4650.0, 'fp': 2763.0, 'tn': 5861.0, 'fn': 3942.0, 'accuracy': 0.6105366945266724, 'precision': 0.6272764205932617, 'recall': 0.541201114654541, 'auc': 0.6432653069496155} \n",
            "538/689 [======================>.......] - ETA: 8s - loss: 0.6659 - tp: 4650.0000 - fp: 2763.0000 - tn: 5861.0000 - fn: 3942.0000 - accuracy: 0.6105 - precision: 0.6273 - recall: 0.5412 - auc: 0.6433\n",
            " For Batch Number 539 the model has a loss of {'loss': 0.665693461894989, 'tp': 4658.0, 'fp': 2764.0, 'tn': 5877.0, 'fn': 3949.0, 'accuracy': 0.6107954382896423, 'precision': 0.6275936365127563, 'recall': 0.5411874055862427, 'auc': 0.6436470150947571} \n",
            "539/689 [======================>.......] - ETA: 8s - loss: 0.6657 - tp: 4658.0000 - fp: 2764.0000 - tn: 5877.0000 - fn: 3949.0000 - accuracy: 0.6108 - precision: 0.6276 - recall: 0.5412 - auc: 0.6436\n",
            " For Batch Number 540 the model has a loss of {'loss': 0.6657459139823914, 'tp': 4666.0, 'fp': 2766.0, 'tn': 5889.0, 'fn': 3959.0, 'accuracy': 0.6108217835426331, 'precision': 0.6278256177902222, 'recall': 0.5409855246543884, 'auc': 0.6435625553131104} \n",
            "540/689 [======================>.......] - ETA: 8s - loss: 0.6657 - tp: 4666.0000 - fp: 2766.0000 - tn: 5889.0000 - fn: 3959.0000 - accuracy: 0.6108 - precision: 0.6278 - recall: 0.5410 - auc: 0.6436\n",
            " For Batch Number 541 the model has a loss of {'loss': 0.6657196283340454, 'tp': 4673.0, 'fp': 2768.0, 'tn': 5901.0, 'fn': 3970.0, 'accuracy': 0.6107901930809021, 'precision': 0.6280069947242737, 'recall': 0.5406687259674072, 'auc': 0.6435893774032593} \n",
            "\n",
            " For Batch Number 542 the model has a loss of {'loss': 0.6655462980270386, 'tp': 4683.0, 'fp': 2771.0, 'tn': 5914.0, 'fn': 3976.0, 'accuracy': 0.6109893918037415, 'precision': 0.6282532811164856, 'recall': 0.5408245921134949, 'auc': 0.643837034702301} \n",
            "542/689 [======================>.......] - ETA: 8s - loss: 0.6655 - tp: 4683.0000 - fp: 2771.0000 - tn: 5914.0000 - fn: 3976.0000 - accuracy: 0.6110 - precision: 0.6283 - recall: 0.5408 - auc: 0.6438\n",
            " For Batch Number 543 the model has a loss of {'loss': 0.6653791666030884, 'tp': 4693.0, 'fp': 2775.0, 'tn': 5928.0, 'fn': 3980.0, 'accuracy': 0.6112453937530518, 'precision': 0.6284145712852478, 'recall': 0.5411045551300049, 'auc': 0.6440073251724243} \n",
            "543/689 [======================>.......] - ETA: 8s - loss: 0.6654 - tp: 4693.0000 - fp: 2775.0000 - tn: 5928.0000 - fn: 3980.0000 - accuracy: 0.6112 - precision: 0.6284 - recall: 0.5411 - auc: 0.6440\n",
            " For Batch Number 544 the model has a loss of {'loss': 0.6651839017868042, 'tp': 4706.0, 'fp': 2778.0, 'tn': 5938.0, 'fn': 3986.0, 'accuracy': 0.611443042755127, 'precision': 0.6288081407546997, 'recall': 0.5414174199104309, 'auc': 0.6442781686782837} \n",
            "\n",
            " For Batch Number 545 the model has a loss of {'loss': 0.6651687622070312, 'tp': 4719.0, 'fp': 2784.0, 'tn': 5946.0, 'fn': 3991.0, 'accuracy': 0.6115252375602722, 'precision': 0.628948450088501, 'recall': 0.5417910218238831, 'auc': 0.6443859934806824} \n",
            "545/689 [======================>.......] - ETA: 8s - loss: 0.6652 - tp: 4719.0000 - fp: 2784.0000 - tn: 5946.0000 - fn: 3991.0000 - accuracy: 0.6115 - precision: 0.6289 - recall: 0.5418 - auc: 0.6444\n",
            " For Batch Number 546 the model has a loss of {'loss': 0.6655619144439697, 'tp': 4728.0, 'fp': 2795.0, 'tn': 5953.0, 'fn': 3996.0, 'accuracy': 0.611320972442627, 'precision': 0.6284726858139038, 'recall': 0.5419532060623169, 'auc': 0.6441464424133301} \n",
            "546/689 [======================>.......] - ETA: 8s - loss: 0.6656 - tp: 4728.0000 - fp: 2795.0000 - tn: 5953.0000 - fn: 3996.0000 - accuracy: 0.6113 - precision: 0.6285 - recall: 0.5420 - auc: 0.6441\n",
            " For Batch Number 547 the model has a loss of {'loss': 0.6652811765670776, 'tp': 4740.0, 'fp': 2798.0, 'tn': 5966.0, 'fn': 4000.0, 'accuracy': 0.6116316318511963, 'precision': 0.6288139820098877, 'recall': 0.5423340797424316, 'auc': 0.6444870829582214} \n",
            "547/689 [======================>.......] - ETA: 8s - loss: 0.6653 - tp: 4740.0000 - fp: 2798.0000 - tn: 5966.0000 - fn: 4000.0000 - accuracy: 0.6116 - precision: 0.6288 - recall: 0.5423 - auc: 0.6445\n",
            " For Batch Number 548 the model has a loss of {'loss': 0.6651602983474731, 'tp': 4751.0, 'fp': 2802.0, 'tn': 5978.0, 'fn': 4005.0, 'accuracy': 0.6118270754814148, 'precision': 0.6290215849876404, 'recall': 0.5425993800163269, 'auc': 0.6447576284408569} \n",
            "548/689 [======================>.......] - ETA: 8s - loss: 0.6652 - tp: 4751.0000 - fp: 2802.0000 - tn: 5978.0000 - fn: 4005.0000 - accuracy: 0.6118 - precision: 0.6290 - recall: 0.5426 - auc: 0.6448\n",
            " For Batch Number 549 the model has a loss of {'loss': 0.6649662852287292, 'tp': 4762.0, 'fp': 2806.0, 'tn': 5990.0, 'fn': 4010.0, 'accuracy': 0.6120218634605408, 'precision': 0.6292283535003662, 'recall': 0.542863667011261, 'auc': 0.6450218558311462} \n",
            "549/689 [======================>.......] - ETA: 8s - loss: 0.6650 - tp: 4762.0000 - fp: 2806.0000 - tn: 5990.0000 - fn: 4010.0000 - accuracy: 0.6120 - precision: 0.6292 - recall: 0.5429 - auc: 0.6450\n",
            " For Batch Number 550 the model has a loss of {'loss': 0.664793848991394, 'tp': 4771.0, 'fp': 2807.0, 'tn': 6001.0, 'fn': 4021.0, 'accuracy': 0.6120454668998718, 'precision': 0.6295856237411499, 'recall': 0.542652428150177, 'auc': 0.645348846912384} \n",
            "550/689 [======================>.......] - ETA: 7s - loss: 0.6648 - tp: 4771.0000 - fp: 2807.0000 - tn: 6001.0000 - fn: 4021.0000 - accuracy: 0.6120 - precision: 0.6296 - recall: 0.5427 - auc: 0.6453\n",
            " For Batch Number 551 the model has a loss of {'loss': 0.6647175550460815, 'tp': 4784.0, 'fp': 2808.0, 'tn': 6009.0, 'fn': 4031.0, 'accuracy': 0.6121256947517395, 'precision': 0.6301369667053223, 'recall': 0.5427112579345703, 'auc': 0.645465612411499} \n",
            "\n",
            " For Batch Number 552 the model has a loss of {'loss': 0.6644865274429321, 'tp': 4798.0, 'fp': 2811.0, 'tn': 6017.0, 'fn': 4038.0, 'accuracy': 0.6122622489929199, 'precision': 0.6305690407752991, 'recall': 0.5430058836936951, 'auc': 0.6457698345184326} \n",
            "552/689 [=======================>......] - ETA: 7s - loss: 0.6645 - tp: 4798.0000 - fp: 2811.0000 - tn: 6017.0000 - fn: 4038.0000 - accuracy: 0.6123 - precision: 0.6306 - recall: 0.5430 - auc: 0.6458\n",
            " For Batch Number 553 the model has a loss of {'loss': 0.6644105911254883, 'tp': 4809.0, 'fp': 2816.0, 'tn': 6031.0, 'fn': 4040.0, 'accuracy': 0.6125677824020386, 'precision': 0.6306885480880737, 'recall': 0.5434512495994568, 'auc': 0.6460919976234436} \n",
            "553/689 [=======================>......] - ETA: 7s - loss: 0.6644 - tp: 4809.0000 - fp: 2816.0000 - tn: 6031.0000 - fn: 4040.0000 - accuracy: 0.6126 - precision: 0.6307 - recall: 0.5435 - auc: 0.6461\n",
            " For Batch Number 554 the model has a loss of {'loss': 0.6642888188362122, 'tp': 4820.0, 'fp': 2824.0, 'tn': 6042.0, 'fn': 4042.0, 'accuracy': 0.6127030849456787, 'precision': 0.6305599212646484, 'recall': 0.5438953042030334, 'auc': 0.646215558052063} \n",
            "554/689 [=======================>......] - ETA: 7s - loss: 0.6643 - tp: 4820.0000 - fp: 2824.0000 - tn: 6042.0000 - fn: 4042.0000 - accuracy: 0.6127 - precision: 0.6306 - recall: 0.5439 - auc: 0.6462\n",
            " For Batch Number 555 the model has a loss of {'loss': 0.664313018321991, 'tp': 4830.0, 'fp': 2832.0, 'tn': 6052.0, 'fn': 4046.0, 'accuracy': 0.6127251982688904, 'precision': 0.6303837299346924, 'recall': 0.5441640615463257, 'auc': 0.6461068391799927} \n",
            "\n",
            " For Batch Number 556 the model has a loss of {'loss': 0.6642643809318542, 'tp': 4842.0, 'fp': 2838.0, 'tn': 6061.0, 'fn': 4051.0, 'accuracy': 0.6128035187721252, 'precision': 0.6304687261581421, 'recall': 0.5444731712341309, 'auc': 0.6462372541427612} \n",
            "556/689 [=======================>......] - ETA: 7s - loss: 0.6643 - tp: 4842.0000 - fp: 2838.0000 - tn: 6061.0000 - fn: 4051.0000 - accuracy: 0.6128 - precision: 0.6305 - recall: 0.5445 - auc: 0.6462\n",
            " For Batch Number 557 the model has a loss of {'loss': 0.6642013788223267, 'tp': 4853.0, 'fp': 2845.0, 'tn': 6069.0, 'fn': 4057.0, 'accuracy': 0.6127693057060242, 'precision': 0.6304234862327576, 'recall': 0.5446689128875732, 'auc': 0.6462966799736023} \n",
            "557/689 [=======================>......] - ETA: 7s - loss: 0.6642 - tp: 4853.0000 - fp: 2845.0000 - tn: 6069.0000 - fn: 4057.0000 - accuracy: 0.6128 - precision: 0.6304 - recall: 0.5447 - auc: 0.6463\n",
            " For Batch Number 558 the model has a loss of {'loss': 0.664237916469574, 'tp': 4860.0, 'fp': 2853.0, 'tn': 6080.0, 'fn': 4063.0, 'accuracy': 0.6126791834831238, 'precision': 0.6301050186157227, 'recall': 0.5446598529815674, 'auc': 0.6462200284004211} \n",
            "558/689 [=======================>......] - ETA: 7s - loss: 0.6642 - tp: 4860.0000 - fp: 2853.0000 - tn: 6080.0000 - fn: 4063.0000 - accuracy: 0.6127 - precision: 0.6301 - recall: 0.5447 - auc: 0.6462\n",
            " For Batch Number 559 the model has a loss of {'loss': 0.6644291877746582, 'tp': 4866.0, 'fp': 2859.0, 'tn': 6093.0, 'fn': 4070.0, 'accuracy': 0.6126453280448914, 'precision': 0.6299028992652893, 'recall': 0.5445389151573181, 'auc': 0.6460028886795044} \n",
            "559/689 [=======================>......] - ETA: 7s - loss: 0.6644 - tp: 4866.0000 - fp: 2859.0000 - tn: 6093.0000 - fn: 4070.0000 - accuracy: 0.6126 - precision: 0.6299 - recall: 0.5445 - auc: 0.6460\n",
            " For Batch Number 560 the model has a loss of {'loss': 0.6642215251922607, 'tp': 4875.0, 'fp': 2863.0, 'tn': 6106.0, 'fn': 4076.0, 'accuracy': 0.6127790212631226, 'precision': 0.6300077438354492, 'recall': 0.5446318984031677, 'auc': 0.6462638974189758} \n",
            "\n",
            " For Batch Number 561 the model has a loss of {'loss': 0.664339005947113, 'tp': 4879.0, 'fp': 2871.0, 'tn': 6116.0, 'fn': 4086.0, 'accuracy': 0.61246657371521, 'precision': 0.6295483708381653, 'recall': 0.5442275404930115, 'auc': 0.6460363864898682} \n",
            "561/689 [=======================>......] - ETA: 7s - loss: 0.6643 - tp: 4879.0000 - fp: 2871.0000 - tn: 6116.0000 - fn: 4086.0000 - accuracy: 0.6125 - precision: 0.6295 - recall: 0.5442 - auc: 0.6460\n",
            " For Batch Number 562 the model has a loss of {'loss': 0.6643508672714233, 'tp': 4883.0, 'fp': 2874.0, 'tn': 6133.0, 'fn': 4094.0, 'accuracy': 0.6125444769859314, 'precision': 0.6294959187507629, 'recall': 0.5439456105232239, 'auc': 0.6460806727409363} \n",
            "\n",
            " For Batch Number 563 the model has a loss of {'loss': 0.6646270751953125, 'tp': 4885.0, 'fp': 2878.0, 'tn': 6146.0, 'fn': 4107.0, 'accuracy': 0.6122890710830688, 'precision': 0.6292670369148254, 'recall': 0.5432606935501099, 'auc': 0.6456324458122253} \n",
            "563/689 [=======================>......] - ETA: 7s - loss: 0.6646 - tp: 4885.0000 - fp: 2878.0000 - tn: 6146.0000 - fn: 4107.0000 - accuracy: 0.6123 - precision: 0.6293 - recall: 0.5433 - auc: 0.6456\n",
            " For Batch Number 564 the model has a loss of {'loss': 0.6646242141723633, 'tp': 4887.0, 'fp': 2880.0, 'tn': 6163.0, 'fn': 4118.0, 'accuracy': 0.6122562289237976, 'precision': 0.6292004585266113, 'recall': 0.5426985025405884, 'auc': 0.6456500291824341} \n",
            "564/689 [=======================>......] - ETA: 7s - loss: 0.6646 - tp: 4887.0000 - fp: 2880.0000 - tn: 6163.0000 - fn: 4118.0000 - accuracy: 0.6123 - precision: 0.6292 - recall: 0.5427 - auc: 0.6457\n",
            " For Batch Number 565 the model has a loss of {'loss': 0.6646715402603149, 'tp': 4891.0, 'fp': 2880.0, 'tn': 6175.0, 'fn': 4134.0, 'accuracy': 0.6120575070381165, 'precision': 0.6293913125991821, 'recall': 0.5419390797615051, 'auc': 0.645520806312561} \n",
            "565/689 [=======================>......] - ETA: 7s - loss: 0.6647 - tp: 4891.0000 - fp: 2880.0000 - tn: 6175.0000 - fn: 4134.0000 - accuracy: 0.6121 - precision: 0.6294 - recall: 0.5419 - auc: 0.6455\n",
            " For Batch Number 566 the model has a loss of {'loss': 0.664570152759552, 'tp': 4897.0, 'fp': 2882.0, 'tn': 6191.0, 'fn': 4142.0, 'accuracy': 0.6121907830238342, 'precision': 0.6295153498649597, 'recall': 0.5417634844779968, 'auc': 0.645623505115509} \n",
            "566/689 [=======================>......] - ETA: 7s - loss: 0.6646 - tp: 4897.0000 - fp: 2882.0000 - tn: 6191.0000 - fn: 4142.0000 - accuracy: 0.6122 - precision: 0.6295 - recall: 0.5418 - auc: 0.6456\n",
            " For Batch Number 567 the model has a loss of {'loss': 0.6645276546478271, 'tp': 4902.0, 'fp': 2889.0, 'tn': 6204.0, 'fn': 4149.0, 'accuracy': 0.6121031641960144, 'precision': 0.6291875243186951, 'recall': 0.5415976047515869, 'auc': 0.645585834980011} \n",
            "\n",
            " For Batch Number 568 the model has a loss of {'loss': 0.6646077036857605, 'tp': 4914.0, 'fp': 2895.0, 'tn': 6208.0, 'fn': 4159.0, 'accuracy': 0.6119058132171631, 'precision': 0.6292738914489746, 'recall': 0.5416069626808167, 'auc': 0.6455099582672119} \n",
            "568/689 [=======================>......] - ETA: 6s - loss: 0.6646 - tp: 4914.0000 - fp: 2895.0000 - tn: 6208.0000 - fn: 4159.0000 - accuracy: 0.6119 - precision: 0.6293 - recall: 0.5416 - auc: 0.6455\n",
            " For Batch Number 569 the model has a loss of {'loss': 0.6645692586898804, 'tp': 4926.0, 'fp': 2907.0, 'tn': 6212.0, 'fn': 4163.0, 'accuracy': 0.6117091178894043, 'precision': 0.6288778185844421, 'recall': 0.5419738292694092, 'auc': 0.6455509662628174} \n",
            "569/689 [=======================>......] - ETA: 6s - loss: 0.6646 - tp: 4926.0000 - fp: 2907.0000 - tn: 6212.0000 - fn: 4163.0000 - accuracy: 0.6117 - precision: 0.6289 - recall: 0.5420 - auc: 0.6456\n",
            " For Batch Number 570 the model has a loss of {'loss': 0.6647271513938904, 'tp': 4937.0, 'fp': 2925.0, 'tn': 6214.0, 'fn': 4164.0, 'accuracy': 0.6113486886024475, 'precision': 0.627957284450531, 'recall': 0.5424678325653076, 'auc': 0.6452653408050537} \n",
            "570/689 [=======================>......] - ETA: 6s - loss: 0.6647 - tp: 4937.0000 - fp: 2925.0000 - tn: 6214.0000 - fn: 4164.0000 - accuracy: 0.6113 - precision: 0.6280 - recall: 0.5425 - auc: 0.6453\n",
            " For Batch Number 571 the model has a loss of {'loss': 0.6648533940315247, 'tp': 4951.0, 'fp': 2937.0, 'tn': 6217.0, 'fn': 4167.0, 'accuracy': 0.6112083792686462, 'precision': 0.6276623010635376, 'recall': 0.5429918766021729, 'auc': 0.6451395153999329} \n",
            "\n",
            " For Batch Number 572 the model has a loss of {'loss': 0.6647325754165649, 'tp': 4966.0, 'fp': 2940.0, 'tn': 6226.0, 'fn': 4172.0, 'accuracy': 0.6114510297775269, 'precision': 0.6281305551528931, 'recall': 0.5434449315071106, 'auc': 0.6453610062599182} \n",
            "572/689 [=======================>......] - ETA: 6s - loss: 0.6647 - tp: 4966.0000 - fp: 2940.0000 - tn: 6226.0000 - fn: 4172.0000 - accuracy: 0.6115 - precision: 0.6281 - recall: 0.5434 - auc: 0.6454\n",
            " For Batch Number 573 the model has a loss of {'loss': 0.6647151112556458, 'tp': 4976.0, 'fp': 2946.0, 'tn': 6234.0, 'fn': 4180.0, 'accuracy': 0.6113656163215637, 'precision': 0.6281242370605469, 'recall': 0.5434687733650208, 'auc': 0.6453822255134583} \n",
            "573/689 [=======================>......] - ETA: 6s - loss: 0.6647 - tp: 4976.0000 - fp: 2946.0000 - tn: 6234.0000 - fn: 4180.0000 - accuracy: 0.6114 - precision: 0.6281 - recall: 0.5435 - auc: 0.6454\n",
            " For Batch Number 574 the model has a loss of {'loss': 0.6646868586540222, 'tp': 4983.0, 'fp': 2953.0, 'tn': 6246.0, 'fn': 4186.0, 'accuracy': 0.6113349199295044, 'precision': 0.6278981566429138, 'recall': 0.5434616804122925, 'auc': 0.6453384160995483} \n",
            "574/689 [=======================>......] - ETA: 6s - loss: 0.6647 - tp: 4983.0000 - fp: 2953.0000 - tn: 6246.0000 - fn: 4186.0000 - accuracy: 0.6113 - precision: 0.6279 - recall: 0.5435 - auc: 0.6453\n",
            " For Batch Number 575 the model has a loss of {'loss': 0.6645788550376892, 'tp': 4991.0, 'fp': 2957.0, 'tn': 6263.0, 'fn': 4189.0, 'accuracy': 0.6116304397583008, 'precision': 0.627956748008728, 'recall': 0.5436819195747375, 'auc': 0.6454829573631287} \n",
            "575/689 [========================>.....] - ETA: 6s - loss: 0.6646 - tp: 4991.0000 - fp: 2957.0000 - tn: 6263.0000 - fn: 4189.0000 - accuracy: 0.6116 - precision: 0.6280 - recall: 0.5437 - auc: 0.6455\n",
            " For Batch Number 576 the model has a loss of {'loss': 0.6644663214683533, 'tp': 4999.0, 'fp': 2959.0, 'tn': 6277.0, 'fn': 4197.0, 'accuracy': 0.6117621660232544, 'precision': 0.6281729340553284, 'recall': 0.5436059236526489, 'auc': 0.6456652283668518} \n",
            "576/689 [========================>.....] - ETA: 6s - loss: 0.6645 - tp: 4999.0000 - fp: 2959.0000 - tn: 6277.0000 - fn: 4197.0000 - accuracy: 0.6118 - precision: 0.6282 - recall: 0.5436 - auc: 0.6457\n",
            " For Batch Number 577 the model has a loss of {'loss': 0.664417028427124, 'tp': 5005.0, 'fp': 2962.0, 'tn': 6292.0, 'fn': 4205.0, 'accuracy': 0.611839234828949, 'precision': 0.6282163858413696, 'recall': 0.5434310436248779, 'auc': 0.6456989645957947} \n",
            "577/689 [========================>.....] - ETA: 6s - loss: 0.6644 - tp: 5005.0000 - fp: 2962.0000 - tn: 6292.0000 - fn: 4205.0000 - accuracy: 0.6118 - precision: 0.6282 - recall: 0.5434 - auc: 0.6457\n",
            " For Batch Number 578 the model has a loss of {'loss': 0.6644541621208191, 'tp': 5011.0, 'fp': 2963.0, 'tn': 6304.0, 'fn': 4218.0, 'accuracy': 0.6117538809776306, 'precision': 0.6284173727035522, 'recall': 0.542962372303009, 'auc': 0.6456311345100403} \n",
            "578/689 [========================>.....] - ETA: 6s - loss: 0.6645 - tp: 5011.0000 - fp: 2963.0000 - tn: 6304.0000 - fn: 4218.0000 - accuracy: 0.6118 - precision: 0.6284 - recall: 0.5430 - auc: 0.6456\n",
            " For Batch Number 579 the model has a loss of {'loss': 0.6644942760467529, 'tp': 5017.0, 'fp': 2963.0, 'tn': 6314.0, 'fn': 4234.0, 'accuracy': 0.6115608811378479, 'precision': 0.6286967396736145, 'recall': 0.5423197746276855, 'auc': 0.645535409450531} \n",
            "\n",
            " For Batch Number 580 the model has a loss of {'loss': 0.6644749045372009, 'tp': 5026.0, 'fp': 2966.0, 'tn': 6328.0, 'fn': 4240.0, 'accuracy': 0.6117457151412964, 'precision': 0.6288788914680481, 'recall': 0.5424131155014038, 'auc': 0.6455788016319275} \n",
            "580/689 [========================>.....] - ETA: 6s - loss: 0.6645 - tp: 5026.0000 - fp: 2966.0000 - tn: 6328.0000 - fn: 4240.0000 - accuracy: 0.6117 - precision: 0.6289 - recall: 0.5424 - auc: 0.6456\n",
            " For Batch Number 581 the model has a loss of {'loss': 0.6644095182418823, 'tp': 5035.0, 'fp': 2969.0, 'tn': 6339.0, 'fn': 4249.0, 'accuracy': 0.6117684841156006, 'precision': 0.6290604472160339, 'recall': 0.5423309206962585, 'auc': 0.6456722617149353} \n",
            "581/689 [========================>.....] - ETA: 6s - loss: 0.6644 - tp: 5035.0000 - fp: 2969.0000 - tn: 6339.0000 - fn: 4249.0000 - accuracy: 0.6118 - precision: 0.6291 - recall: 0.5423 - auc: 0.6457\n",
            " For Batch Number 582 the model has a loss of {'loss': 0.6644036173820496, 'tp': 5046.0, 'fp': 2973.0, 'tn': 6347.0, 'fn': 4258.0, 'accuracy': 0.6117375493049622, 'precision': 0.6292555332183838, 'recall': 0.5423473715782166, 'auc': 0.6456647515296936} \n",
            "582/689 [========================>.....] - ETA: 6s - loss: 0.6644 - tp: 5046.0000 - fp: 2973.0000 - tn: 6347.0000 - fn: 4258.0000 - accuracy: 0.6117 - precision: 0.6293 - recall: 0.5423 - auc: 0.6457\n",
            " For Batch Number 583 the model has a loss of {'loss': 0.6643642783164978, 'tp': 5058.0, 'fp': 2979.0, 'tn': 6356.0, 'fn': 4263.0, 'accuracy': 0.6118139028549194, 'precision': 0.6293392777442932, 'recall': 0.5426456332206726, 'auc': 0.6457704305648804} \n",
            "\n",
            " For Batch Number 584 the model has a loss of {'loss': 0.6643017530441284, 'tp': 5072.0, 'fp': 2987.0, 'tn': 6362.0, 'fn': 4267.0, 'accuracy': 0.6118364930152893, 'precision': 0.6293584704399109, 'recall': 0.5430988073348999, 'auc': 0.6458442807197571} \n",
            "584/689 [========================>.....] - ETA: 6s - loss: 0.6643 - tp: 5072.0000 - fp: 2987.0000 - tn: 6362.0000 - fn: 4267.0000 - accuracy: 0.6118 - precision: 0.6294 - recall: 0.5431 - auc: 0.6458\n",
            " For Batch Number 585 the model has a loss of {'loss': 0.6643438339233398, 'tp': 5083.0, 'fp': 2998.0, 'tn': 6370.0, 'fn': 4269.0, 'accuracy': 0.6118055582046509, 'precision': 0.6290063261985779, 'recall': 0.5435200929641724, 'auc': 0.6457934975624084} \n",
            "585/689 [========================>.....] - ETA: 5s - loss: 0.6643 - tp: 5083.0000 - fp: 2998.0000 - tn: 6370.0000 - fn: 4269.0000 - accuracy: 0.6118 - precision: 0.6290 - recall: 0.5435 - auc: 0.6458\n",
            " For Batch Number 586 the model has a loss of {'loss': 0.6641989946365356, 'tp': 5098.0, 'fp': 3005.0, 'tn': 6376.0, 'fn': 4273.0, 'accuracy': 0.6118813753128052, 'precision': 0.6291496753692627, 'recall': 0.5440188050270081, 'auc': 0.6460058093070984} \n",
            "\n",
            " For Batch Number 587 the model has a loss of {'loss': 0.664181649684906, 'tp': 5109.0, 'fp': 3012.0, 'tn': 6385.0, 'fn': 4278.0, 'accuracy': 0.611903727054596, 'precision': 0.6291097402572632, 'recall': 0.5442633628845215, 'auc': 0.645983099937439} \n",
            "587/689 [========================>.....] - ETA: 5s - loss: 0.6642 - tp: 5109.0000 - fp: 3012.0000 - tn: 6385.0000 - fn: 4278.0000 - accuracy: 0.6119 - precision: 0.6291 - recall: 0.5443 - auc: 0.6460\n",
            " For Batch Number 588 the model has a loss of {'loss': 0.6640638709068298, 'tp': 5121.0, 'fp': 3015.0, 'tn': 6396.0, 'fn': 4284.0, 'accuracy': 0.6120854616165161, 'precision': 0.6294247508049011, 'recall': 0.5444976091384888, 'auc': 0.6461355090141296} \n",
            "588/689 [========================>.....] - ETA: 5s - loss: 0.6641 - tp: 5121.0000 - fp: 3015.0000 - tn: 6396.0000 - fn: 4284.0000 - accuracy: 0.6121 - precision: 0.6294 - recall: 0.5445 - auc: 0.6461\n",
            " For Batch Number 589 the model has a loss of {'loss': 0.6641495823860168, 'tp': 5130.0, 'fp': 3020.0, 'tn': 6404.0, 'fn': 4294.0, 'accuracy': 0.6119481921195984, 'precision': 0.629447877407074, 'recall': 0.5443548560142517, 'auc': 0.6459565758705139} \n",
            "\n",
            " For Batch Number 590 the model has a loss of {'loss': 0.6641498804092407, 'tp': 5138.0, 'fp': 3023.0, 'tn': 6418.0, 'fn': 4301.0, 'accuracy': 0.6120762825012207, 'precision': 0.6295797228813171, 'recall': 0.5443373322486877, 'auc': 0.6459770202636719} \n",
            "590/689 [========================>.....] - ETA: 5s - loss: 0.6641 - tp: 5138.0000 - fp: 3023.0000 - tn: 6418.0000 - fn: 4301.0000 - accuracy: 0.6121 - precision: 0.6296 - recall: 0.5443 - auc: 0.6460\n",
            " For Batch Number 591 the model has a loss of {'loss': 0.6641557216644287, 'tp': 5145.0, 'fp': 3027.0, 'tn': 6428.0, 'fn': 4312.0, 'accuracy': 0.6119394898414612, 'precision': 0.6295888423919678, 'recall': 0.5440414547920227, 'auc': 0.6458758115768433} \n",
            "591/689 [========================>.....] - ETA: 5s - loss: 0.6642 - tp: 5145.0000 - fp: 3027.0000 - tn: 6428.0000 - fn: 4312.0000 - accuracy: 0.6119 - precision: 0.6296 - recall: 0.5440 - auc: 0.6459\n",
            " For Batch Number 592 the model has a loss of {'loss': 0.6640687584877014, 'tp': 5155.0, 'fp': 3029.0, 'tn': 6442.0, 'fn': 4318.0, 'accuracy': 0.6121727228164673, 'precision': 0.629887580871582, 'recall': 0.5441781878471375, 'auc': 0.6459921002388} \n",
            "592/689 [========================>.....] - ETA: 5s - loss: 0.6641 - tp: 5155.0000 - fp: 3029.0000 - tn: 6442.0000 - fn: 4318.0000 - accuracy: 0.6122 - precision: 0.6299 - recall: 0.5442 - auc: 0.6460\n",
            " For Batch Number 593 the model has a loss of {'loss': 0.6640321612358093, 'tp': 5164.0, 'fp': 3032.0, 'tn': 6454.0, 'fn': 4326.0, 'accuracy': 0.6122470498085022, 'precision': 0.6300634741783142, 'recall': 0.5441517233848572, 'auc': 0.6460500955581665} \n",
            "593/689 [========================>.....] - ETA: 5s - loss: 0.6640 - tp: 5164.0000 - fp: 3032.0000 - tn: 6454.0000 - fn: 4326.0000 - accuracy: 0.6122 - precision: 0.6301 - recall: 0.5442 - auc: 0.6461\n",
            " For Batch Number 594 the model has a loss of {'loss': 0.6639406085014343, 'tp': 5173.0, 'fp': 3034.0, 'tn': 6465.0, 'fn': 4336.0, 'accuracy': 0.6122685074806213, 'precision': 0.6303156018257141, 'recall': 0.5440109372138977, 'auc': 0.64613938331604} \n",
            "594/689 [========================>.....] - ETA: 5s - loss: 0.6639 - tp: 5173.0000 - fp: 3034.0000 - tn: 6465.0000 - fn: 4336.0000 - accuracy: 0.6123 - precision: 0.6303 - recall: 0.5440 - auc: 0.6461\n",
            " For Batch Number 595 the model has a loss of {'loss': 0.663925051689148, 'tp': 5182.0, 'fp': 3040.0, 'tn': 6479.0, 'fn': 4339.0, 'accuracy': 0.6124475002288818, 'precision': 0.6302602887153625, 'recall': 0.5442705750465393, 'auc': 0.6461620330810547} \n",
            "595/689 [========================>.....] - ETA: 5s - loss: 0.6639 - tp: 5182.0000 - fp: 3040.0000 - tn: 6479.0000 - fn: 4339.0000 - accuracy: 0.6124 - precision: 0.6303 - recall: 0.5443 - auc: 0.6462\n",
            " For Batch Number 596 the model has a loss of {'loss': 0.6639111638069153, 'tp': 5188.0, 'fp': 3044.0, 'tn': 6496.0, 'fn': 4344.0, 'accuracy': 0.6126258373260498, 'precision': 0.6302235126495361, 'recall': 0.5442719459533691, 'auc': 0.6462359428405762} \n",
            "596/689 [========================>.....] - ETA: 5s - loss: 0.6639 - tp: 5188.0000 - fp: 3044.0000 - tn: 6496.0000 - fn: 4344.0000 - accuracy: 0.6126 - precision: 0.6302 - recall: 0.5443 - auc: 0.6462\n",
            " For Batch Number 597 the model has a loss of {'loss': 0.6635938286781311, 'tp': 5197.0, 'fp': 3046.0, 'tn': 6514.0, 'fn': 4347.0, 'accuracy': 0.613012969493866, 'precision': 0.630474328994751, 'recall': 0.5445305705070496, 'auc': 0.6467709541320801} \n",
            "597/689 [========================>.....] - ETA: 5s - loss: 0.6636 - tp: 5197.0000 - fp: 3046.0000 - tn: 6514.0000 - fn: 4347.0000 - accuracy: 0.6130 - precision: 0.6305 - recall: 0.5445 - auc: 0.6468\n",
            " For Batch Number 598 the model has a loss of {'loss': 0.6637636423110962, 'tp': 5203.0, 'fp': 3048.0, 'tn': 6527.0, 'fn': 4358.0, 'accuracy': 0.6129807829856873, 'precision': 0.6305902600288391, 'recall': 0.5441899299621582, 'auc': 0.6466090083122253} \n",
            "598/689 [=========================>....] - ETA: 5s - loss: 0.6638 - tp: 5203.0000 - fp: 3048.0000 - tn: 6527.0000 - fn: 4358.0000 - accuracy: 0.6130 - precision: 0.6306 - recall: 0.5442 - auc: 0.6466\n",
            " For Batch Number 599 the model has a loss of {'loss': 0.6636038422584534, 'tp': 5210.0, 'fp': 3050.0, 'tn': 6543.0, 'fn': 4365.0, 'accuracy': 0.613157331943512, 'precision': 0.6307505965232849, 'recall': 0.5441253185272217, 'auc': 0.6468886137008667} \n",
            "\n",
            " For Batch Number 600 the model has a loss of {'loss': 0.6635555624961853, 'tp': 5214.0, 'fp': 3051.0, 'tn': 6561.0, 'fn': 4374.0, 'accuracy': 0.61328125, 'precision': 0.630852997303009, 'recall': 0.5438047647476196, 'auc': 0.6470288038253784} \n",
            "600/689 [=========================>....] - ETA: 5s - loss: 0.6636 - tp: 5214.0000 - fp: 3051.0000 - tn: 6561.0000 - fn: 4374.0000 - accuracy: 0.6133 - precision: 0.6309 - recall: 0.5438 - auc: 0.6470\n",
            " For Batch Number 601 the model has a loss of {'loss': 0.6636287569999695, 'tp': 5221.0, 'fp': 3052.0, 'tn': 6573.0, 'fn': 4386.0, 'accuracy': 0.6132487654685974, 'precision': 0.6310890913009644, 'recall': 0.5434578657150269, 'auc': 0.6469542980194092} \n",
            "601/689 [=========================>....] - ETA: 5s - loss: 0.6636 - tp: 5221.0000 - fp: 3052.0000 - tn: 6573.0000 - fn: 4386.0000 - accuracy: 0.6132 - precision: 0.6311 - recall: 0.5435 - auc: 0.6470\n",
            " For Batch Number 602 the model has a loss of {'loss': 0.6634291410446167, 'tp': 5231.0, 'fp': 3053.0, 'tn': 6587.0, 'fn': 4393.0, 'accuracy': 0.6134759187698364, 'precision': 0.6314582228660583, 'recall': 0.5435369610786438, 'auc': 0.6472375392913818} \n",
            "602/689 [=========================>....] - ETA: 4s - loss: 0.6634 - tp: 5231.0000 - fp: 3053.0000 - tn: 6587.0000 - fn: 4393.0000 - accuracy: 0.6135 - precision: 0.6315 - recall: 0.5435 - auc: 0.6472\n",
            " For Batch Number 603 the model has a loss of {'loss': 0.663284420967102, 'tp': 5239.0, 'fp': 3055.0, 'tn': 6602.0, 'fn': 4400.0, 'accuracy': 0.6136505007743835, 'precision': 0.6316614151000977, 'recall': 0.5435211062431335, 'auc': 0.6474649310112} \n",
            "603/689 [=========================>....] - ETA: 4s - loss: 0.6633 - tp: 5239.0000 - fp: 3055.0000 - tn: 6602.0000 - fn: 4400.0000 - accuracy: 0.6137 - precision: 0.6317 - recall: 0.5435 - auc: 0.6475\n",
            " For Batch Number 604 the model has a loss of {'loss': 0.6632035374641418, 'tp': 5247.0, 'fp': 3057.0, 'tn': 6614.0, 'fn': 4410.0, 'accuracy': 0.6136692762374878, 'precision': 0.6318641901016235, 'recall': 0.5433364510536194, 'auc': 0.6475260257720947} \n",
            "\n",
            " For Batch Number 605 the model has a loss of {'loss': 0.6630721688270569, 'tp': 5259.0, 'fp': 3061.0, 'tn': 6624.0, 'fn': 4416.0, 'accuracy': 0.6137913465499878, 'precision': 0.6320913434028625, 'recall': 0.5435658693313599, 'auc': 0.6477121710777283} \n",
            "605/689 [=========================>....] - ETA: 4s - loss: 0.6631 - tp: 5259.0000 - fp: 3061.0000 - tn: 6624.0000 - fn: 4416.0000 - accuracy: 0.6138 - precision: 0.6321 - recall: 0.5436 - auc: 0.6477\n",
            " For Batch Number 606 the model has a loss of {'loss': 0.6628783941268921, 'tp': 5274.0, 'fp': 3064.0, 'tn': 6635.0, 'fn': 4419.0, 'accuracy': 0.6141192317008972, 'precision': 0.6325258016586304, 'recall': 0.5441039800643921, 'auc': 0.648013710975647} \n",
            "606/689 [=========================>....] - ETA: 4s - loss: 0.6629 - tp: 5274.0000 - fp: 3064.0000 - tn: 6635.0000 - fn: 4419.0000 - accuracy: 0.6141 - precision: 0.6325 - recall: 0.5441 - auc: 0.6480\n",
            " For Batch Number 607 the model has a loss of {'loss': 0.6628268957138062, 'tp': 5284.0, 'fp': 3074.0, 'tn': 6645.0, 'fn': 4421.0, 'accuracy': 0.6141371726989746, 'precision': 0.6322086453437805, 'recall': 0.5444616079330444, 'auc': 0.6480791568756104} \n",
            "607/689 [=========================>....] - ETA: 4s - loss: 0.6628 - tp: 5284.0000 - fp: 3074.0000 - tn: 6645.0000 - fn: 4421.0000 - accuracy: 0.6141 - precision: 0.6322 - recall: 0.5445 - auc: 0.6481\n",
            " For Batch Number 608 the model has a loss of {'loss': 0.6629312634468079, 'tp': 5289.0, 'fp': 3081.0, 'tn': 6655.0, 'fn': 4431.0, 'accuracy': 0.6138980388641357, 'precision': 0.6318996548652649, 'recall': 0.5441358089447021, 'auc': 0.6480500102043152} \n",
            "608/689 [=========================>....] - ETA: 4s - loss: 0.6629 - tp: 5289.0000 - fp: 3081.0000 - tn: 6655.0000 - fn: 4431.0000 - accuracy: 0.6139 - precision: 0.6319 - recall: 0.5441 - auc: 0.6481\n",
            " For Batch Number 609 the model has a loss of {'loss': 0.662975013256073, 'tp': 5296.0, 'fp': 3082.0, 'tn': 6664.0, 'fn': 4446.0, 'accuracy': 0.6137109994888306, 'precision': 0.6321317553520203, 'recall': 0.54362553358078, 'auc': 0.6480003595352173} \n",
            "609/689 [=========================>....] - ETA: 4s - loss: 0.6630 - tp: 5296.0000 - fp: 3082.0000 - tn: 6664.0000 - fn: 4446.0000 - accuracy: 0.6137 - precision: 0.6321 - recall: 0.5436 - auc: 0.6480\n",
            " For Batch Number 610 the model has a loss of {'loss': 0.6629371047019958, 'tp': 5306.0, 'fp': 3084.0, 'tn': 6674.0, 'fn': 4456.0, 'accuracy': 0.6137295365333557, 'precision': 0.6324195265769958, 'recall': 0.5435361862182617, 'auc': 0.6481093168258667} \n",
            "610/689 [=========================>....] - ETA: 4s - loss: 0.6629 - tp: 5306.0000 - fp: 3084.0000 - tn: 6674.0000 - fn: 4456.0000 - accuracy: 0.6137 - precision: 0.6324 - recall: 0.5435 - auc: 0.6481\n",
            " For Batch Number 611 the model has a loss of {'loss': 0.6630122661590576, 'tp': 5318.0, 'fp': 3090.0, 'tn': 6685.0, 'fn': 4459.0, 'accuracy': 0.6139013767242432, 'precision': 0.6324928402900696, 'recall': 0.5439296364784241, 'auc': 0.6481980085372925} \n",
            "611/689 [=========================>....] - ETA: 4s - loss: 0.6630 - tp: 5318.0000 - fp: 3090.0000 - tn: 6685.0000 - fn: 4459.0000 - accuracy: 0.6139 - precision: 0.6325 - recall: 0.5439 - auc: 0.6482\n",
            " For Batch Number 612 the model has a loss of {'loss': 0.6632212400436401, 'tp': 5328.0, 'fp': 3100.0, 'tn': 6694.0, 'fn': 4462.0, 'accuracy': 0.6138684749603271, 'precision': 0.6321784257888794, 'recall': 0.5442287921905518, 'auc': 0.6480430960655212} \n",
            "\n",
            " For Batch Number 613 the model has a loss of {'loss': 0.6630135774612427, 'tp': 5340.0, 'fp': 3106.0, 'tn': 6703.0, 'fn': 4467.0, 'accuracy': 0.6139376163482666, 'precision': 0.6322519779205322, 'recall': 0.5445090532302856, 'auc': 0.6482555270195007} \n",
            "613/689 [=========================>....] - ETA: 4s - loss: 0.6630 - tp: 5340.0000 - fp: 3106.0000 - tn: 6703.0000 - fn: 4467.0000 - accuracy: 0.6139 - precision: 0.6323 - recall: 0.5445 - auc: 0.6483\n",
            " For Batch Number 614 the model has a loss of {'loss': 0.6628563404083252, 'tp': 5350.0, 'fp': 3110.0, 'tn': 6713.0, 'fn': 4475.0, 'accuracy': 0.6139556169509888, 'precision': 0.6323876976966858, 'recall': 0.5445292592048645, 'auc': 0.648424506187439} \n",
            "\n",
            " For Batch Number 615 the model has a loss of {'loss': 0.6629318594932556, 'tp': 5359.0, 'fp': 3112.0, 'tn': 6725.0, 'fn': 4484.0, 'accuracy': 0.6140244007110596, 'precision': 0.6326289772987366, 'recall': 0.5444478392601013, 'auc': 0.6483981609344482} \n",
            "615/689 [=========================>....] - ETA: 4s - loss: 0.6629 - tp: 5359.0000 - fp: 3112.0000 - tn: 6725.0000 - fn: 4484.0000 - accuracy: 0.6140 - precision: 0.6326 - recall: 0.5444 - auc: 0.6484\n",
            " For Batch Number 616 the model has a loss of {'loss': 0.6630268692970276, 'tp': 5368.0, 'fp': 3115.0, 'tn': 6734.0, 'fn': 4495.0, 'accuracy': 0.6139407753944397, 'precision': 0.632794976234436, 'recall': 0.544256329536438, 'auc': 0.6482434868812561} \n",
            "616/689 [=========================>....] - ETA: 4s - loss: 0.6630 - tp: 5368.0000 - fp: 3115.0000 - tn: 6734.0000 - fn: 4495.0000 - accuracy: 0.6139 - precision: 0.6328 - recall: 0.5443 - auc: 0.6482\n",
            " For Batch Number 617 the model has a loss of {'loss': 0.6629800200462341, 'tp': 5377.0, 'fp': 3117.0, 'tn': 6746.0, 'fn': 4504.0, 'accuracy': 0.6140093207359314, 'precision': 0.6330350637435913, 'recall': 0.5441756844520569, 'auc': 0.6482964158058167} \n",
            "617/689 [=========================>....] - ETA: 4s - loss: 0.6630 - tp: 5377.0000 - fp: 3117.0000 - tn: 6746.0000 - fn: 4504.0000 - accuracy: 0.6140 - precision: 0.6330 - recall: 0.5442 - auc: 0.6483\n",
            " For Batch Number 618 the model has a loss of {'loss': 0.6629231572151184, 'tp': 5390.0, 'fp': 3120.0, 'tn': 6756.0, 'fn': 4510.0, 'accuracy': 0.6141787767410278, 'precision': 0.6333724856376648, 'recall': 0.5444444417953491, 'auc': 0.6484509706497192} \n",
            "618/689 [=========================>....] - ETA: 4s - loss: 0.6629 - tp: 5390.0000 - fp: 3120.0000 - tn: 6756.0000 - fn: 4510.0000 - accuracy: 0.6142 - precision: 0.6334 - recall: 0.5444 - auc: 0.6485\n",
            " For Batch Number 619 the model has a loss of {'loss': 0.6630843281745911, 'tp': 5397.0, 'fp': 3128.0, 'tn': 6770.0, 'fn': 4513.0, 'accuracy': 0.6142467856407166, 'precision': 0.6330791711807251, 'recall': 0.5446014404296875, 'auc': 0.6482955813407898} \n",
            "619/689 [=========================>....] - ETA: 4s - loss: 0.6631 - tp: 5397.0000 - fp: 3128.0000 - tn: 6770.0000 - fn: 4513.0000 - accuracy: 0.6142 - precision: 0.6331 - recall: 0.5446 - auc: 0.6483\n",
            " For Batch Number 620 the model has a loss of {'loss': 0.6630824208259583, 'tp': 5407.0, 'fp': 3134.0, 'tn': 6779.0, 'fn': 4520.0, 'accuracy': 0.6142137050628662, 'precision': 0.6330640316009521, 'recall': 0.5446761250495911, 'auc': 0.6482663154602051} \n",
            "\n",
            " For Batch Number 621 the model has a loss of {'loss': 0.6629911661148071, 'tp': 5414.0, 'fp': 3138.0, 'tn': 6790.0, 'fn': 4530.0, 'accuracy': 0.614130437374115, 'precision': 0.6330682635307312, 'recall': 0.5444489121437073, 'auc': 0.6483169794082642} \n",
            "621/689 [==========================>...] - ETA: 3s - loss: 0.6630 - tp: 5414.0000 - fp: 3138.0000 - tn: 6790.0000 - fn: 4530.0000 - accuracy: 0.6141 - precision: 0.6331 - recall: 0.5444 - auc: 0.6483\n",
            " For Batch Number 622 the model has a loss of {'loss': 0.6630449891090393, 'tp': 5421.0, 'fp': 3144.0, 'tn': 6799.0, 'fn': 4540.0, 'accuracy': 0.6139469742774963, 'precision': 0.6329246759414673, 'recall': 0.5442224740982056, 'auc': 0.648137629032135} \n",
            "622/689 [==========================>...] - ETA: 3s - loss: 0.6630 - tp: 5421.0000 - fp: 3144.0000 - tn: 6799.0000 - fn: 4540.0000 - accuracy: 0.6139 - precision: 0.6329 - recall: 0.5442 - auc: 0.6481\n",
            " For Batch Number 623 the model has a loss of {'loss': 0.6630085110664368, 'tp': 5428.0, 'fp': 3148.0, 'tn': 6811.0, 'fn': 4549.0, 'accuracy': 0.6139145493507385, 'precision': 0.6329290866851807, 'recall': 0.5440512895584106, 'auc': 0.6481229662895203} \n",
            "\n",
            " For Batch Number 624 the model has a loss of {'loss': 0.6631227135658264, 'tp': 5433.0, 'fp': 3153.0, 'tn': 6825.0, 'fn': 4557.0, 'accuracy': 0.6138821840286255, 'precision': 0.632774293422699, 'recall': 0.5438438653945923, 'auc': 0.648017942905426} \n",
            "624/689 [==========================>...] - ETA: 3s - loss: 0.6631 - tp: 5433.0000 - fp: 3153.0000 - tn: 6825.0000 - fn: 4557.0000 - accuracy: 0.6139 - precision: 0.6328 - recall: 0.5438 - auc: 0.6480\n",
            " For Batch Number 625 the model has a loss of {'loss': 0.6630014181137085, 'tp': 5443.0, 'fp': 3154.0, 'tn': 6838.0, 'fn': 4565.0, 'accuracy': 0.6140499711036682, 'precision': 0.6331278085708618, 'recall': 0.543864905834198, 'auc': 0.6481979489326477} \n",
            "625/689 [==========================>...] - ETA: 3s - loss: 0.6630 - tp: 5443.0000 - fp: 3154.0000 - tn: 6838.0000 - fn: 4565.0000 - accuracy: 0.6140 - precision: 0.6331 - recall: 0.5439 - auc: 0.6482\n",
            " For Batch Number 626 the model has a loss of {'loss': 0.6630111336708069, 'tp': 5451.0, 'fp': 3156.0, 'tn': 6849.0, 'fn': 4576.0, 'accuracy': 0.6140175461769104, 'precision': 0.6333217024803162, 'recall': 0.5436322093009949, 'auc': 0.6481819152832031} \n",
            "626/689 [==========================>...] - ETA: 3s - loss: 0.6630 - tp: 5451.0000 - fp: 3156.0000 - tn: 6849.0000 - fn: 4576.0000 - accuracy: 0.6140 - precision: 0.6333 - recall: 0.5436 - auc: 0.6482\n",
            " For Batch Number 627 the model has a loss of {'loss': 0.6629937291145325, 'tp': 5460.0, 'fp': 3158.0, 'tn': 6859.0, 'fn': 4587.0, 'accuracy': 0.6139852404594421, 'precision': 0.6335576772689819, 'recall': 0.5434458255767822, 'auc': 0.6481660008430481} \n",
            "\n",
            " For Batch Number 628 the model has a loss of {'loss': 0.663072407245636, 'tp': 5468.0, 'fp': 3163.0, 'tn': 6866.0, 'fn': 4599.0, 'accuracy': 0.6137539744377136, 'precision': 0.63353031873703, 'recall': 0.5431607961654663, 'auc': 0.6480456590652466} \n",
            "628/689 [==========================>...] - ETA: 3s - loss: 0.6631 - tp: 5468.0000 - fp: 3163.0000 - tn: 6866.0000 - fn: 4599.0000 - accuracy: 0.6138 - precision: 0.6335 - recall: 0.5432 - auc: 0.6480\n",
            " For Batch Number 629 the model has a loss of {'loss': 0.6629812121391296, 'tp': 5482.0, 'fp': 3170.0, 'tn': 6875.0, 'fn': 4601.0, 'accuracy': 0.6139209270477295, 'precision': 0.633610725402832, 'recall': 0.5436874032020569, 'auc': 0.6481772661209106} \n",
            "\n",
            " For Batch Number 630 the model has a loss of {'loss': 0.6628797650337219, 'tp': 5498.0, 'fp': 3179.0, 'tn': 6878.0, 'fn': 4605.0, 'accuracy': 0.6138888597488403, 'precision': 0.6336291432380676, 'recall': 0.5441948175430298, 'auc': 0.6483197212219238} \n",
            "630/689 [==========================>...] - ETA: 3s - loss: 0.6629 - tp: 5498.0000 - fp: 3179.0000 - tn: 6878.0000 - fn: 4605.0000 - accuracy: 0.6139 - precision: 0.6336 - recall: 0.5442 - auc: 0.6483\n",
            " For Batch Number 631 the model has a loss of {'loss': 0.6629560589790344, 'tp': 5515.0, 'fp': 3193.0, 'tn': 6878.0, 'fn': 4606.0, 'accuracy': 0.6137579083442688, 'precision': 0.6333256959915161, 'recall': 0.5449066162109375, 'auc': 0.648309051990509} \n",
            "\n",
            " For Batch Number 632 the model has a loss of {'loss': 0.6631799340248108, 'tp': 5529.0, 'fp': 3210.0, 'tn': 6878.0, 'fn': 4607.0, 'accuracy': 0.6134790182113647, 'precision': 0.6326810717582703, 'recall': 0.5454814434051514, 'auc': 0.6480624079704285} \n",
            "632/689 [==========================>...] - ETA: 3s - loss: 0.6632 - tp: 5529.0000 - fp: 3210.0000 - tn: 6878.0000 - fn: 4607.0000 - accuracy: 0.6135 - precision: 0.6327 - recall: 0.5455 - auc: 0.6481\n",
            " For Batch Number 633 the model has a loss of {'loss': 0.6630938053131104, 'tp': 5548.0, 'fp': 3221.0, 'tn': 6880.0, 'fn': 4607.0, 'accuracy': 0.61354660987854, 'precision': 0.6326833367347717, 'recall': 0.5463318824768066, 'auc': 0.6481861472129822} \n",
            "633/689 [==========================>...] - ETA: 3s - loss: 0.6631 - tp: 5548.0000 - fp: 3221.0000 - tn: 6880.0000 - fn: 4607.0000 - accuracy: 0.6135 - precision: 0.6327 - recall: 0.5463 - auc: 0.6482\n",
            " For Batch Number 634 the model has a loss of {'loss': 0.6630788445472717, 'tp': 5563.0, 'fp': 3229.0, 'tn': 6884.0, 'fn': 4612.0, 'accuracy': 0.6135153770446777, 'precision': 0.6327342987060547, 'recall': 0.5467321872711182, 'auc': 0.6482359170913696} \n",
            "634/689 [==========================>...] - ETA: 3s - loss: 0.6631 - tp: 5563.0000 - fp: 3229.0000 - tn: 6884.0000 - fn: 4612.0000 - accuracy: 0.6135 - precision: 0.6327 - recall: 0.5467 - auc: 0.6482\n",
            " For Batch Number 635 the model has a loss of {'loss': 0.6631084680557251, 'tp': 5580.0, 'fp': 3235.0, 'tn': 6889.0, 'fn': 4616.0, 'accuracy': 0.6136319041252136, 'precision': 0.6330119371414185, 'recall': 0.5472734570503235, 'auc': 0.6483275294303894} \n",
            "635/689 [==========================>...] - ETA: 3s - loss: 0.6631 - tp: 5580.0000 - fp: 3235.0000 - tn: 6889.0000 - fn: 4616.0000 - accuracy: 0.6136 - precision: 0.6330 - recall: 0.5473 - auc: 0.6483\n",
            " For Batch Number 636 the model has a loss of {'loss': 0.6632651686668396, 'tp': 5590.0, 'fp': 3247.0, 'tn': 6897.0, 'fn': 4618.0, 'accuracy': 0.6135514974594116, 'precision': 0.6325675845146179, 'recall': 0.5476097464561462, 'auc': 0.6481562852859497} \n",
            "636/689 [==========================>...] - ETA: 3s - loss: 0.6633 - tp: 5590.0000 - fp: 3247.0000 - tn: 6897.0000 - fn: 4618.0000 - accuracy: 0.6136 - precision: 0.6326 - recall: 0.5476 - auc: 0.6482\n",
            " For Batch Number 637 the model has a loss of {'loss': 0.6631932258605957, 'tp': 5600.0, 'fp': 3254.0, 'tn': 6907.0, 'fn': 4623.0, 'accuracy': 0.613569438457489, 'precision': 0.6324824690818787, 'recall': 0.5477843880653381, 'auc': 0.6482136845588684} \n",
            "637/689 [==========================>...] - ETA: 2s - loss: 0.6632 - tp: 5600.0000 - fp: 3254.0000 - tn: 6907.0000 - fn: 4623.0000 - accuracy: 0.6136 - precision: 0.6325 - recall: 0.5478 - auc: 0.6482\n",
            " For Batch Number 638 the model has a loss of {'loss': 0.6632131338119507, 'tp': 5610.0, 'fp': 3257.0, 'tn': 6915.0, 'fn': 4634.0, 'accuracy': 0.6134894490242004, 'precision': 0.6326829791069031, 'recall': 0.5476376414299011, 'auc': 0.6481802463531494} \n",
            "\n",
            " For Batch Number 639 the model has a loss of {'loss': 0.663147509098053, 'tp': 5617.0, 'fp': 3257.0, 'tn': 6932.0, 'fn': 4642.0, 'accuracy': 0.6137030720710754, 'precision': 0.6329727172851562, 'recall': 0.5475192666053772, 'auc': 0.6482211351394653} \n",
            "639/689 [==========================>...] - ETA: 2s - loss: 0.6631 - tp: 5617.0000 - fp: 3257.0000 - tn: 6932.0000 - fn: 4642.0000 - accuracy: 0.6137 - precision: 0.6330 - recall: 0.5475 - auc: 0.6482\n",
            " For Batch Number 640 the model has a loss of {'loss': 0.6631693840026855, 'tp': 5622.0, 'fp': 3260.0, 'tn': 6946.0, 'fn': 4652.0, 'accuracy': 0.6136718988418579, 'precision': 0.6329655647277832, 'recall': 0.5472065210342407, 'auc': 0.6481454968452454} \n",
            "640/689 [==========================>...] - ETA: 2s - loss: 0.6632 - tp: 5622.0000 - fp: 3260.0000 - tn: 6946.0000 - fn: 4652.0000 - accuracy: 0.6137 - precision: 0.6330 - recall: 0.5472 - auc: 0.6481\n",
            " For Batch Number 641 the model has a loss of {'loss': 0.663128674030304, 'tp': 5630.0, 'fp': 3265.0, 'tn': 6959.0, 'fn': 4658.0, 'accuracy': 0.6137382984161377, 'precision': 0.632939875125885, 'recall': 0.5472394824028015, 'auc': 0.648181140422821} \n",
            "641/689 [==========================>...] - ETA: 2s - loss: 0.6631 - tp: 5630.0000 - fp: 3265.0000 - tn: 6959.0000 - fn: 4658.0000 - accuracy: 0.6137 - precision: 0.6329 - recall: 0.5472 - auc: 0.6482\n",
            " For Batch Number 642 the model has a loss of {'loss': 0.6631649136543274, 'tp': 5635.0, 'fp': 3271.0, 'tn': 6972.0, 'fn': 4666.0, 'accuracy': 0.6136584877967834, 'precision': 0.6327195167541504, 'recall': 0.5470342636108398, 'auc': 0.6480679512023926} \n",
            "642/689 [==========================>...] - ETA: 2s - loss: 0.6632 - tp: 5635.0000 - fp: 3271.0000 - tn: 6972.0000 - fn: 4666.0000 - accuracy: 0.6137 - precision: 0.6327 - recall: 0.5470 - auc: 0.6481\n",
            " For Batch Number 643 the model has a loss of {'loss': 0.6632146835327148, 'tp': 5639.0, 'fp': 3274.0, 'tn': 6987.0, 'fn': 4676.0, 'accuracy': 0.613627552986145, 'precision': 0.6326713562011719, 'recall': 0.5466796159744263, 'auc': 0.6479194164276123} \n",
            "643/689 [==========================>...] - ETA: 2s - loss: 0.6632 - tp: 5639.0000 - fp: 3274.0000 - tn: 6987.0000 - fn: 4676.0000 - accuracy: 0.6136 - precision: 0.6327 - recall: 0.5467 - auc: 0.6479\n",
            " For Batch Number 644 the model has a loss of {'loss': 0.6631630659103394, 'tp': 5646.0, 'fp': 3275.0, 'tn': 7001.0, 'fn': 4686.0, 'accuracy': 0.6136937141418457, 'precision': 0.632888674736023, 'recall': 0.5464575886726379, 'auc': 0.6480032205581665} \n",
            "\n",
            " For Batch Number 645 the model has a loss of {'loss': 0.6631821990013123, 'tp': 5652.0, 'fp': 3279.0, 'tn': 7011.0, 'fn': 4698.0, 'accuracy': 0.6135174632072449, 'precision': 0.6328518390655518, 'recall': 0.5460869669914246, 'auc': 0.6479523181915283} \n",
            "645/689 [===========================>..] - ETA: 2s - loss: 0.6632 - tp: 5652.0000 - fp: 3279.0000 - tn: 7011.0000 - fn: 4698.0000 - accuracy: 0.6135 - precision: 0.6329 - recall: 0.5461 - auc: 0.6480\n",
            " For Batch Number 646 the model has a loss of {'loss': 0.6631519794464111, 'tp': 5659.0, 'fp': 3281.0, 'tn': 7022.0, 'fn': 4710.0, 'accuracy': 0.6134384870529175, 'precision': 0.6329977512359619, 'recall': 0.5457614064216614, 'auc': 0.6480458974838257} \n",
            "646/689 [===========================>..] - ETA: 2s - loss: 0.6632 - tp: 5659.0000 - fp: 3281.0000 - tn: 7022.0000 - fn: 4710.0000 - accuracy: 0.6134 - precision: 0.6330 - recall: 0.5458 - auc: 0.6480\n",
            " For Batch Number 647 the model has a loss of {'loss': 0.6629608273506165, 'tp': 5672.0, 'fp': 3283.0, 'tn': 7034.0, 'fn': 4715.0, 'accuracy': 0.6136978268623352, 'precision': 0.6333891749382019, 'recall': 0.5460671782493591, 'auc': 0.6483220458030701} \n",
            "647/689 [===========================>..] - ETA: 2s - loss: 0.6630 - tp: 5672.0000 - fp: 3283.0000 - tn: 7034.0000 - fn: 4715.0000 - accuracy: 0.6137 - precision: 0.6334 - recall: 0.5461 - auc: 0.6483\n",
            " For Batch Number 648 the model has a loss of {'loss': 0.6629655957221985, 'tp': 5680.0, 'fp': 3295.0, 'tn': 7043.0, 'fn': 4718.0, 'accuracy': 0.6135706305503845, 'precision': 0.6328690648078918, 'recall': 0.5462588667869568, 'auc': 0.6482533812522888} \n",
            "648/689 [===========================>..] - ETA: 2s - loss: 0.6630 - tp: 5680.0000 - fp: 3295.0000 - tn: 7043.0000 - fn: 4718.0000 - accuracy: 0.6136 - precision: 0.6329 - recall: 0.5463 - auc: 0.6483\n",
            " For Batch Number 649 the model has a loss of {'loss': 0.6628953814506531, 'tp': 5694.0, 'fp': 3303.0, 'tn': 7049.0, 'fn': 4722.0, 'accuracy': 0.6135882139205933, 'precision': 0.6328776478767395, 'recall': 0.546658992767334, 'auc': 0.6483716368675232} \n",
            "649/689 [===========================>..] - ETA: 2s - loss: 0.6629 - tp: 5694.0000 - fp: 3303.0000 - tn: 7049.0000 - fn: 4722.0000 - accuracy: 0.6136 - precision: 0.6329 - recall: 0.5467 - auc: 0.6484\n",
            " For Batch Number 650 the model has a loss of {'loss': 0.662796139717102, 'tp': 5707.0, 'fp': 3310.0, 'tn': 7058.0, 'fn': 4725.0, 'accuracy': 0.6137019395828247, 'precision': 0.6329156160354614, 'recall': 0.5470666885375977, 'auc': 0.6485435366630554} \n",
            "650/689 [===========================>..] - ETA: 2s - loss: 0.6628 - tp: 5707.0000 - fp: 3310.0000 - tn: 7058.0000 - fn: 4725.0000 - accuracy: 0.6137 - precision: 0.6329 - recall: 0.5471 - auc: 0.6485\n",
            " For Batch Number 651 the model has a loss of {'loss': 0.663001298904419, 'tp': 5716.0, 'fp': 3320.0, 'tn': 7065.0, 'fn': 4731.0, 'accuracy': 0.613527238368988, 'precision': 0.6325808167457581, 'recall': 0.547142744064331, 'auc': 0.6484094262123108} \n",
            "651/689 [===========================>..] - ETA: 2s - loss: 0.6630 - tp: 5716.0000 - fp: 3320.0000 - tn: 7065.0000 - fn: 4731.0000 - accuracy: 0.6135 - precision: 0.6326 - recall: 0.5471 - auc: 0.6484\n",
            " For Batch Number 652 the model has a loss of {'loss': 0.6629589796066284, 'tp': 5725.0, 'fp': 3326.0, 'tn': 7075.0, 'fn': 4738.0, 'accuracy': 0.6134969592094421, 'precision': 0.6325268149375916, 'recall': 0.5471662282943726, 'auc': 0.6485018134117126} \n",
            "652/689 [===========================>..] - ETA: 2s - loss: 0.6630 - tp: 5725.0000 - fp: 3326.0000 - tn: 7075.0000 - fn: 4738.0000 - accuracy: 0.6135 - precision: 0.6325 - recall: 0.5472 - auc: 0.6485\n",
            " For Batch Number 653 the model has a loss of {'loss': 0.6627582907676697, 'tp': 5732.0, 'fp': 3331.0, 'tn': 7091.0, 'fn': 4742.0, 'accuracy': 0.6136581301689148, 'precision': 0.632461667060852, 'recall': 0.5472598671913147, 'auc': 0.6487320065498352} \n",
            "653/689 [===========================>..] - ETA: 2s - loss: 0.6628 - tp: 5732.0000 - fp: 3331.0000 - tn: 7091.0000 - fn: 4742.0000 - accuracy: 0.6137 - precision: 0.6325 - recall: 0.5473 - auc: 0.6487\n",
            " For Batch Number 654 the model has a loss of {'loss': 0.6625979542732239, 'tp': 5741.0, 'fp': 3333.0, 'tn': 7108.0, 'fn': 4746.0, 'accuracy': 0.6139621734619141, 'precision': 0.6326867938041687, 'recall': 0.547439694404602, 'auc': 0.6490784287452698} \n",
            "654/689 [===========================>..] - ETA: 2s - loss: 0.6626 - tp: 5741.0000 - fp: 3333.0000 - tn: 7108.0000 - fn: 4746.0000 - accuracy: 0.6140 - precision: 0.6327 - recall: 0.5474 - auc: 0.6491\n",
            " For Batch Number 655 the model has a loss of {'loss': 0.6626918911933899, 'tp': 5749.0, 'fp': 3333.0, 'tn': 7121.0, 'fn': 4757.0, 'accuracy': 0.6140267252922058, 'precision': 0.6330103278160095, 'recall': 0.5472111105918884, 'auc': 0.649085521697998} \n",
            "\n",
            " For Batch Number 656 the model has a loss of {'loss': 0.6626447439193726, 'tp': 5757.0, 'fp': 3336.0, 'tn': 7135.0, 'fn': 4764.0, 'accuracy': 0.6141387224197388, 'precision': 0.6331244111061096, 'recall': 0.547191321849823, 'auc': 0.6491906046867371} \n",
            "656/689 [===========================>..] - ETA: 1s - loss: 0.6626 - tp: 5757.0000 - fp: 3336.0000 - tn: 7135.0000 - fn: 4764.0000 - accuracy: 0.6141 - precision: 0.6331 - recall: 0.5472 - auc: 0.6492\n",
            " For Batch Number 657 the model has a loss of {'loss': 0.6624358892440796, 'tp': 5769.0, 'fp': 3336.0, 'tn': 7149.0, 'fn': 4770.0, 'accuracy': 0.6144406199455261, 'precision': 0.6336079239845276, 'recall': 0.5473954081535339, 'auc': 0.6495799422264099} \n",
            "657/689 [===========================>..] - ETA: 1s - loss: 0.6624 - tp: 5769.0000 - fp: 3336.0000 - tn: 7149.0000 - fn: 4770.0000 - accuracy: 0.6144 - precision: 0.6336 - recall: 0.5474 - auc: 0.6496\n",
            " For Batch Number 658 the model has a loss of {'loss': 0.6623117923736572, 'tp': 5777.0, 'fp': 3341.0, 'tn': 7162.0, 'fn': 4776.0, 'accuracy': 0.6145041584968567, 'precision': 0.6335819363594055, 'recall': 0.5474272966384888, 'auc': 0.6497592329978943} \n",
            "658/689 [===========================>..] - ETA: 1s - loss: 0.6623 - tp: 5777.0000 - fp: 3341.0000 - tn: 7162.0000 - fn: 4776.0000 - accuracy: 0.6145 - precision: 0.6336 - recall: 0.5474 - auc: 0.6498\n",
            " For Batch Number 659 the model has a loss of {'loss': 0.6622247695922852, 'tp': 5786.0, 'fp': 3348.0, 'tn': 7172.0, 'fn': 4782.0, 'accuracy': 0.6144726872444153, 'precision': 0.6334574222564697, 'recall': 0.5475019216537476, 'auc': 0.649817705154419} \n",
            "659/689 [===========================>..] - ETA: 1s - loss: 0.6622 - tp: 5786.0000 - fp: 3348.0000 - tn: 7172.0000 - fn: 4782.0000 - accuracy: 0.6145 - precision: 0.6335 - recall: 0.5475 - auc: 0.6498\n",
            " For Batch Number 660 the model has a loss of {'loss': 0.6624377369880676, 'tp': 5792.0, 'fp': 3356.0, 'tn': 7181.0, 'fn': 4791.0, 'accuracy': 0.6142519116401672, 'precision': 0.6331438422203064, 'recall': 0.5472928285598755, 'auc': 0.6495554447174072} \n",
            "660/689 [===========================>..] - ETA: 1s - loss: 0.6624 - tp: 5792.0000 - fp: 3356.0000 - tn: 7181.0000 - fn: 4791.0000 - accuracy: 0.6143 - precision: 0.6331 - recall: 0.5473 - auc: 0.6496\n",
            " For Batch Number 661 the model has a loss of {'loss': 0.6624690890312195, 'tp': 5799.0, 'fp': 3366.0, 'tn': 7192.0, 'fn': 4795.0, 'accuracy': 0.6141735911369324, 'precision': 0.6327332258224487, 'recall': 0.5473853349685669, 'auc': 0.6494523286819458} \n",
            "661/689 [===========================>..] - ETA: 1s - loss: 0.6625 - tp: 5799.0000 - fp: 3366.0000 - tn: 7192.0000 - fn: 4795.0000 - accuracy: 0.6142 - precision: 0.6327 - recall: 0.5474 - auc: 0.6495\n",
            " For Batch Number 662 the model has a loss of {'loss': 0.6625098586082458, 'tp': 5805.0, 'fp': 3374.0, 'tn': 7207.0, 'fn': 4798.0, 'accuracy': 0.6142371892929077, 'precision': 0.6324218511581421, 'recall': 0.5474865436553955, 'auc': 0.6493836641311646} \n",
            "662/689 [===========================>..] - ETA: 1s - loss: 0.6625 - tp: 5805.0000 - fp: 3374.0000 - tn: 7207.0000 - fn: 4798.0000 - accuracy: 0.6142 - precision: 0.6324 - recall: 0.5475 - auc: 0.6494\n",
            " For Batch Number 663 the model has a loss of {'loss': 0.6623574495315552, 'tp': 5816.0, 'fp': 3375.0, 'tn': 7219.0, 'fn': 4806.0, 'accuracy': 0.6143947839736938, 'precision': 0.6327929496765137, 'recall': 0.5475428104400635, 'auc': 0.6495912075042725} \n",
            "663/689 [===========================>..] - ETA: 1s - loss: 0.6624 - tp: 5816.0000 - fp: 3375.0000 - tn: 7219.0000 - fn: 4806.0000 - accuracy: 0.6144 - precision: 0.6328 - recall: 0.5475 - auc: 0.6496\n",
            " For Batch Number 664 the model has a loss of {'loss': 0.6622374057769775, 'tp': 5823.0, 'fp': 3378.0, 'tn': 7235.0, 'fn': 4812.0, 'accuracy': 0.6145519614219666, 'precision': 0.6328659653663635, 'recall': 0.5475317239761353, 'auc': 0.6497446894645691} \n",
            "\n",
            " For Batch Number 665 the model has a loss of {'loss': 0.662186324596405, 'tp': 5827.0, 'fp': 3378.0, 'tn': 7252.0, 'fn': 4823.0, 'accuracy': 0.6146146655082703, 'precision': 0.6330255270004272, 'recall': 0.547136127948761, 'auc': 0.6498027443885803} \n",
            "665/689 [===========================>..] - ETA: 1s - loss: 0.6622 - tp: 5827.0000 - fp: 3378.0000 - tn: 7252.0000 - fn: 4823.0000 - accuracy: 0.6146 - precision: 0.6330 - recall: 0.5471 - auc: 0.6498\n",
            " For Batch Number 666 the model has a loss of {'loss': 0.6622563004493713, 'tp': 5830.0, 'fp': 3379.0, 'tn': 7267.0, 'fn': 4836.0, 'accuracy': 0.6145364046096802, 'precision': 0.6330763101577759, 'recall': 0.5465966463088989, 'auc': 0.6496356725692749} \n",
            "666/689 [===========================>..] - ETA: 1s - loss: 0.6623 - tp: 5830.0000 - fp: 3379.0000 - tn: 7267.0000 - fn: 4836.0000 - accuracy: 0.6145 - precision: 0.6331 - recall: 0.5466 - auc: 0.6496\n",
            " For Batch Number 667 the model has a loss of {'loss': 0.6621926426887512, 'tp': 5835.0, 'fp': 3380.0, 'tn': 7284.0, 'fn': 4845.0, 'accuracy': 0.614645779132843, 'precision': 0.6332067251205444, 'recall': 0.5463483333587646, 'auc': 0.649815022945404} \n",
            "667/689 [============================>.] - ETA: 1s - loss: 0.6622 - tp: 5835.0000 - fp: 3380.0000 - tn: 7284.0000 - fn: 4845.0000 - accuracy: 0.6146 - precision: 0.6332 - recall: 0.5463 - auc: 0.6498\n",
            " For Batch Number 668 the model has a loss of {'loss': 0.6620790958404541, 'tp': 5841.0, 'fp': 3380.0, 'tn': 7299.0, 'fn': 4856.0, 'accuracy': 0.6147080659866333, 'precision': 0.6334453821182251, 'recall': 0.546040952205658, 'auc': 0.6499649286270142} \n",
            "668/689 [============================>.] - ETA: 1s - loss: 0.6621 - tp: 5841.0000 - fp: 3380.0000 - tn: 7299.0000 - fn: 4856.0000 - accuracy: 0.6147 - precision: 0.6334 - recall: 0.5460 - auc: 0.6500\n",
            " For Batch Number 669 the model has a loss of {'loss': 0.6618924736976624, 'tp': 5850.0, 'fp': 3382.0, 'tn': 7314.0, 'fn': 4862.0, 'accuracy': 0.6149103045463562, 'precision': 0.6336655020713806, 'recall': 0.5461165308952332, 'auc': 0.6502086520195007} \n",
            "669/689 [============================>.] - ETA: 1s - loss: 0.6619 - tp: 5850.0000 - fp: 3382.0000 - tn: 7314.0000 - fn: 4862.0000 - accuracy: 0.6149 - precision: 0.6337 - recall: 0.5461 - auc: 0.6502\n",
            " For Batch Number 670 the model has a loss of {'loss': 0.6618000268936157, 'tp': 5856.0, 'fp': 3386.0, 'tn': 7329.0, 'fn': 4869.0, 'accuracy': 0.6149719953536987, 'precision': 0.6336290836334229, 'recall': 0.5460140109062195, 'auc': 0.6502695083618164} \n",
            "670/689 [============================>.] - ETA: 1s - loss: 0.6618 - tp: 5856.0000 - fp: 3386.0000 - tn: 7329.0000 - fn: 4869.0000 - accuracy: 0.6150 - precision: 0.6336 - recall: 0.5460 - auc: 0.6503\n",
            " For Batch Number 671 the model has a loss of {'loss': 0.6616020202636719, 'tp': 5866.0, 'fp': 3390.0, 'tn': 7342.0, 'fn': 4874.0, 'accuracy': 0.6151266694068909, 'precision': 0.6337510943412781, 'recall': 0.5461825132369995, 'auc': 0.650536060333252} \n",
            "671/689 [============================>.] - ETA: 1s - loss: 0.6616 - tp: 5866.0000 - fp: 3390.0000 - tn: 7342.0000 - fn: 4874.0000 - accuracy: 0.6151 - precision: 0.6338 - recall: 0.5462 - auc: 0.6505\n",
            " For Batch Number 672 the model has a loss of {'loss': 0.6615190505981445, 'tp': 5877.0, 'fp': 3393.0, 'tn': 7352.0, 'fn': 4882.0, 'accuracy': 0.6151878833770752, 'precision': 0.6339805722236633, 'recall': 0.5462403297424316, 'auc': 0.650633692741394} \n",
            "672/689 [============================>.] - ETA: 0s - loss: 0.6615 - tp: 5877.0000 - fp: 3393.0000 - tn: 7352.0000 - fn: 4882.0000 - accuracy: 0.6152 - precision: 0.6340 - recall: 0.5462 - auc: 0.6506\n",
            " For Batch Number 673 the model has a loss of {'loss': 0.6618453860282898, 'tp': 5883.0, 'fp': 3403.0, 'tn': 7360.0, 'fn': 4890.0, 'accuracy': 0.6149238348007202, 'precision': 0.6335343718528748, 'recall': 0.5460874438285828, 'auc': 0.6502562165260315} \n",
            "673/689 [============================>.] - ETA: 0s - loss: 0.6618 - tp: 5883.0000 - fp: 3403.0000 - tn: 7360.0000 - fn: 4890.0000 - accuracy: 0.6149 - precision: 0.6335 - recall: 0.5461 - auc: 0.6503\n",
            " For Batch Number 674 the model has a loss of {'loss': 0.6623445749282837, 'tp': 5890.0, 'fp': 3409.0, 'tn': 7373.0, 'fn': 4896.0, 'accuracy': 0.6149387955665588, 'precision': 0.6334014534950256, 'recall': 0.5460782647132874, 'auc': 0.6500728726387024} \n",
            "674/689 [============================>.] - ETA: 0s - loss: 0.6623 - tp: 5890.0000 - fp: 3409.0000 - tn: 7373.0000 - fn: 4896.0000 - accuracy: 0.6149 - precision: 0.6334 - recall: 0.5461 - auc: 0.6501\n",
            " For Batch Number 675 the model has a loss of {'loss': 0.6623815894126892, 'tp': 5896.0, 'fp': 3413.0, 'tn': 7382.0, 'fn': 4909.0, 'accuracy': 0.6147222518920898, 'precision': 0.6333655714988708, 'recall': 0.5456733107566833, 'auc': 0.6499595642089844} \n",
            "675/689 [============================>.] - ETA: 0s - loss: 0.6624 - tp: 5896.0000 - fp: 3413.0000 - tn: 7382.0000 - fn: 4909.0000 - accuracy: 0.6147 - precision: 0.6334 - recall: 0.5457 - auc: 0.6500\n",
            " For Batch Number 676 the model has a loss of {'loss': 0.6623337864875793, 'tp': 5901.0, 'fp': 3415.0, 'tn': 7396.0, 'fn': 4920.0, 'accuracy': 0.6146911978721619, 'precision': 0.6334263682365417, 'recall': 0.5453285574913025, 'auc': 0.6499315500259399} \n",
            "676/689 [============================>.] - ETA: 0s - loss: 0.6623 - tp: 5901.0000 - fp: 3415.0000 - tn: 7396.0000 - fn: 4920.0000 - accuracy: 0.6147 - precision: 0.6334 - recall: 0.5453 - auc: 0.6499\n",
            " For Batch Number 677 the model has a loss of {'loss': 0.6624735593795776, 'tp': 5908.0, 'fp': 3420.0, 'tn': 7409.0, 'fn': 4927.0, 'accuracy': 0.6147063970565796, 'precision': 0.6333619356155396, 'recall': 0.5452699661254883, 'auc': 0.6499392986297607} \n",
            "677/689 [============================>.] - ETA: 0s - loss: 0.6625 - tp: 5908.0000 - fp: 3420.0000 - tn: 7409.0000 - fn: 4927.0000 - accuracy: 0.6147 - precision: 0.6334 - recall: 0.5453 - auc: 0.6499\n",
            " For Batch Number 678 the model has a loss of {'loss': 0.6626875996589661, 'tp': 5918.0, 'fp': 3423.0, 'tn': 7415.0, 'fn': 4940.0, 'accuracy': 0.614537239074707, 'precision': 0.6335510015487671, 'recall': 0.5450358986854553, 'auc': 0.6496403217315674} \n",
            "678/689 [============================>.] - ETA: 0s - loss: 0.6627 - tp: 5918.0000 - fp: 3423.0000 - tn: 7415.0000 - fn: 4940.0000 - accuracy: 0.6145 - precision: 0.6336 - recall: 0.5450 - auc: 0.6496\n",
            " For Batch Number 679 the model has a loss of {'loss': 0.6628267765045166, 'tp': 5926.0, 'fp': 3434.0, 'tn': 7424.0, 'fn': 4944.0, 'accuracy': 0.6144145727157593, 'precision': 0.6331196427345276, 'recall': 0.5451701879501343, 'auc': 0.6494961380958557} \n",
            "679/689 [============================>.] - ETA: 0s - loss: 0.6628 - tp: 5926.0000 - fp: 3434.0000 - tn: 7424.0000 - fn: 4944.0000 - accuracy: 0.6144 - precision: 0.6331 - recall: 0.5452 - auc: 0.6495\n",
            " For Batch Number 680 the model has a loss of {'loss': 0.662888765335083, 'tp': 5933.0, 'fp': 3440.0, 'tn': 7435.0, 'fn': 4952.0, 'accuracy': 0.614338219165802, 'precision': 0.6329883933067322, 'recall': 0.5450620055198669, 'auc': 0.6493785381317139} \n",
            "680/689 [============================>.] - ETA: 0s - loss: 0.6629 - tp: 5933.0000 - fp: 3440.0000 - tn: 7435.0000 - fn: 4952.0000 - accuracy: 0.6143 - precision: 0.6330 - recall: 0.5451 - auc: 0.6494\n",
            " For Batch Number 681 the model has a loss of {'loss': 0.662790060043335, 'tp': 5942.0, 'fp': 3444.0, 'tn': 7447.0, 'fn': 4959.0, 'accuracy': 0.614399790763855, 'precision': 0.6330705285072327, 'recall': 0.5450876355171204, 'auc': 0.6495004296302795} \n",
            "681/689 [============================>.] - ETA: 0s - loss: 0.6628 - tp: 5942.0000 - fp: 3444.0000 - tn: 7447.0000 - fn: 4959.0000 - accuracy: 0.6144 - precision: 0.6331 - recall: 0.5451 - auc: 0.6495\n",
            " For Batch Number 682 the model has a loss of {'loss': 0.662623405456543, 'tp': 5949.0, 'fp': 3447.0, 'tn': 7464.0, 'fn': 4964.0, 'accuracy': 0.6145986318588257, 'precision': 0.6331417560577393, 'recall': 0.545129656791687, 'auc': 0.6496835947036743} \n",
            "682/689 [============================>.] - ETA: 0s - loss: 0.6626 - tp: 5949.0000 - fp: 3447.0000 - tn: 7464.0000 - fn: 4964.0000 - accuracy: 0.6146 - precision: 0.6331 - recall: 0.5451 - auc: 0.6497\n",
            " For Batch Number 683 the model has a loss of {'loss': 0.6626016497612, 'tp': 5960.0, 'fp': 3449.0, 'tn': 7473.0, 'fn': 4974.0, 'accuracy': 0.6146138310432434, 'precision': 0.6334360837936401, 'recall': 0.5450887084007263, 'auc': 0.6496619582176208} \n",
            "683/689 [============================>.] - ETA: 0s - loss: 0.6626 - tp: 5960.0000 - fp: 3449.0000 - tn: 7473.0000 - fn: 4974.0000 - accuracy: 0.6146 - precision: 0.6334 - recall: 0.5451 - auc: 0.6497\n",
            " For Batch Number 684 the model has a loss of {'loss': 0.6624827980995178, 'tp': 5968.0, 'fp': 3452.0, 'tn': 7487.0, 'fn': 4981.0, 'accuracy': 0.6147204041481018, 'precision': 0.6335456371307373, 'recall': 0.545072615146637, 'auc': 0.6498033404350281} \n",
            "684/689 [============================>.] - ETA: 0s - loss: 0.6625 - tp: 5968.0000 - fp: 3452.0000 - tn: 7487.0000 - fn: 4981.0000 - accuracy: 0.6147 - precision: 0.6335 - recall: 0.5451 - auc: 0.6498\n",
            " For Batch Number 685 the model has a loss of {'loss': 0.6624763607978821, 'tp': 5976.0, 'fp': 3456.0, 'tn': 7502.0, 'fn': 4986.0, 'accuracy': 0.6148722767829895, 'precision': 0.6335877776145935, 'recall': 0.5451560020446777, 'auc': 0.6499285697937012} \n",
            "685/689 [============================>.] - ETA: 0s - loss: 0.6625 - tp: 5976.0000 - fp: 3456.0000 - tn: 7502.0000 - fn: 4986.0000 - accuracy: 0.6149 - precision: 0.6336 - recall: 0.5452 - auc: 0.6499\n",
            " For Batch Number 686 the model has a loss of {'loss': 0.6624645590782166, 'tp': 5985.0, 'fp': 3460.0, 'tn': 7513.0, 'fn': 4994.0, 'accuracy': 0.614886999130249, 'precision': 0.6336686015129089, 'recall': 0.5451316237449646, 'auc': 0.6499853134155273} \n",
            "686/689 [============================>.] - ETA: 0s - loss: 0.6625 - tp: 5985.0000 - fp: 3460.0000 - tn: 7513.0000 - fn: 4994.0000 - accuracy: 0.6149 - precision: 0.6337 - recall: 0.5451 - auc: 0.6500\n",
            " For Batch Number 687 the model has a loss of {'loss': 0.6624802350997925, 'tp': 5992.0, 'fp': 3464.0, 'tn': 7524.0, 'fn': 5004.0, 'accuracy': 0.6148107647895813, 'precision': 0.633671760559082, 'recall': 0.5449254512786865, 'auc': 0.6499069333076477} \n",
            "687/689 [============================>.] - ETA: 0s - loss: 0.6625 - tp: 5992.0000 - fp: 3464.0000 - tn: 7524.0000 - fn: 5004.0000 - accuracy: 0.6148 - precision: 0.6337 - recall: 0.5449 - auc: 0.6499\n",
            " For Batch Number 688 the model has a loss of {'loss': 0.6623513698577881, 'tp': 6000.0, 'fp': 3467.0, 'tn': 7540.0, 'fn': 5009.0, 'accuracy': 0.6150072813034058, 'precision': 0.6337804794311523, 'recall': 0.5450085997581482, 'auc': 0.6500494480133057} \n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.6624 - tp: 6000.0000 - fp: 3467.0000 - tn: 7540.0000 - fn: 5009.0000 - accuracy: 0.6150 - precision: 0.6338 - recall: 0.5450 - auc: 0.6500\n",
            " For Batch Number 689 the model has a loss of {'loss': 0.662358283996582, 'tp': 6009.0, 'fp': 3472.0, 'tn': 7552.0, 'fn': 5013.0, 'accuracy': 0.61512291431427, 'precision': 0.6337938904762268, 'recall': 0.5451823472976685, 'auc': 0.6501267552375793} \n",
            "\n",
            " For Epoch Number 1 the model has a loss of 0.662358283996582\n",
            "689/689 [==============================] - 40s 58ms/step - loss: 0.6624 - tp: 6009.0000 - fp: 3472.0000 - tn: 7552.0000 - fn: 5013.0000 - accuracy: 0.6151 - precision: 0.6338 - recall: 0.5452 - auc: 0.6501\n",
            "Epoch 2/3\n",
            "\n",
            " For Batch Number 1 the model has a loss of {'loss': 0.7642431259155273, 'tp': 5.0, 'fp': 6.0, 'tn': 10.0, 'fn': 11.0, 'accuracy': 0.46875, 'precision': 0.4545454680919647, 'recall': 0.3125, 'auc': 0.587890625} \n",
            "  1/689 [..............................] - ETA: 1:26 - loss: 0.7642 - tp: 5.0000 - fp: 6.0000 - tn: 10.0000 - fn: 11.0000 - accuracy: 0.4688 - precision: 0.4545 - recall: 0.3125 - auc: 0.5879\n",
            " For Batch Number 2 the model has a loss of {'loss': 0.6568993926048279, 'tp': 14.0, 'fp': 9.0, 'tn': 22.0, 'fn': 19.0, 'accuracy': 0.5625, 'precision': 0.6086956262588501, 'recall': 0.42424243688583374, 'auc': 0.7072336077690125} \n",
            "  2/689 [..............................] - ETA: 39s - loss: 0.6569 - tp: 14.0000 - fp: 9.0000 - tn: 22.0000 - fn: 19.0000 - accuracy: 0.5625 - precision: 0.6087 - recall: 0.4242 - auc: 0.7072\n",
            " For Batch Number 3 the model has a loss of {'loss': 0.6425997018814087, 'tp': 22.0, 'fp': 11.0, 'tn': 34.0, 'fn': 29.0, 'accuracy': 0.5833333134651184, 'precision': 0.6666666865348816, 'recall': 0.4313725531101227, 'auc': 0.7202613949775696} \n",
            "  3/689 [..............................] - ETA: 43s - loss: 0.6426 - tp: 22.0000 - fp: 11.0000 - tn: 34.0000 - fn: 29.0000 - accuracy: 0.5833 - precision: 0.6667 - recall: 0.4314 - auc: 0.7203\n",
            " For Batch Number 4 the model has a loss of {'loss': 0.6133962869644165, 'tp': 33.0, 'fp': 12.0, 'tn': 48.0, 'fn': 35.0, 'accuracy': 0.6328125, 'precision': 0.7333333492279053, 'recall': 0.4852941036224365, 'auc': 0.7276960015296936} \n",
            "  4/689 [..............................] - ETA: 42s - loss: 0.6134 - tp: 33.0000 - fp: 12.0000 - tn: 48.0000 - fn: 35.0000 - accuracy: 0.6328 - precision: 0.7333 - recall: 0.4853 - auc: 0.7277\n",
            " For Batch Number 5 the model has a loss of {'loss': 0.6086398959159851, 'tp': 41.0, 'fp': 14.0, 'tn': 61.0, 'fn': 44.0, 'accuracy': 0.637499988079071, 'precision': 0.7454545497894287, 'recall': 0.48235294222831726, 'auc': 0.7199999690055847} \n",
            "  5/689 [..............................] - ETA: 41s - loss: 0.6086 - tp: 41.0000 - fp: 14.0000 - tn: 61.0000 - fn: 44.0000 - accuracy: 0.6375 - precision: 0.7455 - recall: 0.4824 - auc: 0.7200\n",
            " For Batch Number 6 the model has a loss of {'loss': 0.5989495515823364, 'tp': 52.0, 'fp': 15.0, 'tn': 75.0, 'fn': 50.0, 'accuracy': 0.6614583134651184, 'precision': 0.7761194109916687, 'recall': 0.5098039507865906, 'auc': 0.7247276902198792} \n",
            "  6/689 [..............................] - ETA: 40s - loss: 0.5989 - tp: 52.0000 - fp: 15.0000 - tn: 75.0000 - fn: 50.0000 - accuracy: 0.6615 - precision: 0.7761 - recall: 0.5098 - auc: 0.7247\n",
            " For Batch Number 7 the model has a loss of {'loss': 0.5976200103759766, 'tp': 64.0, 'fp': 16.0, 'tn': 87.0, 'fn': 57.0, 'accuracy': 0.6741071343421936, 'precision': 0.800000011920929, 'recall': 0.5289255976676941, 'auc': 0.728476345539093} \n",
            "  7/689 [..............................] - ETA: 40s - loss: 0.5976 - tp: 64.0000 - fp: 16.0000 - tn: 87.0000 - fn: 57.0000 - accuracy: 0.6741 - precision: 0.8000 - recall: 0.5289 - auc: 0.7285\n",
            " For Batch Number 8 the model has a loss of {'loss': 0.6026856899261475, 'tp': 72.0, 'fp': 19.0, 'tn': 102.0, 'fn': 63.0, 'accuracy': 0.6796875, 'precision': 0.791208803653717, 'recall': 0.5333333611488342, 'auc': 0.7212121486663818} \n",
            "  8/689 [..............................] - ETA: 42s - loss: 0.6027 - tp: 72.0000 - fp: 19.0000 - tn: 102.0000 - fn: 63.0000 - accuracy: 0.6797 - precision: 0.7912 - recall: 0.5333 - auc: 0.7212\n",
            " For Batch Number 9 the model has a loss of {'loss': 0.6155925393104553, 'tp': 80.0, 'fp': 24.0, 'tn': 112.0, 'fn': 72.0, 'accuracy': 0.6666666865348816, 'precision': 0.7692307829856873, 'recall': 0.5263158082962036, 'auc': 0.7107681632041931} \n",
            "  9/689 [..............................] - ETA: 42s - loss: 0.6156 - tp: 80.0000 - fp: 24.0000 - tn: 112.0000 - fn: 72.0000 - accuracy: 0.6667 - precision: 0.7692 - recall: 0.5263 - auc: 0.7108\n",
            " For Batch Number 10 the model has a loss of {'loss': 0.6153368353843689, 'tp': 89.0, 'fp': 30.0, 'tn': 124.0, 'fn': 77.0, 'accuracy': 0.6656249761581421, 'precision': 0.7478991746902466, 'recall': 0.5361445546150208, 'auc': 0.7067556381225586} \n",
            " 10/689 [..............................] - ETA: 41s - loss: 0.6153 - tp: 89.0000 - fp: 30.0000 - tn: 124.0000 - fn: 77.0000 - accuracy: 0.6656 - precision: 0.7479 - recall: 0.5361 - auc: 0.7068\n",
            " For Batch Number 11 the model has a loss of {'loss': 0.6171482801437378, 'tp': 95.0, 'fp': 35.0, 'tn': 135.0, 'fn': 87.0, 'accuracy': 0.6534090638160706, 'precision': 0.7307692170143127, 'recall': 0.5219780206680298, 'auc': 0.7003555297851562} \n",
            "\n",
            " For Batch Number 12 the model has a loss of {'loss': 0.6193239092826843, 'tp': 104.0, 'fp': 37.0, 'tn': 143.0, 'fn': 100.0, 'accuracy': 0.6432291865348816, 'precision': 0.73758864402771, 'recall': 0.5098039507865906, 'auc': 0.6943219304084778} \n",
            " 12/689 [..............................] - ETA: 40s - loss: 0.6193 - tp: 104.0000 - fp: 37.0000 - tn: 143.0000 - fn: 100.0000 - accuracy: 0.6432 - precision: 0.7376 - recall: 0.5098 - auc: 0.6943\n",
            " For Batch Number 13 the model has a loss of {'loss': 0.6224358081817627, 'tp': 112.0, 'fp': 41.0, 'tn': 154.0, 'fn': 109.0, 'accuracy': 0.6394230723381042, 'precision': 0.7320261597633362, 'recall': 0.5067873597145081, 'auc': 0.6876552104949951} \n",
            " 13/689 [..............................] - ETA: 39s - loss: 0.6224 - tp: 112.0000 - fp: 41.0000 - tn: 154.0000 - fn: 109.0000 - accuracy: 0.6394 - precision: 0.7320 - recall: 0.5068 - auc: 0.6877\n",
            " For Batch Number 14 the model has a loss of {'loss': 0.6165676116943359, 'tp': 122.0, 'fp': 41.0, 'tn': 168.0, 'fn': 117.0, 'accuracy': 0.6473214030265808, 'precision': 0.7484662532806396, 'recall': 0.5104602575302124, 'auc': 0.695671796798706} \n",
            " 14/689 [..............................] - ETA: 39s - loss: 0.6166 - tp: 122.0000 - fp: 41.0000 - tn: 168.0000 - fn: 117.0000 - accuracy: 0.6473 - precision: 0.7485 - recall: 0.5105 - auc: 0.6957\n",
            " For Batch Number 15 the model has a loss of {'loss': 0.6228718161582947, 'tp': 130.0, 'fp': 49.0, 'tn': 177.0, 'fn': 124.0, 'accuracy': 0.6395833492279053, 'precision': 0.7262569665908813, 'recall': 0.5118110179901123, 'auc': 0.6823217868804932} \n",
            " 15/689 [..............................] - ETA: 40s - loss: 0.6229 - tp: 130.0000 - fp: 49.0000 - tn: 177.0000 - fn: 124.0000 - accuracy: 0.6396 - precision: 0.7263 - recall: 0.5118 - auc: 0.6823\n",
            " For Batch Number 16 the model has a loss of {'loss': 0.6215829849243164, 'tp': 140.0, 'fp': 54.0, 'tn': 188.0, 'fn': 130.0, 'accuracy': 0.640625, 'precision': 0.7216494679450989, 'recall': 0.5185185074806213, 'auc': 0.6817033886909485} \n",
            " 16/689 [..............................] - ETA: 39s - loss: 0.6216 - tp: 140.0000 - fp: 54.0000 - tn: 188.0000 - fn: 130.0000 - accuracy: 0.6406 - precision: 0.7216 - recall: 0.5185 - auc: 0.6817\n",
            " For Batch Number 17 the model has a loss of {'loss': 0.6241574287414551, 'tp': 148.0, 'fp': 61.0, 'tn': 201.0, 'fn': 134.0, 'accuracy': 0.6415441036224365, 'precision': 0.7081339955329895, 'recall': 0.5248227119445801, 'auc': 0.678550124168396} \n",
            " 17/689 [..............................] - ETA: 39s - loss: 0.6242 - tp: 148.0000 - fp: 61.0000 - tn: 201.0000 - fn: 134.0000 - accuracy: 0.6415 - precision: 0.7081 - recall: 0.5248 - auc: 0.6786\n",
            " For Batch Number 18 the model has a loss of {'loss': 0.6247095465660095, 'tp': 156.0, 'fp': 65.0, 'tn': 215.0, 'fn': 140.0, 'accuracy': 0.6440972089767456, 'precision': 0.7058823704719543, 'recall': 0.5270270109176636, 'auc': 0.6767374277114868} \n",
            " 18/689 [..............................] - ETA: 39s - loss: 0.6247 - tp: 156.0000 - fp: 65.0000 - tn: 215.0000 - fn: 140.0000 - accuracy: 0.6441 - precision: 0.7059 - recall: 0.5270 - auc: 0.6767\n",
            " For Batch Number 19 the model has a loss of {'loss': 0.6208732724189758, 'tp': 165.0, 'fp': 67.0, 'tn': 229.0, 'fn': 147.0, 'accuracy': 0.6480262875556946, 'precision': 0.7112069129943848, 'recall': 0.5288461446762085, 'auc': 0.6856266856193542} \n",
            " 19/689 [..............................] - ETA: 39s - loss: 0.6209 - tp: 165.0000 - fp: 67.0000 - tn: 229.0000 - fn: 147.0000 - accuracy: 0.6480 - precision: 0.7112 - recall: 0.5288 - auc: 0.6856\n",
            " For Batch Number 20 the model has a loss of {'loss': 0.6246055364608765, 'tp': 170.0, 'fp': 73.0, 'tn': 241.0, 'fn': 156.0, 'accuracy': 0.6421874761581421, 'precision': 0.6995884776115417, 'recall': 0.5214723944664001, 'auc': 0.6811819672584534} \n",
            " 20/689 [..............................] - ETA: 39s - loss: 0.6246 - tp: 170.0000 - fp: 73.0000 - tn: 241.0000 - fn: 156.0000 - accuracy: 0.6422 - precision: 0.6996 - recall: 0.5215 - auc: 0.6812\n",
            " For Batch Number 21 the model has a loss of {'loss': 0.6259326338768005, 'tp': 179.0, 'fp': 73.0, 'tn': 252.0, 'fn': 168.0, 'accuracy': 0.6413690447807312, 'precision': 0.7103174328804016, 'recall': 0.5158501267433167, 'auc': 0.6795212030410767} \n",
            " 21/689 [..............................] - ETA: 39s - loss: 0.6259 - tp: 179.0000 - fp: 73.0000 - tn: 252.0000 - fn: 168.0000 - accuracy: 0.6414 - precision: 0.7103 - recall: 0.5159 - auc: 0.6795\n",
            " For Batch Number 22 the model has a loss of {'loss': 0.6219543814659119, 'tp': 187.0, 'fp': 74.0, 'tn': 268.0, 'fn': 175.0, 'accuracy': 0.6463068127632141, 'precision': 0.7164750695228577, 'recall': 0.5165745615959167, 'auc': 0.6864075064659119} \n",
            "\n",
            " For Batch Number 23 the model has a loss of {'loss': 0.6190388202667236, 'tp': 194.0, 'fp': 75.0, 'tn': 283.0, 'fn': 184.0, 'accuracy': 0.648097813129425, 'precision': 0.7211896181106567, 'recall': 0.5132275223731995, 'auc': 0.6895007491111755} \n",
            " 23/689 [>.............................] - ETA: 38s - loss: 0.6190 - tp: 194.0000 - fp: 75.0000 - tn: 283.0000 - fn: 184.0000 - accuracy: 0.6481 - precision: 0.7212 - recall: 0.5132 - auc: 0.6895\n",
            " For Batch Number 24 the model has a loss of {'loss': 0.6223281025886536, 'tp': 203.0, 'fp': 77.0, 'tn': 296.0, 'fn': 192.0, 'accuracy': 0.6497395634651184, 'precision': 0.7250000238418579, 'recall': 0.5139240622520447, 'auc': 0.6897207498550415} \n",
            " 24/689 [>.............................] - ETA: 39s - loss: 0.6223 - tp: 203.0000 - fp: 77.0000 - tn: 296.0000 - fn: 192.0000 - accuracy: 0.6497 - precision: 0.7250 - recall: 0.5139 - auc: 0.6897\n",
            " For Batch Number 25 the model has a loss of {'loss': 0.616993248462677, 'tp': 211.0, 'fp': 79.0, 'tn': 315.0, 'fn': 195.0, 'accuracy': 0.6575000286102295, 'precision': 0.7275862097740173, 'recall': 0.5197044610977173, 'auc': 0.6975194215774536} \n",
            " 25/689 [>.............................] - ETA: 39s - loss: 0.6170 - tp: 211.0000 - fp: 79.0000 - tn: 315.0000 - fn: 195.0000 - accuracy: 0.6575 - precision: 0.7276 - recall: 0.5197 - auc: 0.6975\n",
            " For Batch Number 26 the model has a loss of {'loss': 0.6124367117881775, 'tp': 222.0, 'fp': 81.0, 'tn': 330.0, 'fn': 199.0, 'accuracy': 0.6634615659713745, 'precision': 0.7326732873916626, 'recall': 0.5273159146308899, 'auc': 0.7051944732666016} \n",
            " 26/689 [>.............................] - ETA: 39s - loss: 0.6124 - tp: 222.0000 - fp: 81.0000 - tn: 330.0000 - fn: 199.0000 - accuracy: 0.6635 - precision: 0.7327 - recall: 0.5273 - auc: 0.7052\n",
            " For Batch Number 27 the model has a loss of {'loss': 0.6083447933197021, 'tp': 233.0, 'fp': 83.0, 'tn': 343.0, 'fn': 205.0, 'accuracy': 0.6666666865348816, 'precision': 0.7373417615890503, 'recall': 0.5319634675979614, 'auc': 0.7113989591598511} \n",
            " 27/689 [>.............................] - ETA: 39s - loss: 0.6083 - tp: 233.0000 - fp: 83.0000 - tn: 343.0000 - fn: 205.0000 - accuracy: 0.6667 - precision: 0.7373 - recall: 0.5320 - auc: 0.7114\n",
            " For Batch Number 28 the model has a loss of {'loss': 0.6103276014328003, 'tp': 242.0, 'fp': 86.0, 'tn': 357.0, 'fn': 211.0, 'accuracy': 0.6685267686843872, 'precision': 0.7378048896789551, 'recall': 0.5342163443565369, 'auc': 0.7106772065162659} \n",
            " 28/689 [>.............................] - ETA: 39s - loss: 0.6103 - tp: 242.0000 - fp: 86.0000 - tn: 357.0000 - fn: 211.0000 - accuracy: 0.6685 - precision: 0.7378 - recall: 0.5342 - auc: 0.7107\n",
            " For Batch Number 29 the model has a loss of {'loss': 0.6091482043266296, 'tp': 251.0, 'fp': 88.0, 'tn': 370.0, 'fn': 219.0, 'accuracy': 0.6691810488700867, 'precision': 0.7404129505157471, 'recall': 0.5340425372123718, 'auc': 0.712138831615448} \n",
            " 29/689 [>.............................] - ETA: 39s - loss: 0.6091 - tp: 251.0000 - fp: 88.0000 - tn: 370.0000 - fn: 219.0000 - accuracy: 0.6692 - precision: 0.7404 - recall: 0.5340 - auc: 0.7121\n",
            " For Batch Number 30 the model has a loss of {'loss': 0.6084046959877014, 'tp': 259.0, 'fp': 90.0, 'tn': 384.0, 'fn': 227.0, 'accuracy': 0.6697916388511658, 'precision': 0.7421203255653381, 'recall': 0.5329217910766602, 'auc': 0.712352991104126} \n",
            " 30/689 [>.............................] - ETA: 39s - loss: 0.6084 - tp: 259.0000 - fp: 90.0000 - tn: 384.0000 - fn: 227.0000 - accuracy: 0.6698 - precision: 0.7421 - recall: 0.5329 - auc: 0.7124\n",
            " For Batch Number 31 the model has a loss of {'loss': 0.6111196875572205, 'tp': 271.0, 'fp': 92.0, 'tn': 390.0, 'fn': 239.0, 'accuracy': 0.6663306355476379, 'precision': 0.7465564608573914, 'recall': 0.5313725471496582, 'auc': 0.7074302434921265} \n",
            " 31/689 [>.............................] - ETA: 39s - loss: 0.6111 - tp: 271.0000 - fp: 92.0000 - tn: 390.0000 - fn: 239.0000 - accuracy: 0.6663 - precision: 0.7466 - recall: 0.5314 - auc: 0.7074\n",
            " For Batch Number 32 the model has a loss of {'loss': 0.6062192320823669, 'tp': 283.0, 'fp': 93.0, 'tn': 404.0, 'fn': 244.0, 'accuracy': 0.6708984375, 'precision': 0.7526595592498779, 'recall': 0.53700190782547, 'auc': 0.7122564315795898} \n",
            "\n",
            " For Batch Number 33 the model has a loss of {'loss': 0.6188547611236572, 'tp': 288.0, 'fp': 103.0, 'tn': 413.0, 'fn': 252.0, 'accuracy': 0.6638257503509521, 'precision': 0.7365728616714478, 'recall': 0.5333333611488342, 'auc': 0.7011268734931946} \n",
            " 33/689 [>.............................] - ETA: 39s - loss: 0.6189 - tp: 288.0000 - fp: 103.0000 - tn: 413.0000 - fn: 252.0000 - accuracy: 0.6638 - precision: 0.7366 - recall: 0.5333 - auc: 0.7011\n",
            " For Batch Number 34 the model has a loss of {'loss': 0.616671085357666, 'tp': 299.0, 'fp': 106.0, 'tn': 427.0, 'fn': 256.0, 'accuracy': 0.6672794222831726, 'precision': 0.7382715940475464, 'recall': 0.5387387275695801, 'auc': 0.7040295600891113} \n",
            " 34/689 [>.............................] - ETA: 38s - loss: 0.6167 - tp: 299.0000 - fp: 106.0000 - tn: 427.0000 - fn: 256.0000 - accuracy: 0.6673 - precision: 0.7383 - recall: 0.5387 - auc: 0.7040\n",
            " For Batch Number 35 the model has a loss of {'loss': 0.6148812770843506, 'tp': 312.0, 'fp': 108.0, 'tn': 437.0, 'fn': 263.0, 'accuracy': 0.668749988079071, 'precision': 0.7428571581840515, 'recall': 0.5426086783409119, 'auc': 0.7070761322975159} \n",
            "\n",
            " For Batch Number 36 the model has a loss of {'loss': 0.6206144094467163, 'tp': 320.0, 'fp': 115.0, 'tn': 443.0, 'fn': 274.0, 'accuracy': 0.6623263955116272, 'precision': 0.7356321811676025, 'recall': 0.5387205481529236, 'auc': 0.7011181712150574} \n",
            " 36/689 [>.............................] - ETA: 38s - loss: 0.6206 - tp: 320.0000 - fp: 115.0000 - tn: 443.0000 - fn: 274.0000 - accuracy: 0.6623 - precision: 0.7356 - recall: 0.5387 - auc: 0.7011\n",
            " For Batch Number 37 the model has a loss of {'loss': 0.6204774975776672, 'tp': 334.0, 'fp': 121.0, 'tn': 449.0, 'fn': 280.0, 'accuracy': 0.6613175868988037, 'precision': 0.7340659499168396, 'recall': 0.5439739227294922, 'auc': 0.7009643316268921} \n",
            " 37/689 [>.............................] - ETA: 38s - loss: 0.6205 - tp: 334.0000 - fp: 121.0000 - tn: 449.0000 - fn: 280.0000 - accuracy: 0.6613 - precision: 0.7341 - recall: 0.5440 - auc: 0.7010\n",
            " For Batch Number 38 the model has a loss of {'loss': 0.6183562278747559, 'tp': 346.0, 'fp': 125.0, 'tn': 456.0, 'fn': 289.0, 'accuracy': 0.6595394611358643, 'precision': 0.7346072196960449, 'recall': 0.5448818802833557, 'auc': 0.7030303478240967} \n",
            " 38/689 [>.............................] - ETA: 38s - loss: 0.6184 - tp: 346.0000 - fp: 125.0000 - tn: 456.0000 - fn: 289.0000 - accuracy: 0.6595 - precision: 0.7346 - recall: 0.5449 - auc: 0.7030\n",
            " For Batch Number 39 the model has a loss of {'loss': 0.6190048456192017, 'tp': 361.0, 'fp': 131.0, 'tn': 465.0, 'fn': 291.0, 'accuracy': 0.6618589758872986, 'precision': 0.7337398529052734, 'recall': 0.553680956363678, 'auc': 0.7030047178268433} \n",
            " 39/689 [>.............................] - ETA: 38s - loss: 0.6190 - tp: 361.0000 - fp: 131.0000 - tn: 465.0000 - fn: 291.0000 - accuracy: 0.6619 - precision: 0.7337 - recall: 0.5537 - auc: 0.7030\n",
            " For Batch Number 40 the model has a loss of {'loss': 0.6170685291290283, 'tp': 376.0, 'fp': 136.0, 'tn': 471.0, 'fn': 297.0, 'accuracy': 0.6617187261581421, 'precision': 0.734375, 'recall': 0.5586923956871033, 'auc': 0.7051706910133362} \n",
            " 40/689 [>.............................] - ETA: 38s - loss: 0.6171 - tp: 376.0000 - fp: 136.0000 - tn: 471.0000 - fn: 297.0000 - accuracy: 0.6617 - precision: 0.7344 - recall: 0.5587 - auc: 0.7052\n",
            " For Batch Number 41 the model has a loss of {'loss': 0.6195999979972839, 'tp': 386.0, 'fp': 149.0, 'tn': 478.0, 'fn': 299.0, 'accuracy': 0.6585366129875183, 'precision': 0.7214953303337097, 'recall': 0.563503623008728, 'auc': 0.7009091973304749} \n",
            " 41/689 [>.............................] - ETA: 37s - loss: 0.6196 - tp: 386.0000 - fp: 149.0000 - tn: 478.0000 - fn: 299.0000 - accuracy: 0.6585 - precision: 0.7215 - recall: 0.5635 - auc: 0.7009\n",
            " For Batch Number 42 the model has a loss of {'loss': 0.6185846328735352, 'tp': 400.0, 'fp': 154.0, 'tn': 487.0, 'fn': 303.0, 'accuracy': 0.659970223903656, 'precision': 0.7220216393470764, 'recall': 0.5689900517463684, 'auc': 0.7021490931510925} \n",
            " 42/689 [>.............................] - ETA: 38s - loss: 0.6186 - tp: 400.0000 - fp: 154.0000 - tn: 487.0000 - fn: 303.0000 - accuracy: 0.6600 - precision: 0.7220 - recall: 0.5690 - auc: 0.7021\n",
            " For Batch Number 43 the model has a loss of {'loss': 0.6179669499397278, 'tp': 411.0, 'fp': 157.0, 'tn': 496.0, 'fn': 312.0, 'accuracy': 0.6591569781303406, 'precision': 0.7235915660858154, 'recall': 0.5684647560119629, 'auc': 0.7026777267456055} \n",
            " 43/689 [>.............................] - ETA: 38s - loss: 0.6180 - tp: 411.0000 - fp: 157.0000 - tn: 496.0000 - fn: 312.0000 - accuracy: 0.6592 - precision: 0.7236 - recall: 0.5685 - auc: 0.7027\n",
            " For Batch Number 44 the model has a loss of {'loss': 0.6193735003471375, 'tp': 420.0, 'fp': 164.0, 'tn': 505.0, 'fn': 319.0, 'accuracy': 0.6569602489471436, 'precision': 0.7191780805587769, 'recall': 0.5683355927467346, 'auc': 0.7009320259094238} \n",
            " 44/689 [>.............................] - ETA: 38s - loss: 0.6194 - tp: 420.0000 - fp: 164.0000 - tn: 505.0000 - fn: 319.0000 - accuracy: 0.6570 - precision: 0.7192 - recall: 0.5683 - auc: 0.7009\n",
            " For Batch Number 45 the model has a loss of {'loss': 0.6206651329994202, 'tp': 431.0, 'fp': 171.0, 'tn': 514.0, 'fn': 324.0, 'accuracy': 0.65625, 'precision': 0.7159468531608582, 'recall': 0.5708609223365784, 'auc': 0.6996412873268127} \n",
            " 45/689 [>.............................] - ETA: 38s - loss: 0.6207 - tp: 431.0000 - fp: 171.0000 - tn: 514.0000 - fn: 324.0000 - accuracy: 0.6562 - precision: 0.7159 - recall: 0.5709 - auc: 0.6996\n",
            " For Batch Number 46 the model has a loss of {'loss': 0.621173620223999, 'tp': 441.0, 'fp': 174.0, 'tn': 526.0, 'fn': 331.0, 'accuracy': 0.6569293737411499, 'precision': 0.7170731425285339, 'recall': 0.5712435245513916, 'auc': 0.6991922855377197} \n",
            " 46/689 [=>............................] - ETA: 38s - loss: 0.6212 - tp: 441.0000 - fp: 174.0000 - tn: 526.0000 - fn: 331.0000 - accuracy: 0.6569 - precision: 0.7171 - recall: 0.5712 - auc: 0.6992\n",
            " For Batch Number 47 the model has a loss of {'loss': 0.6212849020957947, 'tp': 452.0, 'fp': 175.0, 'tn': 537.0, 'fn': 340.0, 'accuracy': 0.657579779624939, 'precision': 0.720893144607544, 'recall': 0.5707070827484131, 'auc': 0.6991792917251587} \n",
            " 47/689 [=>............................] - ETA: 38s - loss: 0.6213 - tp: 452.0000 - fp: 175.0000 - tn: 537.0000 - fn: 340.0000 - accuracy: 0.6576 - precision: 0.7209 - recall: 0.5707 - auc: 0.6992\n",
            " For Batch Number 48 the model has a loss of {'loss': 0.6236346960067749, 'tp': 455.0, 'fp': 184.0, 'tn': 553.0, 'fn': 344.0, 'accuracy': 0.65625, 'precision': 0.7120500802993774, 'recall': 0.5694618225097656, 'auc': 0.696552574634552} \n",
            " 48/689 [=>............................] - ETA: 38s - loss: 0.6236 - tp: 455.0000 - fp: 184.0000 - tn: 553.0000 - fn: 344.0000 - accuracy: 0.6562 - precision: 0.7121 - recall: 0.5695 - auc: 0.6966\n",
            " For Batch Number 49 the model has a loss of {'loss': 0.623526394367218, 'tp': 464.0, 'fp': 185.0, 'tn': 567.0, 'fn': 352.0, 'accuracy': 0.6575255393981934, 'precision': 0.7149460911750793, 'recall': 0.5686274766921997, 'auc': 0.69647616147995} \n",
            " 49/689 [=>............................] - ETA: 38s - loss: 0.6235 - tp: 464.0000 - fp: 185.0000 - tn: 567.0000 - fn: 352.0000 - accuracy: 0.6575 - precision: 0.7149 - recall: 0.5686 - auc: 0.6965\n",
            " For Batch Number 50 the model has a loss of {'loss': 0.6239655017852783, 'tp': 473.0, 'fp': 186.0, 'tn': 578.0, 'fn': 363.0, 'accuracy': 0.6568750143051147, 'precision': 0.7177541851997375, 'recall': 0.5657894611358643, 'auc': 0.6956164240837097} \n",
            " 50/689 [=>............................] - ETA: 38s - loss: 0.6240 - tp: 473.0000 - fp: 186.0000 - tn: 578.0000 - fn: 363.0000 - accuracy: 0.6569 - precision: 0.7178 - recall: 0.5658 - auc: 0.6956\n",
            " For Batch Number 51 the model has a loss of {'loss': 0.6247847080230713, 'tp': 482.0, 'fp': 189.0, 'tn': 587.0, 'fn': 374.0, 'accuracy': 0.655024528503418, 'precision': 0.7183308601379395, 'recall': 0.5630841255187988, 'auc': 0.6940758228302002} \n",
            " 51/689 [=>............................] - ETA: 38s - loss: 0.6248 - tp: 482.0000 - fp: 189.0000 - tn: 587.0000 - fn: 374.0000 - accuracy: 0.6550 - precision: 0.7183 - recall: 0.5631 - auc: 0.6941\n",
            " For Batch Number 52 the model has a loss of {'loss': 0.6255857944488525, 'tp': 492.0, 'fp': 191.0, 'tn': 600.0, 'fn': 381.0, 'accuracy': 0.65625, 'precision': 0.7203513979911804, 'recall': 0.5635738968849182, 'auc': 0.6935252547264099} \n",
            " 52/689 [=>............................] - ETA: 38s - loss: 0.6256 - tp: 492.0000 - fp: 191.0000 - tn: 600.0000 - fn: 381.0000 - accuracy: 0.6562 - precision: 0.7204 - recall: 0.5636 - auc: 0.6935\n",
            " For Batch Number 53 the model has a loss of {'loss': 0.6256136894226074, 'tp': 501.0, 'fp': 196.0, 'tn': 614.0, 'fn': 385.0, 'accuracy': 0.6574292182922363, 'precision': 0.7187948226928711, 'recall': 0.5654627680778503, 'auc': 0.6933874487876892} \n",
            " 53/689 [=>............................] - ETA: 38s - loss: 0.6256 - tp: 501.0000 - fp: 196.0000 - tn: 614.0000 - fn: 385.0000 - accuracy: 0.6574 - precision: 0.7188 - recall: 0.5655 - auc: 0.6934\n",
            " For Batch Number 54 the model has a loss of {'loss': 0.6256819367408752, 'tp': 512.0, 'fp': 201.0, 'tn': 622.0, 'fn': 393.0, 'accuracy': 0.65625, 'precision': 0.7180925607681274, 'recall': 0.5657458305358887, 'auc': 0.6935991644859314} \n",
            " 54/689 [=>............................] - ETA: 38s - loss: 0.6257 - tp: 512.0000 - fp: 201.0000 - tn: 622.0000 - fn: 393.0000 - accuracy: 0.6562 - precision: 0.7181 - recall: 0.5657 - auc: 0.6936\n",
            " For Batch Number 55 the model has a loss of {'loss': 0.6267236471176147, 'tp': 520.0, 'fp': 210.0, 'tn': 631.0, 'fn': 399.0, 'accuracy': 0.6539772748947144, 'precision': 0.7123287916183472, 'recall': 0.5658324360847473, 'auc': 0.6919317245483398} \n",
            " 55/689 [=>............................] - ETA: 38s - loss: 0.6267 - tp: 520.0000 - fp: 210.0000 - tn: 631.0000 - fn: 399.0000 - accuracy: 0.6540 - precision: 0.7123 - recall: 0.5658 - auc: 0.6919\n",
            " For Batch Number 56 the model has a loss of {'loss': 0.6264952421188354, 'tp': 532.0, 'fp': 216.0, 'tn': 640.0, 'fn': 404.0, 'accuracy': 0.6540178656578064, 'precision': 0.7112299203872681, 'recall': 0.5683760643005371, 'auc': 0.6918577551841736} \n",
            " 56/689 [=>............................] - ETA: 38s - loss: 0.6265 - tp: 532.0000 - fp: 216.0000 - tn: 640.0000 - fn: 404.0000 - accuracy: 0.6540 - precision: 0.7112 - recall: 0.5684 - auc: 0.6919\n",
            " For Batch Number 57 the model has a loss of {'loss': 0.6255662441253662, 'tp': 544.0, 'fp': 220.0, 'tn': 653.0, 'fn': 407.0, 'accuracy': 0.65625, 'precision': 0.7120419144630432, 'recall': 0.5720294713973999, 'auc': 0.6926349997520447} \n",
            " 57/689 [=>............................] - ETA: 38s - loss: 0.6256 - tp: 544.0000 - fp: 220.0000 - tn: 653.0000 - fn: 407.0000 - accuracy: 0.6562 - precision: 0.7120 - recall: 0.5720 - auc: 0.6926\n",
            " For Batch Number 58 the model has a loss of {'loss': 0.6255148649215698, 'tp': 551.0, 'fp': 226.0, 'tn': 666.0, 'fn': 413.0, 'accuracy': 0.6557112336158752, 'precision': 0.7091377377510071, 'recall': 0.5715767741203308, 'auc': 0.6920552253723145} \n",
            " 58/689 [=>............................] - ETA: 38s - loss: 0.6255 - tp: 551.0000 - fp: 226.0000 - tn: 666.0000 - fn: 413.0000 - accuracy: 0.6557 - precision: 0.7091 - recall: 0.5716 - auc: 0.6921\n",
            " For Batch Number 59 the model has a loss of {'loss': 0.6248957514762878, 'tp': 559.0, 'fp': 230.0, 'tn': 681.0, 'fn': 418.0, 'accuracy': 0.6567796468734741, 'precision': 0.7084917426109314, 'recall': 0.5721596479415894, 'auc': 0.6934162378311157} \n",
            " 59/689 [=>............................] - ETA: 39s - loss: 0.6249 - tp: 559.0000 - fp: 230.0000 - tn: 681.0000 - fn: 418.0000 - accuracy: 0.6568 - precision: 0.7085 - recall: 0.5722 - auc: 0.6934\n",
            " For Batch Number 60 the model has a loss of {'loss': 0.6254980564117432, 'tp': 565.0, 'fp': 235.0, 'tn': 694.0, 'fn': 426.0, 'accuracy': 0.6557291746139526, 'precision': 0.706250011920929, 'recall': 0.5701311826705933, 'auc': 0.692119836807251} \n",
            " 60/689 [=>............................] - ETA: 40s - loss: 0.6255 - tp: 565.0000 - fp: 235.0000 - tn: 694.0000 - fn: 426.0000 - accuracy: 0.6557 - precision: 0.7063 - recall: 0.5701 - auc: 0.6921\n",
            " For Batch Number 61 the model has a loss of {'loss': 0.6257308125495911, 'tp': 573.0, 'fp': 236.0, 'tn': 707.0, 'fn': 436.0, 'accuracy': 0.6557376980781555, 'precision': 0.7082818150520325, 'recall': 0.5678889751434326, 'auc': 0.692145049571991} \n",
            " 61/689 [=>............................] - ETA: 40s - loss: 0.6257 - tp: 573.0000 - fp: 236.0000 - tn: 707.0000 - fn: 436.0000 - accuracy: 0.6557 - precision: 0.7083 - recall: 0.5679 - auc: 0.6921\n",
            " For Batch Number 62 the model has a loss of {'loss': 0.6242508888244629, 'tp': 580.0, 'fp': 237.0, 'tn': 723.0, 'fn': 444.0, 'accuracy': 0.6567540168762207, 'precision': 0.7099143266677856, 'recall': 0.56640625, 'auc': 0.6946080327033997} \n",
            " 62/689 [=>............................] - ETA: 40s - loss: 0.6243 - tp: 580.0000 - fp: 237.0000 - tn: 723.0000 - fn: 444.0000 - accuracy: 0.6568 - precision: 0.7099 - recall: 0.5664 - auc: 0.6946\n",
            " For Batch Number 63 the model has a loss of {'loss': 0.6235558986663818, 'tp': 587.0, 'fp': 238.0, 'tn': 738.0, 'fn': 453.0, 'accuracy': 0.6572420597076416, 'precision': 0.7115151286125183, 'recall': 0.5644230842590332, 'auc': 0.6961154341697693} \n",
            " 63/689 [=>............................] - ETA: 41s - loss: 0.6236 - tp: 587.0000 - fp: 238.0000 - tn: 738.0000 - fn: 453.0000 - accuracy: 0.6572 - precision: 0.7115 - recall: 0.5644 - auc: 0.6961\n",
            " For Batch Number 64 the model has a loss of {'loss': 0.6242828369140625, 'tp': 595.0, 'fp': 239.0, 'tn': 749.0, 'fn': 465.0, 'accuracy': 0.65625, 'precision': 0.7134292721748352, 'recall': 0.5613207817077637, 'auc': 0.6945534944534302} \n",
            " 64/689 [=>............................] - ETA: 42s - loss: 0.6243 - tp: 595.0000 - fp: 239.0000 - tn: 749.0000 - fn: 465.0000 - accuracy: 0.6562 - precision: 0.7134 - recall: 0.5613 - auc: 0.6946\n",
            " For Batch Number 65 the model has a loss of {'loss': 0.6227661371231079, 'tp': 606.0, 'fp': 241.0, 'tn': 761.0, 'fn': 472.0, 'accuracy': 0.6572115421295166, 'precision': 0.7154663801193237, 'recall': 0.5621521472930908, 'auc': 0.6960869431495667} \n",
            " 65/689 [=>............................] - ETA: 43s - loss: 0.6228 - tp: 606.0000 - fp: 241.0000 - tn: 761.0000 - fn: 472.0000 - accuracy: 0.6572 - precision: 0.7155 - recall: 0.5622 - auc: 0.6961\n",
            " For Batch Number 66 the model has a loss of {'loss': 0.6206753253936768, 'tp': 620.0, 'fp': 241.0, 'tn': 772.0, 'fn': 479.0, 'accuracy': 0.6590909361839294, 'precision': 0.7200928926467896, 'recall': 0.5641492009162903, 'auc': 0.6987582445144653} \n",
            " 66/689 [=>............................] - ETA: 43s - loss: 0.6207 - tp: 620.0000 - fp: 241.0000 - tn: 772.0000 - fn: 479.0000 - accuracy: 0.6591 - precision: 0.7201 - recall: 0.5641 - auc: 0.6988\n",
            " For Batch Number 67 the model has a loss of {'loss': 0.6211010217666626, 'tp': 629.0, 'fp': 249.0, 'tn': 779.0, 'fn': 487.0, 'accuracy': 0.6567164063453674, 'precision': 0.7164009213447571, 'recall': 0.5636200904846191, 'auc': 0.6973435282707214} \n",
            " 67/689 [=>............................] - ETA: 44s - loss: 0.6211 - tp: 629.0000 - fp: 249.0000 - tn: 779.0000 - fn: 487.0000 - accuracy: 0.6567 - precision: 0.7164 - recall: 0.5636 - auc: 0.6973\n",
            " For Batch Number 68 the model has a loss of {'loss': 0.622117817401886, 'tp': 638.0, 'fp': 255.0, 'tn': 791.0, 'fn': 492.0, 'accuracy': 0.6567095518112183, 'precision': 0.7144457101821899, 'recall': 0.5646017789840698, 'auc': 0.6962363719940186} \n",
            " 68/689 [=>............................] - ETA: 44s - loss: 0.6221 - tp: 638.0000 - fp: 255.0000 - tn: 791.0000 - fn: 492.0000 - accuracy: 0.6567 - precision: 0.7144 - recall: 0.5646 - auc: 0.6962\n",
            " For Batch Number 69 the model has a loss of {'loss': 0.6224327087402344, 'tp': 648.0, 'fp': 261.0, 'tn': 802.0, 'fn': 497.0, 'accuracy': 0.6567028760910034, 'precision': 0.7128713130950928, 'recall': 0.5659388899803162, 'auc': 0.6958772540092468} \n",
            " 69/689 [==>...........................] - ETA: 45s - loss: 0.6224 - tp: 648.0000 - fp: 261.0000 - tn: 802.0000 - fn: 497.0000 - accuracy: 0.6567 - precision: 0.7129 - recall: 0.5659 - auc: 0.6959\n",
            " For Batch Number 70 the model has a loss of {'loss': 0.6216813325881958, 'tp': 658.0, 'fp': 262.0, 'tn': 813.0, 'fn': 507.0, 'accuracy': 0.6566964387893677, 'precision': 0.7152174115180969, 'recall': 0.5648068785667419, 'auc': 0.6955392956733704} \n",
            " 70/689 [==>...........................] - ETA: 45s - loss: 0.6217 - tp: 658.0000 - fp: 262.0000 - tn: 813.0000 - fn: 507.0000 - accuracy: 0.6567 - precision: 0.7152 - recall: 0.5648 - auc: 0.6955\n",
            " For Batch Number 71 the model has a loss of {'loss': 0.6240582466125488, 'tp': 666.0, 'fp': 269.0, 'tn': 823.0, 'fn': 514.0, 'accuracy': 0.6553696990013123, 'precision': 0.7122994661331177, 'recall': 0.5644067525863647, 'auc': 0.6937496662139893} \n",
            " 71/689 [==>...........................] - ETA: 45s - loss: 0.6241 - tp: 666.0000 - fp: 269.0000 - tn: 823.0000 - fn: 514.0000 - accuracy: 0.6554 - precision: 0.7123 - recall: 0.5644 - auc: 0.6937\n",
            " For Batch Number 72 the model has a loss of {'loss': 0.6235532164573669, 'tp': 678.0, 'fp': 271.0, 'tn': 835.0, 'fn': 520.0, 'accuracy': 0.6566840410232544, 'precision': 0.7144362330436707, 'recall': 0.5659432411193848, 'auc': 0.6957568526268005} \n",
            " 72/689 [==>...........................] - ETA: 46s - loss: 0.6236 - tp: 678.0000 - fp: 271.0000 - tn: 835.0000 - fn: 520.0000 - accuracy: 0.6567 - precision: 0.7144 - recall: 0.5659 - auc: 0.6958\n",
            " For Batch Number 73 the model has a loss of {'loss': 0.6230119466781616, 'tp': 688.0, 'fp': 273.0, 'tn': 848.0, 'fn': 527.0, 'accuracy': 0.6575342416763306, 'precision': 0.7159209251403809, 'recall': 0.5662551522254944, 'auc': 0.6965047717094421} \n",
            " 73/689 [==>...........................] - ETA: 46s - loss: 0.6230 - tp: 688.0000 - fp: 273.0000 - tn: 848.0000 - fn: 527.0000 - accuracy: 0.6575 - precision: 0.7159 - recall: 0.5663 - auc: 0.6965\n",
            " For Batch Number 74 the model has a loss of {'loss': 0.6228978037834167, 'tp': 698.0, 'fp': 278.0, 'tn': 858.0, 'fn': 534.0, 'accuracy': 0.6570945978164673, 'precision': 0.7151639461517334, 'recall': 0.5665584206581116, 'auc': 0.6965779662132263} \n",
            " 74/689 [==>...........................] - ETA: 47s - loss: 0.6229 - tp: 698.0000 - fp: 278.0000 - tn: 858.0000 - fn: 534.0000 - accuracy: 0.6571 - precision: 0.7152 - recall: 0.5666 - auc: 0.6966\n",
            " For Batch Number 75 the model has a loss of {'loss': 0.6214597821235657, 'tp': 707.0, 'fp': 279.0, 'tn': 874.0, 'fn': 540.0, 'accuracy': 0.6587499976158142, 'precision': 0.7170385122299194, 'recall': 0.5669606924057007, 'auc': 0.6983692646026611} \n",
            " 75/689 [==>...........................] - ETA: 47s - loss: 0.6215 - tp: 707.0000 - fp: 279.0000 - tn: 874.0000 - fn: 540.0000 - accuracy: 0.6587 - precision: 0.7170 - recall: 0.5670 - auc: 0.6984\n",
            " For Batch Number 76 the model has a loss of {'loss': 0.6220036745071411, 'tp': 717.0, 'fp': 281.0, 'tn': 885.0, 'fn': 549.0, 'accuracy': 0.6587170958518982, 'precision': 0.7184368968009949, 'recall': 0.5663506984710693, 'auc': 0.6982182264328003} \n",
            " 76/689 [==>...........................] - ETA: 48s - loss: 0.6220 - tp: 717.0000 - fp: 281.0000 - tn: 885.0000 - fn: 549.0000 - accuracy: 0.6587 - precision: 0.7184 - recall: 0.5664 - auc: 0.6982\n",
            " For Batch Number 77 the model has a loss of {'loss': 0.6218079924583435, 'tp': 728.0, 'fp': 286.0, 'tn': 897.0, 'fn': 553.0, 'accuracy': 0.6594967246055603, 'precision': 0.7179487347602844, 'recall': 0.568306028842926, 'auc': 0.6983957290649414} \n",
            " 77/689 [==>...........................] - ETA: 48s - loss: 0.6218 - tp: 728.0000 - fp: 286.0000 - tn: 897.0000 - fn: 553.0000 - accuracy: 0.6595 - precision: 0.7179 - recall: 0.5683 - auc: 0.6984\n",
            " For Batch Number 78 the model has a loss of {'loss': 0.6203519105911255, 'tp': 739.0, 'fp': 289.0, 'tn': 911.0, 'fn': 557.0, 'accuracy': 0.661057710647583, 'precision': 0.7188715934753418, 'recall': 0.5702160596847534, 'auc': 0.6999578475952148} \n",
            " 78/689 [==>...........................] - ETA: 48s - loss: 0.6204 - tp: 739.0000 - fp: 289.0000 - tn: 911.0000 - fn: 557.0000 - accuracy: 0.6611 - precision: 0.7189 - recall: 0.5702 - auc: 0.7000\n",
            " For Batch Number 79 the model has a loss of {'loss': 0.6197215914726257, 'tp': 750.0, 'fp': 293.0, 'tn': 920.0, 'fn': 565.0, 'accuracy': 0.6606012582778931, 'precision': 0.7190795540809631, 'recall': 0.5703421831130981, 'auc': 0.7006128430366516} \n",
            " 79/689 [==>...........................] - ETA: 48s - loss: 0.6197 - tp: 750.0000 - fp: 293.0000 - tn: 920.0000 - fn: 565.0000 - accuracy: 0.6606 - precision: 0.7191 - recall: 0.5703 - auc: 0.7006\n",
            " For Batch Number 80 the model has a loss of {'loss': 0.6200469732284546, 'tp': 760.0, 'fp': 298.0, 'tn': 930.0, 'fn': 572.0, 'accuracy': 0.66015625, 'precision': 0.7183364629745483, 'recall': 0.5705705881118774, 'auc': 0.6998317241668701} \n",
            " 80/689 [==>...........................] - ETA: 48s - loss: 0.6200 - tp: 760.0000 - fp: 298.0000 - tn: 930.0000 - fn: 572.0000 - accuracy: 0.6602 - precision: 0.7183 - recall: 0.5706 - auc: 0.6998\n",
            " For Batch Number 81 the model has a loss of {'loss': 0.622320830821991, 'tp': 770.0, 'fp': 302.0, 'tn': 938.0, 'fn': 582.0, 'accuracy': 0.6589506268501282, 'precision': 0.7182835936546326, 'recall': 0.5695266127586365, 'auc': 0.6985062956809998} \n",
            " 81/689 [==>...........................] - ETA: 48s - loss: 0.6223 - tp: 770.0000 - fp: 302.0000 - tn: 938.0000 - fn: 582.0000 - accuracy: 0.6590 - precision: 0.7183 - recall: 0.5695 - auc: 0.6985\n",
            " For Batch Number 82 the model has a loss of {'loss': 0.6217288374900818, 'tp': 778.0, 'fp': 306.0, 'tn': 952.0, 'fn': 588.0, 'accuracy': 0.6592987775802612, 'precision': 0.7177121639251709, 'recall': 0.569546103477478, 'auc': 0.6982334852218628} \n",
            " 82/689 [==>...........................] - ETA: 48s - loss: 0.6217 - tp: 778.0000 - fp: 306.0000 - tn: 952.0000 - fn: 588.0000 - accuracy: 0.6593 - precision: 0.7177 - recall: 0.5695 - auc: 0.6982\n",
            " For Batch Number 83 the model has a loss of {'loss': 0.6229740977287292, 'tp': 786.0, 'fp': 311.0, 'tn': 962.0, 'fn': 597.0, 'accuracy': 0.6581325531005859, 'precision': 0.7164995670318604, 'recall': 0.5683296918869019, 'auc': 0.6964575052261353} \n",
            " 83/689 [==>...........................] - ETA: 48s - loss: 0.6230 - tp: 786.0000 - fp: 311.0000 - tn: 962.0000 - fn: 597.0000 - accuracy: 0.6581 - precision: 0.7165 - recall: 0.5683 - auc: 0.6965\n",
            " For Batch Number 84 the model has a loss of {'loss': 0.6228059530258179, 'tp': 793.0, 'fp': 316.0, 'tn': 974.0, 'fn': 605.0, 'accuracy': 0.6573660969734192, 'precision': 0.7150586247444153, 'recall': 0.5672389268875122, 'auc': 0.696043074131012} \n",
            " 84/689 [==>...........................] - ETA: 48s - loss: 0.6228 - tp: 793.0000 - fp: 316.0000 - tn: 974.0000 - fn: 605.0000 - accuracy: 0.6574 - precision: 0.7151 - recall: 0.5672 - auc: 0.6960\n",
            " For Batch Number 85 the model has a loss of {'loss': 0.6225090622901917, 'tp': 800.0, 'fp': 319.0, 'tn': 990.0, 'fn': 611.0, 'accuracy': 0.658088207244873, 'precision': 0.7149240374565125, 'recall': 0.5669738054275513, 'auc': 0.6959949135780334} \n",
            " 85/689 [==>...........................] - ETA: 48s - loss: 0.6225 - tp: 800.0000 - fp: 319.0000 - tn: 990.0000 - fn: 611.0000 - accuracy: 0.6581 - precision: 0.7149 - recall: 0.5670 - auc: 0.6960\n",
            " For Batch Number 86 the model has a loss of {'loss': 0.6244983077049255, 'tp': 806.0, 'fp': 322.0, 'tn': 1003.0, 'fn': 621.0, 'accuracy': 0.6573401093482971, 'precision': 0.7145389914512634, 'recall': 0.5648213028907776, 'auc': 0.6948428153991699} \n",
            " 86/689 [==>...........................] - ETA: 49s - loss: 0.6245 - tp: 806.0000 - fp: 322.0000 - tn: 1003.0000 - fn: 621.0000 - accuracy: 0.6573 - precision: 0.7145 - recall: 0.5648 - auc: 0.6948\n",
            " For Batch Number 87 the model has a loss of {'loss': 0.6255951523780823, 'tp': 812.0, 'fp': 325.0, 'tn': 1017.0, 'fn': 630.0, 'accuracy': 0.6569684147834778, 'precision': 0.7141600847244263, 'recall': 0.5631067752838135, 'auc': 0.6941752433776855} \n",
            " 87/689 [==>...........................] - ETA: 49s - loss: 0.6256 - tp: 812.0000 - fp: 325.0000 - tn: 1017.0000 - fn: 630.0000 - accuracy: 0.6570 - precision: 0.7142 - recall: 0.5631 - auc: 0.6942\n",
            " For Batch Number 88 the model has a loss of {'loss': 0.6258043646812439, 'tp': 818.0, 'fp': 327.0, 'tn': 1031.0, 'fn': 640.0, 'accuracy': 0.6566051244735718, 'precision': 0.7144104838371277, 'recall': 0.5610425472259521, 'auc': 0.6935333609580994} \n",
            " 88/689 [==>...........................] - ETA: 49s - loss: 0.6258 - tp: 818.0000 - fp: 327.0000 - tn: 1031.0000 - fn: 640.0000 - accuracy: 0.6566 - precision: 0.7144 - recall: 0.5610 - auc: 0.6935\n",
            " For Batch Number 89 the model has a loss of {'loss': 0.626053512096405, 'tp': 822.0, 'fp': 331.0, 'tn': 1046.0, 'fn': 649.0, 'accuracy': 0.6558988690376282, 'precision': 0.7129228115081787, 'recall': 0.5588035583496094, 'auc': 0.6933512687683105} \n",
            " 89/689 [==>...........................] - ETA: 49s - loss: 0.6261 - tp: 822.0000 - fp: 331.0000 - tn: 1046.0000 - fn: 649.0000 - accuracy: 0.6559 - precision: 0.7129 - recall: 0.5588 - auc: 0.6934\n",
            " For Batch Number 90 the model has a loss of {'loss': 0.6278733015060425, 'tp': 827.0, 'fp': 334.0, 'tn': 1058.0, 'fn': 661.0, 'accuracy': 0.6545138955116272, 'precision': 0.7123169898986816, 'recall': 0.5557795763015747, 'auc': 0.691275417804718} \n",
            " 90/689 [==>...........................] - ETA: 50s - loss: 0.6279 - tp: 827.0000 - fp: 334.0000 - tn: 1058.0000 - fn: 661.0000 - accuracy: 0.6545 - precision: 0.7123 - recall: 0.5558 - auc: 0.6913\n",
            " For Batch Number 91 the model has a loss of {'loss': 0.6277176737785339, 'tp': 832.0, 'fp': 335.0, 'tn': 1076.0, 'fn': 669.0, 'accuracy': 0.6552197933197021, 'precision': 0.7129391431808472, 'recall': 0.554297149181366, 'auc': 0.6915214657783508} \n",
            " 91/689 [==>...........................] - ETA: 50s - loss: 0.6277 - tp: 832.0000 - fp: 335.0000 - tn: 1076.0000 - fn: 669.0000 - accuracy: 0.6552 - precision: 0.7129 - recall: 0.5543 - auc: 0.6915\n",
            " For Batch Number 92 the model has a loss of {'loss': 0.6271544694900513, 'tp': 839.0, 'fp': 337.0, 'tn': 1092.0, 'fn': 676.0, 'accuracy': 0.655910313129425, 'precision': 0.7134353518486023, 'recall': 0.5537953972816467, 'auc': 0.6917212009429932} \n",
            " 92/689 [===>..........................] - ETA: 50s - loss: 0.6272 - tp: 839.0000 - fp: 337.0000 - tn: 1092.0000 - fn: 676.0000 - accuracy: 0.6559 - precision: 0.7134 - recall: 0.5538 - auc: 0.6917\n",
            " For Batch Number 93 the model has a loss of {'loss': 0.6281347274780273, 'tp': 843.0, 'fp': 341.0, 'tn': 1105.0, 'fn': 687.0, 'accuracy': 0.6545698642730713, 'precision': 0.7119932174682617, 'recall': 0.5509803891181946, 'auc': 0.6903491020202637} \n",
            " 93/689 [===>..........................] - ETA: 50s - loss: 0.6281 - tp: 843.0000 - fp: 341.0000 - tn: 1105.0000 - fn: 687.0000 - accuracy: 0.6546 - precision: 0.7120 - recall: 0.5510 - auc: 0.6903\n",
            " For Batch Number 94 the model has a loss of {'loss': 0.6287090182304382, 'tp': 849.0, 'fp': 344.0, 'tn': 1117.0, 'fn': 698.0, 'accuracy': 0.6535904407501221, 'precision': 0.7116513252258301, 'recall': 0.5488041639328003, 'auc': 0.6890944242477417} \n",
            " 94/689 [===>..........................] - ETA: 50s - loss: 0.6287 - tp: 849.0000 - fp: 344.0000 - tn: 1117.0000 - fn: 698.0000 - accuracy: 0.6536 - precision: 0.7117 - recall: 0.5488 - auc: 0.6891\n",
            " For Batch Number 95 the model has a loss of {'loss': 0.6285048723220825, 'tp': 859.0, 'fp': 345.0, 'tn': 1130.0, 'fn': 706.0, 'accuracy': 0.6542763113975525, 'precision': 0.7134551405906677, 'recall': 0.5488817691802979, 'auc': 0.6894022226333618} \n",
            " 95/689 [===>..........................] - ETA: 50s - loss: 0.6285 - tp: 859.0000 - fp: 345.0000 - tn: 1130.0000 - fn: 706.0000 - accuracy: 0.6543 - precision: 0.7135 - recall: 0.5489 - auc: 0.6894\n",
            " For Batch Number 96 the model has a loss of {'loss': 0.6293874382972717, 'tp': 863.0, 'fp': 351.0, 'tn': 1142.0, 'fn': 716.0, 'accuracy': 0.6526692509651184, 'precision': 0.7108731269836426, 'recall': 0.5465484261512756, 'auc': 0.6881972551345825} \n",
            " 96/689 [===>..........................] - ETA: 51s - loss: 0.6294 - tp: 863.0000 - fp: 351.0000 - tn: 1142.0000 - fn: 716.0000 - accuracy: 0.6527 - precision: 0.7109 - recall: 0.5465 - auc: 0.6882\n",
            " For Batch Number 97 the model has a loss of {'loss': 0.6285712122917175, 'tp': 871.0, 'fp': 355.0, 'tn': 1158.0, 'fn': 720.0, 'accuracy': 0.6536726951599121, 'precision': 0.710440456867218, 'recall': 0.5474544167518616, 'auc': 0.6887481808662415} \n",
            " 97/689 [===>..........................] - ETA: 50s - loss: 0.6286 - tp: 871.0000 - fp: 355.0000 - tn: 1158.0000 - fn: 720.0000 - accuracy: 0.6537 - precision: 0.7104 - recall: 0.5475 - auc: 0.6887\n",
            " For Batch Number 98 the model has a loss of {'loss': 0.629492998123169, 'tp': 875.0, 'fp': 361.0, 'tn': 1170.0, 'fn': 730.0, 'accuracy': 0.6521046161651611, 'precision': 0.7079287767410278, 'recall': 0.545171320438385, 'auc': 0.6874876618385315} \n",
            " 98/689 [===>..........................] - ETA: 50s - loss: 0.6295 - tp: 875.0000 - fp: 361.0000 - tn: 1170.0000 - fn: 730.0000 - accuracy: 0.6521 - precision: 0.7079 - recall: 0.5452 - auc: 0.6875\n",
            " For Batch Number 99 the model has a loss of {'loss': 0.6299006342887878, 'tp': 881.0, 'fp': 363.0, 'tn': 1184.0, 'fn': 740.0, 'accuracy': 0.651830792427063, 'precision': 0.7081993818283081, 'recall': 0.5434916615486145, 'auc': 0.6868598461151123} \n",
            " 99/689 [===>..........................] - ETA: 50s - loss: 0.6299 - tp: 881.0000 - fp: 363.0000 - tn: 1184.0000 - fn: 740.0000 - accuracy: 0.6518 - precision: 0.7082 - recall: 0.5435 - auc: 0.6869\n",
            " For Batch Number 100 the model has a loss of {'loss': 0.6302333474159241, 'tp': 887.0, 'fp': 364.0, 'tn': 1197.0, 'fn': 752.0, 'accuracy': 0.6512500047683716, 'precision': 0.7090327739715576, 'recall': 0.5411836504936218, 'auc': 0.6866902112960815} \n",
            "100/689 [===>..........................] - ETA: 50s - loss: 0.6302 - tp: 887.0000 - fp: 364.0000 - tn: 1197.0000 - fn: 752.0000 - accuracy: 0.6513 - precision: 0.7090 - recall: 0.5412 - auc: 0.6867\n",
            " For Batch Number 101 the model has a loss of {'loss': 0.6299234628677368, 'tp': 894.0, 'fp': 365.0, 'tn': 1212.0, 'fn': 761.0, 'accuracy': 0.6516088843345642, 'precision': 0.7100873589515686, 'recall': 0.5401812791824341, 'auc': 0.6870366930961609} \n",
            "101/689 [===>..........................] - ETA: 50s - loss: 0.6299 - tp: 894.0000 - fp: 365.0000 - tn: 1212.0000 - fn: 761.0000 - accuracy: 0.6516 - precision: 0.7101 - recall: 0.5402 - auc: 0.6870\n",
            " For Batch Number 102 the model has a loss of {'loss': 0.6300565600395203, 'tp': 902.0, 'fp': 370.0, 'tn': 1227.0, 'fn': 765.0, 'accuracy': 0.6522671580314636, 'precision': 0.7091194987297058, 'recall': 0.541091799736023, 'auc': 0.687496542930603} \n",
            "102/689 [===>..........................] - ETA: 50s - loss: 0.6301 - tp: 902.0000 - fp: 370.0000 - tn: 1227.0000 - fn: 765.0000 - accuracy: 0.6523 - precision: 0.7091 - recall: 0.5411 - auc: 0.6875\n",
            " For Batch Number 103 the model has a loss of {'loss': 0.6296271085739136, 'tp': 913.0, 'fp': 374.0, 'tn': 1240.0, 'fn': 769.0, 'accuracy': 0.6532160043716431, 'precision': 0.7094017267227173, 'recall': 0.5428062081336975, 'auc': 0.6879353523254395} \n",
            "103/689 [===>..........................] - ETA: 50s - loss: 0.6296 - tp: 913.0000 - fp: 374.0000 - tn: 1240.0000 - fn: 769.0000 - accuracy: 0.6532 - precision: 0.7094 - recall: 0.5428 - auc: 0.6879\n",
            " For Batch Number 104 the model has a loss of {'loss': 0.6302074193954468, 'tp': 920.0, 'fp': 381.0, 'tn': 1254.0, 'fn': 773.0, 'accuracy': 0.653245210647583, 'precision': 0.7071483731269836, 'recall': 0.5434140563011169, 'auc': 0.6869988441467285} \n",
            "104/689 [===>..........................] - ETA: 50s - loss: 0.6302 - tp: 920.0000 - fp: 381.0000 - tn: 1254.0000 - fn: 773.0000 - accuracy: 0.6532 - precision: 0.7071 - recall: 0.5434 - auc: 0.6870\n",
            " For Batch Number 105 the model has a loss of {'loss': 0.6305423378944397, 'tp': 927.0, 'fp': 384.0, 'tn': 1265.0, 'fn': 784.0, 'accuracy': 0.6523809432983398, 'precision': 0.7070938348770142, 'recall': 0.5417883992195129, 'auc': 0.6864718794822693} \n",
            "105/689 [===>..........................] - ETA: 51s - loss: 0.6305 - tp: 927.0000 - fp: 384.0000 - tn: 1265.0000 - fn: 784.0000 - accuracy: 0.6524 - precision: 0.7071 - recall: 0.5418 - auc: 0.6865\n",
            " For Batch Number 106 the model has a loss of {'loss': 0.6314557790756226, 'tp': 932.0, 'fp': 389.0, 'tn': 1277.0, 'fn': 794.0, 'accuracy': 0.651238203048706, 'precision': 0.7055261135101318, 'recall': 0.5399768352508545, 'auc': 0.684711754322052} \n",
            "106/689 [===>..........................] - ETA: 51s - loss: 0.6315 - tp: 932.0000 - fp: 389.0000 - tn: 1277.0000 - fn: 794.0000 - accuracy: 0.6512 - precision: 0.7055 - recall: 0.5400 - auc: 0.6847\n",
            " For Batch Number 107 the model has a loss of {'loss': 0.6317905783653259, 'tp': 938.0, 'fp': 392.0, 'tn': 1288.0, 'fn': 806.0, 'accuracy': 0.6501168012619019, 'precision': 0.7052631378173828, 'recall': 0.5378440618515015, 'auc': 0.684197187423706} \n",
            "107/689 [===>..........................] - ETA: 51s - loss: 0.6318 - tp: 938.0000 - fp: 392.0000 - tn: 1288.0000 - fn: 806.0000 - accuracy: 0.6501 - precision: 0.7053 - recall: 0.5378 - auc: 0.6842\n",
            " For Batch Number 108 the model has a loss of {'loss': 0.6316672563552856, 'tp': 942.0, 'fp': 396.0, 'tn': 1303.0, 'fn': 815.0, 'accuracy': 0.6495949029922485, 'precision': 0.7040358781814575, 'recall': 0.5361411571502686, 'auc': 0.6840699315071106} \n",
            "108/689 [===>..........................] - ETA: 51s - loss: 0.6317 - tp: 942.0000 - fp: 396.0000 - tn: 1303.0000 - fn: 815.0000 - accuracy: 0.6496 - precision: 0.7040 - recall: 0.5361 - auc: 0.6841\n",
            " For Batch Number 109 the model has a loss of {'loss': 0.6318838596343994, 'tp': 949.0, 'fp': 397.0, 'tn': 1313.0, 'fn': 829.0, 'accuracy': 0.64850914478302, 'precision': 0.7050520181655884, 'recall': 0.5337457656860352, 'auc': 0.6835737824440002} \n",
            "109/689 [===>..........................] - ETA: 51s - loss: 0.6319 - tp: 949.0000 - fp: 397.0000 - tn: 1313.0000 - fn: 829.0000 - accuracy: 0.6485 - precision: 0.7051 - recall: 0.5337 - auc: 0.6836\n",
            " For Batch Number 110 the model has a loss of {'loss': 0.6322260499000549, 'tp': 955.0, 'fp': 402.0, 'tn': 1326.0, 'fn': 837.0, 'accuracy': 0.6480113863945007, 'precision': 0.7037582993507385, 'recall': 0.5329241156578064, 'auc': 0.6829918622970581} \n",
            "110/689 [===>..........................] - ETA: 51s - loss: 0.6322 - tp: 955.0000 - fp: 402.0000 - tn: 1326.0000 - fn: 837.0000 - accuracy: 0.6480 - precision: 0.7038 - recall: 0.5329 - auc: 0.6830\n",
            " For Batch Number 111 the model has a loss of {'loss': 0.6323599815368652, 'tp': 961.0, 'fp': 408.0, 'tn': 1342.0, 'fn': 841.0, 'accuracy': 0.6483671069145203, 'precision': 0.701972246170044, 'recall': 0.5332963466644287, 'auc': 0.6820936799049377} \n",
            "111/689 [===>..........................] - ETA: 51s - loss: 0.6324 - tp: 961.0000 - fp: 408.0000 - tn: 1342.0000 - fn: 841.0000 - accuracy: 0.6484 - precision: 0.7020 - recall: 0.5333 - auc: 0.6821\n",
            " For Batch Number 112 the model has a loss of {'loss': 0.6318222880363464, 'tp': 968.0, 'fp': 409.0, 'tn': 1358.0, 'fn': 849.0, 'accuracy': 0.6489955186843872, 'precision': 0.7029774785041809, 'recall': 0.5327462553977966, 'auc': 0.6822978854179382} \n",
            "112/689 [===>..........................] - ETA: 51s - loss: 0.6318 - tp: 968.0000 - fp: 409.0000 - tn: 1358.0000 - fn: 849.0000 - accuracy: 0.6490 - precision: 0.7030 - recall: 0.5327 - auc: 0.6823\n",
            " For Batch Number 113 the model has a loss of {'loss': 0.6316956877708435, 'tp': 975.0, 'fp': 412.0, 'tn': 1372.0, 'fn': 857.0, 'accuracy': 0.6490597128868103, 'precision': 0.7029560208320618, 'recall': 0.5322052240371704, 'auc': 0.6825762987136841} \n",
            "113/689 [===>..........................] - ETA: 51s - loss: 0.6317 - tp: 975.0000 - fp: 412.0000 - tn: 1372.0000 - fn: 857.0000 - accuracy: 0.6491 - precision: 0.7030 - recall: 0.5322 - auc: 0.6826\n",
            " For Batch Number 114 the model has a loss of {'loss': 0.6321894526481628, 'tp': 980.0, 'fp': 414.0, 'tn': 1385.0, 'fn': 869.0, 'accuracy': 0.6483004093170166, 'precision': 0.7030128836631775, 'recall': 0.5300162434577942, 'auc': 0.6814444065093994} \n",
            "114/689 [===>..........................] - ETA: 52s - loss: 0.6322 - tp: 980.0000 - fp: 414.0000 - tn: 1385.0000 - fn: 869.0000 - accuracy: 0.6483 - precision: 0.7030 - recall: 0.5300 - auc: 0.6814\n",
            " For Batch Number 115 the model has a loss of {'loss': 0.631769061088562, 'tp': 988.0, 'fp': 415.0, 'tn': 1398.0, 'fn': 879.0, 'accuracy': 0.648369550704956, 'precision': 0.7042052745819092, 'recall': 0.5291911959648132, 'auc': 0.6817505955696106} \n",
            "115/689 [====>.........................] - ETA: 52s - loss: 0.6318 - tp: 988.0000 - fp: 415.0000 - tn: 1398.0000 - fn: 879.0000 - accuracy: 0.6484 - precision: 0.7042 - recall: 0.5292 - auc: 0.6818\n",
            " For Batch Number 116 the model has a loss of {'loss': 0.6318511366844177, 'tp': 995.0, 'fp': 417.0, 'tn': 1410.0, 'fn': 890.0, 'accuracy': 0.6478987336158752, 'precision': 0.704674243927002, 'recall': 0.5278514623641968, 'auc': 0.6813029050827026} \n",
            "116/689 [====>.........................] - ETA: 52s - loss: 0.6319 - tp: 995.0000 - fp: 417.0000 - tn: 1410.0000 - fn: 890.0000 - accuracy: 0.6479 - precision: 0.7047 - recall: 0.5279 - auc: 0.6813\n",
            " For Batch Number 117 the model has a loss of {'loss': 0.6314063668251038, 'tp': 1000.0, 'fp': 419.0, 'tn': 1427.0, 'fn': 898.0, 'accuracy': 0.6482371687889099, 'precision': 0.7047216296195984, 'recall': 0.5268703699111938, 'auc': 0.6817941069602966} \n",
            "117/689 [====>.........................] - ETA: 52s - loss: 0.6314 - tp: 1000.0000 - fp: 419.0000 - tn: 1427.0000 - fn: 898.0000 - accuracy: 0.6482 - precision: 0.7047 - recall: 0.5269 - auc: 0.6818\n",
            " For Batch Number 118 the model has a loss of {'loss': 0.6319819688796997, 'tp': 1007.0, 'fp': 423.0, 'tn': 1437.0, 'fn': 909.0, 'accuracy': 0.6472457647323608, 'precision': 0.7041957974433899, 'recall': 0.5255740880966187, 'auc': 0.6809747815132141} \n",
            "118/689 [====>.........................] - ETA: 51s - loss: 0.6320 - tp: 1007.0000 - fp: 423.0000 - tn: 1437.0000 - fn: 909.0000 - accuracy: 0.6472 - precision: 0.7042 - recall: 0.5256 - auc: 0.6810\n",
            " For Batch Number 119 the model has a loss of {'loss': 0.6326805949211121, 'tp': 1015.0, 'fp': 430.0, 'tn': 1446.0, 'fn': 917.0, 'accuracy': 0.6462709903717041, 'precision': 0.7024221420288086, 'recall': 0.5253623127937317, 'auc': 0.6808289289474487} \n",
            "119/689 [====>.........................] - ETA: 51s - loss: 0.6327 - tp: 1015.0000 - fp: 430.0000 - tn: 1446.0000 - fn: 917.0000 - accuracy: 0.6463 - precision: 0.7024 - recall: 0.5254 - auc: 0.6808\n",
            " For Batch Number 120 the model has a loss of {'loss': 0.6332165002822876, 'tp': 1022.0, 'fp': 436.0, 'tn': 1462.0, 'fn': 920.0, 'accuracy': 0.6468750238418579, 'precision': 0.7009602189064026, 'recall': 0.526261568069458, 'auc': 0.6810527443885803} \n",
            "120/689 [====>.........................] - ETA: 51s - loss: 0.6332 - tp: 1022.0000 - fp: 436.0000 - tn: 1462.0000 - fn: 920.0000 - accuracy: 0.6469 - precision: 0.7010 - recall: 0.5263 - auc: 0.6811\n",
            " For Batch Number 121 the model has a loss of {'loss': 0.6334483027458191, 'tp': 1031.0, 'fp': 443.0, 'tn': 1471.0, 'fn': 927.0, 'accuracy': 0.6461777091026306, 'precision': 0.6994572877883911, 'recall': 0.5265576839447021, 'auc': 0.6804844737052917} \n",
            "121/689 [====>.........................] - ETA: 51s - loss: 0.6334 - tp: 1031.0000 - fp: 443.0000 - tn: 1471.0000 - fn: 927.0000 - accuracy: 0.6462 - precision: 0.6995 - recall: 0.5266 - auc: 0.6805\n",
            " For Batch Number 122 the model has a loss of {'loss': 0.6336643695831299, 'tp': 1041.0, 'fp': 448.0, 'tn': 1480.0, 'fn': 935.0, 'accuracy': 0.6457479596138, 'precision': 0.6991269588470459, 'recall': 0.5268218517303467, 'auc': 0.6803407669067383} \n",
            "122/689 [====>.........................] - ETA: 51s - loss: 0.6337 - tp: 1041.0000 - fp: 448.0000 - tn: 1480.0000 - fn: 935.0000 - accuracy: 0.6457 - precision: 0.6991 - recall: 0.5268 - auc: 0.6803\n",
            " For Batch Number 123 the model has a loss of {'loss': 0.6341662406921387, 'tp': 1046.0, 'fp': 453.0, 'tn': 1498.0, 'fn': 939.0, 'accuracy': 0.6463414430618286, 'precision': 0.6977985501289368, 'recall': 0.5269521474838257, 'auc': 0.6800329685211182} \n",
            "123/689 [====>.........................] - ETA: 51s - loss: 0.6342 - tp: 1046.0000 - fp: 453.0000 - tn: 1498.0000 - fn: 939.0000 - accuracy: 0.6463 - precision: 0.6978 - recall: 0.5270 - auc: 0.6800\n",
            " For Batch Number 124 the model has a loss of {'loss': 0.6348156332969666, 'tp': 1048.0, 'fp': 461.0, 'tn': 1509.0, 'fn': 950.0, 'accuracy': 0.6444052457809448, 'precision': 0.694499671459198, 'recall': 0.5245245099067688, 'auc': 0.6788309812545776} \n",
            "124/689 [====>.........................] - ETA: 51s - loss: 0.6348 - tp: 1048.0000 - fp: 461.0000 - tn: 1509.0000 - fn: 950.0000 - accuracy: 0.6444 - precision: 0.6945 - recall: 0.5245 - auc: 0.6788\n",
            " For Batch Number 125 the model has a loss of {'loss': 0.634976863861084, 'tp': 1053.0, 'fp': 463.0, 'tn': 1525.0, 'fn': 959.0, 'accuracy': 0.6445000171661377, 'precision': 0.6945910453796387, 'recall': 0.5233598351478577, 'auc': 0.6786419749259949} \n",
            "125/689 [====>.........................] - ETA: 51s - loss: 0.6350 - tp: 1053.0000 - fp: 463.0000 - tn: 1525.0000 - fn: 959.0000 - accuracy: 0.6445 - precision: 0.6946 - recall: 0.5234 - auc: 0.6786\n",
            " For Batch Number 126 the model has a loss of {'loss': 0.6360235214233398, 'tp': 1057.0, 'fp': 464.0, 'tn': 1539.0, 'fn': 972.0, 'accuracy': 0.6438491940498352, 'precision': 0.694937527179718, 'recall': 0.5209462642669678, 'auc': 0.6771498918533325} \n",
            "126/689 [====>.........................] - ETA: 50s - loss: 0.6360 - tp: 1057.0000 - fp: 464.0000 - tn: 1539.0000 - fn: 972.0000 - accuracy: 0.6438 - precision: 0.6949 - recall: 0.5209 - auc: 0.6771\n",
            " For Batch Number 127 the model has a loss of {'loss': 0.6363163590431213, 'tp': 1061.0, 'fp': 466.0, 'tn': 1554.0, 'fn': 983.0, 'accuracy': 0.6434547305107117, 'precision': 0.6948264837265015, 'recall': 0.5190802216529846, 'auc': 0.6767898201942444} \n",
            "127/689 [====>.........................] - ETA: 50s - loss: 0.6363 - tp: 1061.0000 - fp: 466.0000 - tn: 1554.0000 - fn: 983.0000 - accuracy: 0.6435 - precision: 0.6948 - recall: 0.5191 - auc: 0.6768\n",
            " For Batch Number 128 the model has a loss of {'loss': 0.6365219950675964, 'tp': 1068.0, 'fp': 469.0, 'tn': 1566.0, 'fn': 993.0, 'accuracy': 0.64306640625, 'precision': 0.6948601007461548, 'recall': 0.5181950330734253, 'auc': 0.6764209270477295} \n",
            "128/689 [====>.........................] - ETA: 50s - loss: 0.6365 - tp: 1068.0000 - fp: 469.0000 - tn: 1566.0000 - fn: 993.0000 - accuracy: 0.6431 - precision: 0.6949 - recall: 0.5182 - auc: 0.6764\n",
            " For Batch Number 129 the model has a loss of {'loss': 0.6364300847053528, 'tp': 1075.0, 'fp': 472.0, 'tn': 1581.0, 'fn': 1000.0, 'accuracy': 0.643410861492157, 'precision': 0.6948933601379395, 'recall': 0.5180723071098328, 'auc': 0.6763158440589905} \n",
            "129/689 [====>.........................] - ETA: 50s - loss: 0.6364 - tp: 1075.0000 - fp: 472.0000 - tn: 1581.0000 - fn: 1000.0000 - accuracy: 0.6434 - precision: 0.6949 - recall: 0.5181 - auc: 0.6763\n",
            " For Batch Number 130 the model has a loss of {'loss': 0.6367473602294922, 'tp': 1085.0, 'fp': 476.0, 'tn': 1590.0, 'fn': 1009.0, 'accuracy': 0.6430288553237915, 'precision': 0.695067286491394, 'recall': 0.5181471109390259, 'auc': 0.6764476299285889} \n",
            "130/689 [====>.........................] - ETA: 50s - loss: 0.6367 - tp: 1085.0000 - fp: 476.0000 - tn: 1590.0000 - fn: 1009.0000 - accuracy: 0.6430 - precision: 0.6951 - recall: 0.5181 - auc: 0.6764\n",
            " For Batch Number 131 the model has a loss of {'loss': 0.63678377866745, 'tp': 1096.0, 'fp': 486.0, 'tn': 1599.0, 'fn': 1011.0, 'accuracy': 0.6428912281990051, 'precision': 0.6927939057350159, 'recall': 0.5201708674430847, 'auc': 0.676258385181427} \n",
            "131/689 [====>.........................] - ETA: 50s - loss: 0.6368 - tp: 1096.0000 - fp: 486.0000 - tn: 1599.0000 - fn: 1011.0000 - accuracy: 0.6429 - precision: 0.6928 - recall: 0.5202 - auc: 0.6763\n",
            " For Batch Number 132 the model has a loss of {'loss': 0.636576235294342, 'tp': 1111.0, 'fp': 496.0, 'tn': 1605.0, 'fn': 1012.0, 'accuracy': 0.6429924368858337, 'precision': 0.6913503408432007, 'recall': 0.5233160853385925, 'auc': 0.6766708493232727} \n",
            "132/689 [====>.........................] - ETA: 50s - loss: 0.6366 - tp: 1111.0000 - fp: 496.0000 - tn: 1605.0000 - fn: 1012.0000 - accuracy: 0.6430 - precision: 0.6914 - recall: 0.5233 - auc: 0.6767\n",
            " For Batch Number 133 the model has a loss of {'loss': 0.6377894878387451, 'tp': 1121.0, 'fp': 507.0, 'tn': 1610.0, 'fn': 1018.0, 'accuracy': 0.6416823267936707, 'precision': 0.6885749101638794, 'recall': 0.5240767002105713, 'auc': 0.6750714182853699} \n",
            "133/689 [====>.........................] - ETA: 49s - loss: 0.6378 - tp: 1121.0000 - fp: 507.0000 - tn: 1610.0000 - fn: 1018.0000 - accuracy: 0.6417 - precision: 0.6886 - recall: 0.5241 - auc: 0.6751\n",
            " For Batch Number 134 the model has a loss of {'loss': 0.6379365921020508, 'tp': 1132.0, 'fp': 516.0, 'tn': 1618.0, 'fn': 1022.0, 'accuracy': 0.6413246393203735, 'precision': 0.6868932247161865, 'recall': 0.52553391456604, 'auc': 0.6747134327888489} \n",
            "134/689 [====>.........................] - ETA: 49s - loss: 0.6379 - tp: 1132.0000 - fp: 516.0000 - tn: 1618.0000 - fn: 1022.0000 - accuracy: 0.6413 - precision: 0.6869 - recall: 0.5255 - auc: 0.6747\n",
            " For Batch Number 135 the model has a loss of {'loss': 0.6387427449226379, 'tp': 1140.0, 'fp': 523.0, 'tn': 1625.0, 'fn': 1032.0, 'accuracy': 0.6400462985038757, 'precision': 0.685508131980896, 'recall': 0.5248618721961975, 'auc': 0.6735295057296753} \n",
            "135/689 [====>.........................] - ETA: 49s - loss: 0.6387 - tp: 1140.0000 - fp: 523.0000 - tn: 1625.0000 - fn: 1032.0000 - accuracy: 0.6400 - precision: 0.6855 - recall: 0.5249 - auc: 0.6735\n",
            " For Batch Number 136 the model has a loss of {'loss': 0.6385896801948547, 'tp': 1149.0, 'fp': 527.0, 'tn': 1636.0, 'fn': 1040.0, 'accuracy': 0.6399356722831726, 'precision': 0.6855608820915222, 'recall': 0.5248972177505493, 'auc': 0.6737828254699707} \n",
            "136/689 [====>.........................] - ETA: 49s - loss: 0.6386 - tp: 1149.0000 - fp: 527.0000 - tn: 1636.0000 - fn: 1040.0000 - accuracy: 0.6399 - precision: 0.6856 - recall: 0.5249 - auc: 0.6738\n",
            " For Batch Number 137 the model has a loss of {'loss': 0.6384354829788208, 'tp': 1161.0, 'fp': 530.0, 'tn': 1645.0, 'fn': 1048.0, 'accuracy': 0.6400547623634338, 'precision': 0.6865760087966919, 'recall': 0.525577187538147, 'auc': 0.6742970943450928} \n",
            "137/689 [====>.........................] - ETA: 49s - loss: 0.6384 - tp: 1161.0000 - fp: 530.0000 - tn: 1645.0000 - fn: 1048.0000 - accuracy: 0.6401 - precision: 0.6866 - recall: 0.5256 - auc: 0.6743\n",
            " For Batch Number 138 the model has a loss of {'loss': 0.6382801532745361, 'tp': 1172.0, 'fp': 534.0, 'tn': 1654.0, 'fn': 1056.0, 'accuracy': 0.6399456262588501, 'precision': 0.6869871020317078, 'recall': 0.5260323286056519, 'auc': 0.6744218468666077} \n",
            "138/689 [=====>........................] - ETA: 49s - loss: 0.6383 - tp: 1172.0000 - fp: 534.0000 - tn: 1654.0000 - fn: 1056.0000 - accuracy: 0.6399 - precision: 0.6870 - recall: 0.5260 - auc: 0.6744\n",
            " For Batch Number 139 the model has a loss of {'loss': 0.6387185454368591, 'tp': 1181.0, 'fp': 544.0, 'tn': 1662.0, 'fn': 1061.0, 'accuracy': 0.6391636729240417, 'precision': 0.6846376657485962, 'recall': 0.5267618298530579, 'auc': 0.6736893653869629} \n",
            "139/689 [=====>........................] - ETA: 49s - loss: 0.6387 - tp: 1181.0000 - fp: 544.0000 - tn: 1662.0000 - fn: 1061.0000 - accuracy: 0.6392 - precision: 0.6846 - recall: 0.5268 - auc: 0.6737\n",
            " For Batch Number 140 the model has a loss of {'loss': 0.6397019624710083, 'tp': 1190.0, 'fp': 552.0, 'tn': 1670.0, 'fn': 1068.0, 'accuracy': 0.6383928656578064, 'precision': 0.6831228733062744, 'recall': 0.5270150303840637, 'auc': 0.6729366779327393} \n",
            "140/689 [=====>........................] - ETA: 49s - loss: 0.6397 - tp: 1190.0000 - fp: 552.0000 - tn: 1670.0000 - fn: 1068.0000 - accuracy: 0.6384 - precision: 0.6831 - recall: 0.5270 - auc: 0.6729\n",
            " For Batch Number 141 the model has a loss of {'loss': 0.6403471231460571, 'tp': 1199.0, 'fp': 560.0, 'tn': 1679.0, 'fn': 1074.0, 'accuracy': 0.6378546357154846, 'precision': 0.6816372871398926, 'recall': 0.5274966955184937, 'auc': 0.6722505688667297} \n",
            "141/689 [=====>........................] - ETA: 48s - loss: 0.6403 - tp: 1199.0000 - fp: 560.0000 - tn: 1679.0000 - fn: 1074.0000 - accuracy: 0.6379 - precision: 0.6816 - recall: 0.5275 - auc: 0.6723\n",
            " For Batch Number 142 the model has a loss of {'loss': 0.6403791308403015, 'tp': 1208.0, 'fp': 566.0, 'tn': 1691.0, 'fn': 1079.0, 'accuracy': 0.6379841566085815, 'precision': 0.6809470057487488, 'recall': 0.5282028913497925, 'auc': 0.6724687218666077} \n",
            "142/689 [=====>........................] - ETA: 48s - loss: 0.6404 - tp: 1208.0000 - fp: 566.0000 - tn: 1691.0000 - fn: 1079.0000 - accuracy: 0.6380 - precision: 0.6809 - recall: 0.5282 - auc: 0.6725\n",
            " For Batch Number 143 the model has a loss of {'loss': 0.6406273245811462, 'tp': 1216.0, 'fp': 570.0, 'tn': 1701.0, 'fn': 1089.0, 'accuracy': 0.6374562978744507, 'precision': 0.6808510422706604, 'recall': 0.5275487899780273, 'auc': 0.6724295616149902} \n",
            "143/689 [=====>........................] - ETA: 48s - loss: 0.6406 - tp: 1216.0000 - fp: 570.0000 - tn: 1701.0000 - fn: 1089.0000 - accuracy: 0.6375 - precision: 0.6809 - recall: 0.5275 - auc: 0.6724\n",
            " For Batch Number 144 the model has a loss of {'loss': 0.6402785181999207, 'tp': 1223.0, 'fp': 574.0, 'tn': 1714.0, 'fn': 1097.0, 'accuracy': 0.6373698115348816, 'precision': 0.6805787682533264, 'recall': 0.5271551609039307, 'auc': 0.6729509830474854} \n",
            "144/689 [=====>........................] - ETA: 48s - loss: 0.6403 - tp: 1223.0000 - fp: 574.0000 - tn: 1714.0000 - fn: 1097.0000 - accuracy: 0.6374 - precision: 0.6806 - recall: 0.5272 - auc: 0.6730\n",
            " For Batch Number 145 the model has a loss of {'loss': 0.639843761920929, 'tp': 1231.0, 'fp': 577.0, 'tn': 1729.0, 'fn': 1103.0, 'accuracy': 0.6379310488700867, 'precision': 0.6808628439903259, 'recall': 0.5274207592010498, 'auc': 0.6738844513893127} \n",
            "145/689 [=====>........................] - ETA: 48s - loss: 0.6398 - tp: 1231.0000 - fp: 577.0000 - tn: 1729.0000 - fn: 1103.0000 - accuracy: 0.6379 - precision: 0.6809 - recall: 0.5274 - auc: 0.6739\n",
            " For Batch Number 146 the model has a loss of {'loss': 0.6398631930351257, 'tp': 1239.0, 'fp': 582.0, 'tn': 1740.0, 'fn': 1111.0, 'accuracy': 0.637628436088562, 'precision': 0.6803953647613525, 'recall': 0.5272340178489685, 'auc': 0.6737527251243591} \n",
            "146/689 [=====>........................] - ETA: 48s - loss: 0.6399 - tp: 1239.0000 - fp: 582.0000 - tn: 1740.0000 - fn: 1111.0000 - accuracy: 0.6376 - precision: 0.6804 - recall: 0.5272 - auc: 0.6738\n",
            " For Batch Number 147 the model has a loss of {'loss': 0.6418936848640442, 'tp': 1247.0, 'fp': 588.0, 'tn': 1748.0, 'fn': 1121.0, 'accuracy': 0.6366921663284302, 'precision': 0.6795640587806702, 'recall': 0.5266047120094299, 'auc': 0.6718294024467468} \n",
            "147/689 [=====>........................] - ETA: 48s - loss: 0.6419 - tp: 1247.0000 - fp: 588.0000 - tn: 1748.0000 - fn: 1121.0000 - accuracy: 0.6367 - precision: 0.6796 - recall: 0.5266 - auc: 0.6718\n",
            " For Batch Number 148 the model has a loss of {'loss': 0.6430660486221313, 'tp': 1257.0, 'fp': 593.0, 'tn': 1757.0, 'fn': 1129.0, 'accuracy': 0.6364020109176636, 'precision': 0.6794594526290894, 'recall': 0.5268231630325317, 'auc': 0.6708706617355347} \n",
            "148/689 [=====>........................] - ETA: 48s - loss: 0.6431 - tp: 1257.0000 - fp: 593.0000 - tn: 1757.0000 - fn: 1129.0000 - accuracy: 0.6364 - precision: 0.6795 - recall: 0.5268 - auc: 0.6709\n",
            " For Batch Number 149 the model has a loss of {'loss': 0.6435906887054443, 'tp': 1265.0, 'fp': 599.0, 'tn': 1766.0, 'fn': 1138.0, 'accuracy': 0.635696291923523, 'precision': 0.678648054599762, 'recall': 0.526425302028656, 'auc': 0.6703727841377258} \n",
            "149/689 [=====>........................] - ETA: 47s - loss: 0.6436 - tp: 1265.0000 - fp: 599.0000 - tn: 1766.0000 - fn: 1138.0000 - accuracy: 0.6357 - precision: 0.6786 - recall: 0.5264 - auc: 0.6704\n",
            " For Batch Number 150 the model has a loss of {'loss': 0.6433113217353821, 'tp': 1278.0, 'fp': 605.0, 'tn': 1774.0, 'fn': 1143.0, 'accuracy': 0.6358333230018616, 'precision': 0.6787042021751404, 'recall': 0.5278810262680054, 'auc': 0.6705501079559326} \n",
            "150/689 [=====>........................] - ETA: 47s - loss: 0.6433 - tp: 1278.0000 - fp: 605.0000 - tn: 1774.0000 - fn: 1143.0000 - accuracy: 0.6358 - precision: 0.6787 - recall: 0.5279 - auc: 0.6706\n",
            " For Batch Number 151 the model has a loss of {'loss': 0.6433731317520142, 'tp': 1295.0, 'fp': 614.0, 'tn': 1779.0, 'fn': 1144.0, 'accuracy': 0.6361755132675171, 'precision': 0.6783656477928162, 'recall': 0.5309553146362305, 'auc': 0.6708419322967529} \n",
            "151/689 [=====>........................] - ETA: 47s - loss: 0.6434 - tp: 1295.0000 - fp: 614.0000 - tn: 1779.0000 - fn: 1144.0000 - accuracy: 0.6362 - precision: 0.6784 - recall: 0.5310 - auc: 0.6708\n",
            " For Batch Number 152 the model has a loss of {'loss': 0.6431726813316345, 'tp': 1312.0, 'fp': 624.0, 'tn': 1784.0, 'fn': 1144.0, 'accuracy': 0.6365131735801697, 'precision': 0.6776859760284424, 'recall': 0.534201979637146, 'auc': 0.671103835105896} \n",
            "152/689 [=====>........................] - ETA: 47s - loss: 0.6432 - tp: 1312.0000 - fp: 624.0000 - tn: 1784.0000 - fn: 1144.0000 - accuracy: 0.6365 - precision: 0.6777 - recall: 0.5342 - auc: 0.6711\n",
            " For Batch Number 153 the model has a loss of {'loss': 0.6444069743156433, 'tp': 1321.0, 'fp': 641.0, 'tn': 1789.0, 'fn': 1145.0, 'accuracy': 0.6352124214172363, 'precision': 0.6732925772666931, 'recall': 0.5356853008270264, 'auc': 0.6695545315742493} \n",
            "153/689 [=====>........................] - ETA: 47s - loss: 0.6444 - tp: 1321.0000 - fp: 641.0000 - tn: 1789.0000 - fn: 1145.0000 - accuracy: 0.6352 - precision: 0.6733 - recall: 0.5357 - auc: 0.6696\n",
            " For Batch Number 154 the model has a loss of {'loss': 0.64467853307724, 'tp': 1334.0, 'fp': 648.0, 'tn': 1794.0, 'fn': 1152.0, 'accuracy': 0.6347402334213257, 'precision': 0.673057496547699, 'recall': 0.5366050004959106, 'auc': 0.6693825721740723} \n",
            "154/689 [=====>........................] - ETA: 47s - loss: 0.6447 - tp: 1334.0000 - fp: 648.0000 - tn: 1794.0000 - fn: 1152.0000 - accuracy: 0.6347 - precision: 0.6731 - recall: 0.5366 - auc: 0.6694\n",
            " For Batch Number 155 the model has a loss of {'loss': 0.6441676616668701, 'tp': 1346.0, 'fp': 653.0, 'tn': 1806.0, 'fn': 1155.0, 'accuracy': 0.6354838609695435, 'precision': 0.6733366847038269, 'recall': 0.5381847023963928, 'auc': 0.6702225804328918} \n",
            "155/689 [=====>........................] - ETA: 47s - loss: 0.6442 - tp: 1346.0000 - fp: 653.0000 - tn: 1806.0000 - fn: 1155.0000 - accuracy: 0.6355 - precision: 0.6733 - recall: 0.5382 - auc: 0.6702\n",
            " For Batch Number 156 the model has a loss of {'loss': 0.6447339653968811, 'tp': 1354.0, 'fp': 658.0, 'tn': 1817.0, 'fn': 1163.0, 'accuracy': 0.6352163553237915, 'precision': 0.6729622483253479, 'recall': 0.5379419922828674, 'auc': 0.6692898869514465} \n",
            "156/689 [=====>........................] - ETA: 47s - loss: 0.6447 - tp: 1354.0000 - fp: 658.0000 - tn: 1817.0000 - fn: 1163.0000 - accuracy: 0.6352 - precision: 0.6730 - recall: 0.5379 - auc: 0.6693\n",
            " For Batch Number 157 the model has a loss of {'loss': 0.6445406675338745, 'tp': 1361.0, 'fp': 661.0, 'tn': 1832.0, 'fn': 1170.0, 'accuracy': 0.6355493664741516, 'precision': 0.6730959415435791, 'recall': 0.5377321243286133, 'auc': 0.669564962387085} \n",
            "157/689 [=====>........................] - ETA: 47s - loss: 0.6445 - tp: 1361.0000 - fp: 661.0000 - tn: 1832.0000 - fn: 1170.0000 - accuracy: 0.6355 - precision: 0.6731 - recall: 0.5377 - auc: 0.6696\n",
            " For Batch Number 158 the model has a loss of {'loss': 0.64461749792099, 'tp': 1366.0, 'fp': 663.0, 'tn': 1847.0, 'fn': 1180.0, 'accuracy': 0.6354826092720032, 'precision': 0.6732380390167236, 'recall': 0.5365278720855713, 'auc': 0.6696308255195618} \n",
            "158/689 [=====>........................] - ETA: 46s - loss: 0.6446 - tp: 1366.0000 - fp: 663.0000 - tn: 1847.0000 - fn: 1180.0000 - accuracy: 0.6355 - precision: 0.6732 - recall: 0.5365 - auc: 0.6696\n",
            " For Batch Number 159 the model has a loss of {'loss': 0.6454387903213501, 'tp': 1374.0, 'fp': 666.0, 'tn': 1856.0, 'fn': 1192.0, 'accuracy': 0.6348270177841187, 'precision': 0.6735293865203857, 'recall': 0.5354637503623962, 'auc': 0.6686528325080872} \n",
            "159/689 [=====>........................] - ETA: 46s - loss: 0.6454 - tp: 1374.0000 - fp: 666.0000 - tn: 1856.0000 - fn: 1192.0000 - accuracy: 0.6348 - precision: 0.6735 - recall: 0.5355 - auc: 0.6687\n",
            " For Batch Number 160 the model has a loss of {'loss': 0.6451709866523743, 'tp': 1381.0, 'fp': 667.0, 'tn': 1872.0, 'fn': 1200.0, 'accuracy': 0.6353515386581421, 'precision': 0.67431640625, 'recall': 0.5350639224052429, 'auc': 0.6690036654472351} \n",
            "160/689 [=====>........................] - ETA: 46s - loss: 0.6452 - tp: 1381.0000 - fp: 667.0000 - tn: 1872.0000 - fn: 1200.0000 - accuracy: 0.6354 - precision: 0.6743 - recall: 0.5351 - auc: 0.6690\n",
            " For Batch Number 161 the model has a loss of {'loss': 0.6446453332901001, 'tp': 1389.0, 'fp': 673.0, 'tn': 1885.0, 'fn': 1205.0, 'accuracy': 0.6354813575744629, 'precision': 0.6736178398132324, 'recall': 0.5354664325714111, 'auc': 0.6695887446403503} \n",
            "161/689 [======>.......................] - ETA: 46s - loss: 0.6446 - tp: 1389.0000 - fp: 673.0000 - tn: 1885.0000 - fn: 1205.0000 - accuracy: 0.6355 - precision: 0.6736 - recall: 0.5355 - auc: 0.6696\n",
            " For Batch Number 162 the model has a loss of {'loss': 0.6448633670806885, 'tp': 1394.0, 'fp': 677.0, 'tn': 1899.0, 'fn': 1214.0, 'accuracy': 0.6352237462997437, 'precision': 0.6731047630310059, 'recall': 0.5345091819763184, 'auc': 0.6691139936447144} \n",
            "162/689 [======>.......................] - ETA: 46s - loss: 0.6449 - tp: 1394.0000 - fp: 677.0000 - tn: 1899.0000 - fn: 1214.0000 - accuracy: 0.6352 - precision: 0.6731 - recall: 0.5345 - auc: 0.6691\n",
            " For Batch Number 163 the model has a loss of {'loss': 0.6447456479072571, 'tp': 1407.0, 'fp': 679.0, 'tn': 1907.0, 'fn': 1223.0, 'accuracy': 0.6353527903556824, 'precision': 0.6744966506958008, 'recall': 0.5349810123443604, 'auc': 0.6694312691688538} \n",
            "163/689 [======>.......................] - ETA: 46s - loss: 0.6447 - tp: 1407.0000 - fp: 679.0000 - tn: 1907.0000 - fn: 1223.0000 - accuracy: 0.6354 - precision: 0.6745 - recall: 0.5350 - auc: 0.6694\n",
            " For Batch Number 164 the model has a loss of {'loss': 0.6447327136993408, 'tp': 1418.0, 'fp': 681.0, 'tn': 1915.0, 'fn': 1234.0, 'accuracy': 0.6350991129875183, 'precision': 0.6755598187446594, 'recall': 0.534690797328949, 'auc': 0.6691531538963318} \n",
            "164/689 [======>.......................] - ETA: 46s - loss: 0.6447 - tp: 1418.0000 - fp: 681.0000 - tn: 1915.0000 - fn: 1234.0000 - accuracy: 0.6351 - precision: 0.6756 - recall: 0.5347 - auc: 0.6692\n",
            " For Batch Number 165 the model has a loss of {'loss': 0.6458910703659058, 'tp': 1423.0, 'fp': 693.0, 'tn': 1926.0, 'fn': 1238.0, 'accuracy': 0.6342803239822388, 'precision': 0.6724952459335327, 'recall': 0.534761369228363, 'auc': 0.6677762269973755} \n",
            "165/689 [======>.......................] - ETA: 46s - loss: 0.6459 - tp: 1423.0000 - fp: 693.0000 - tn: 1926.0000 - fn: 1238.0000 - accuracy: 0.6343 - precision: 0.6725 - recall: 0.5348 - auc: 0.6678\n",
            " For Batch Number 166 the model has a loss of {'loss': 0.6460325121879578, 'tp': 1433.0, 'fp': 701.0, 'tn': 1935.0, 'fn': 1243.0, 'accuracy': 0.634036123752594, 'precision': 0.6715089082717896, 'recall': 0.5355007648468018, 'auc': 0.6674538254737854} \n",
            "166/689 [======>.......................] - ETA: 45s - loss: 0.6460 - tp: 1433.0000 - fp: 701.0000 - tn: 1935.0000 - fn: 1243.0000 - accuracy: 0.6340 - precision: 0.6715 - recall: 0.5355 - auc: 0.6675\n",
            " For Batch Number 167 the model has a loss of {'loss': 0.6459479928016663, 'tp': 1443.0, 'fp': 711.0, 'tn': 1943.0, 'fn': 1247.0, 'accuracy': 0.633607804775238, 'precision': 0.6699164509773254, 'recall': 0.5364312529563904, 'auc': 0.6672725081443787} \n",
            "167/689 [======>.......................] - ETA: 45s - loss: 0.6459 - tp: 1443.0000 - fp: 711.0000 - tn: 1943.0000 - fn: 1247.0000 - accuracy: 0.6336 - precision: 0.6699 - recall: 0.5364 - auc: 0.6673\n",
            " For Batch Number 168 the model has a loss of {'loss': 0.6463754773139954, 'tp': 1451.0, 'fp': 722.0, 'tn': 1949.0, 'fn': 1254.0, 'accuracy': 0.632440447807312, 'precision': 0.6677404642105103, 'recall': 0.5364140272140503, 'auc': 0.6666039228439331} \n",
            "168/689 [======>.......................] - ETA: 45s - loss: 0.6464 - tp: 1451.0000 - fp: 722.0000 - tn: 1949.0000 - fn: 1254.0000 - accuracy: 0.6324 - precision: 0.6677 - recall: 0.5364 - auc: 0.6666\n",
            " For Batch Number 169 the model has a loss of {'loss': 0.6466182470321655, 'tp': 1460.0, 'fp': 730.0, 'tn': 1956.0, 'fn': 1262.0, 'accuracy': 0.63165682554245, 'precision': 0.6666666865348816, 'recall': 0.5363703370094299, 'auc': 0.6663070321083069} \n",
            "169/689 [======>.......................] - ETA: 45s - loss: 0.6466 - tp: 1460.0000 - fp: 730.0000 - tn: 1956.0000 - fn: 1262.0000 - accuracy: 0.6317 - precision: 0.6667 - recall: 0.5364 - auc: 0.6663\n",
            " For Batch Number 170 the model has a loss of {'loss': 0.6467816233634949, 'tp': 1472.0, 'fp': 735.0, 'tn': 1964.0, 'fn': 1269.0, 'accuracy': 0.6316176652908325, 'precision': 0.6669687628746033, 'recall': 0.5370302796363831, 'auc': 0.666064441204071} \n",
            "170/689 [======>.......................] - ETA: 45s - loss: 0.6468 - tp: 1472.0000 - fp: 735.0000 - tn: 1964.0000 - fn: 1269.0000 - accuracy: 0.6316 - precision: 0.6670 - recall: 0.5370 - auc: 0.6661\n",
            " For Batch Number 171 the model has a loss of {'loss': 0.6466729044914246, 'tp': 1479.0, 'fp': 740.0, 'tn': 1976.0, 'fn': 1277.0, 'accuracy': 0.6313961744308472, 'precision': 0.6665164232254028, 'recall': 0.5366473197937012, 'auc': 0.6662341356277466} \n",
            "171/689 [======>.......................] - ETA: 45s - loss: 0.6467 - tp: 1479.0000 - fp: 740.0000 - tn: 1976.0000 - fn: 1277.0000 - accuracy: 0.6314 - precision: 0.6665 - recall: 0.5366 - auc: 0.6662\n",
            " For Batch Number 172 the model has a loss of {'loss': 0.6469135880470276, 'tp': 1486.0, 'fp': 743.0, 'tn': 1985.0, 'fn': 1290.0, 'accuracy': 0.6306322813034058, 'precision': 0.6666666865348816, 'recall': 0.5353025794029236, 'auc': 0.6660873889923096} \n",
            "172/689 [======>.......................] - ETA: 45s - loss: 0.6469 - tp: 1486.0000 - fp: 743.0000 - tn: 1985.0000 - fn: 1290.0000 - accuracy: 0.6306 - precision: 0.6667 - recall: 0.5353 - auc: 0.6661\n",
            " For Batch Number 173 the model has a loss of {'loss': 0.6466718316078186, 'tp': 1493.0, 'fp': 749.0, 'tn': 1999.0, 'fn': 1295.0, 'accuracy': 0.6307803392410278, 'precision': 0.6659232974052429, 'recall': 0.5355093479156494, 'auc': 0.666295051574707} \n",
            "173/689 [======>.......................] - ETA: 44s - loss: 0.6467 - tp: 1493.0000 - fp: 749.0000 - tn: 1999.0000 - fn: 1295.0000 - accuracy: 0.6308 - precision: 0.6659 - recall: 0.5355 - auc: 0.6663\n",
            " For Batch Number 174 the model has a loss of {'loss': 0.6464200615882874, 'tp': 1501.0, 'fp': 753.0, 'tn': 2013.0, 'fn': 1301.0, 'accuracy': 0.6311063170433044, 'precision': 0.6659272313117981, 'recall': 0.5356888175010681, 'auc': 0.6665409207344055} \n",
            "174/689 [======>.......................] - ETA: 44s - loss: 0.6464 - tp: 1501.0000 - fp: 753.0000 - tn: 2013.0000 - fn: 1301.0000 - accuracy: 0.6311 - precision: 0.6659 - recall: 0.5357 - auc: 0.6665\n",
            " For Batch Number 175 the model has a loss of {'loss': 0.6463979482650757, 'tp': 1509.0, 'fp': 757.0, 'tn': 2024.0, 'fn': 1310.0, 'accuracy': 0.6308928728103638, 'precision': 0.6659311652183533, 'recall': 0.5352962017059326, 'auc': 0.6664234399795532} \n",
            "\n",
            " For Batch Number 176 the model has a loss of {'loss': 0.6458384990692139, 'tp': 1516.0, 'fp': 759.0, 'tn': 2042.0, 'fn': 1315.0, 'accuracy': 0.6317471861839294, 'precision': 0.666373610496521, 'recall': 0.5354998111724854, 'auc': 0.6673644185066223} \n",
            "176/689 [======>.......................] - ETA: 44s - loss: 0.6458 - tp: 1516.0000 - fp: 759.0000 - tn: 2042.0000 - fn: 1315.0000 - accuracy: 0.6317 - precision: 0.6664 - recall: 0.5355 - auc: 0.6674\n",
            " For Batch Number 177 the model has a loss of {'loss': 0.6462867259979248, 'tp': 1520.0, 'fp': 765.0, 'tn': 2054.0, 'fn': 1325.0, 'accuracy': 0.6310028433799744, 'precision': 0.6652078628540039, 'recall': 0.5342706441879272, 'auc': 0.6666929125785828} \n",
            "177/689 [======>.......................] - ETA: 44s - loss: 0.6463 - tp: 1520.0000 - fp: 765.0000 - tn: 2054.0000 - fn: 1325.0000 - accuracy: 0.6310 - precision: 0.6652 - recall: 0.5343 - auc: 0.6667\n",
            " For Batch Number 178 the model has a loss of {'loss': 0.6461741924285889, 'tp': 1526.0, 'fp': 767.0, 'tn': 2069.0, 'fn': 1334.0, 'accuracy': 0.631144642829895, 'precision': 0.6655036807060242, 'recall': 0.533566415309906, 'auc': 0.6669069528579712} \n",
            "178/689 [======>.......................] - ETA: 44s - loss: 0.6462 - tp: 1526.0000 - fp: 767.0000 - tn: 2069.0000 - fn: 1334.0000 - accuracy: 0.6311 - precision: 0.6655 - recall: 0.5336 - auc: 0.6669\n",
            " For Batch Number 179 the model has a loss of {'loss': 0.6467265486717224, 'tp': 1532.0, 'fp': 770.0, 'tn': 2080.0, 'fn': 1346.0, 'accuracy': 0.630586564540863, 'precision': 0.6655082702636719, 'recall': 0.532314121723175, 'auc': 0.6661572456359863} \n",
            "179/689 [======>.......................] - ETA: 43s - loss: 0.6467 - tp: 1532.0000 - fp: 770.0000 - tn: 2080.0000 - fn: 1346.0000 - accuracy: 0.6306 - precision: 0.6655 - recall: 0.5323 - auc: 0.6662\n",
            " For Batch Number 180 the model has a loss of {'loss': 0.6468861103057861, 'tp': 1540.0, 'fp': 772.0, 'tn': 2092.0, 'fn': 1356.0, 'accuracy': 0.6305555701255798, 'precision': 0.6660899519920349, 'recall': 0.5317679643630981, 'auc': 0.6657032370567322} \n",
            "180/689 [======>.......................] - ETA: 43s - loss: 0.6469 - tp: 1540.0000 - fp: 772.0000 - tn: 2092.0000 - fn: 1356.0000 - accuracy: 0.6306 - precision: 0.6661 - recall: 0.5318 - auc: 0.6657\n",
            " For Batch Number 181 the model has a loss of {'loss': 0.6465678811073303, 'tp': 1547.0, 'fp': 775.0, 'tn': 2107.0, 'fn': 1363.0, 'accuracy': 0.6308701634407043, 'precision': 0.6662359833717346, 'recall': 0.531615138053894, 'auc': 0.6660243272781372} \n",
            "181/689 [======>.......................] - ETA: 43s - loss: 0.6466 - tp: 1547.0000 - fp: 775.0000 - tn: 2107.0000 - fn: 1363.0000 - accuracy: 0.6309 - precision: 0.6662 - recall: 0.5316 - auc: 0.6660\n",
            " For Batch Number 182 the model has a loss of {'loss': 0.646915078163147, 'tp': 1554.0, 'fp': 779.0, 'tn': 2118.0, 'fn': 1373.0, 'accuracy': 0.6304945349693298, 'precision': 0.6660951375961304, 'recall': 0.5309190154075623, 'auc': 0.6653608083724976} \n",
            "182/689 [======>.......................] - ETA: 43s - loss: 0.6469 - tp: 1554.0000 - fp: 779.0000 - tn: 2118.0000 - fn: 1373.0000 - accuracy: 0.6305 - precision: 0.6661 - recall: 0.5309 - auc: 0.6654\n",
            " For Batch Number 183 the model has a loss of {'loss': 0.6473021507263184, 'tp': 1560.0, 'fp': 782.0, 'tn': 2131.0, 'fn': 1383.0, 'accuracy': 0.6302937269210815, 'precision': 0.6660973429679871, 'recall': 0.5300713777542114, 'auc': 0.6647281646728516} \n",
            "183/689 [======>.......................] - ETA: 43s - loss: 0.6473 - tp: 1560.0000 - fp: 782.0000 - tn: 2131.0000 - fn: 1383.0000 - accuracy: 0.6303 - precision: 0.6661 - recall: 0.5301 - auc: 0.6647\n",
            " For Batch Number 184 the model has a loss of {'loss': 0.6473339200019836, 'tp': 1568.0, 'fp': 787.0, 'tn': 2144.0, 'fn': 1389.0, 'accuracy': 0.6304348111152649, 'precision': 0.6658174395561218, 'recall': 0.5302671790122986, 'auc': 0.6648313999176025} \n",
            "184/689 [=======>......................] - ETA: 43s - loss: 0.6473 - tp: 1568.0000 - fp: 787.0000 - tn: 2144.0000 - fn: 1389.0000 - accuracy: 0.6304 - precision: 0.6658 - recall: 0.5303 - auc: 0.6648\n",
            " For Batch Number 185 the model has a loss of {'loss': 0.6466111540794373, 'tp': 1578.0, 'fp': 787.0, 'tn': 2161.0, 'fn': 1394.0, 'accuracy': 0.6315878629684448, 'precision': 0.6672304272651672, 'recall': 0.5309556126594543, 'auc': 0.6656013131141663} \n",
            "185/689 [=======>......................] - ETA: 42s - loss: 0.6466 - tp: 1578.0000 - fp: 787.0000 - tn: 2161.0000 - fn: 1394.0000 - accuracy: 0.6316 - precision: 0.6672 - recall: 0.5310 - auc: 0.6656\n",
            " For Batch Number 186 the model has a loss of {'loss': 0.6467117667198181, 'tp': 1587.0, 'fp': 792.0, 'tn': 2174.0, 'fn': 1399.0, 'accuracy': 0.6318884491920471, 'precision': 0.6670870184898376, 'recall': 0.5314802527427673, 'auc': 0.6656352281570435} \n",
            "186/689 [=======>......................] - ETA: 42s - loss: 0.6467 - tp: 1587.0000 - fp: 792.0000 - tn: 2174.0000 - fn: 1399.0000 - accuracy: 0.6319 - precision: 0.6671 - recall: 0.5315 - auc: 0.6656\n",
            " For Batch Number 187 the model has a loss of {'loss': 0.6464847326278687, 'tp': 1599.0, 'fp': 793.0, 'tn': 2184.0, 'fn': 1408.0, 'accuracy': 0.6321858167648315, 'precision': 0.66847825050354, 'recall': 0.5317592024803162, 'auc': 0.6658710241317749} \n",
            "187/689 [=======>......................] - ETA: 42s - loss: 0.6465 - tp: 1599.0000 - fp: 793.0000 - tn: 2184.0000 - fn: 1408.0000 - accuracy: 0.6322 - precision: 0.6685 - recall: 0.5318 - auc: 0.6659\n",
            " For Batch Number 188 the model has a loss of {'loss': 0.6463667154312134, 'tp': 1608.0, 'fp': 796.0, 'tn': 2194.0, 'fn': 1418.0, 'accuracy': 0.631981372833252, 'precision': 0.6688851714134216, 'recall': 0.5313946008682251, 'auc': 0.6659190058708191} \n",
            "188/689 [=======>......................] - ETA: 42s - loss: 0.6464 - tp: 1608.0000 - fp: 796.0000 - tn: 2194.0000 - fn: 1418.0000 - accuracy: 0.6320 - precision: 0.6689 - recall: 0.5314 - auc: 0.6659\n",
            " For Batch Number 189 the model has a loss of {'loss': 0.6463304758071899, 'tp': 1616.0, 'fp': 800.0, 'tn': 2204.0, 'fn': 1428.0, 'accuracy': 0.6316137313842773, 'precision': 0.6688741445541382, 'recall': 0.5308803915977478, 'auc': 0.6656407713890076} \n",
            "189/689 [=======>......................] - ETA: 42s - loss: 0.6463 - tp: 1616.0000 - fp: 800.0000 - tn: 2204.0000 - fn: 1428.0000 - accuracy: 0.6316 - precision: 0.6689 - recall: 0.5309 - auc: 0.6656\n",
            " For Batch Number 190 the model has a loss of {'loss': 0.6460697650909424, 'tp': 1626.0, 'fp': 802.0, 'tn': 2216.0, 'fn': 1436.0, 'accuracy': 0.6319078803062439, 'precision': 0.6696869730949402, 'recall': 0.5310254693031311, 'auc': 0.666336178779602} \n",
            "\n",
            " For Batch Number 191 the model has a loss of {'loss': 0.6458069086074829, 'tp': 1636.0, 'fp': 806.0, 'tn': 2227.0, 'fn': 1443.0, 'accuracy': 0.6320353150367737, 'precision': 0.6699426770210266, 'recall': 0.5313413739204407, 'auc': 0.6666668653488159} \n",
            "191/689 [=======>......................] - ETA: 42s - loss: 0.6458 - tp: 1636.0000 - fp: 806.0000 - tn: 2227.0000 - fn: 1443.0000 - accuracy: 0.6320 - precision: 0.6699 - recall: 0.5313 - auc: 0.6667\n",
            " For Batch Number 192 the model has a loss of {'loss': 0.645168125629425, 'tp': 1648.0, 'fp': 808.0, 'tn': 2239.0, 'fn': 1449.0, 'accuracy': 0.6326497197151184, 'precision': 0.6710097789764404, 'recall': 0.532127857208252, 'auc': 0.6673586964607239} \n",
            "\n",
            " For Batch Number 193 the model has a loss of {'loss': 0.6449248194694519, 'tp': 1658.0, 'fp': 811.0, 'tn': 2251.0, 'fn': 1456.0, 'accuracy': 0.6329339146614075, 'precision': 0.6715269088745117, 'recall': 0.5324341654777527, 'auc': 0.6675245761871338} \n",
            "193/689 [=======>......................] - ETA: 41s - loss: 0.6449 - tp: 1658.0000 - fp: 811.0000 - tn: 2251.0000 - fn: 1456.0000 - accuracy: 0.6329 - precision: 0.6715 - recall: 0.5324 - auc: 0.6675\n",
            " For Batch Number 194 the model has a loss of {'loss': 0.6458171606063843, 'tp': 1665.0, 'fp': 818.0, 'tn': 2262.0, 'fn': 1463.0, 'accuracy': 0.6325708627700806, 'precision': 0.670559823513031, 'recall': 0.5322890281677246, 'auc': 0.666755735874176} \n",
            "194/689 [=======>......................] - ETA: 41s - loss: 0.6458 - tp: 1665.0000 - fp: 818.0000 - tn: 2262.0000 - fn: 1463.0000 - accuracy: 0.6326 - precision: 0.6706 - recall: 0.5323 - auc: 0.6668\n",
            " For Batch Number 195 the model has a loss of {'loss': 0.6456948518753052, 'tp': 1676.0, 'fp': 823.0, 'tn': 2271.0, 'fn': 1470.0, 'accuracy': 0.6325320601463318, 'precision': 0.6706682443618774, 'recall': 0.5327399969100952, 'auc': 0.6669003963470459} \n",
            "\n",
            " For Batch Number 196 the model has a loss of {'loss': 0.6454872488975525, 'tp': 1685.0, 'fp': 827.0, 'tn': 2283.0, 'fn': 1477.0, 'accuracy': 0.6326530575752258, 'precision': 0.6707802414894104, 'recall': 0.5328905582427979, 'auc': 0.6671799421310425} \n",
            "196/689 [=======>......................] - ETA: 41s - loss: 0.6455 - tp: 1685.0000 - fp: 827.0000 - tn: 2283.0000 - fn: 1477.0000 - accuracy: 0.6327 - precision: 0.6708 - recall: 0.5329 - auc: 0.6672\n",
            " For Batch Number 197 the model has a loss of {'loss': 0.6454623937606812, 'tp': 1693.0, 'fp': 828.0, 'tn': 2293.0, 'fn': 1490.0, 'accuracy': 0.6322969794273376, 'precision': 0.6715589165687561, 'recall': 0.5318881273269653, 'auc': 0.6671740412712097} \n",
            "197/689 [=======>......................] - ETA: 41s - loss: 0.6455 - tp: 1693.0000 - fp: 828.0000 - tn: 2293.0000 - fn: 1490.0000 - accuracy: 0.6323 - precision: 0.6716 - recall: 0.5319 - auc: 0.6672\n",
            " For Batch Number 198 the model has a loss of {'loss': 0.6461684703826904, 'tp': 1698.0, 'fp': 835.0, 'tn': 2304.0, 'fn': 1499.0, 'accuracy': 0.6316288113594055, 'precision': 0.6703513860702515, 'recall': 0.5311229228973389, 'auc': 0.6664103269577026} \n",
            "198/689 [=======>......................] - ETA: 41s - loss: 0.6462 - tp: 1698.0000 - fp: 835.0000 - tn: 2304.0000 - fn: 1499.0000 - accuracy: 0.6316 - precision: 0.6704 - recall: 0.5311 - auc: 0.6664\n",
            " For Batch Number 199 the model has a loss of {'loss': 0.6462714672088623, 'tp': 1708.0, 'fp': 839.0, 'tn': 2313.0, 'fn': 1508.0, 'accuracy': 0.6314384341239929, 'precision': 0.6705928444862366, 'recall': 0.5310945510864258, 'auc': 0.6663981080055237} \n",
            "199/689 [=======>......................] - ETA: 41s - loss: 0.6463 - tp: 1708.0000 - fp: 839.0000 - tn: 2313.0000 - fn: 1508.0000 - accuracy: 0.6314 - precision: 0.6706 - recall: 0.5311 - auc: 0.6664\n",
            " For Batch Number 200 the model has a loss of {'loss': 0.6465540528297424, 'tp': 1715.0, 'fp': 844.0, 'tn': 2327.0, 'fn': 1514.0, 'accuracy': 0.6315624713897705, 'precision': 0.6701836585998535, 'recall': 0.5311241745948792, 'auc': 0.6662013530731201} \n",
            "200/689 [=======>......................] - ETA: 40s - loss: 0.6466 - tp: 1715.0000 - fp: 844.0000 - tn: 2327.0000 - fn: 1514.0000 - accuracy: 0.6316 - precision: 0.6702 - recall: 0.5311 - auc: 0.6662\n",
            " For Batch Number 201 the model has a loss of {'loss': 0.6457961201667786, 'tp': 1725.0, 'fp': 846.0, 'tn': 2344.0, 'fn': 1517.0, 'accuracy': 0.6326181888580322, 'precision': 0.6709451675415039, 'recall': 0.5320789813995361, 'auc': 0.6672862768173218} \n",
            "201/689 [=======>......................] - ETA: 40s - loss: 0.6458 - tp: 1725.0000 - fp: 846.0000 - tn: 2344.0000 - fn: 1517.0000 - accuracy: 0.6326 - precision: 0.6709 - recall: 0.5321 - auc: 0.6673\n",
            " For Batch Number 202 the model has a loss of {'loss': 0.6461323499679565, 'tp': 1732.0, 'fp': 850.0, 'tn': 2353.0, 'fn': 1529.0, 'accuracy': 0.6319616436958313, 'precision': 0.6707978248596191, 'recall': 0.5311254262924194, 'auc': 0.6667052507400513} \n",
            "202/689 [=======>......................] - ETA: 40s - loss: 0.6461 - tp: 1732.0000 - fp: 850.0000 - tn: 2353.0000 - fn: 1529.0000 - accuracy: 0.6320 - precision: 0.6708 - recall: 0.5311 - auc: 0.6667\n",
            " For Batch Number 203 the model has a loss of {'loss': 0.6460047960281372, 'tp': 1740.0, 'fp': 853.0, 'tn': 2365.0, 'fn': 1538.0, 'accuracy': 0.6319273114204407, 'precision': 0.6710374355316162, 'recall': 0.5308114886283875, 'auc': 0.6668274998664856} \n",
            "203/689 [=======>......................] - ETA: 40s - loss: 0.6460 - tp: 1740.0000 - fp: 853.0000 - tn: 2365.0000 - fn: 1538.0000 - accuracy: 0.6319 - precision: 0.6710 - recall: 0.5308 - auc: 0.6668\n",
            " For Batch Number 204 the model has a loss of {'loss': 0.64640212059021, 'tp': 1748.0, 'fp': 856.0, 'tn': 2374.0, 'fn': 1550.0, 'accuracy': 0.6314338445663452, 'precision': 0.6712749600410461, 'recall': 0.5300182104110718, 'auc': 0.6663347482681274} \n",
            "204/689 [=======>......................] - ETA: 40s - loss: 0.6464 - tp: 1748.0000 - fp: 856.0000 - tn: 2374.0000 - fn: 1550.0000 - accuracy: 0.6314 - precision: 0.6713 - recall: 0.5300 - auc: 0.6663\n",
            " For Batch Number 205 the model has a loss of {'loss': 0.6462815999984741, 'tp': 1759.0, 'fp': 860.0, 'tn': 2384.0, 'fn': 1557.0, 'accuracy': 0.631554901599884, 'precision': 0.6716303825378418, 'recall': 0.530458390712738, 'auc': 0.6665342450141907} \n",
            "205/689 [=======>......................] - ETA: 40s - loss: 0.6463 - tp: 1759.0000 - fp: 860.0000 - tn: 2384.0000 - fn: 1557.0000 - accuracy: 0.6316 - precision: 0.6716 - recall: 0.5305 - auc: 0.6665\n",
            " For Batch Number 206 the model has a loss of {'loss': 0.6463768482208252, 'tp': 1767.0, 'fp': 865.0, 'tn': 2398.0, 'fn': 1562.0, 'accuracy': 0.6318264603614807, 'precision': 0.6713525652885437, 'recall': 0.5307900309562683, 'auc': 0.66639244556427} \n",
            "206/689 [=======>......................] - ETA: 40s - loss: 0.6464 - tp: 1767.0000 - fp: 865.0000 - tn: 2398.0000 - fn: 1562.0000 - accuracy: 0.6318 - precision: 0.6714 - recall: 0.5308 - auc: 0.6664\n",
            " For Batch Number 207 the model has a loss of {'loss': 0.6466012597084045, 'tp': 1774.0, 'fp': 872.0, 'tn': 2411.0, 'fn': 1567.0, 'accuracy': 0.6317934989929199, 'precision': 0.67044597864151, 'recall': 0.5309787392616272, 'auc': 0.6659116744995117} \n",
            "207/689 [========>.....................] - ETA: 39s - loss: 0.6466 - tp: 1774.0000 - fp: 872.0000 - tn: 2411.0000 - fn: 1567.0000 - accuracy: 0.6318 - precision: 0.6704 - recall: 0.5310 - auc: 0.6659\n",
            " For Batch Number 208 the model has a loss of {'loss': 0.6467984318733215, 'tp': 1781.0, 'fp': 878.0, 'tn': 2424.0, 'fn': 1573.0, 'accuracy': 0.631760835647583, 'precision': 0.6698006987571716, 'recall': 0.5310077667236328, 'auc': 0.6655065417289734} \n",
            "208/689 [========>.....................] - ETA: 39s - loss: 0.6468 - tp: 1781.0000 - fp: 878.0000 - tn: 2424.0000 - fn: 1573.0000 - accuracy: 0.6318 - precision: 0.6698 - recall: 0.5310 - auc: 0.6655\n",
            " For Batch Number 209 the model has a loss of {'loss': 0.6469324231147766, 'tp': 1788.0, 'fp': 882.0, 'tn': 2437.0, 'fn': 1581.0, 'accuracy': 0.63172847032547, 'precision': 0.6696628928184509, 'recall': 0.5307213068008423, 'auc': 0.6652817726135254} \n",
            "\n",
            " For Batch Number 210 the model has a loss of {'loss': 0.6466953158378601, 'tp': 1795.0, 'fp': 885.0, 'tn': 2452.0, 'fn': 1588.0, 'accuracy': 0.6319940686225891, 'precision': 0.6697761416435242, 'recall': 0.5305941700935364, 'auc': 0.6654598712921143} \n",
            "210/689 [========>.....................] - ETA: 39s - loss: 0.6467 - tp: 1795.0000 - fp: 885.0000 - tn: 2452.0000 - fn: 1588.0000 - accuracy: 0.6320 - precision: 0.6698 - recall: 0.5306 - auc: 0.6655\n",
            " For Batch Number 211 the model has a loss of {'loss': 0.6467043161392212, 'tp': 1802.0, 'fp': 888.0, 'tn': 2465.0, 'fn': 1597.0, 'accuracy': 0.631960928440094, 'precision': 0.6698884963989258, 'recall': 0.5301559567451477, 'auc': 0.6654754877090454} \n",
            "211/689 [========>.....................] - ETA: 39s - loss: 0.6467 - tp: 1802.0000 - fp: 888.0000 - tn: 2465.0000 - fn: 1597.0000 - accuracy: 0.6320 - precision: 0.6699 - recall: 0.5302 - auc: 0.6655\n",
            " For Batch Number 212 the model has a loss of {'loss': 0.646339476108551, 'tp': 1809.0, 'fp': 889.0, 'tn': 2482.0, 'fn': 1604.0, 'accuracy': 0.6325176954269409, 'precision': 0.6704966425895691, 'recall': 0.530032217502594, 'auc': 0.6661478281021118} \n",
            "\n",
            " For Batch Number 213 the model has a loss of {'loss': 0.6460939645767212, 'tp': 1813.0, 'fp': 891.0, 'tn': 2501.0, 'fn': 1611.0, 'accuracy': 0.6329225301742554, 'precision': 0.670488178730011, 'recall': 0.5294976830482483, 'auc': 0.6665149331092834} \n",
            "213/689 [========>.....................] - ETA: 39s - loss: 0.6461 - tp: 1813.0000 - fp: 891.0000 - tn: 2501.0000 - fn: 1611.0000 - accuracy: 0.6329 - precision: 0.6705 - recall: 0.5295 - auc: 0.6665\n",
            " For Batch Number 214 the model has a loss of {'loss': 0.6465597152709961, 'tp': 1816.0, 'fp': 894.0, 'tn': 2517.0, 'fn': 1621.0, 'accuracy': 0.6327394843101501, 'precision': 0.6701107025146484, 'recall': 0.5283677577972412, 'auc': 0.665608286857605} \n",
            "214/689 [========>.....................] - ETA: 39s - loss: 0.6466 - tp: 1816.0000 - fp: 894.0000 - tn: 2517.0000 - fn: 1621.0000 - accuracy: 0.6327 - precision: 0.6701 - recall: 0.5284 - auc: 0.6656\n",
            " For Batch Number 215 the model has a loss of {'loss': 0.6465867161750793, 'tp': 1822.0, 'fp': 897.0, 'tn': 2532.0, 'fn': 1629.0, 'accuracy': 0.632848858833313, 'precision': 0.6700993180274963, 'recall': 0.5279629230499268, 'auc': 0.6657067537307739} \n",
            "215/689 [========>.....................] - ETA: 38s - loss: 0.6466 - tp: 1822.0000 - fp: 897.0000 - tn: 2532.0000 - fn: 1629.0000 - accuracy: 0.6328 - precision: 0.6701 - recall: 0.5280 - auc: 0.6657\n",
            " For Batch Number 216 the model has a loss of {'loss': 0.646742582321167, 'tp': 1827.0, 'fp': 899.0, 'tn': 2547.0, 'fn': 1639.0, 'accuracy': 0.6328125, 'precision': 0.6702127456665039, 'recall': 0.5271205902099609, 'auc': 0.6655582189559937} \n",
            "216/689 [========>.....................] - ETA: 38s - loss: 0.6467 - tp: 1827.0000 - fp: 899.0000 - tn: 2547.0000 - fn: 1639.0000 - accuracy: 0.6328 - precision: 0.6702 - recall: 0.5271 - auc: 0.6656\n",
            " For Batch Number 217 the model has a loss of {'loss': 0.647343099117279, 'tp': 1830.0, 'fp': 902.0, 'tn': 2560.0, 'fn': 1652.0, 'accuracy': 0.6322004795074463, 'precision': 0.6698389649391174, 'recall': 0.5255600214004517, 'auc': 0.6646487712860107} \n",
            "217/689 [========>.....................] - ETA: 38s - loss: 0.6473 - tp: 1830.0000 - fp: 902.0000 - tn: 2560.0000 - fn: 1652.0000 - accuracy: 0.6322 - precision: 0.6698 - recall: 0.5256 - auc: 0.6646\n",
            " For Batch Number 218 the model has a loss of {'loss': 0.6472474336624146, 'tp': 1837.0, 'fp': 904.0, 'tn': 2574.0, 'fn': 1661.0, 'accuracy': 0.6323108077049255, 'precision': 0.6701933741569519, 'recall': 0.5251572132110596, 'auc': 0.6648468971252441} \n",
            "218/689 [========>.....................] - ETA: 38s - loss: 0.6472 - tp: 1837.0000 - fp: 904.0000 - tn: 2574.0000 - fn: 1661.0000 - accuracy: 0.6323 - precision: 0.6702 - recall: 0.5252 - auc: 0.6648\n",
            " For Batch Number 219 the model has a loss of {'loss': 0.6470658779144287, 'tp': 1844.0, 'fp': 905.0, 'tn': 2588.0, 'fn': 1671.0, 'accuracy': 0.6324200630187988, 'precision': 0.670789361000061, 'recall': 0.5246087908744812, 'auc': 0.6650627851486206} \n",
            "219/689 [========>.....................] - ETA: 38s - loss: 0.6471 - tp: 1844.0000 - fp: 905.0000 - tn: 2588.0000 - fn: 1671.0000 - accuracy: 0.6324 - precision: 0.6708 - recall: 0.5246 - auc: 0.6651\n",
            " For Batch Number 220 the model has a loss of {'loss': 0.6468912959098816, 'tp': 1853.0, 'fp': 905.0, 'tn': 2601.0, 'fn': 1681.0, 'accuracy': 0.6326704621315002, 'precision': 0.6718636751174927, 'recall': 0.5243350267410278, 'auc': 0.6653516292572021} \n",
            "220/689 [========>.....................] - ETA: 38s - loss: 0.6469 - tp: 1853.0000 - fp: 905.0000 - tn: 2601.0000 - fn: 1681.0000 - accuracy: 0.6327 - precision: 0.6719 - recall: 0.5243 - auc: 0.6654\n",
            " For Batch Number 221 the model has a loss of {'loss': 0.6468299627304077, 'tp': 1864.0, 'fp': 908.0, 'tn': 2612.0, 'fn': 1688.0, 'accuracy': 0.6329185366630554, 'precision': 0.6724386811256409, 'recall': 0.5247747898101807, 'auc': 0.6655648350715637} \n",
            "221/689 [========>.....................] - ETA: 38s - loss: 0.6468 - tp: 1864.0000 - fp: 908.0000 - tn: 2612.0000 - fn: 1688.0000 - accuracy: 0.6329 - precision: 0.6724 - recall: 0.5248 - auc: 0.6656\n",
            " For Batch Number 222 the model has a loss of {'loss': 0.6467118263244629, 'tp': 1877.0, 'fp': 912.0, 'tn': 2624.0, 'fn': 1691.0, 'accuracy': 0.6335867047309875, 'precision': 0.6730010509490967, 'recall': 0.5260650515556335, 'auc': 0.665652334690094} \n",
            "222/689 [========>.....................] - ETA: 38s - loss: 0.6467 - tp: 1877.0000 - fp: 912.0000 - tn: 2624.0000 - fn: 1691.0000 - accuracy: 0.6336 - precision: 0.6730 - recall: 0.5261 - auc: 0.6657\n",
            " For Batch Number 223 the model has a loss of {'loss': 0.6470643281936646, 'tp': 1890.0, 'fp': 924.0, 'tn': 2625.0, 'fn': 1697.0, 'accuracy': 0.632707417011261, 'precision': 0.6716417670249939, 'recall': 0.5269026756286621, 'auc': 0.6654022932052612} \n",
            "223/689 [========>.....................] - ETA: 38s - loss: 0.6471 - tp: 1890.0000 - fp: 924.0000 - tn: 2625.0000 - fn: 1697.0000 - accuracy: 0.6327 - precision: 0.6716 - recall: 0.5269 - auc: 0.6654\n",
            " For Batch Number 224 the model has a loss of {'loss': 0.6470704078674316, 'tp': 1907.0, 'fp': 937.0, 'tn': 2627.0, 'fn': 1697.0, 'accuracy': 0.6325334906578064, 'precision': 0.6705344319343567, 'recall': 0.5291342735290527, 'auc': 0.6653921604156494} \n",
            "224/689 [========>.....................] - ETA: 37s - loss: 0.6471 - tp: 1907.0000 - fp: 937.0000 - tn: 2627.0000 - fn: 1697.0000 - accuracy: 0.6325 - precision: 0.6705 - recall: 0.5291 - auc: 0.6654\n",
            " For Batch Number 225 the model has a loss of {'loss': 0.6474489569664001, 'tp': 1921.0, 'fp': 949.0, 'tn': 2629.0, 'fn': 1701.0, 'accuracy': 0.6319444179534912, 'precision': 0.6693379878997803, 'recall': 0.5303699374198914, 'auc': 0.6651920080184937} \n",
            "225/689 [========>.....................] - ETA: 37s - loss: 0.6474 - tp: 1921.0000 - fp: 949.0000 - tn: 2629.0000 - fn: 1701.0000 - accuracy: 0.6319 - precision: 0.6693 - recall: 0.5304 - auc: 0.6652\n",
            " For Batch Number 226 the model has a loss of {'loss': 0.6477377414703369, 'tp': 1934.0, 'fp': 963.0, 'tn': 2632.0, 'fn': 1703.0, 'accuracy': 0.6313605904579163, 'precision': 0.667587161064148, 'recall': 0.5317569375038147, 'auc': 0.6647427082061768} \n",
            "226/689 [========>.....................] - ETA: 37s - loss: 0.6477 - tp: 1934.0000 - fp: 963.0000 - tn: 2632.0000 - fn: 1703.0000 - accuracy: 0.6314 - precision: 0.6676 - recall: 0.5318 - auc: 0.6647\n",
            " For Batch Number 227 the model has a loss of {'loss': 0.6481637358665466, 'tp': 1943.0, 'fp': 971.0, 'tn': 2642.0, 'fn': 1708.0, 'accuracy': 0.6311949491500854, 'precision': 0.6667810678482056, 'recall': 0.5321829915046692, 'auc': 0.6643592715263367} \n",
            "227/689 [========>.....................] - ETA: 37s - loss: 0.6482 - tp: 1943.0000 - fp: 971.0000 - tn: 2642.0000 - fn: 1708.0000 - accuracy: 0.6312 - precision: 0.6668 - recall: 0.5322 - auc: 0.6644\n",
            " For Batch Number 228 the model has a loss of {'loss': 0.6481781005859375, 'tp': 1948.0, 'fp': 979.0, 'tn': 2656.0, 'fn': 1713.0, 'accuracy': 0.6310306787490845, 'precision': 0.6655278205871582, 'recall': 0.5320950746536255, 'auc': 0.6639732122421265} \n",
            "228/689 [========>.....................] - ETA: 37s - loss: 0.6482 - tp: 1948.0000 - fp: 979.0000 - tn: 2656.0000 - fn: 1713.0000 - accuracy: 0.6310 - precision: 0.6655 - recall: 0.5321 - auc: 0.6640\n",
            " For Batch Number 229 the model has a loss of {'loss': 0.6478572487831116, 'tp': 1953.0, 'fp': 983.0, 'tn': 2673.0, 'fn': 1719.0, 'accuracy': 0.6312772631645203, 'precision': 0.6651907563209534, 'recall': 0.531862735748291, 'auc': 0.6645172238349915} \n",
            "\n",
            " For Batch Number 230 the model has a loss of {'loss': 0.6477627158164978, 'tp': 1957.0, 'fp': 983.0, 'tn': 2689.0, 'fn': 1731.0, 'accuracy': 0.6312500238418579, 'precision': 0.6656462550163269, 'recall': 0.5306398868560791, 'auc': 0.6647791266441345} \n",
            "230/689 [=========>....................] - ETA: 37s - loss: 0.6478 - tp: 1957.0000 - fp: 983.0000 - tn: 2689.0000 - fn: 1731.0000 - accuracy: 0.6313 - precision: 0.6656 - recall: 0.5306 - auc: 0.6648\n",
            " For Batch Number 231 the model has a loss of {'loss': 0.6488059163093567, 'tp': 1958.0, 'fp': 986.0, 'tn': 2701.0, 'fn': 1747.0, 'accuracy': 0.6302759647369385, 'precision': 0.6650815010070801, 'recall': 0.5284750461578369, 'auc': 0.6632679104804993} \n",
            "231/689 [=========>....................] - ETA: 37s - loss: 0.6488 - tp: 1958.0000 - fp: 986.0000 - tn: 2701.0000 - fn: 1747.0000 - accuracy: 0.6303 - precision: 0.6651 - recall: 0.5285 - auc: 0.6633\n",
            " For Batch Number 232 the model has a loss of {'loss': 0.648882269859314, 'tp': 1962.0, 'fp': 986.0, 'tn': 2718.0, 'fn': 1758.0, 'accuracy': 0.6303879022598267, 'precision': 0.6655359268188477, 'recall': 0.5274193286895752, 'auc': 0.6631070971488953} \n",
            "232/689 [=========>....................] - ETA: 36s - loss: 0.6489 - tp: 1962.0000 - fp: 986.0000 - tn: 2718.0000 - fn: 1758.0000 - accuracy: 0.6304 - precision: 0.6655 - recall: 0.5274 - auc: 0.6631\n",
            " For Batch Number 233 the model has a loss of {'loss': 0.6489642262458801, 'tp': 1967.0, 'fp': 988.0, 'tn': 2731.0, 'fn': 1770.0, 'accuracy': 0.6300965547561646, 'precision': 0.6656514406204224, 'recall': 0.5263580679893494, 'auc': 0.663058340549469} \n",
            "233/689 [=========>....................] - ETA: 36s - loss: 0.6490 - tp: 1967.0000 - fp: 988.0000 - tn: 2731.0000 - fn: 1770.0000 - accuracy: 0.6301 - precision: 0.6657 - recall: 0.5264 - auc: 0.6631\n",
            " For Batch Number 234 the model has a loss of {'loss': 0.6487764716148376, 'tp': 1976.0, 'fp': 991.0, 'tn': 2745.0, 'fn': 1776.0, 'accuracy': 0.6304754018783569, 'precision': 0.6659925580024719, 'recall': 0.526652455329895, 'auc': 0.6635197401046753} \n",
            "234/689 [=========>....................] - ETA: 36s - loss: 0.6488 - tp: 1976.0000 - fp: 991.0000 - tn: 2745.0000 - fn: 1776.0000 - accuracy: 0.6305 - precision: 0.6660 - recall: 0.5267 - auc: 0.6635\n",
            " For Batch Number 235 the model has a loss of {'loss': 0.6483895182609558, 'tp': 1991.0, 'fp': 997.0, 'tn': 2754.0, 'fn': 1778.0, 'accuracy': 0.6309840679168701, 'precision': 0.6663320064544678, 'recall': 0.5282568335533142, 'auc': 0.664007306098938} \n",
            "235/689 [=========>....................] - ETA: 36s - loss: 0.6484 - tp: 1991.0000 - fp: 997.0000 - tn: 2754.0000 - fn: 1778.0000 - accuracy: 0.6310 - precision: 0.6663 - recall: 0.5283 - auc: 0.6640\n",
            " For Batch Number 236 the model has a loss of {'loss': 0.6479707360267639, 'tp': 2010.0, 'fp': 1003.0, 'tn': 2760.0, 'fn': 1779.0, 'accuracy': 0.6316207647323608, 'precision': 0.6671091914176941, 'recall': 0.5304829478263855, 'auc': 0.6645492315292358} \n",
            "236/689 [=========>....................] - ETA: 36s - loss: 0.6480 - tp: 2010.0000 - fp: 1003.0000 - tn: 2760.0000 - fn: 1779.0000 - accuracy: 0.6316 - precision: 0.6671 - recall: 0.5305 - auc: 0.6645\n",
            " For Batch Number 237 the model has a loss of {'loss': 0.6486294269561768, 'tp': 2021.0, 'fp': 1017.0, 'tn': 2762.0, 'fn': 1784.0, 'accuracy': 0.6306698322296143, 'precision': 0.6652402877807617, 'recall': 0.5311432480812073, 'auc': 0.6638704538345337} \n",
            "237/689 [=========>....................] - ETA: 36s - loss: 0.6486 - tp: 2021.0000 - fp: 1017.0000 - tn: 2762.0000 - fn: 1784.0000 - accuracy: 0.6307 - precision: 0.6652 - recall: 0.5311 - auc: 0.6639\n",
            " For Batch Number 238 the model has a loss of {'loss': 0.649238109588623, 'tp': 2032.0, 'fp': 1030.0, 'tn': 2766.0, 'fn': 1788.0, 'accuracy': 0.629989504814148, 'precision': 0.6636185646057129, 'recall': 0.5319371819496155, 'auc': 0.663318395614624} \n",
            "238/689 [=========>....................] - ETA: 36s - loss: 0.6492 - tp: 2032.0000 - fp: 1030.0000 - tn: 2766.0000 - fn: 1788.0000 - accuracy: 0.6300 - precision: 0.6636 - recall: 0.5319 - auc: 0.6633\n",
            " For Batch Number 239 the model has a loss of {'loss': 0.6495636701583862, 'tp': 2040.0, 'fp': 1039.0, 'tn': 2775.0, 'fn': 1794.0, 'accuracy': 0.6295763850212097, 'precision': 0.6625527739524841, 'recall': 0.5320813655853271, 'auc': 0.662777304649353} \n",
            "239/689 [=========>....................] - ETA: 36s - loss: 0.6496 - tp: 2040.0000 - fp: 1039.0000 - tn: 2775.0000 - fn: 1794.0000 - accuracy: 0.6296 - precision: 0.6626 - recall: 0.5321 - auc: 0.6628\n",
            " For Batch Number 240 the model has a loss of {'loss': 0.6498185396194458, 'tp': 2046.0, 'fp': 1041.0, 'tn': 2786.0, 'fn': 1807.0, 'accuracy': 0.6291666626930237, 'precision': 0.6627793908119202, 'recall': 0.5310148000717163, 'auc': 0.6624552607536316} \n",
            "240/689 [=========>....................] - ETA: 36s - loss: 0.6498 - tp: 2046.0000 - fp: 1041.0000 - tn: 2786.0000 - fn: 1807.0000 - accuracy: 0.6292 - precision: 0.6628 - recall: 0.5310 - auc: 0.6625\n",
            " For Batch Number 241 the model has a loss of {'loss': 0.6501084566116333, 'tp': 2051.0, 'fp': 1045.0, 'tn': 2800.0, 'fn': 1816.0, 'accuracy': 0.6290197372436523, 'precision': 0.6624677181243896, 'recall': 0.5303853154182434, 'auc': 0.6620573401451111} \n",
            "241/689 [=========>....................] - ETA: 36s - loss: 0.6501 - tp: 2051.0000 - fp: 1045.0000 - tn: 2800.0000 - fn: 1816.0000 - accuracy: 0.6290 - precision: 0.6625 - recall: 0.5304 - auc: 0.6621\n",
            " For Batch Number 242 the model has a loss of {'loss': 0.6495639681816101, 'tp': 2060.0, 'fp': 1045.0, 'tn': 2817.0, 'fn': 1822.0, 'accuracy': 0.6297779083251953, 'precision': 0.6634460687637329, 'recall': 0.5306543111801147, 'auc': 0.6629859209060669} \n",
            "242/689 [=========>....................] - ETA: 35s - loss: 0.6496 - tp: 2060.0000 - fp: 1045.0000 - tn: 2817.0000 - fn: 1822.0000 - accuracy: 0.6298 - precision: 0.6634 - recall: 0.5307 - auc: 0.6630\n",
            " For Batch Number 243 the model has a loss of {'loss': 0.6498410105705261, 'tp': 2068.0, 'fp': 1051.0, 'tn': 2827.0, 'fn': 1830.0, 'accuracy': 0.6295010447502136, 'precision': 0.6630330085754395, 'recall': 0.5305284857749939, 'auc': 0.6626774668693542} \n",
            "243/689 [=========>....................] - ETA: 35s - loss: 0.6498 - tp: 2068.0000 - fp: 1051.0000 - tn: 2827.0000 - fn: 1830.0000 - accuracy: 0.6295 - precision: 0.6630 - recall: 0.5305 - auc: 0.6627\n",
            " For Batch Number 244 the model has a loss of {'loss': 0.6495708227157593, 'tp': 2080.0, 'fp': 1054.0, 'tn': 2836.0, 'fn': 1838.0, 'accuracy': 0.6296106576919556, 'precision': 0.663688600063324, 'recall': 0.5308831334114075, 'auc': 0.6629969477653503} \n",
            "244/689 [=========>....................] - ETA: 35s - loss: 0.6496 - tp: 2080.0000 - fp: 1054.0000 - tn: 2836.0000 - fn: 1838.0000 - accuracy: 0.6296 - precision: 0.6637 - recall: 0.5309 - auc: 0.6630\n",
            " For Batch Number 245 the model has a loss of {'loss': 0.6494331955909729, 'tp': 2092.0, 'fp': 1059.0, 'tn': 2846.0, 'fn': 1843.0, 'accuracy': 0.6298469305038452, 'precision': 0.6639162302017212, 'recall': 0.5316391587257385, 'auc': 0.6631030440330505} \n",
            "245/689 [=========>....................] - ETA: 35s - loss: 0.6494 - tp: 2092.0000 - fp: 1059.0000 - tn: 2846.0000 - fn: 1843.0000 - accuracy: 0.6298 - precision: 0.6639 - recall: 0.5316 - auc: 0.6631\n",
            " For Batch Number 246 the model has a loss of {'loss': 0.6495577692985535, 'tp': 2108.0, 'fp': 1075.0, 'tn': 2846.0, 'fn': 1843.0, 'accuracy': 0.6293191313743591, 'precision': 0.6622682809829712, 'recall': 0.5335358381271362, 'auc': 0.6629491448402405} \n",
            "246/689 [=========>....................] - ETA: 35s - loss: 0.6496 - tp: 2108.0000 - fp: 1075.0000 - tn: 2846.0000 - fn: 1843.0000 - accuracy: 0.6293 - precision: 0.6623 - recall: 0.5335 - auc: 0.6629\n",
            " For Batch Number 247 the model has a loss of {'loss': 0.6492576599121094, 'tp': 2126.0, 'fp': 1088.0, 'tn': 2847.0, 'fn': 1843.0, 'accuracy': 0.6291751265525818, 'precision': 0.6614810228347778, 'recall': 0.5356513261795044, 'auc': 0.6632323861122131} \n",
            "247/689 [=========>....................] - ETA: 35s - loss: 0.6493 - tp: 2126.0000 - fp: 1088.0000 - tn: 2847.0000 - fn: 1843.0000 - accuracy: 0.6292 - precision: 0.6615 - recall: 0.5357 - auc: 0.6632\n",
            " For Batch Number 248 the model has a loss of {'loss': 0.649745523929596, 'tp': 2134.0, 'fp': 1098.0, 'tn': 2857.0, 'fn': 1847.0, 'accuracy': 0.62890625, 'precision': 0.6602723002433777, 'recall': 0.5360462069511414, 'auc': 0.6627110838890076} \n",
            "248/689 [=========>....................] - ETA: 35s - loss: 0.6497 - tp: 2134.0000 - fp: 1098.0000 - tn: 2857.0000 - fn: 1847.0000 - accuracy: 0.6289 - precision: 0.6603 - recall: 0.5360 - auc: 0.6627\n",
            " For Batch Number 249 the model has a loss of {'loss': 0.6503340601921082, 'tp': 2142.0, 'fp': 1107.0, 'tn': 2866.0, 'fn': 1853.0, 'accuracy': 0.6285140514373779, 'precision': 0.6592797636985779, 'recall': 0.5361701846122742, 'auc': 0.6621261239051819} \n",
            "249/689 [=========>....................] - ETA: 35s - loss: 0.6503 - tp: 2142.0000 - fp: 1107.0000 - tn: 2866.0000 - fn: 1853.0000 - accuracy: 0.6285 - precision: 0.6593 - recall: 0.5362 - auc: 0.6621\n",
            " For Batch Number 250 the model has a loss of {'loss': 0.6502657532691956, 'tp': 2153.0, 'fp': 1110.0, 'tn': 2875.0, 'fn': 1862.0, 'accuracy': 0.6284999847412109, 'precision': 0.6598222255706787, 'recall': 0.5362390875816345, 'auc': 0.6623151898384094} \n",
            "250/689 [=========>....................] - ETA: 35s - loss: 0.6503 - tp: 2153.0000 - fp: 1110.0000 - tn: 2875.0000 - fn: 1862.0000 - accuracy: 0.6285 - precision: 0.6598 - recall: 0.5362 - auc: 0.6623\n",
            " For Batch Number 251 the model has a loss of {'loss': 0.649793803691864, 'tp': 2163.0, 'fp': 1111.0, 'tn': 2891.0, 'fn': 1867.0, 'accuracy': 0.6292330622673035, 'precision': 0.6606597304344177, 'recall': 0.5367245674133301, 'auc': 0.6630042195320129} \n",
            "\n",
            " For Batch Number 252 the model has a loss of {'loss': 0.6499453783035278, 'tp': 2171.0, 'fp': 1114.0, 'tn': 2903.0, 'fn': 1876.0, 'accuracy': 0.6292162537574768, 'precision': 0.6608827710151672, 'recall': 0.536446750164032, 'auc': 0.6628177762031555} \n",
            "252/689 [=========>....................] - ETA: 34s - loss: 0.6499 - tp: 2171.0000 - fp: 1114.0000 - tn: 2903.0000 - fn: 1876.0000 - accuracy: 0.6292 - precision: 0.6609 - recall: 0.5364 - auc: 0.6628\n",
            " For Batch Number 253 the model has a loss of {'loss': 0.6495644450187683, 'tp': 2178.0, 'fp': 1118.0, 'tn': 2920.0, 'fn': 1880.0, 'accuracy': 0.6296936869621277, 'precision': 0.6608009934425354, 'recall': 0.5367175936698914, 'auc': 0.663411021232605} \n",
            "253/689 [==========>...................] - ETA: 34s - loss: 0.6496 - tp: 2178.0000 - fp: 1118.0000 - tn: 2920.0000 - fn: 1880.0000 - accuracy: 0.6297 - precision: 0.6608 - recall: 0.5367 - auc: 0.6634\n",
            " For Batch Number 254 the model has a loss of {'loss': 0.6495950818061829, 'tp': 2185.0, 'fp': 1123.0, 'tn': 2933.0, 'fn': 1887.0, 'accuracy': 0.6296752095222473, 'precision': 0.6605199575424194, 'recall': 0.5365913510322571, 'auc': 0.663350522518158} \n",
            "254/689 [==========>...................] - ETA: 34s - loss: 0.6496 - tp: 2185.0000 - fp: 1123.0000 - tn: 2933.0000 - fn: 1887.0000 - accuracy: 0.6297 - precision: 0.6605 - recall: 0.5366 - auc: 0.6634\n",
            " For Batch Number 255 the model has a loss of {'loss': 0.6496983170509338, 'tp': 2194.0, 'fp': 1126.0, 'tn': 2943.0, 'fn': 1897.0, 'accuracy': 0.6295343041419983, 'precision': 0.6608433723449707, 'recall': 0.5362991690635681, 'auc': 0.6631576418876648} \n",
            "255/689 [==========>...................] - ETA: 34s - loss: 0.6497 - tp: 2194.0000 - fp: 1126.0000 - tn: 2943.0000 - fn: 1897.0000 - accuracy: 0.6295 - precision: 0.6608 - recall: 0.5363 - auc: 0.6632\n",
            " For Batch Number 256 the model has a loss of {'loss': 0.6497908234596252, 'tp': 2202.0, 'fp': 1129.0, 'tn': 2956.0, 'fn': 1905.0, 'accuracy': 0.629638671875, 'precision': 0.6610627174377441, 'recall': 0.5361577868461609, 'auc': 0.6630405783653259} \n",
            "256/689 [==========>...................] - ETA: 34s - loss: 0.6498 - tp: 2202.0000 - fp: 1129.0000 - tn: 2956.0000 - fn: 1905.0000 - accuracy: 0.6296 - precision: 0.6611 - recall: 0.5362 - auc: 0.6630\n",
            " For Batch Number 257 the model has a loss of {'loss': 0.6495809555053711, 'tp': 2209.0, 'fp': 1134.0, 'tn': 2971.0, 'fn': 1910.0, 'accuracy': 0.6298637986183167, 'precision': 0.6607837080955505, 'recall': 0.5362952351570129, 'auc': 0.6631497740745544} \n",
            "257/689 [==========>...................] - ETA: 34s - loss: 0.6496 - tp: 2209.0000 - fp: 1134.0000 - tn: 2971.0000 - fn: 1910.0000 - accuracy: 0.6299 - precision: 0.6608 - recall: 0.5363 - auc: 0.6631\n",
            " For Batch Number 258 the model has a loss of {'loss': 0.6496168971061707, 'tp': 2219.0, 'fp': 1137.0, 'tn': 2979.0, 'fn': 1921.0, 'accuracy': 0.6296027302742004, 'precision': 0.6612038016319275, 'recall': 0.5359903573989868, 'auc': 0.6631215810775757} \n",
            "258/689 [==========>...................] - ETA: 34s - loss: 0.6496 - tp: 2219.0000 - fp: 1137.0000 - tn: 2979.0000 - fn: 1921.0000 - accuracy: 0.6296 - precision: 0.6612 - recall: 0.5360 - auc: 0.6631\n",
            " For Batch Number 259 the model has a loss of {'loss': 0.6495808362960815, 'tp': 2229.0, 'fp': 1144.0, 'tn': 2993.0, 'fn': 1922.0, 'accuracy': 0.6300675868988037, 'precision': 0.6608360409736633, 'recall': 0.5369790196418762, 'auc': 0.6631364226341248} \n",
            "259/689 [==========>...................] - ETA: 34s - loss: 0.6496 - tp: 2229.0000 - fp: 1144.0000 - tn: 2993.0000 - fn: 1922.0000 - accuracy: 0.6301 - precision: 0.6608 - recall: 0.5370 - auc: 0.6631\n",
            " For Batch Number 260 the model has a loss of {'loss': 0.6495417356491089, 'tp': 2239.0, 'fp': 1146.0, 'tn': 3002.0, 'fn': 1933.0, 'accuracy': 0.6299278736114502, 'precision': 0.6614475846290588, 'recall': 0.5366730690002441, 'auc': 0.66306471824646} \n",
            "260/689 [==========>...................] - ETA: 34s - loss: 0.6495 - tp: 2239.0000 - fp: 1146.0000 - tn: 3002.0000 - fn: 1933.0000 - accuracy: 0.6299 - precision: 0.6614 - recall: 0.5367 - auc: 0.6631\n",
            " For Batch Number 261 the model has a loss of {'loss': 0.649644136428833, 'tp': 2245.0, 'fp': 1152.0, 'tn': 3014.0, 'fn': 1941.0, 'accuracy': 0.6296695470809937, 'precision': 0.6608772277832031, 'recall': 0.5363115072250366, 'auc': 0.6629095077514648} \n",
            "261/689 [==========>...................] - ETA: 34s - loss: 0.6496 - tp: 2245.0000 - fp: 1152.0000 - tn: 3014.0000 - fn: 1941.0000 - accuracy: 0.6297 - precision: 0.6609 - recall: 0.5363 - auc: 0.6629\n",
            " For Batch Number 262 the model has a loss of {'loss': 0.6498417258262634, 'tp': 2252.0, 'fp': 1158.0, 'tn': 3027.0, 'fn': 1947.0, 'accuracy': 0.6296517252922058, 'precision': 0.6604105830192566, 'recall': 0.5363181829452515, 'auc': 0.6628426909446716} \n",
            "262/689 [==========>...................] - ETA: 33s - loss: 0.6498 - tp: 2252.0000 - fp: 1158.0000 - tn: 3027.0000 - fn: 1947.0000 - accuracy: 0.6297 - precision: 0.6604 - recall: 0.5363 - auc: 0.6628\n",
            " For Batch Number 263 the model has a loss of {'loss': 0.6499471068382263, 'tp': 2257.0, 'fp': 1162.0, 'tn': 3039.0, 'fn': 1958.0, 'accuracy': 0.6292775869369507, 'precision': 0.6601345539093018, 'recall': 0.535468578338623, 'auc': 0.6625478267669678} \n",
            "\n",
            " For Batch Number 264 the model has a loss of {'loss': 0.6499607563018799, 'tp': 2263.0, 'fp': 1164.0, 'tn': 3053.0, 'fn': 1968.0, 'accuracy': 0.6292613744735718, 'precision': 0.6603443026542664, 'recall': 0.5348617434501648, 'auc': 0.6626309752464294} \n",
            "264/689 [==========>...................] - ETA: 33s - loss: 0.6500 - tp: 2263.0000 - fp: 1164.0000 - tn: 3053.0000 - fn: 1968.0000 - accuracy: 0.6293 - precision: 0.6603 - recall: 0.5349 - auc: 0.6626\n",
            " For Batch Number 265 the model has a loss of {'loss': 0.6501281261444092, 'tp': 2266.0, 'fp': 1169.0, 'tn': 3068.0, 'fn': 1977.0, 'accuracy': 0.6290094256401062, 'precision': 0.6596797704696655, 'recall': 0.5340560674667358, 'auc': 0.662399172782898} \n",
            "265/689 [==========>...................] - ETA: 33s - loss: 0.6501 - tp: 2266.0000 - fp: 1169.0000 - tn: 3068.0000 - fn: 1977.0000 - accuracy: 0.6290 - precision: 0.6597 - recall: 0.5341 - auc: 0.6624\n",
            " For Batch Number 266 the model has a loss of {'loss': 0.650540828704834, 'tp': 2273.0, 'fp': 1170.0, 'tn': 3075.0, 'fn': 1994.0, 'accuracy': 0.6282894611358643, 'precision': 0.6601800918579102, 'recall': 0.5326927304267883, 'auc': 0.6617014408111572} \n",
            "266/689 [==========>...................] - ETA: 33s - loss: 0.6505 - tp: 2273.0000 - fp: 1170.0000 - tn: 3075.0000 - fn: 1994.0000 - accuracy: 0.6283 - precision: 0.6602 - recall: 0.5327 - auc: 0.6617\n",
            " For Batch Number 267 the model has a loss of {'loss': 0.6509366035461426, 'tp': 2282.0, 'fp': 1181.0, 'tn': 3082.0, 'fn': 1999.0, 'accuracy': 0.6278089880943298, 'precision': 0.6589662432670593, 'recall': 0.5330530405044556, 'auc': 0.661178469657898} \n",
            "267/689 [==========>...................] - ETA: 33s - loss: 0.6509 - tp: 2282.0000 - fp: 1181.0000 - tn: 3082.0000 - fn: 1999.0000 - accuracy: 0.6278 - precision: 0.6590 - recall: 0.5331 - auc: 0.6612\n",
            " For Batch Number 268 the model has a loss of {'loss': 0.6509077548980713, 'tp': 2296.0, 'fp': 1195.0, 'tn': 3084.0, 'fn': 2001.0, 'accuracy': 0.6273320913314819, 'precision': 0.6576911807060242, 'recall': 0.5343262553215027, 'auc': 0.6611302495002747} \n",
            "268/689 [==========>...................] - ETA: 33s - loss: 0.6509 - tp: 2296.0000 - fp: 1195.0000 - tn: 3084.0000 - fn: 2001.0000 - accuracy: 0.6273 - precision: 0.6577 - recall: 0.5343 - auc: 0.6611\n",
            " For Batch Number 269 the model has a loss of {'loss': 0.6508544683456421, 'tp': 2308.0, 'fp': 1208.0, 'tn': 3089.0, 'fn': 2003.0, 'accuracy': 0.626974880695343, 'precision': 0.6564277410507202, 'recall': 0.535374641418457, 'auc': 0.6610161066055298} \n",
            "\n",
            " For Batch Number 270 the model has a loss of {'loss': 0.6509408354759216, 'tp': 2318.0, 'fp': 1213.0, 'tn': 3099.0, 'fn': 2010.0, 'accuracy': 0.6269676089286804, 'precision': 0.6564712524414062, 'recall': 0.5355822443962097, 'auc': 0.6610484719276428} \n",
            "270/689 [==========>...................] - ETA: 33s - loss: 0.6509 - tp: 2318.0000 - fp: 1213.0000 - tn: 3099.0000 - fn: 2010.0000 - accuracy: 0.6270 - precision: 0.6565 - recall: 0.5356 - auc: 0.6610\n",
            " For Batch Number 271 the model has a loss of {'loss': 0.6509577631950378, 'tp': 2327.0, 'fp': 1215.0, 'tn': 3108.0, 'fn': 2022.0, 'accuracy': 0.6267297267913818, 'precision': 0.6569734811782837, 'recall': 0.5350655317306519, 'auc': 0.6610275506973267} \n",
            "271/689 [==========>...................] - ETA: 33s - loss: 0.6510 - tp: 2327.0000 - fp: 1215.0000 - tn: 3108.0000 - fn: 2022.0000 - accuracy: 0.6267 - precision: 0.6570 - recall: 0.5351 - auc: 0.6610\n",
            " For Batch Number 272 the model has a loss of {'loss': 0.6510472297668457, 'tp': 2336.0, 'fp': 1218.0, 'tn': 3119.0, 'fn': 2031.0, 'accuracy': 0.6267233490943909, 'precision': 0.6572875380516052, 'recall': 0.5349209904670715, 'auc': 0.6609495282173157} \n",
            "\n",
            " For Batch Number 273 the model has a loss of {'loss': 0.6510928273200989, 'tp': 2345.0, 'fp': 1221.0, 'tn': 3128.0, 'fn': 2042.0, 'accuracy': 0.6264880895614624, 'precision': 0.6575995683670044, 'recall': 0.5345338582992554, 'auc': 0.6608718037605286} \n",
            "273/689 [==========>...................] - ETA: 32s - loss: 0.6511 - tp: 2345.0000 - fp: 1221.0000 - tn: 3128.0000 - fn: 2042.0000 - accuracy: 0.6265 - precision: 0.6576 - recall: 0.5345 - auc: 0.6609\n",
            " For Batch Number 274 the model has a loss of {'loss': 0.6511478424072266, 'tp': 2353.0, 'fp': 1228.0, 'tn': 3140.0, 'fn': 2047.0, 'accuracy': 0.6264826655387878, 'precision': 0.6570790410041809, 'recall': 0.5347727537155151, 'auc': 0.6606189012527466} \n",
            "274/689 [==========>...................] - ETA: 32s - loss: 0.6511 - tp: 2353.0000 - fp: 1228.0000 - tn: 3140.0000 - fn: 2047.0000 - accuracy: 0.6265 - precision: 0.6571 - recall: 0.5348 - auc: 0.6606\n",
            " For Batch Number 275 the model has a loss of {'loss': 0.6509655117988586, 'tp': 2361.0, 'fp': 1234.0, 'tn': 3154.0, 'fn': 2051.0, 'accuracy': 0.6267045736312866, 'precision': 0.6567454934120178, 'recall': 0.5351314544677734, 'auc': 0.6606897115707397} \n",
            "275/689 [==========>...................] - ETA: 32s - loss: 0.6510 - tp: 2361.0000 - fp: 1234.0000 - tn: 3154.0000 - fn: 2051.0000 - accuracy: 0.6267 - precision: 0.6567 - recall: 0.5351 - auc: 0.6607\n",
            " For Batch Number 276 the model has a loss of {'loss': 0.6507044434547424, 'tp': 2373.0, 'fp': 1237.0, 'tn': 3165.0, 'fn': 2057.0, 'accuracy': 0.6270380616188049, 'precision': 0.6573407053947449, 'recall': 0.5356659293174744, 'auc': 0.6611007452011108} \n",
            "276/689 [===========>..................] - ETA: 32s - loss: 0.6507 - tp: 2373.0000 - fp: 1237.0000 - tn: 3165.0000 - fn: 2057.0000 - accuracy: 0.6270 - precision: 0.6573 - recall: 0.5357 - auc: 0.6611\n",
            " For Batch Number 277 the model has a loss of {'loss': 0.6509124040603638, 'tp': 2380.0, 'fp': 1242.0, 'tn': 3175.0, 'fn': 2067.0, 'accuracy': 0.6266922354698181, 'precision': 0.6570955514907837, 'recall': 0.5351922512054443, 'auc': 0.6609228849411011} \n",
            "277/689 [===========>..................] - ETA: 32s - loss: 0.6509 - tp: 2380.0000 - fp: 1242.0000 - tn: 3175.0000 - fn: 2067.0000 - accuracy: 0.6267 - precision: 0.6571 - recall: 0.5352 - auc: 0.6609\n",
            " For Batch Number 278 the model has a loss of {'loss': 0.6508995890617371, 'tp': 2387.0, 'fp': 1247.0, 'tn': 3190.0, 'fn': 2072.0, 'accuracy': 0.6269109845161438, 'precision': 0.6568519473075867, 'recall': 0.535321831703186, 'auc': 0.6610932946205139} \n",
            "278/689 [===========>..................] - ETA: 32s - loss: 0.6509 - tp: 2387.0000 - fp: 1247.0000 - tn: 3190.0000 - fn: 2072.0000 - accuracy: 0.6269 - precision: 0.6569 - recall: 0.5353 - auc: 0.6611\n",
            " For Batch Number 279 the model has a loss of {'loss': 0.6506592631340027, 'tp': 2393.0, 'fp': 1251.0, 'tn': 3208.0, 'fn': 2076.0, 'accuracy': 0.6273521780967712, 'precision': 0.6566959619522095, 'recall': 0.5354665517807007, 'auc': 0.6614254713058472} \n",
            "279/689 [===========>..................] - ETA: 32s - loss: 0.6507 - tp: 2393.0000 - fp: 1251.0000 - tn: 3208.0000 - fn: 2076.0000 - accuracy: 0.6274 - precision: 0.6567 - recall: 0.5355 - auc: 0.6614\n",
            " For Batch Number 280 the model has a loss of {'loss': 0.6509362459182739, 'tp': 2399.0, 'fp': 1252.0, 'tn': 3218.0, 'fn': 2091.0, 'accuracy': 0.6268973350524902, 'precision': 0.6570802330970764, 'recall': 0.5342984199523926, 'auc': 0.6609235405921936} \n",
            "280/689 [===========>..................] - ETA: 32s - loss: 0.6509 - tp: 2399.0000 - fp: 1252.0000 - tn: 3218.0000 - fn: 2091.0000 - accuracy: 0.6269 - precision: 0.6571 - recall: 0.5343 - auc: 0.6609\n",
            " For Batch Number 281 the model has a loss of {'loss': 0.650969922542572, 'tp': 2404.0, 'fp': 1255.0, 'tn': 3232.0, 'fn': 2101.0, 'accuracy': 0.6267793774604797, 'precision': 0.6570101380348206, 'recall': 0.533629298210144, 'auc': 0.660919189453125} \n",
            "281/689 [===========>..................] - ETA: 32s - loss: 0.6510 - tp: 2404.0000 - fp: 1255.0000 - tn: 3232.0000 - fn: 2101.0000 - accuracy: 0.6268 - precision: 0.6570 - recall: 0.5336 - auc: 0.6609\n",
            " For Batch Number 282 the model has a loss of {'loss': 0.6507154703140259, 'tp': 2414.0, 'fp': 1255.0, 'tn': 3245.0, 'fn': 2110.0, 'accuracy': 0.6271054744720459, 'precision': 0.657944917678833, 'recall': 0.5335986018180847, 'auc': 0.6613074541091919} \n",
            "\n",
            " For Batch Number 283 the model has a loss of {'loss': 0.6508288979530334, 'tp': 2422.0, 'fp': 1258.0, 'tn': 3257.0, 'fn': 2119.0, 'accuracy': 0.6270980834960938, 'precision': 0.658152163028717, 'recall': 0.5333626866340637, 'auc': 0.6612502932548523} \n",
            "283/689 [===========>..................] - ETA: 31s - loss: 0.6508 - tp: 2422.0000 - fp: 1258.0000 - tn: 3257.0000 - fn: 2119.0000 - accuracy: 0.6271 - precision: 0.6582 - recall: 0.5334 - auc: 0.6613\n",
            " For Batch Number 284 the model has a loss of {'loss': 0.6510962247848511, 'tp': 2428.0, 'fp': 1264.0, 'tn': 3268.0, 'fn': 2128.0, 'accuracy': 0.6267605423927307, 'precision': 0.6576381325721741, 'recall': 0.5329236388206482, 'auc': 0.6606478095054626} \n",
            "\n",
            " For Batch Number 285 the model has a loss of {'loss': 0.6510953307151794, 'tp': 2437.0, 'fp': 1271.0, 'tn': 3278.0, 'fn': 2134.0, 'accuracy': 0.6266447305679321, 'precision': 0.657227635383606, 'recall': 0.5331437587738037, 'auc': 0.6606627702713013} \n",
            "285/689 [===========>..................] - ETA: 31s - loss: 0.6511 - tp: 2437.0000 - fp: 1271.0000 - tn: 3278.0000 - fn: 2134.0000 - accuracy: 0.6266 - precision: 0.6572 - recall: 0.5331 - auc: 0.6607\n",
            " For Batch Number 286 the model has a loss of {'loss': 0.6507840752601624, 'tp': 2449.0, 'fp': 1275.0, 'tn': 3289.0, 'fn': 2139.0, 'accuracy': 0.6269667744636536, 'precision': 0.657626211643219, 'recall': 0.5337837934494019, 'auc': 0.6611301302909851} \n",
            "286/689 [===========>..................] - ETA: 31s - loss: 0.6508 - tp: 2449.0000 - fp: 1275.0000 - tn: 3289.0000 - fn: 2139.0000 - accuracy: 0.6270 - precision: 0.6576 - recall: 0.5338 - auc: 0.6611\n",
            " For Batch Number 287 the model has a loss of {'loss': 0.6505454182624817, 'tp': 2462.0, 'fp': 1281.0, 'tn': 3298.0, 'fn': 2143.0, 'accuracy': 0.6271777153015137, 'precision': 0.6577611565589905, 'recall': 0.5346362590789795, 'auc': 0.6614401936531067} \n",
            "\n",
            " For Batch Number 288 the model has a loss of {'loss': 0.650424063205719, 'tp': 2473.0, 'fp': 1290.0, 'tn': 3305.0, 'fn': 2148.0, 'accuracy': 0.626953125, 'precision': 0.6571884155273438, 'recall': 0.535165548324585, 'auc': 0.6615890264511108} \n",
            "288/689 [===========>..................] - ETA: 31s - loss: 0.6504 - tp: 2473.0000 - fp: 1290.0000 - tn: 3305.0000 - fn: 2148.0000 - accuracy: 0.6270 - precision: 0.6572 - recall: 0.5352 - auc: 0.6616\n",
            " For Batch Number 289 the model has a loss of {'loss': 0.6501772403717041, 'tp': 2481.0, 'fp': 1296.0, 'tn': 3318.0, 'fn': 2153.0, 'accuracy': 0.6270545125007629, 'precision': 0.6568705439567566, 'recall': 0.5353906154632568, 'auc': 0.6617650985717773} \n",
            "\n",
            " For Batch Number 290 the model has a loss of {'loss': 0.6497597694396973, 'tp': 2490.0, 'fp': 1301.0, 'tn': 3333.0, 'fn': 2156.0, 'accuracy': 0.6274784207344055, 'precision': 0.6568188071250916, 'recall': 0.5359448790550232, 'auc': 0.6622498631477356} \n",
            "290/689 [===========>..................] - ETA: 31s - loss: 0.6498 - tp: 2490.0000 - fp: 1301.0000 - tn: 3333.0000 - fn: 2156.0000 - accuracy: 0.6275 - precision: 0.6568 - recall: 0.5359 - auc: 0.6622\n",
            " For Batch Number 291 the model has a loss of {'loss': 0.6497755646705627, 'tp': 2496.0, 'fp': 1306.0, 'tn': 3349.0, 'fn': 2161.0, 'accuracy': 0.6276847124099731, 'precision': 0.6564965844154358, 'recall': 0.5359673500061035, 'auc': 0.6622930765151978} \n",
            "291/689 [===========>..................] - ETA: 30s - loss: 0.6498 - tp: 2496.0000 - fp: 1306.0000 - tn: 3349.0000 - fn: 2161.0000 - accuracy: 0.6277 - precision: 0.6565 - recall: 0.5360 - auc: 0.6623\n",
            " For Batch Number 292 the model has a loss of {'loss': 0.6498295664787292, 'tp': 2503.0, 'fp': 1306.0, 'tn': 3361.0, 'fn': 2174.0, 'accuracy': 0.6275684833526611, 'precision': 0.657127857208252, 'recall': 0.5351721048355103, 'auc': 0.6621208786964417} \n",
            "292/689 [===========>..................] - ETA: 30s - loss: 0.6498 - tp: 2503.0000 - fp: 1306.0000 - tn: 3361.0000 - fn: 2174.0000 - accuracy: 0.6276 - precision: 0.6571 - recall: 0.5352 - auc: 0.6621\n",
            " For Batch Number 293 the model has a loss of {'loss': 0.6499334573745728, 'tp': 2508.0, 'fp': 1311.0, 'tn': 3374.0, 'fn': 2183.0, 'accuracy': 0.627346396446228, 'precision': 0.6567164063453674, 'recall': 0.5346407890319824, 'auc': 0.6618539094924927} \n",
            "293/689 [===========>..................] - ETA: 30s - loss: 0.6499 - tp: 2508.0000 - fp: 1311.0000 - tn: 3374.0000 - fn: 2183.0000 - accuracy: 0.6273 - precision: 0.6567 - recall: 0.5346 - auc: 0.6619\n",
            " For Batch Number 294 the model has a loss of {'loss': 0.6501340270042419, 'tp': 2516.0, 'fp': 1312.0, 'tn': 3384.0, 'fn': 2196.0, 'accuracy': 0.6271258592605591, 'precision': 0.6572622656822205, 'recall': 0.5339558720588684, 'auc': 0.6615985631942749} \n",
            "294/689 [===========>..................] - ETA: 30s - loss: 0.6501 - tp: 2516.0000 - fp: 1312.0000 - tn: 3384.0000 - fn: 2196.0000 - accuracy: 0.6271 - precision: 0.6573 - recall: 0.5340 - auc: 0.6616\n",
            " For Batch Number 295 the model has a loss of {'loss': 0.650179922580719, 'tp': 2524.0, 'fp': 1314.0, 'tn': 3398.0, 'fn': 2204.0, 'accuracy': 0.627330482006073, 'precision': 0.6576341986656189, 'recall': 0.5338409543037415, 'auc': 0.6616692543029785} \n",
            "295/689 [===========>..................] - ETA: 30s - loss: 0.6502 - tp: 2524.0000 - fp: 1314.0000 - tn: 3398.0000 - fn: 2204.0000 - accuracy: 0.6273 - precision: 0.6576 - recall: 0.5338 - auc: 0.6617\n",
            " For Batch Number 296 the model has a loss of {'loss': 0.6503498554229736, 'tp': 2528.0, 'fp': 1321.0, 'tn': 3412.0, 'fn': 2211.0, 'accuracy': 0.6271114945411682, 'precision': 0.6567939519882202, 'recall': 0.5334458947181702, 'auc': 0.6615880131721497} \n",
            "296/689 [===========>..................] - ETA: 30s - loss: 0.6503 - tp: 2528.0000 - fp: 1321.0000 - tn: 3412.0000 - fn: 2211.0000 - accuracy: 0.6271 - precision: 0.6568 - recall: 0.5334 - auc: 0.6616\n",
            " For Batch Number 297 the model has a loss of {'loss': 0.6501724720001221, 'tp': 2536.0, 'fp': 1323.0, 'tn': 3426.0, 'fn': 2219.0, 'accuracy': 0.6273148059844971, 'precision': 0.6571650505065918, 'recall': 0.5333333611488342, 'auc': 0.6618418097496033} \n",
            "297/689 [===========>..................] - ETA: 30s - loss: 0.6502 - tp: 2536.0000 - fp: 1323.0000 - tn: 3426.0000 - fn: 2219.0000 - accuracy: 0.6273 - precision: 0.6572 - recall: 0.5333 - auc: 0.6618\n",
            " For Batch Number 298 the model has a loss of {'loss': 0.6500231027603149, 'tp': 2544.0, 'fp': 1327.0, 'tn': 3440.0, 'fn': 2225.0, 'accuracy': 0.6275168061256409, 'precision': 0.6571944952011108, 'recall': 0.5334451794624329, 'auc': 0.6622099876403809} \n",
            "298/689 [===========>..................] - ETA: 30s - loss: 0.6500 - tp: 2544.0000 - fp: 1327.0000 - tn: 3440.0000 - fn: 2225.0000 - accuracy: 0.6275 - precision: 0.6572 - recall: 0.5334 - auc: 0.6622\n",
            " For Batch Number 299 the model has a loss of {'loss': 0.650174081325531, 'tp': 2552.0, 'fp': 1331.0, 'tn': 3451.0, 'fn': 2234.0, 'accuracy': 0.6274038553237915, 'precision': 0.6572238206863403, 'recall': 0.5332219004631042, 'auc': 0.6620665788650513} \n",
            "299/689 [============>.................] - ETA: 30s - loss: 0.6502 - tp: 2552.0000 - fp: 1331.0000 - tn: 3451.0000 - fn: 2234.0000 - accuracy: 0.6274 - precision: 0.6572 - recall: 0.5332 - auc: 0.6621\n",
            " For Batch Number 300 the model has a loss of {'loss': 0.6499983668327332, 'tp': 2561.0, 'fp': 1331.0, 'tn': 3463.0, 'fn': 2245.0, 'accuracy': 0.6274999976158142, 'precision': 0.6580164432525635, 'recall': 0.5328755974769592, 'auc': 0.6621838212013245} \n",
            "300/689 [============>.................] - ETA: 30s - loss: 0.6500 - tp: 2561.0000 - fp: 1331.0000 - tn: 3463.0000 - fn: 2245.0000 - accuracy: 0.6275 - precision: 0.6580 - recall: 0.5329 - auc: 0.6622\n",
            " For Batch Number 301 the model has a loss of {'loss': 0.6498715281486511, 'tp': 2572.0, 'fp': 1333.0, 'tn': 3475.0, 'fn': 2252.0, 'accuracy': 0.6278031468391418, 'precision': 0.6586427688598633, 'recall': 0.5331674814224243, 'auc': 0.6624240875244141} \n",
            "301/689 [============>.................] - ETA: 30s - loss: 0.6499 - tp: 2572.0000 - fp: 1333.0000 - tn: 3475.0000 - fn: 2252.0000 - accuracy: 0.6278 - precision: 0.6586 - recall: 0.5332 - auc: 0.6624\n",
            " For Batch Number 302 the model has a loss of {'loss': 0.6496865749359131, 'tp': 2583.0, 'fp': 1338.0, 'tn': 3483.0, 'fn': 2260.0, 'accuracy': 0.6276903748512268, 'precision': 0.6587605476379395, 'recall': 0.5333470702171326, 'auc': 0.662667989730835} \n",
            "302/689 [============>.................] - ETA: 29s - loss: 0.6497 - tp: 2583.0000 - fp: 1338.0000 - tn: 3483.0000 - fn: 2260.0000 - accuracy: 0.6277 - precision: 0.6588 - recall: 0.5333 - auc: 0.6627\n",
            " For Batch Number 303 the model has a loss of {'loss': 0.6496537923812866, 'tp': 2594.0, 'fp': 1344.0, 'tn': 3494.0, 'fn': 2264.0, 'accuracy': 0.6278877854347229, 'precision': 0.6587100028991699, 'recall': 0.5339645743370056, 'auc': 0.6627066731452942} \n",
            "\n",
            " For Batch Number 304 the model has a loss of {'loss': 0.6496327519416809, 'tp': 2609.0, 'fp': 1348.0, 'tn': 3503.0, 'fn': 2268.0, 'accuracy': 0.6282894611358643, 'precision': 0.6593378782272339, 'recall': 0.5349600315093994, 'auc': 0.6630634665489197} \n",
            "304/689 [============>.................] - ETA: 29s - loss: 0.6496 - tp: 2609.0000 - fp: 1348.0000 - tn: 3503.0000 - fn: 2268.0000 - accuracy: 0.6283 - precision: 0.6593 - recall: 0.5350 - auc: 0.6631\n",
            " For Batch Number 305 the model has a loss of {'loss': 0.6497405767440796, 'tp': 2618.0, 'fp': 1367.0, 'tn': 3507.0, 'fn': 2268.0, 'accuracy': 0.6275614500045776, 'precision': 0.656963586807251, 'recall': 0.5358166098594666, 'auc': 0.6626165509223938} \n",
            "\n",
            " For Batch Number 306 the model has a loss of {'loss': 0.6499296426773071, 'tp': 2623.0, 'fp': 1374.0, 'tn': 3522.0, 'fn': 2273.0, 'accuracy': 0.6275531053543091, 'precision': 0.6562421917915344, 'recall': 0.5357434749603271, 'auc': 0.6623930335044861} \n",
            "306/689 [============>.................] - ETA: 29s - loss: 0.6499 - tp: 2623.0000 - fp: 1374.0000 - tn: 3522.0000 - fn: 2273.0000 - accuracy: 0.6276 - precision: 0.6562 - recall: 0.5357 - auc: 0.6624\n",
            " For Batch Number 307 the model has a loss of {'loss': 0.6506689786911011, 'tp': 2626.0, 'fp': 1377.0, 'tn': 3536.0, 'fn': 2285.0, 'accuracy': 0.6272394061088562, 'precision': 0.6560080051422119, 'recall': 0.5347179770469666, 'auc': 0.6615673303604126} \n",
            "307/689 [============>.................] - ETA: 29s - loss: 0.6507 - tp: 2626.0000 - fp: 1377.0000 - tn: 3536.0000 - fn: 2285.0000 - accuracy: 0.6272 - precision: 0.6560 - recall: 0.5347 - auc: 0.6616\n",
            " For Batch Number 308 the model has a loss of {'loss': 0.6509512662887573, 'tp': 2630.0, 'fp': 1378.0, 'tn': 3550.0, 'fn': 2298.0, 'accuracy': 0.6270292401313782, 'precision': 0.6561876535415649, 'recall': 0.5336850881576538, 'auc': 0.6612268686294556} \n",
            "308/689 [============>.................] - ETA: 29s - loss: 0.6510 - tp: 2630.0000 - fp: 1378.0000 - tn: 3550.0000 - fn: 2298.0000 - accuracy: 0.6270 - precision: 0.6562 - recall: 0.5337 - auc: 0.6612\n",
            " For Batch Number 309 the model has a loss of {'loss': 0.651008129119873, 'tp': 2632.0, 'fp': 1380.0, 'tn': 3569.0, 'fn': 2307.0, 'accuracy': 0.6271237730979919, 'precision': 0.6560319066047668, 'recall': 0.532901406288147, 'auc': 0.6610898375511169} \n",
            "309/689 [============>.................] - ETA: 29s - loss: 0.6510 - tp: 2632.0000 - fp: 1380.0000 - tn: 3569.0000 - fn: 2307.0000 - accuracy: 0.6271 - precision: 0.6560 - recall: 0.5329 - auc: 0.6611\n",
            " For Batch Number 310 the model has a loss of {'loss': 0.6514765024185181, 'tp': 2637.0, 'fp': 1381.0, 'tn': 3578.0, 'fn': 2324.0, 'accuracy': 0.6265121102333069, 'precision': 0.6562966704368591, 'recall': 0.5315460562705994, 'auc': 0.6602573990821838} \n",
            "310/689 [============>.................] - ETA: 29s - loss: 0.6515 - tp: 2637.0000 - fp: 1381.0000 - tn: 3578.0000 - fn: 2324.0000 - accuracy: 0.6265 - precision: 0.6563 - recall: 0.5315 - auc: 0.6603\n",
            " For Batch Number 311 the model has a loss of {'loss': 0.6513738632202148, 'tp': 2644.0, 'fp': 1384.0, 'tn': 3591.0, 'fn': 2333.0, 'accuracy': 0.6265072226524353, 'precision': 0.6564051508903503, 'recall': 0.5312437415122986, 'auc': 0.6604689955711365} \n",
            "\n",
            " For Batch Number 312 the model has a loss of {'loss': 0.6511245369911194, 'tp': 2661.0, 'fp': 1395.0, 'tn': 3592.0, 'fn': 2336.0, 'accuracy': 0.6263020634651184, 'precision': 0.6560651063919067, 'recall': 0.532519519329071, 'auc': 0.6608115434646606} \n",
            "312/689 [============>.................] - ETA: 28s - loss: 0.6511 - tp: 2661.0000 - fp: 1395.0000 - tn: 3592.0000 - fn: 2336.0000 - accuracy: 0.6263 - precision: 0.6561 - recall: 0.5325 - auc: 0.6608\n",
            " For Batch Number 313 the model has a loss of {'loss': 0.6517422795295715, 'tp': 2675.0, 'fp': 1413.0, 'tn': 3592.0, 'fn': 2336.0, 'accuracy': 0.6256988644599915, 'precision': 0.6543542146682739, 'recall': 0.5338255763053894, 'auc': 0.6601792573928833} \n",
            "\n",
            " For Batch Number 314 the model has a loss of {'loss': 0.6516320705413818, 'tp': 2694.0, 'fp': 1426.0, 'tn': 3592.0, 'fn': 2336.0, 'accuracy': 0.6255971193313599, 'precision': 0.6538835167884827, 'recall': 0.5355864763259888, 'auc': 0.6603596806526184} \n",
            "314/689 [============>.................] - ETA: 28s - loss: 0.6516 - tp: 2694.0000 - fp: 1426.0000 - tn: 3592.0000 - fn: 2336.0000 - accuracy: 0.6256 - precision: 0.6539 - recall: 0.5356 - auc: 0.6604\n",
            " For Batch Number 315 the model has a loss of {'loss': 0.6516088843345642, 'tp': 2708.0, 'fp': 1444.0, 'tn': 3592.0, 'fn': 2336.0, 'accuracy': 0.625, 'precision': 0.6522157788276672, 'recall': 0.5368754863739014, 'auc': 0.6601893901824951} \n",
            "315/689 [============>.................] - ETA: 28s - loss: 0.6516 - tp: 2708.0000 - fp: 1444.0000 - tn: 3592.0000 - fn: 2336.0000 - accuracy: 0.6250 - precision: 0.6522 - recall: 0.5369 - auc: 0.6602\n",
            " For Batch Number 316 the model has a loss of {'loss': 0.6514448523521423, 'tp': 2719.0, 'fp': 1446.0, 'tn': 3605.0, 'fn': 2342.0, 'accuracy': 0.6253955960273743, 'precision': 0.6528211236000061, 'recall': 0.5372456312179565, 'auc': 0.6604561805725098} \n",
            "316/689 [============>.................] - ETA: 28s - loss: 0.6514 - tp: 2719.0000 - fp: 1446.0000 - tn: 3605.0000 - fn: 2342.0000 - accuracy: 0.6254 - precision: 0.6528 - recall: 0.5372 - auc: 0.6605\n",
            " For Batch Number 317 the model has a loss of {'loss': 0.651321530342102, 'tp': 2726.0, 'fp': 1447.0, 'tn': 3619.0, 'fn': 2352.0, 'accuracy': 0.6254929304122925, 'precision': 0.653247058391571, 'recall': 0.5368255376815796, 'auc': 0.6607654094696045} \n",
            "317/689 [============>.................] - ETA: 28s - loss: 0.6513 - tp: 2726.0000 - fp: 1447.0000 - tn: 3619.0000 - fn: 2352.0000 - accuracy: 0.6255 - precision: 0.6532 - recall: 0.5368 - auc: 0.6608\n",
            " For Batch Number 318 the model has a loss of {'loss': 0.651311993598938, 'tp': 2731.0, 'fp': 1449.0, 'tn': 3634.0, 'fn': 2362.0, 'accuracy': 0.6254913806915283, 'precision': 0.6533492803573608, 'recall': 0.536226212978363, 'auc': 0.6608669757843018} \n",
            "318/689 [============>.................] - ETA: 28s - loss: 0.6513 - tp: 2731.0000 - fp: 1449.0000 - tn: 3634.0000 - fn: 2362.0000 - accuracy: 0.6255 - precision: 0.6533 - recall: 0.5362 - auc: 0.6609\n",
            " For Batch Number 319 the model has a loss of {'loss': 0.6515912413597107, 'tp': 2736.0, 'fp': 1451.0, 'tn': 3647.0, 'fn': 2374.0, 'accuracy': 0.6252939105033875, 'precision': 0.653451144695282, 'recall': 0.5354207158088684, 'auc': 0.6607351899147034} \n",
            "\n",
            " For Batch Number 320 the model has a loss of {'loss': 0.6515842080116272, 'tp': 2744.0, 'fp': 1452.0, 'tn': 3659.0, 'fn': 2385.0, 'accuracy': 0.625292956829071, 'precision': 0.6539561748504639, 'recall': 0.5349970459938049, 'auc': 0.6606229543685913} \n",
            "320/689 [============>.................] - ETA: 28s - loss: 0.6516 - tp: 2744.0000 - fp: 1452.0000 - tn: 3659.0000 - fn: 2385.0000 - accuracy: 0.6253 - precision: 0.6540 - recall: 0.5350 - auc: 0.6606\n",
            " For Batch Number 321 the model has a loss of {'loss': 0.6515825986862183, 'tp': 2751.0, 'fp': 1457.0, 'tn': 3671.0, 'fn': 2393.0, 'accuracy': 0.6251947283744812, 'precision': 0.6537547707557678, 'recall': 0.5347978472709656, 'auc': 0.660517692565918} \n",
            "321/689 [============>.................] - ETA: 28s - loss: 0.6516 - tp: 2751.0000 - fp: 1457.0000 - tn: 3671.0000 - fn: 2393.0000 - accuracy: 0.6252 - precision: 0.6538 - recall: 0.5348 - auc: 0.6605\n",
            " For Batch Number 322 the model has a loss of {'loss': 0.6515690088272095, 'tp': 2762.0, 'fp': 1461.0, 'tn': 3685.0, 'fn': 2396.0, 'accuracy': 0.6256793737411499, 'precision': 0.6540374159812927, 'recall': 0.5354788899421692, 'auc': 0.660599410533905} \n",
            "322/689 [=============>................] - ETA: 28s - loss: 0.6516 - tp: 2762.0000 - fp: 1461.0000 - tn: 3685.0000 - fn: 2396.0000 - accuracy: 0.6257 - precision: 0.6540 - recall: 0.5355 - auc: 0.6606\n",
            " For Batch Number 323 the model has a loss of {'loss': 0.6515800356864929, 'tp': 2775.0, 'fp': 1464.0, 'tn': 3693.0, 'fn': 2404.0, 'accuracy': 0.6257739663124084, 'precision': 0.6546355485916138, 'recall': 0.5358177423477173, 'auc': 0.6608707308769226} \n",
            "323/689 [=============>................] - ETA: 27s - loss: 0.6516 - tp: 2775.0000 - fp: 1464.0000 - tn: 3693.0000 - fn: 2404.0000 - accuracy: 0.6258 - precision: 0.6546 - recall: 0.5358 - auc: 0.6609\n",
            " For Batch Number 324 the model has a loss of {'loss': 0.6520897746086121, 'tp': 2781.0, 'fp': 1475.0, 'tn': 3706.0, 'fn': 2406.0, 'accuracy': 0.6256751418113708, 'precision': 0.6534304618835449, 'recall': 0.5361480712890625, 'auc': 0.6601914167404175} \n",
            "324/689 [=============>................] - ETA: 27s - loss: 0.6521 - tp: 2781.0000 - fp: 1475.0000 - tn: 3706.0000 - fn: 2406.0000 - accuracy: 0.6257 - precision: 0.6534 - recall: 0.5361 - auc: 0.6602\n",
            " For Batch Number 325 the model has a loss of {'loss': 0.6517953872680664, 'tp': 2793.0, 'fp': 1477.0, 'tn': 3717.0, 'fn': 2413.0, 'accuracy': 0.6259615421295166, 'precision': 0.6540983319282532, 'recall': 0.5364963412284851, 'auc': 0.6604992747306824} \n",
            "325/689 [=============>................] - ETA: 27s - loss: 0.6518 - tp: 2793.0000 - fp: 1477.0000 - tn: 3717.0000 - fn: 2413.0000 - accuracy: 0.6260 - precision: 0.6541 - recall: 0.5365 - auc: 0.6605\n",
            " For Batch Number 326 the model has a loss of {'loss': 0.651373028755188, 'tp': 2805.0, 'fp': 1478.0, 'tn': 3730.0, 'fn': 2419.0, 'accuracy': 0.6264379024505615, 'precision': 0.6549147963523865, 'recall': 0.5369448661804199, 'auc': 0.661034882068634} \n",
            "326/689 [=============>................] - ETA: 27s - loss: 0.6514 - tp: 2805.0000 - fp: 1478.0000 - tn: 3730.0000 - fn: 2419.0000 - accuracy: 0.6264 - precision: 0.6549 - recall: 0.5369 - auc: 0.6610\n",
            " For Batch Number 327 the model has a loss of {'loss': 0.651358962059021, 'tp': 2810.0, 'fp': 1482.0, 'tn': 3745.0, 'fn': 2427.0, 'accuracy': 0.6264334917068481, 'precision': 0.6547064185142517, 'recall': 0.5365667343139648, 'auc': 0.6610795855522156} \n",
            "327/689 [=============>................] - ETA: 27s - loss: 0.6514 - tp: 2810.0000 - fp: 1482.0000 - tn: 3745.0000 - fn: 2427.0000 - accuracy: 0.6264 - precision: 0.6547 - recall: 0.5366 - auc: 0.6611\n",
            " For Batch Number 328 the model has a loss of {'loss': 0.6506885290145874, 'tp': 2818.0, 'fp': 1482.0, 'tn': 3765.0, 'fn': 2431.0, 'accuracy': 0.6271913051605225, 'precision': 0.6553488373756409, 'recall': 0.536864161491394, 'auc': 0.6620578765869141} \n",
            "328/689 [=============>................] - ETA: 27s - loss: 0.6507 - tp: 2818.0000 - fp: 1482.0000 - tn: 3765.0000 - fn: 2431.0000 - accuracy: 0.6272 - precision: 0.6553 - recall: 0.5369 - auc: 0.6621\n",
            " For Batch Number 329 the model has a loss of {'loss': 0.6504452228546143, 'tp': 2822.0, 'fp': 1488.0, 'tn': 3782.0, 'fn': 2436.0, 'accuracy': 0.6272796392440796, 'precision': 0.6547563672065735, 'recall': 0.5367059707641602, 'auc': 0.6623706817626953} \n",
            "329/689 [=============>................] - ETA: 27s - loss: 0.6504 - tp: 2822.0000 - fp: 1488.0000 - tn: 3782.0000 - fn: 2436.0000 - accuracy: 0.6273 - precision: 0.6548 - recall: 0.5367 - auc: 0.6624\n",
            " For Batch Number 330 the model has a loss of {'loss': 0.6505025029182434, 'tp': 2826.0, 'fp': 1494.0, 'tn': 3797.0, 'fn': 2443.0, 'accuracy': 0.6271780133247375, 'precision': 0.6541666388511658, 'recall': 0.5363446474075317, 'auc': 0.6623689532279968} \n",
            "330/689 [=============>................] - ETA: 27s - loss: 0.6505 - tp: 2826.0000 - fp: 1494.0000 - tn: 3797.0000 - fn: 2443.0000 - accuracy: 0.6272 - precision: 0.6542 - recall: 0.5363 - auc: 0.6624\n",
            " For Batch Number 331 the model has a loss of {'loss': 0.6509618759155273, 'tp': 2833.0, 'fp': 1495.0, 'tn': 3810.0, 'fn': 2454.0, 'accuracy': 0.6271714568138123, 'precision': 0.6545748710632324, 'recall': 0.5358426570892334, 'auc': 0.6620096564292908} \n",
            "331/689 [=============>................] - ETA: 27s - loss: 0.6510 - tp: 2833.0000 - fp: 1495.0000 - tn: 3810.0000 - fn: 2454.0000 - accuracy: 0.6272 - precision: 0.6546 - recall: 0.5358 - auc: 0.6620\n",
            " For Batch Number 332 the model has a loss of {'loss': 0.6510844230651855, 'tp': 2840.0, 'fp': 1495.0, 'tn': 3824.0, 'fn': 2465.0, 'accuracy': 0.6272590160369873, 'precision': 0.6551326513290405, 'recall': 0.5353440046310425, 'auc': 0.6619616150856018} \n",
            "332/689 [=============>................] - ETA: 27s - loss: 0.6511 - tp: 2840.0000 - fp: 1495.0000 - tn: 3824.0000 - fn: 2465.0000 - accuracy: 0.6273 - precision: 0.6551 - recall: 0.5353 - auc: 0.6620\n",
            " For Batch Number 333 the model has a loss of {'loss': 0.6512953639030457, 'tp': 2846.0, 'fp': 1497.0, 'tn': 3836.0, 'fn': 2477.0, 'accuracy': 0.62706458568573, 'precision': 0.655307412147522, 'recall': 0.5346608757972717, 'auc': 0.6614501476287842} \n",
            "333/689 [=============>................] - ETA: 27s - loss: 0.6513 - tp: 2846.0000 - fp: 1497.0000 - tn: 3836.0000 - fn: 2477.0000 - accuracy: 0.6271 - precision: 0.6553 - recall: 0.5347 - auc: 0.6615\n",
            " For Batch Number 334 the model has a loss of {'loss': 0.6515426635742188, 'tp': 2854.0, 'fp': 1503.0, 'tn': 3845.0, 'fn': 2486.0, 'accuracy': 0.626777708530426, 'precision': 0.6550378799438477, 'recall': 0.5344569087028503, 'auc': 0.6610642075538635} \n",
            "334/689 [=============>................] - ETA: 27s - loss: 0.6515 - tp: 2854.0000 - fp: 1503.0000 - tn: 3845.0000 - fn: 2486.0000 - accuracy: 0.6268 - precision: 0.6550 - recall: 0.5345 - auc: 0.6611\n",
            " For Batch Number 335 the model has a loss of {'loss': 0.6519813537597656, 'tp': 2867.0, 'fp': 1516.0, 'tn': 3847.0, 'fn': 2490.0, 'accuracy': 0.6263059973716736, 'precision': 0.6541181802749634, 'recall': 0.5351876020431519, 'auc': 0.6607287526130676} \n",
            "335/689 [=============>................] - ETA: 27s - loss: 0.6520 - tp: 2867.0000 - fp: 1516.0000 - tn: 3847.0000 - fn: 2490.0000 - accuracy: 0.6263 - precision: 0.6541 - recall: 0.5352 - auc: 0.6607\n",
            " For Batch Number 336 the model has a loss of {'loss': 0.6522064208984375, 'tp': 2885.0, 'fp': 1530.0, 'tn': 3847.0, 'fn': 2490.0, 'accuracy': 0.6261160969734192, 'precision': 0.6534541249275208, 'recall': 0.5367441773414612, 'auc': 0.6606782674789429} \n",
            "336/689 [=============>................] - ETA: 27s - loss: 0.6522 - tp: 2885.0000 - fp: 1530.0000 - tn: 3847.0000 - fn: 2490.0000 - accuracy: 0.6261 - precision: 0.6535 - recall: 0.5367 - auc: 0.6607\n",
            " For Batch Number 337 the model has a loss of {'loss': 0.6526070237159729, 'tp': 2896.0, 'fp': 1547.0, 'tn': 3849.0, 'fn': 2492.0, 'accuracy': 0.6254636645317078, 'precision': 0.6518118381500244, 'recall': 0.537490725517273, 'auc': 0.6601412892341614} \n",
            "337/689 [=============>................] - ETA: 27s - loss: 0.6526 - tp: 2896.0000 - fp: 1547.0000 - tn: 3849.0000 - fn: 2492.0000 - accuracy: 0.6255 - precision: 0.6518 - recall: 0.5375 - auc: 0.6601\n",
            " For Batch Number 338 the model has a loss of {'loss': 0.6524737477302551, 'tp': 2903.0, 'fp': 1549.0, 'tn': 3864.0, 'fn': 2500.0, 'accuracy': 0.6256471872329712, 'precision': 0.6520664691925049, 'recall': 0.5372940897941589, 'auc': 0.6602149605751038} \n",
            "338/689 [=============>................] - ETA: 27s - loss: 0.6525 - tp: 2903.0000 - fp: 1549.0000 - tn: 3864.0000 - fn: 2500.0000 - accuracy: 0.6256 - precision: 0.6521 - recall: 0.5373 - auc: 0.6602\n",
            " For Batch Number 339 the model has a loss of {'loss': 0.6528832316398621, 'tp': 2905.0, 'fp': 1549.0, 'tn': 3876.0, 'fn': 2518.0, 'accuracy': 0.6250922083854675, 'precision': 0.6522226929664612, 'recall': 0.5356813669204712, 'auc': 0.659547746181488} \n",
            "339/689 [=============>................] - ETA: 27s - loss: 0.6529 - tp: 2905.0000 - fp: 1549.0000 - tn: 3876.0000 - fn: 2518.0000 - accuracy: 0.6251 - precision: 0.6522 - recall: 0.5357 - auc: 0.6595\n",
            " For Batch Number 340 the model has a loss of {'loss': 0.6528640389442444, 'tp': 2911.0, 'fp': 1549.0, 'tn': 3891.0, 'fn': 2529.0, 'accuracy': 0.6251838207244873, 'precision': 0.652690589427948, 'recall': 0.5351102948188782, 'auc': 0.659614086151123} \n",
            "340/689 [=============>................] - ETA: 27s - loss: 0.6529 - tp: 2911.0000 - fp: 1549.0000 - tn: 3891.0000 - fn: 2529.0000 - accuracy: 0.6252 - precision: 0.6527 - recall: 0.5351 - auc: 0.6596\n",
            " For Batch Number 341 the model has a loss of {'loss': 0.6531402468681335, 'tp': 2917.0, 'fp': 1550.0, 'tn': 3901.0, 'fn': 2544.0, 'accuracy': 0.6248167157173157, 'precision': 0.6530109643936157, 'recall': 0.5341512560844421, 'auc': 0.6591538190841675} \n",
            "341/689 [=============>................] - ETA: 27s - loss: 0.6531 - tp: 2917.0000 - fp: 1550.0000 - tn: 3901.0000 - fn: 2544.0000 - accuracy: 0.6248 - precision: 0.6530 - recall: 0.5342 - auc: 0.6592\n",
            " For Batch Number 342 the model has a loss of {'loss': 0.6535276174545288, 'tp': 2922.0, 'fp': 1558.0, 'tn': 3913.0, 'fn': 2551.0, 'accuracy': 0.6245431303977966, 'precision': 0.6522321701049805, 'recall': 0.5338936448097229, 'auc': 0.6585798859596252} \n",
            "342/689 [=============>................] - ETA: 27s - loss: 0.6535 - tp: 2922.0000 - fp: 1558.0000 - tn: 3913.0000 - fn: 2551.0000 - accuracy: 0.6245 - precision: 0.6522 - recall: 0.5339 - auc: 0.6586\n",
            " For Batch Number 343 the model has a loss of {'loss': 0.6535175442695618, 'tp': 2930.0, 'fp': 1567.0, 'tn': 3921.0, 'fn': 2558.0, 'accuracy': 0.624180018901825, 'precision': 0.6515454649925232, 'recall': 0.5338921546936035, 'auc': 0.6584288477897644} \n",
            "343/689 [=============>................] - ETA: 27s - loss: 0.6535 - tp: 2930.0000 - fp: 1567.0000 - tn: 3921.0000 - fn: 2558.0000 - accuracy: 0.6242 - precision: 0.6515 - recall: 0.5339 - auc: 0.6584\n",
            " For Batch Number 344 the model has a loss of {'loss': 0.653458297252655, 'tp': 2938.0, 'fp': 1574.0, 'tn': 3932.0, 'fn': 2564.0, 'accuracy': 0.6240915656089783, 'precision': 0.651152491569519, 'recall': 0.5339876413345337, 'auc': 0.6583548188209534} \n",
            "344/689 [=============>................] - ETA: 27s - loss: 0.6535 - tp: 2938.0000 - fp: 1574.0000 - tn: 3932.0000 - fn: 2564.0000 - accuracy: 0.6241 - precision: 0.6512 - recall: 0.5340 - auc: 0.6584\n",
            " For Batch Number 345 the model has a loss of {'loss': 0.6533389091491699, 'tp': 2944.0, 'fp': 1578.0, 'tn': 3946.0, 'fn': 2572.0, 'accuracy': 0.6240941882133484, 'precision': 0.6510393619537354, 'recall': 0.533720076084137, 'auc': 0.6585156321525574} \n",
            "345/689 [==============>...............] - ETA: 27s - loss: 0.6533 - tp: 2944.0000 - fp: 1578.0000 - tn: 3946.0000 - fn: 2572.0000 - accuracy: 0.6241 - precision: 0.6510 - recall: 0.5337 - auc: 0.6585\n",
            " For Batch Number 346 the model has a loss of {'loss': 0.6530808210372925, 'tp': 2949.0, 'fp': 1578.0, 'tn': 3966.0, 'fn': 2579.0, 'accuracy': 0.6245484352111816, 'precision': 0.651424765586853, 'recall': 0.5334659814834595, 'auc': 0.658927321434021} \n",
            "346/689 [==============>...............] - ETA: 27s - loss: 0.6531 - tp: 2949.0000 - fp: 1578.0000 - tn: 3966.0000 - fn: 2579.0000 - accuracy: 0.6245 - precision: 0.6514 - recall: 0.5335 - auc: 0.6589\n",
            " For Batch Number 347 the model has a loss of {'loss': 0.6532461047172546, 'tp': 2950.0, 'fp': 1579.0, 'tn': 3983.0, 'fn': 2592.0, 'accuracy': 0.6243696212768555, 'precision': 0.651357889175415, 'recall': 0.5322988033294678, 'auc': 0.6588326096534729} \n",
            "347/689 [==============>...............] - ETA: 28s - loss: 0.6532 - tp: 2950.0000 - fp: 1579.0000 - tn: 3983.0000 - fn: 2592.0000 - accuracy: 0.6244 - precision: 0.6514 - recall: 0.5323 - auc: 0.6588\n",
            " For Batch Number 348 the model has a loss of {'loss': 0.6529255509376526, 'tp': 2952.0, 'fp': 1579.0, 'tn': 4004.0, 'fn': 2601.0, 'accuracy': 0.6246408224105835, 'precision': 0.6515117883682251, 'recall': 0.531604528427124, 'auc': 0.6594365835189819} \n",
            "348/689 [==============>...............] - ETA: 28s - loss: 0.6529 - tp: 2952.0000 - fp: 1579.0000 - tn: 4004.0000 - fn: 2601.0000 - accuracy: 0.6246 - precision: 0.6515 - recall: 0.5316 - auc: 0.6594\n",
            " For Batch Number 349 the model has a loss of {'loss': 0.6531169414520264, 'tp': 2958.0, 'fp': 1581.0, 'tn': 4018.0, 'fn': 2611.0, 'accuracy': 0.6246418356895447, 'precision': 0.6516854166984558, 'recall': 0.5311546325683594, 'auc': 0.6592234969139099} \n",
            "349/689 [==============>...............] - ETA: 28s - loss: 0.6531 - tp: 2958.0000 - fp: 1581.0000 - tn: 4018.0000 - fn: 2611.0000 - accuracy: 0.6246 - precision: 0.6517 - recall: 0.5312 - auc: 0.6592\n",
            " For Batch Number 350 the model has a loss of {'loss': 0.6530413031578064, 'tp': 2964.0, 'fp': 1584.0, 'tn': 4032.0, 'fn': 2620.0, 'accuracy': 0.6246428489685059, 'precision': 0.6517150402069092, 'recall': 0.530802309513092, 'auc': 0.6592566967010498} \n",
            "350/689 [==============>...............] - ETA: 28s - loss: 0.6530 - tp: 2964.0000 - fp: 1584.0000 - tn: 4032.0000 - fn: 2620.0000 - accuracy: 0.6246 - precision: 0.6517 - recall: 0.5308 - auc: 0.6593\n",
            " For Batch Number 351 the model has a loss of {'loss': 0.6529670357704163, 'tp': 2972.0, 'fp': 1588.0, 'tn': 4041.0, 'fn': 2631.0, 'accuracy': 0.6243767738342285, 'precision': 0.6517543792724609, 'recall': 0.5304301381111145, 'auc': 0.6593155264854431} \n",
            "351/689 [==============>...............] - ETA: 28s - loss: 0.6530 - tp: 2972.0000 - fp: 1588.0000 - tn: 4041.0000 - fn: 2631.0000 - accuracy: 0.6244 - precision: 0.6518 - recall: 0.5304 - auc: 0.6593\n",
            " For Batch Number 352 the model has a loss of {'loss': 0.6532387137413025, 'tp': 2984.0, 'fp': 1607.0, 'tn': 4041.0, 'fn': 2632.0, 'accuracy': 0.6236683130264282, 'precision': 0.6499673128128052, 'recall': 0.5313390493392944, 'auc': 0.6589142680168152} \n",
            "352/689 [==============>...............] - ETA: 28s - loss: 0.6532 - tp: 2984.0000 - fp: 1607.0000 - tn: 4041.0000 - fn: 2632.0000 - accuracy: 0.6237 - precision: 0.6500 - recall: 0.5313 - auc: 0.6589\n",
            " For Batch Number 353 the model has a loss of {'loss': 0.6529418230056763, 'tp': 3002.0, 'fp': 1615.0, 'tn': 4045.0, 'fn': 2634.0, 'accuracy': 0.6238491535186768, 'precision': 0.6502057909965515, 'recall': 0.5326472520828247, 'auc': 0.6592943072319031} \n",
            "353/689 [==============>...............] - ETA: 28s - loss: 0.6529 - tp: 3002.0000 - fp: 1615.0000 - tn: 4045.0000 - fn: 2634.0000 - accuracy: 0.6238 - precision: 0.6502 - recall: 0.5326 - auc: 0.6593\n",
            " For Batch Number 354 the model has a loss of {'loss': 0.6526496410369873, 'tp': 3014.0, 'fp': 1619.0, 'tn': 4057.0, 'fn': 2638.0, 'accuracy': 0.6242055296897888, 'precision': 0.6505504250526428, 'recall': 0.5332625508308411, 'auc': 0.6595717668533325} \n",
            "354/689 [==============>...............] - ETA: 28s - loss: 0.6526 - tp: 3014.0000 - fp: 1619.0000 - tn: 4057.0000 - fn: 2638.0000 - accuracy: 0.6242 - precision: 0.6506 - recall: 0.5333 - auc: 0.6596\n",
            " For Batch Number 355 the model has a loss of {'loss': 0.6523961424827576, 'tp': 3023.0, 'fp': 1623.0, 'tn': 4070.0, 'fn': 2644.0, 'accuracy': 0.624383807182312, 'precision': 0.6506672501564026, 'recall': 0.5334392189979553, 'auc': 0.6598845720291138} \n",
            "355/689 [==============>...............] - ETA: 27s - loss: 0.6524 - tp: 3023.0000 - fp: 1623.0000 - tn: 4070.0000 - fn: 2644.0000 - accuracy: 0.6244 - precision: 0.6507 - recall: 0.5334 - auc: 0.6599\n",
            " For Batch Number 356 the model has a loss of {'loss': 0.6527396440505981, 'tp': 3030.0, 'fp': 1624.0, 'tn': 4080.0, 'fn': 2658.0, 'accuracy': 0.6241222023963928, 'precision': 0.6510528326034546, 'recall': 0.5327004194259644, 'auc': 0.6594303846359253} \n",
            "356/689 [==============>...............] - ETA: 27s - loss: 0.6527 - tp: 3030.0000 - fp: 1624.0000 - tn: 4080.0000 - fn: 2658.0000 - accuracy: 0.6241 - precision: 0.6511 - recall: 0.5327 - auc: 0.6594\n",
            " For Batch Number 357 the model has a loss of {'loss': 0.6523459553718567, 'tp': 3039.0, 'fp': 1625.0, 'tn': 4097.0, 'fn': 2663.0, 'accuracy': 0.6246498823165894, 'precision': 0.6515865921974182, 'recall': 0.5329709053039551, 'auc': 0.6600126624107361} \n",
            "357/689 [==============>...............] - ETA: 27s - loss: 0.6523 - tp: 3039.0000 - fp: 1625.0000 - tn: 4097.0000 - fn: 2663.0000 - accuracy: 0.6246 - precision: 0.6516 - recall: 0.5330 - auc: 0.6600\n",
            " For Batch Number 358 the model has a loss of {'loss': 0.6524155735969543, 'tp': 3044.0, 'fp': 1628.0, 'tn': 4108.0, 'fn': 2676.0, 'accuracy': 0.6243016719818115, 'precision': 0.6515411138534546, 'recall': 0.5321678519248962, 'auc': 0.6597582697868347} \n",
            "358/689 [==============>...............] - ETA: 27s - loss: 0.6524 - tp: 3044.0000 - fp: 1628.0000 - tn: 4108.0000 - fn: 2676.0000 - accuracy: 0.6243 - precision: 0.6515 - recall: 0.5322 - auc: 0.6598\n",
            " For Batch Number 359 the model has a loss of {'loss': 0.6523468494415283, 'tp': 3053.0, 'fp': 1630.0, 'tn': 4118.0, 'fn': 2687.0, 'accuracy': 0.6242165565490723, 'precision': 0.6519325375556946, 'recall': 0.5318815112113953, 'auc': 0.6599224805831909} \n",
            "359/689 [==============>...............] - ETA: 27s - loss: 0.6523 - tp: 3053.0000 - fp: 1630.0000 - tn: 4118.0000 - fn: 2687.0000 - accuracy: 0.6242 - precision: 0.6519 - recall: 0.5319 - auc: 0.6599\n",
            " For Batch Number 360 the model has a loss of {'loss': 0.6525065302848816, 'tp': 3063.0, 'fp': 1640.0, 'tn': 4123.0, 'fn': 2694.0, 'accuracy': 0.6237847208976746, 'precision': 0.6512864232063293, 'recall': 0.5320479273796082, 'auc': 0.6597294807434082} \n",
            "360/689 [==============>...............] - ETA: 27s - loss: 0.6525 - tp: 3063.0000 - fp: 1640.0000 - tn: 4123.0000 - fn: 2694.0000 - accuracy: 0.6238 - precision: 0.6513 - recall: 0.5320 - auc: 0.6597\n",
            " For Batch Number 361 the model has a loss of {'loss': 0.652104914188385, 'tp': 3080.0, 'fp': 1648.0, 'tn': 4128.0, 'fn': 2696.0, 'accuracy': 0.6239612102508545, 'precision': 0.6514382362365723, 'recall': 0.5332409739494324, 'auc': 0.6602070927619934} \n",
            "361/689 [==============>...............] - ETA: 27s - loss: 0.6521 - tp: 3080.0000 - fp: 1648.0000 - tn: 4128.0000 - fn: 2696.0000 - accuracy: 0.6240 - precision: 0.6514 - recall: 0.5332 - auc: 0.6602\n",
            " For Batch Number 362 the model has a loss of {'loss': 0.6519026160240173, 'tp': 3093.0, 'fp': 1656.0, 'tn': 4135.0, 'fn': 2700.0, 'accuracy': 0.6239640712738037, 'precision': 0.651295006275177, 'recall': 0.5339202284812927, 'auc': 0.6603932976722717} \n",
            "362/689 [==============>...............] - ETA: 27s - loss: 0.6519 - tp: 3093.0000 - fp: 1656.0000 - tn: 4135.0000 - fn: 2700.0000 - accuracy: 0.6240 - precision: 0.6513 - recall: 0.5339 - auc: 0.6604\n",
            " For Batch Number 363 the model has a loss of {'loss': 0.6519768834114075, 'tp': 3103.0, 'fp': 1667.0, 'tn': 4145.0, 'fn': 2701.0, 'accuracy': 0.6239669322967529, 'precision': 0.6505240797996521, 'recall': 0.5346313118934631, 'auc': 0.6603516340255737} \n",
            "363/689 [==============>...............] - ETA: 27s - loss: 0.6520 - tp: 3103.0000 - fp: 1667.0000 - tn: 4145.0000 - fn: 2701.0000 - accuracy: 0.6240 - precision: 0.6505 - recall: 0.5346 - auc: 0.6604\n",
            " For Batch Number 364 the model has a loss of {'loss': 0.6524509191513062, 'tp': 3113.0, 'fp': 1675.0, 'tn': 4151.0, 'fn': 2709.0, 'accuracy': 0.6236263513565063, 'precision': 0.6501671075820923, 'recall': 0.5346959829330444, 'auc': 0.659832775592804} \n",
            "364/689 [==============>...............] - ETA: 27s - loss: 0.6525 - tp: 3113.0000 - fp: 1675.0000 - tn: 4151.0000 - fn: 2709.0000 - accuracy: 0.6236 - precision: 0.6502 - recall: 0.5347 - auc: 0.6598\n",
            " For Batch Number 365 the model has a loss of {'loss': 0.65241539478302, 'tp': 3118.0, 'fp': 1682.0, 'tn': 4166.0, 'fn': 2714.0, 'accuracy': 0.623630166053772, 'precision': 0.6495833396911621, 'recall': 0.5346364974975586, 'auc': 0.6599277257919312} \n",
            "365/689 [==============>...............] - ETA: 27s - loss: 0.6524 - tp: 3118.0000 - fp: 1682.0000 - tn: 4166.0000 - fn: 2714.0000 - accuracy: 0.6236 - precision: 0.6496 - recall: 0.5346 - auc: 0.6599\n",
            " For Batch Number 366 the model has a loss of {'loss': 0.6530963182449341, 'tp': 3122.0, 'fp': 1685.0, 'tn': 4180.0, 'fn': 2725.0, 'accuracy': 0.6234630942344666, 'precision': 0.6494694948196411, 'recall': 0.5339490175247192, 'auc': 0.6594609022140503} \n",
            "366/689 [==============>...............] - ETA: 26s - loss: 0.6531 - tp: 3122.0000 - fp: 1685.0000 - tn: 4180.0000 - fn: 2725.0000 - accuracy: 0.6235 - precision: 0.6495 - recall: 0.5339 - auc: 0.6595\n",
            " For Batch Number 367 the model has a loss of {'loss': 0.6537133455276489, 'tp': 3125.0, 'fp': 1685.0, 'tn': 4194.0, 'fn': 2740.0, 'accuracy': 0.6232118606567383, 'precision': 0.6496881246566772, 'recall': 0.5328218340873718, 'auc': 0.6588215231895447} \n",
            "367/689 [==============>...............] - ETA: 26s - loss: 0.6537 - tp: 3125.0000 - fp: 1685.0000 - tn: 4194.0000 - fn: 2740.0000 - accuracy: 0.6232 - precision: 0.6497 - recall: 0.5328 - auc: 0.6588\n",
            " For Batch Number 368 the model has a loss of {'loss': 0.6534513831138611, 'tp': 3129.0, 'fp': 1685.0, 'tn': 4214.0, 'fn': 2748.0, 'accuracy': 0.62355637550354, 'precision': 0.6499792337417603, 'recall': 0.5324144959449768, 'auc': 0.6591841578483582} \n",
            "368/689 [===============>..............] - ETA: 26s - loss: 0.6535 - tp: 3129.0000 - fp: 1685.0000 - tn: 4214.0000 - fn: 2748.0000 - accuracy: 0.6236 - precision: 0.6500 - recall: 0.5324 - auc: 0.6592\n",
            " For Batch Number 369 the model has a loss of {'loss': 0.6535037159919739, 'tp': 3132.0, 'fp': 1687.0, 'tn': 4230.0, 'fn': 2759.0, 'accuracy': 0.6234756112098694, 'precision': 0.6499273777008057, 'recall': 0.5316584706306458, 'auc': 0.6590721011161804} \n",
            "369/689 [===============>..............] - ETA: 26s - loss: 0.6535 - tp: 3132.0000 - fp: 1687.0000 - tn: 4230.0000 - fn: 2759.0000 - accuracy: 0.6235 - precision: 0.6499 - recall: 0.5317 - auc: 0.6591\n",
            " For Batch Number 370 the model has a loss of {'loss': 0.6534605026245117, 'tp': 3142.0, 'fp': 1689.0, 'tn': 4238.0, 'fn': 2771.0, 'accuracy': 0.6233108043670654, 'precision': 0.650382936000824, 'recall': 0.531371533870697, 'auc': 0.659212052822113} \n",
            "370/689 [===============>..............] - ETA: 26s - loss: 0.6535 - tp: 3142.0000 - fp: 1689.0000 - tn: 4238.0000 - fn: 2771.0000 - accuracy: 0.6233 - precision: 0.6504 - recall: 0.5314 - auc: 0.6592\n",
            " For Batch Number 371 the model has a loss of {'loss': 0.6534613966941833, 'tp': 3158.0, 'fp': 1704.0, 'tn': 4239.0, 'fn': 2771.0, 'accuracy': 0.6230626702308655, 'precision': 0.6495269536972046, 'recall': 0.5326361656188965, 'auc': 0.659151554107666} \n",
            "371/689 [===============>..............] - ETA: 26s - loss: 0.6535 - tp: 3158.0000 - fp: 1704.0000 - tn: 4239.0000 - fn: 2771.0000 - accuracy: 0.6231 - precision: 0.6495 - recall: 0.5326 - auc: 0.6592\n",
            " For Batch Number 372 the model has a loss of {'loss': 0.6534717082977295, 'tp': 3175.0, 'fp': 1719.0, 'tn': 4239.0, 'fn': 2771.0, 'accuracy': 0.6228158473968506, 'precision': 0.6487535834312439, 'recall': 0.533972442150116, 'auc': 0.6591143012046814} \n",
            "372/689 [===============>..............] - ETA: 26s - loss: 0.6535 - tp: 3175.0000 - fp: 1719.0000 - tn: 4239.0000 - fn: 2771.0000 - accuracy: 0.6228 - precision: 0.6488 - recall: 0.5340 - auc: 0.6591\n",
            " For Batch Number 373 the model has a loss of {'loss': 0.6536985039710999, 'tp': 3191.0, 'fp': 1735.0, 'tn': 4239.0, 'fn': 2771.0, 'accuracy': 0.6224865913391113, 'precision': 0.6477872729301453, 'recall': 0.5352230668067932, 'auc': 0.6588883996009827} \n",
            "373/689 [===============>..............] - ETA: 26s - loss: 0.6537 - tp: 3191.0000 - fp: 1735.0000 - tn: 4239.0000 - fn: 2771.0000 - accuracy: 0.6225 - precision: 0.6478 - recall: 0.5352 - auc: 0.6589\n",
            " For Batch Number 374 the model has a loss of {'loss': 0.653949499130249, 'tp': 3202.0, 'fp': 1755.0, 'tn': 4239.0, 'fn': 2772.0, 'accuracy': 0.6217412948608398, 'precision': 0.6459552049636841, 'recall': 0.5359892845153809, 'auc': 0.6584405303001404} \n",
            "374/689 [===============>..............] - ETA: 26s - loss: 0.6539 - tp: 3202.0000 - fp: 1755.0000 - tn: 4239.0000 - fn: 2772.0000 - accuracy: 0.6217 - precision: 0.6460 - recall: 0.5360 - auc: 0.6584\n",
            " For Batch Number 375 the model has a loss of {'loss': 0.6540428996086121, 'tp': 3210.0, 'fp': 1757.0, 'tn': 4247.0, 'fn': 2786.0, 'accuracy': 0.6214166879653931, 'precision': 0.6462653279304504, 'recall': 0.535356879234314, 'auc': 0.658328115940094} \n",
            "375/689 [===============>..............] - ETA: 26s - loss: 0.6540 - tp: 3210.0000 - fp: 1757.0000 - tn: 4247.0000 - fn: 2786.0000 - accuracy: 0.6214 - precision: 0.6463 - recall: 0.5354 - auc: 0.6583\n",
            " For Batch Number 376 the model has a loss of {'loss': 0.6542519330978394, 'tp': 3211.0, 'fp': 1761.0, 'tn': 4258.0, 'fn': 2802.0, 'accuracy': 0.6207612752914429, 'precision': 0.6458165645599365, 'recall': 0.5340096354484558, 'auc': 0.6579258441925049} \n",
            "376/689 [===============>..............] - ETA: 26s - loss: 0.6543 - tp: 3211.0000 - fp: 1761.0000 - tn: 4258.0000 - fn: 2802.0000 - accuracy: 0.6208 - precision: 0.6458 - recall: 0.5340 - auc: 0.6579\n",
            " For Batch Number 377 the model has a loss of {'loss': 0.6541330218315125, 'tp': 3215.0, 'fp': 1761.0, 'tn': 4277.0, 'fn': 2811.0, 'accuracy': 0.6210212111473083, 'precision': 0.6461012959480286, 'recall': 0.5335214138031006, 'auc': 0.6580197811126709} \n",
            "377/689 [===============>..............] - ETA: 25s - loss: 0.6541 - tp: 3215.0000 - fp: 1761.0000 - tn: 4277.0000 - fn: 2811.0000 - accuracy: 0.6210 - precision: 0.6461 - recall: 0.5335 - auc: 0.6580\n",
            " For Batch Number 378 the model has a loss of {'loss': 0.6540886759757996, 'tp': 3220.0, 'fp': 1761.0, 'tn': 4293.0, 'fn': 2822.0, 'accuracy': 0.6211144328117371, 'precision': 0.6464565396308899, 'recall': 0.5329360961914062, 'auc': 0.6580386757850647} \n",
            "\n",
            " For Batch Number 379 the model has a loss of {'loss': 0.6541380286216736, 'tp': 3226.0, 'fp': 1762.0, 'tn': 4309.0, 'fn': 2831.0, 'accuracy': 0.6212895512580872, 'precision': 0.6467521786689758, 'recall': 0.5326068997383118, 'auc': 0.6578455567359924} \n",
            "379/689 [===============>..............] - ETA: 25s - loss: 0.6541 - tp: 3226.0000 - fp: 1762.0000 - tn: 4309.0000 - fn: 2831.0000 - accuracy: 0.6213 - precision: 0.6468 - recall: 0.5326 - auc: 0.6578\n",
            " For Batch Number 380 the model has a loss of {'loss': 0.6540839672088623, 'tp': 3232.0, 'fp': 1765.0, 'tn': 4320.0, 'fn': 2843.0, 'accuracy': 0.621052622795105, 'precision': 0.6467880606651306, 'recall': 0.5320164561271667, 'auc': 0.657955527305603} \n",
            "380/689 [===============>..............] - ETA: 25s - loss: 0.6541 - tp: 3232.0000 - fp: 1765.0000 - tn: 4320.0000 - fn: 2843.0000 - accuracy: 0.6211 - precision: 0.6468 - recall: 0.5320 - auc: 0.6580\n",
            " For Batch Number 381 the model has a loss of {'loss': 0.6540231108665466, 'tp': 3245.0, 'fp': 1770.0, 'tn': 4328.0, 'fn': 2849.0, 'accuracy': 0.6211450099945068, 'precision': 0.6470588445663452, 'recall': 0.5324909687042236, 'auc': 0.6580101251602173} \n",
            "381/689 [===============>..............] - ETA: 25s - loss: 0.6540 - tp: 3245.0000 - fp: 1770.0000 - tn: 4328.0000 - fn: 2849.0000 - accuracy: 0.6211 - precision: 0.6471 - recall: 0.5325 - auc: 0.6580\n",
            " For Batch Number 382 the model has a loss of {'loss': 0.65451580286026, 'tp': 3252.0, 'fp': 1784.0, 'tn': 4336.0, 'fn': 2852.0, 'accuracy': 0.6207460761070251, 'precision': 0.6457505822181702, 'recall': 0.5327653884887695, 'auc': 0.6576130986213684} \n",
            "382/689 [===============>..............] - ETA: 25s - loss: 0.6545 - tp: 3252.0000 - fp: 1784.0000 - tn: 4336.0000 - fn: 2852.0000 - accuracy: 0.6207 - precision: 0.6458 - recall: 0.5328 - auc: 0.6576\n",
            " For Batch Number 383 the model has a loss of {'loss': 0.6545058488845825, 'tp': 3266.0, 'fp': 1794.0, 'tn': 4340.0, 'fn': 2856.0, 'accuracy': 0.6205939650535583, 'precision': 0.6454545259475708, 'recall': 0.5334857702255249, 'auc': 0.6576017141342163} \n",
            "\n",
            " For Batch Number 384 the model has a loss of {'loss': 0.6548962593078613, 'tp': 3274.0, 'fp': 1810.0, 'tn': 4345.0, 'fn': 2859.0, 'accuracy': 0.6200358271598816, 'precision': 0.6439810991287231, 'recall': 0.533833384513855, 'auc': 0.656974732875824} \n",
            "384/689 [===============>..............] - ETA: 25s - loss: 0.6549 - tp: 3274.0000 - fp: 1810.0000 - tn: 4345.0000 - fn: 2859.0000 - accuracy: 0.6200 - precision: 0.6440 - recall: 0.5338 - auc: 0.6570\n",
            " For Batch Number 385 the model has a loss of {'loss': 0.6547459363937378, 'tp': 3283.0, 'fp': 1811.0, 'tn': 4358.0, 'fn': 2868.0, 'accuracy': 0.6202110648155212, 'precision': 0.6444836854934692, 'recall': 0.5337343811988831, 'auc': 0.657089352607727} \n",
            "385/689 [===============>..............] - ETA: 25s - loss: 0.6547 - tp: 3283.0000 - fp: 1811.0000 - tn: 4358.0000 - fn: 2868.0000 - accuracy: 0.6202 - precision: 0.6445 - recall: 0.5337 - auc: 0.6571\n",
            " For Batch Number 386 the model has a loss of {'loss': 0.6548254489898682, 'tp': 3286.0, 'fp': 1814.0, 'tn': 4374.0, 'fn': 2878.0, 'accuracy': 0.6201424598693848, 'precision': 0.6443137526512146, 'recall': 0.5330954194068909, 'auc': 0.6568440794944763} \n",
            "386/689 [===============>..............] - ETA: 25s - loss: 0.6548 - tp: 3286.0000 - fp: 1814.0000 - tn: 4374.0000 - fn: 2878.0000 - accuracy: 0.6201 - precision: 0.6443 - recall: 0.5331 - auc: 0.6568\n",
            " For Batch Number 387 the model has a loss of {'loss': 0.655156672000885, 'tp': 3291.0, 'fp': 1815.0, 'tn': 4386.0, 'fn': 2892.0, 'accuracy': 0.6199128031730652, 'precision': 0.6445358395576477, 'recall': 0.5322659015655518, 'auc': 0.6563866138458252} \n",
            "387/689 [===============>..............] - ETA: 24s - loss: 0.6552 - tp: 3291.0000 - fp: 1815.0000 - tn: 4386.0000 - fn: 2892.0000 - accuracy: 0.6199 - precision: 0.6445 - recall: 0.5323 - auc: 0.6564\n",
            " For Batch Number 388 the model has a loss of {'loss': 0.654963493347168, 'tp': 3296.0, 'fp': 1815.0, 'tn': 4405.0, 'fn': 2900.0, 'accuracy': 0.6202480792999268, 'precision': 0.6448835730552673, 'recall': 0.5319560766220093, 'auc': 0.6565688252449036} \n",
            "\n",
            " For Batch Number 389 the model has a loss of {'loss': 0.6547102928161621, 'tp': 3300.0, 'fp': 1815.0, 'tn': 4425.0, 'fn': 2908.0, 'accuracy': 0.6205816268920898, 'precision': 0.6451612710952759, 'recall': 0.531572163105011, 'auc': 0.6568633913993835} \n",
            "389/689 [===============>..............] - ETA: 24s - loss: 0.6547 - tp: 3300.0000 - fp: 1815.0000 - tn: 4425.0000 - fn: 2908.0000 - accuracy: 0.6206 - precision: 0.6452 - recall: 0.5316 - auc: 0.6569\n",
            " For Batch Number 390 the model has a loss of {'loss': 0.6548171043395996, 'tp': 3304.0, 'fp': 1818.0, 'tn': 4441.0, 'fn': 2917.0, 'accuracy': 0.6205929517745972, 'precision': 0.6450605392456055, 'recall': 0.531104326248169, 'auc': 0.6567062735557556} \n",
            "390/689 [===============>..............] - ETA: 24s - loss: 0.6548 - tp: 3304.0000 - fp: 1818.0000 - tn: 4441.0000 - fn: 2917.0000 - accuracy: 0.6206 - precision: 0.6451 - recall: 0.5311 - auc: 0.6567\n",
            " For Batch Number 391 the model has a loss of {'loss': 0.6550732254981995, 'tp': 3310.0, 'fp': 1819.0, 'tn': 4449.0, 'fn': 2934.0, 'accuracy': 0.6201246976852417, 'precision': 0.6453499794006348, 'recall': 0.5301089286804199, 'auc': 0.6561962962150574} \n",
            "391/689 [================>.............] - ETA: 24s - loss: 0.6551 - tp: 3310.0000 - fp: 1819.0000 - tn: 4449.0000 - fn: 2934.0000 - accuracy: 0.6201 - precision: 0.6453 - recall: 0.5301 - auc: 0.6562\n",
            " For Batch Number 392 the model has a loss of {'loss': 0.6551355123519897, 'tp': 3317.0, 'fp': 1825.0, 'tn': 4456.0, 'fn': 2946.0, 'accuracy': 0.6196588277816772, 'precision': 0.6450797319412231, 'recall': 0.5296183824539185, 'auc': 0.6560097932815552} \n",
            "392/689 [================>.............] - ETA: 24s - loss: 0.6551 - tp: 3317.0000 - fp: 1825.0000 - tn: 4456.0000 - fn: 2946.0000 - accuracy: 0.6197 - precision: 0.6451 - recall: 0.5296 - auc: 0.6560\n",
            " For Batch Number 393 the model has a loss of {'loss': 0.655082106590271, 'tp': 3337.0, 'fp': 1837.0, 'tn': 4456.0, 'fn': 2946.0, 'accuracy': 0.619672417640686, 'precision': 0.644955575466156, 'recall': 0.531115710735321, 'auc': 0.6561538577079773} \n",
            "393/689 [================>.............] - ETA: 24s - loss: 0.6551 - tp: 3337.0000 - fp: 1837.0000 - tn: 4456.0000 - fn: 2946.0000 - accuracy: 0.6197 - precision: 0.6450 - recall: 0.5311 - auc: 0.6562\n",
            " For Batch Number 394 the model has a loss of {'loss': 0.6555796265602112, 'tp': 3351.0, 'fp': 1855.0, 'tn': 4456.0, 'fn': 2946.0, 'accuracy': 0.6192100048065186, 'precision': 0.6436803936958313, 'recall': 0.5321581959724426, 'auc': 0.6556842923164368} \n",
            "394/689 [================>.............] - ETA: 24s - loss: 0.6556 - tp: 3351.0000 - fp: 1855.0000 - tn: 4456.0000 - fn: 2946.0000 - accuracy: 0.6192 - precision: 0.6437 - recall: 0.5322 - auc: 0.6557\n",
            " For Batch Number 395 the model has a loss of {'loss': 0.6561436057090759, 'tp': 3364.0, 'fp': 1874.0, 'tn': 4456.0, 'fn': 2946.0, 'accuracy': 0.6186708807945251, 'precision': 0.6422298550605774, 'recall': 0.5331220030784607, 'auc': 0.655153214931488} \n",
            "395/689 [================>.............] - ETA: 24s - loss: 0.6561 - tp: 3364.0000 - fp: 1874.0000 - tn: 4456.0000 - fn: 2946.0000 - accuracy: 0.6187 - precision: 0.6422 - recall: 0.5331 - auc: 0.6552\n",
            " For Batch Number 396 the model has a loss of {'loss': 0.6559285521507263, 'tp': 3375.0, 'fp': 1875.0, 'tn': 4469.0, 'fn': 2953.0, 'accuracy': 0.6190025210380554, 'precision': 0.6428571343421936, 'recall': 0.5333438515663147, 'auc': 0.6554121971130371} \n",
            "396/689 [================>.............] - ETA: 24s - loss: 0.6559 - tp: 3375.0000 - fp: 1875.0000 - tn: 4469.0000 - fn: 2953.0000 - accuracy: 0.6190 - precision: 0.6429 - recall: 0.5333 - auc: 0.6554\n",
            " For Batch Number 397 the model has a loss of {'loss': 0.6559875011444092, 'tp': 3383.0, 'fp': 1876.0, 'tn': 4478.0, 'fn': 2967.0, 'accuracy': 0.6187815070152283, 'precision': 0.643278181552887, 'recall': 0.5327559113502502, 'auc': 0.655247688293457} \n",
            "397/689 [================>.............] - ETA: 24s - loss: 0.6560 - tp: 3383.0000 - fp: 1876.0000 - tn: 4478.0000 - fn: 2967.0000 - accuracy: 0.6188 - precision: 0.6433 - recall: 0.5328 - auc: 0.6552\n",
            " For Batch Number 398 the model has a loss of {'loss': 0.6558024287223816, 'tp': 3390.0, 'fp': 1876.0, 'tn': 4492.0, 'fn': 2978.0, 'accuracy': 0.6188756227493286, 'precision': 0.64375239610672, 'recall': 0.5323492288589478, 'auc': 0.6554704308509827} \n",
            "398/689 [================>.............] - ETA: 23s - loss: 0.6558 - tp: 3390.0000 - fp: 1876.0000 - tn: 4492.0000 - fn: 2978.0000 - accuracy: 0.6189 - precision: 0.6438 - recall: 0.5323 - auc: 0.6555\n",
            " For Batch Number 399 the model has a loss of {'loss': 0.6558043360710144, 'tp': 3396.0, 'fp': 1878.0, 'tn': 4505.0, 'fn': 2989.0, 'accuracy': 0.6188126802444458, 'precision': 0.6439135670661926, 'recall': 0.5318715572357178, 'auc': 0.6553192734718323} \n",
            "399/689 [================>.............] - ETA: 23s - loss: 0.6558 - tp: 3396.0000 - fp: 1878.0000 - tn: 4505.0000 - fn: 2989.0000 - accuracy: 0.6188 - precision: 0.6439 - recall: 0.5319 - auc: 0.6553\n",
            " For Batch Number 400 the model has a loss of {'loss': 0.6555837392807007, 'tp': 3406.0, 'fp': 1878.0, 'tn': 4520.0, 'fn': 2996.0, 'accuracy': 0.6192187666893005, 'precision': 0.6445874571800232, 'recall': 0.5320212244987488, 'auc': 0.6555340886116028} \n",
            "400/689 [================>.............] - ETA: 23s - loss: 0.6556 - tp: 3406.0000 - fp: 1878.0000 - tn: 4520.0000 - fn: 2996.0000 - accuracy: 0.6192 - precision: 0.6446 - recall: 0.5320 - auc: 0.6555\n",
            " For Batch Number 401 the model has a loss of {'loss': 0.6558208465576172, 'tp': 3412.0, 'fp': 1885.0, 'tn': 4534.0, 'fn': 3001.0, 'accuracy': 0.6192331910133362, 'precision': 0.6441382169723511, 'recall': 0.5320442914962769, 'auc': 0.6551339626312256} \n",
            "401/689 [================>.............] - ETA: 23s - loss: 0.6558 - tp: 3412.0000 - fp: 1885.0000 - tn: 4534.0000 - fn: 3001.0000 - accuracy: 0.6192 - precision: 0.6441 - recall: 0.5320 - auc: 0.6551\n",
            " For Batch Number 402 the model has a loss of {'loss': 0.6555874943733215, 'tp': 3422.0, 'fp': 1886.0, 'tn': 4547.0, 'fn': 3009.0, 'accuracy': 0.6194807291030884, 'precision': 0.6446872353553772, 'recall': 0.5321100950241089, 'auc': 0.6553851366043091} \n",
            "402/689 [================>.............] - ETA: 23s - loss: 0.6556 - tp: 3422.0000 - fp: 1886.0000 - tn: 4547.0000 - fn: 3009.0000 - accuracy: 0.6195 - precision: 0.6447 - recall: 0.5321 - auc: 0.6554\n",
            " For Batch Number 403 the model has a loss of {'loss': 0.6557849049568176, 'tp': 3427.0, 'fp': 1891.0, 'tn': 4560.0, 'fn': 3018.0, 'accuracy': 0.6193393468856812, 'precision': 0.6444151997566223, 'recall': 0.5317299962043762, 'auc': 0.6551244258880615} \n",
            "403/689 [================>.............] - ETA: 23s - loss: 0.6558 - tp: 3427.0000 - fp: 1891.0000 - tn: 4560.0000 - fn: 3018.0000 - accuracy: 0.6193 - precision: 0.6444 - recall: 0.5317 - auc: 0.6551\n",
            " For Batch Number 404 the model has a loss of {'loss': 0.6558006405830383, 'tp': 3434.0, 'fp': 1894.0, 'tn': 4570.0, 'fn': 3030.0, 'accuracy': 0.6191213130950928, 'precision': 0.6445195078849792, 'recall': 0.53125, 'auc': 0.6550097465515137} \n",
            "404/689 [================>.............] - ETA: 23s - loss: 0.6558 - tp: 3434.0000 - fp: 1894.0000 - tn: 4570.0000 - fn: 3030.0000 - accuracy: 0.6191 - precision: 0.6445 - recall: 0.5312 - auc: 0.6550\n",
            " For Batch Number 405 the model has a loss of {'loss': 0.6562155485153198, 'tp': 3436.0, 'fp': 1901.0, 'tn': 4587.0, 'fn': 3036.0, 'accuracy': 0.6190586686134338, 'precision': 0.6438074111938477, 'recall': 0.5309023261070251, 'auc': 0.6545631885528564} \n",
            "405/689 [================>.............] - ETA: 23s - loss: 0.6562 - tp: 3436.0000 - fp: 1901.0000 - tn: 4587.0000 - fn: 3036.0000 - accuracy: 0.6191 - precision: 0.6438 - recall: 0.5309 - auc: 0.6546\n",
            " For Batch Number 406 the model has a loss of {'loss': 0.6563273668289185, 'tp': 3442.0, 'fp': 1903.0, 'tn': 4597.0, 'fn': 3050.0, 'accuracy': 0.6187654137611389, 'precision': 0.6439663171768188, 'recall': 0.5301910042762756, 'auc': 0.6542467474937439} \n",
            "406/689 [================>.............] - ETA: 23s - loss: 0.6563 - tp: 3442.0000 - fp: 1903.0000 - tn: 4597.0000 - fn: 3050.0000 - accuracy: 0.6188 - precision: 0.6440 - recall: 0.5302 - auc: 0.6542\n",
            " For Batch Number 407 the model has a loss of {'loss': 0.6562623977661133, 'tp': 3448.0, 'fp': 1905.0, 'tn': 4611.0, 'fn': 3060.0, 'accuracy': 0.6187807321548462, 'precision': 0.6441248059272766, 'recall': 0.5298094749450684, 'auc': 0.654300332069397} \n",
            "407/689 [================>.............] - ETA: 23s - loss: 0.6563 - tp: 3448.0000 - fp: 1905.0000 - tn: 4611.0000 - fn: 3060.0000 - accuracy: 0.6188 - precision: 0.6441 - recall: 0.5298 - auc: 0.6543\n",
            " For Batch Number 408 the model has a loss of {'loss': 0.6560868620872498, 'tp': 3453.0, 'fp': 1906.0, 'tn': 4628.0, 'fn': 3069.0, 'accuracy': 0.6189491152763367, 'precision': 0.6443366408348083, 'recall': 0.5294387936592102, 'auc': 0.6545416712760925} \n",
            "408/689 [================>.............] - ETA: 22s - loss: 0.6561 - tp: 3453.0000 - fp: 1906.0000 - tn: 4628.0000 - fn: 3069.0000 - accuracy: 0.6189 - precision: 0.6443 - recall: 0.5294 - auc: 0.6545\n",
            " For Batch Number 409 the model has a loss of {'loss': 0.6560764908790588, 'tp': 3459.0, 'fp': 1907.0, 'tn': 4642.0, 'fn': 3080.0, 'accuracy': 0.6189639568328857, 'precision': 0.6446142196655273, 'recall': 0.5289799571037292, 'auc': 0.6544418334960938} \n",
            "409/689 [================>.............] - ETA: 22s - loss: 0.6561 - tp: 3459.0000 - fp: 1907.0000 - tn: 4642.0000 - fn: 3080.0000 - accuracy: 0.6190 - precision: 0.6446 - recall: 0.5290 - auc: 0.6544\n",
            " For Batch Number 410 the model has a loss of {'loss': 0.656093418598175, 'tp': 3465.0, 'fp': 1909.0, 'tn': 4657.0, 'fn': 3089.0, 'accuracy': 0.6190548539161682, 'precision': 0.6447710990905762, 'recall': 0.5286847949028015, 'auc': 0.6543623805046082} \n",
            "410/689 [================>.............] - ETA: 22s - loss: 0.6561 - tp: 3465.0000 - fp: 1909.0000 - tn: 4657.0000 - fn: 3089.0000 - accuracy: 0.6191 - precision: 0.6448 - recall: 0.5287 - auc: 0.6544\n",
            " For Batch Number 411 the model has a loss of {'loss': 0.6562172770500183, 'tp': 3472.0, 'fp': 1912.0, 'tn': 4668.0, 'fn': 3100.0, 'accuracy': 0.6189172863960266, 'precision': 0.6448736786842346, 'recall': 0.5283018946647644, 'auc': 0.654240608215332} \n",
            "411/689 [================>.............] - ETA: 22s - loss: 0.6562 - tp: 3472.0000 - fp: 1912.0000 - tn: 4668.0000 - fn: 3100.0000 - accuracy: 0.6189 - precision: 0.6449 - recall: 0.5283 - auc: 0.6542\n",
            " For Batch Number 412 the model has a loss of {'loss': 0.6559452414512634, 'tp': 3483.0, 'fp': 1918.0, 'tn': 4681.0, 'fn': 3102.0, 'accuracy': 0.6192354559898376, 'precision': 0.6448805928230286, 'recall': 0.5289294123649597, 'auc': 0.6546019911766052} \n",
            "412/689 [================>.............] - ETA: 22s - loss: 0.6559 - tp: 3483.0000 - fp: 1918.0000 - tn: 4681.0000 - fn: 3102.0000 - accuracy: 0.6192 - precision: 0.6449 - recall: 0.5289 - auc: 0.6546\n",
            " For Batch Number 413 the model has a loss of {'loss': 0.6558970808982849, 'tp': 3496.0, 'fp': 1924.0, 'tn': 4689.0, 'fn': 3107.0, 'accuracy': 0.6193250417709351, 'precision': 0.645018458366394, 'recall': 0.5294563174247742, 'auc': 0.6547141075134277} \n",
            "413/689 [================>.............] - ETA: 22s - loss: 0.6559 - tp: 3496.0000 - fp: 1924.0000 - tn: 4689.0000 - fn: 3107.0000 - accuracy: 0.6193 - precision: 0.6450 - recall: 0.5295 - auc: 0.6547\n",
            " For Batch Number 414 the model has a loss of {'loss': 0.6556991934776306, 'tp': 3508.0, 'fp': 1931.0, 'tn': 4699.0, 'fn': 3110.0, 'accuracy': 0.6194897294044495, 'precision': 0.644971489906311, 'recall': 0.5300695300102234, 'auc': 0.6549786329269409} \n",
            "414/689 [=================>............] - ETA: 22s - loss: 0.6557 - tp: 3508.0000 - fp: 1931.0000 - tn: 4699.0000 - fn: 3110.0000 - accuracy: 0.6195 - precision: 0.6450 - recall: 0.5301 - auc: 0.6550\n",
            " For Batch Number 415 the model has a loss of {'loss': 0.6556330919265747, 'tp': 3519.0, 'fp': 1935.0, 'tn': 4710.0, 'fn': 3116.0, 'accuracy': 0.6196536421775818, 'precision': 0.6452144980430603, 'recall': 0.5303692817687988, 'auc': 0.655114471912384} \n",
            "415/689 [=================>............] - ETA: 22s - loss: 0.6556 - tp: 3519.0000 - fp: 1935.0000 - tn: 4710.0000 - fn: 3116.0000 - accuracy: 0.6197 - precision: 0.6452 - recall: 0.5304 - auc: 0.6551\n",
            " For Batch Number 416 the model has a loss of {'loss': 0.655649721622467, 'tp': 3529.0, 'fp': 1940.0, 'tn': 4721.0, 'fn': 3122.0, 'accuracy': 0.6197415590286255, 'precision': 0.6452733874320984, 'recall': 0.530596911907196, 'auc': 0.6551578044891357} \n",
            "416/689 [=================>............] - ETA: 22s - loss: 0.6556 - tp: 3529.0000 - fp: 1940.0000 - tn: 4721.0000 - fn: 3122.0000 - accuracy: 0.6197 - precision: 0.6453 - recall: 0.5306 - auc: 0.6552\n",
            " For Batch Number 417 the model has a loss of {'loss': 0.6556751132011414, 'tp': 3534.0, 'fp': 1950.0, 'tn': 4733.0, 'fn': 3127.0, 'accuracy': 0.6195293664932251, 'precision': 0.6444201469421387, 'recall': 0.5305509567260742, 'auc': 0.6551588773727417} \n",
            "417/689 [=================>............] - ETA: 22s - loss: 0.6557 - tp: 3534.0000 - fp: 1950.0000 - tn: 4733.0000 - fn: 3127.0000 - accuracy: 0.6195 - precision: 0.6444 - recall: 0.5306 - auc: 0.6552\n",
            " For Batch Number 418 the model has a loss of {'loss': 0.6556517481803894, 'tp': 3545.0, 'fp': 1951.0, 'tn': 4742.0, 'fn': 3138.0, 'accuracy': 0.6195424795150757, 'precision': 0.6450145840644836, 'recall': 0.5304504036903381, 'auc': 0.6552855372428894} \n",
            "418/689 [=================>............] - ETA: 22s - loss: 0.6557 - tp: 3545.0000 - fp: 1951.0000 - tn: 4742.0000 - fn: 3138.0000 - accuracy: 0.6195 - precision: 0.6450 - recall: 0.5305 - auc: 0.6553\n",
            " For Batch Number 419 the model has a loss of {'loss': 0.6557509899139404, 'tp': 3555.0, 'fp': 1953.0, 'tn': 4751.0, 'fn': 3149.0, 'accuracy': 0.6194809079170227, 'precision': 0.6454248428344727, 'recall': 0.5302804112434387, 'auc': 0.6551465392112732} \n",
            "\n",
            " For Batch Number 420 the model has a loss of {'loss': 0.6555418968200684, 'tp': 3564.0, 'fp': 1957.0, 'tn': 4763.0, 'fn': 3156.0, 'accuracy': 0.6195684671401978, 'precision': 0.6455352306365967, 'recall': 0.5303571224212646, 'auc': 0.6554052233695984} \n",
            "420/689 [=================>............] - ETA: 21s - loss: 0.6555 - tp: 3564.0000 - fp: 1957.0000 - tn: 4763.0000 - fn: 3156.0000 - accuracy: 0.6196 - precision: 0.6455 - recall: 0.5304 - auc: 0.6554\n",
            " For Batch Number 421 the model has a loss of {'loss': 0.6552891135215759, 'tp': 3576.0, 'fp': 1960.0, 'tn': 4777.0, 'fn': 3159.0, 'accuracy': 0.620026707649231, 'precision': 0.6459537744522095, 'recall': 0.5309576988220215, 'auc': 0.6557710766792297} \n",
            "421/689 [=================>............] - ETA: 21s - loss: 0.6553 - tp: 3576.0000 - fp: 1960.0000 - tn: 4777.0000 - fn: 3159.0000 - accuracy: 0.6200 - precision: 0.6460 - recall: 0.5310 - auc: 0.6558\n",
            " For Batch Number 422 the model has a loss of {'loss': 0.6552411317825317, 'tp': 3583.0, 'fp': 1966.0, 'tn': 4790.0, 'fn': 3165.0, 'accuracy': 0.6200385093688965, 'precision': 0.6457019448280334, 'recall': 0.5309721231460571, 'auc': 0.6557315587997437} \n",
            "422/689 [=================>............] - ETA: 21s - loss: 0.6552 - tp: 3583.0000 - fp: 1966.0000 - tn: 4790.0000 - fn: 3165.0000 - accuracy: 0.6200 - precision: 0.6457 - recall: 0.5310 - auc: 0.6557\n",
            " For Batch Number 423 the model has a loss of {'loss': 0.6551699638366699, 'tp': 3593.0, 'fp': 1969.0, 'tn': 4801.0, 'fn': 3173.0, 'accuracy': 0.620124101638794, 'precision': 0.6459906697273254, 'recall': 0.5310375690460205, 'auc': 0.6558224558830261} \n",
            "423/689 [=================>............] - ETA: 21s - loss: 0.6552 - tp: 3593.0000 - fp: 1969.0000 - tn: 4801.0000 - fn: 3173.0000 - accuracy: 0.6201 - precision: 0.6460 - recall: 0.5310 - auc: 0.6558\n",
            " For Batch Number 424 the model has a loss of {'loss': 0.6551836729049683, 'tp': 3602.0, 'fp': 1975.0, 'tn': 4808.0, 'fn': 3183.0, 'accuracy': 0.6198408007621765, 'precision': 0.6458669304847717, 'recall': 0.5308769345283508, 'auc': 0.6556459069252014} \n",
            "424/689 [=================>............] - ETA: 21s - loss: 0.6552 - tp: 3602.0000 - fp: 1975.0000 - tn: 4808.0000 - fn: 3183.0000 - accuracy: 0.6198 - precision: 0.6459 - recall: 0.5309 - auc: 0.6556\n",
            " For Batch Number 425 the model has a loss of {'loss': 0.6547984480857849, 'tp': 3613.0, 'fp': 1977.0, 'tn': 4823.0, 'fn': 3187.0, 'accuracy': 0.6202940940856934, 'precision': 0.6463327407836914, 'recall': 0.5313235521316528, 'auc': 0.656113862991333} \n",
            "425/689 [=================>............] - ETA: 21s - loss: 0.6548 - tp: 3613.0000 - fp: 1977.0000 - tn: 4823.0000 - fn: 3187.0000 - accuracy: 0.6203 - precision: 0.6463 - recall: 0.5313 - auc: 0.6561\n",
            " For Batch Number 426 the model has a loss of {'loss': 0.6547989249229431, 'tp': 3620.0, 'fp': 1982.0, 'tn': 4835.0, 'fn': 3195.0, 'accuracy': 0.6202318072319031, 'precision': 0.6461977958679199, 'recall': 0.5311812162399292, 'auc': 0.6560320258140564} \n",
            "426/689 [=================>............] - ETA: 21s - loss: 0.6548 - tp: 3620.0000 - fp: 1982.0000 - tn: 4835.0000 - fn: 3195.0000 - accuracy: 0.6202 - precision: 0.6462 - recall: 0.5312 - auc: 0.6560\n",
            " For Batch Number 427 the model has a loss of {'loss': 0.6549721360206604, 'tp': 3627.0, 'fp': 1986.0, 'tn': 4844.0, 'fn': 3207.0, 'accuracy': 0.6199502348899841, 'precision': 0.6461785435676575, 'recall': 0.5307286977767944, 'auc': 0.6557191610336304} \n",
            "427/689 [=================>............] - ETA: 21s - loss: 0.6550 - tp: 3627.0000 - fp: 1986.0000 - tn: 4844.0000 - fn: 3207.0000 - accuracy: 0.6200 - precision: 0.6462 - recall: 0.5307 - auc: 0.6557\n",
            " For Batch Number 428 the model has a loss of {'loss': 0.6551721096038818, 'tp': 3632.0, 'fp': 1990.0, 'tn': 4856.0, 'fn': 3218.0, 'accuracy': 0.6197429895401001, 'precision': 0.6460334658622742, 'recall': 0.5302189588546753, 'auc': 0.655504584312439} \n",
            "428/689 [=================>............] - ETA: 21s - loss: 0.6552 - tp: 3632.0000 - fp: 1990.0000 - tn: 4856.0000 - fn: 3218.0000 - accuracy: 0.6197 - precision: 0.6460 - recall: 0.5302 - auc: 0.6555\n",
            " For Batch Number 429 the model has a loss of {'loss': 0.6549968719482422, 'tp': 3642.0, 'fp': 1993.0, 'tn': 4869.0, 'fn': 3224.0, 'accuracy': 0.6199737787246704, 'precision': 0.6463176608085632, 'recall': 0.5304398536682129, 'auc': 0.6557471752166748} \n",
            "429/689 [=================>............] - ETA: 21s - loss: 0.6550 - tp: 3642.0000 - fp: 1993.0000 - tn: 4869.0000 - fn: 3224.0000 - accuracy: 0.6200 - precision: 0.6463 - recall: 0.5304 - auc: 0.6557\n",
            " For Batch Number 430 the model has a loss of {'loss': 0.6550165414810181, 'tp': 3650.0, 'fp': 1996.0, 'tn': 4881.0, 'fn': 3233.0, 'accuracy': 0.6199854612350464, 'precision': 0.6464753746986389, 'recall': 0.5302920341491699, 'auc': 0.6557589769363403} \n",
            "430/689 [=================>............] - ETA: 20s - loss: 0.6550 - tp: 3650.0000 - fp: 1996.0000 - tn: 4881.0000 - fn: 3233.0000 - accuracy: 0.6200 - precision: 0.6465 - recall: 0.5303 - auc: 0.6558\n",
            " For Batch Number 431 the model has a loss of {'loss': 0.6549274325370789, 'tp': 3657.0, 'fp': 1999.0, 'tn': 4893.0, 'fn': 3243.0, 'accuracy': 0.6199246048927307, 'precision': 0.6465700268745422, 'recall': 0.5299999713897705, 'auc': 0.6557387113571167} \n",
            "431/689 [=================>............] - ETA: 20s - loss: 0.6549 - tp: 3657.0000 - fp: 1999.0000 - tn: 4893.0000 - fn: 3243.0000 - accuracy: 0.6199 - precision: 0.6466 - recall: 0.5300 - auc: 0.6557\n",
            " For Batch Number 432 the model has a loss of {'loss': 0.6551213264465332, 'tp': 3665.0, 'fp': 2003.0, 'tn': 4902.0, 'fn': 3254.0, 'accuracy': 0.6197193264961243, 'precision': 0.6466125845909119, 'recall': 0.5297008156776428, 'auc': 0.655504047870636} \n",
            "\n",
            " For Batch Number 433 the model has a loss of {'loss': 0.6550816893577576, 'tp': 3675.0, 'fp': 2005.0, 'tn': 4913.0, 'fn': 3263.0, 'accuracy': 0.6198036670684814, 'precision': 0.6470070481300354, 'recall': 0.5296915769577026, 'auc': 0.6555860638618469} \n",
            "433/689 [=================>............] - ETA: 20s - loss: 0.6551 - tp: 3675.0000 - fp: 2005.0000 - tn: 4913.0000 - fn: 3263.0000 - accuracy: 0.6198 - precision: 0.6470 - recall: 0.5297 - auc: 0.6556\n",
            " For Batch Number 434 the model has a loss of {'loss': 0.6550487875938416, 'tp': 3684.0, 'fp': 2010.0, 'tn': 4927.0, 'fn': 3267.0, 'accuracy': 0.6200316548347473, 'precision': 0.6469968557357788, 'recall': 0.5299956798553467, 'auc': 0.6555668711662292} \n",
            "434/689 [=================>............] - ETA: 20s - loss: 0.6550 - tp: 3684.0000 - fp: 2010.0000 - tn: 4927.0000 - fn: 3267.0000 - accuracy: 0.6200 - precision: 0.6470 - recall: 0.5300 - auc: 0.6556\n",
            " For Batch Number 435 the model has a loss of {'loss': 0.6550689339637756, 'tp': 3691.0, 'fp': 2014.0, 'tn': 4940.0, 'fn': 3275.0, 'accuracy': 0.6200430989265442, 'precision': 0.6469763517379761, 'recall': 0.5298593044281006, 'auc': 0.6555121541023254} \n",
            "435/689 [=================>............] - ETA: 20s - loss: 0.6551 - tp: 3691.0000 - fp: 2014.0000 - tn: 4940.0000 - fn: 3275.0000 - accuracy: 0.6200 - precision: 0.6470 - recall: 0.5299 - auc: 0.6555\n",
            " For Batch Number 436 the model has a loss of {'loss': 0.6550416946411133, 'tp': 3697.0, 'fp': 2018.0, 'tn': 4952.0, 'fn': 3285.0, 'accuracy': 0.6199111342430115, 'precision': 0.6468941569328308, 'recall': 0.5295044183731079, 'auc': 0.6554569602012634} \n",
            "436/689 [=================>............] - ETA: 20s - loss: 0.6550 - tp: 3697.0000 - fp: 2018.0000 - tn: 4952.0000 - fn: 3285.0000 - accuracy: 0.6199 - precision: 0.6469 - recall: 0.5295 - auc: 0.6555\n",
            " For Batch Number 437 the model has a loss of {'loss': 0.6550381183624268, 'tp': 3702.0, 'fp': 2021.0, 'tn': 4966.0, 'fn': 3295.0, 'accuracy': 0.6198512315750122, 'precision': 0.6468635201454163, 'recall': 0.5290839076042175, 'auc': 0.6554088592529297} \n",
            "437/689 [==================>...........] - ETA: 20s - loss: 0.6550 - tp: 3702.0000 - fp: 2021.0000 - tn: 4966.0000 - fn: 3295.0000 - accuracy: 0.6199 - precision: 0.6469 - recall: 0.5291 - auc: 0.6554\n",
            " For Batch Number 438 the model has a loss of {'loss': 0.6547946929931641, 'tp': 3715.0, 'fp': 2021.0, 'tn': 4981.0, 'fn': 3299.0, 'accuracy': 0.6204338073730469, 'precision': 0.6476638913154602, 'recall': 0.5296549797058105, 'auc': 0.6557786464691162} \n",
            "438/689 [==================>...........] - ETA: 20s - loss: 0.6548 - tp: 3715.0000 - fp: 2021.0000 - tn: 4981.0000 - fn: 3299.0000 - accuracy: 0.6204 - precision: 0.6477 - recall: 0.5297 - auc: 0.6558\n",
            " For Batch Number 439 the model has a loss of {'loss': 0.6547254920005798, 'tp': 3724.0, 'fp': 2023.0, 'tn': 4992.0, 'fn': 3309.0, 'accuracy': 0.6204441785812378, 'precision': 0.6479902267456055, 'recall': 0.5295037627220154, 'auc': 0.6558677554130554} \n",
            "439/689 [==================>...........] - ETA: 20s - loss: 0.6547 - tp: 3724.0000 - fp: 2023.0000 - tn: 4992.0000 - fn: 3309.0000 - accuracy: 0.6204 - precision: 0.6480 - recall: 0.5295 - auc: 0.6559\n",
            " For Batch Number 440 the model has a loss of {'loss': 0.6546198129653931, 'tp': 3729.0, 'fp': 2025.0, 'tn': 5010.0, 'fn': 3316.0, 'accuracy': 0.6206676363945007, 'precision': 0.6480709314346313, 'recall': 0.5293115973472595, 'auc': 0.6559290885925293} \n",
            "440/689 [==================>...........] - ETA: 20s - loss: 0.6546 - tp: 3729.0000 - fp: 2025.0000 - tn: 5010.0000 - fn: 3316.0000 - accuracy: 0.6207 - precision: 0.6481 - recall: 0.5293 - auc: 0.6559\n",
            " For Batch Number 441 the model has a loss of {'loss': 0.6545132398605347, 'tp': 3738.0, 'fp': 2027.0, 'tn': 5026.0, 'fn': 3321.0, 'accuracy': 0.6210317611694336, 'precision': 0.6483954787254333, 'recall': 0.529536783695221, 'auc': 0.6560800671577454} \n",
            "441/689 [==================>...........] - ETA: 19s - loss: 0.6545 - tp: 3738.0000 - fp: 2027.0000 - tn: 5026.0000 - fn: 3321.0000 - accuracy: 0.6210 - precision: 0.6484 - recall: 0.5295 - auc: 0.6561\n",
            " For Batch Number 442 the model has a loss of {'loss': 0.6545614004135132, 'tp': 3745.0, 'fp': 2030.0, 'tn': 5037.0, 'fn': 3332.0, 'accuracy': 0.6208993196487427, 'precision': 0.6484848260879517, 'recall': 0.529179036617279, 'auc': 0.6559503078460693} \n",
            "442/689 [==================>...........] - ETA: 19s - loss: 0.6546 - tp: 3745.0000 - fp: 2030.0000 - tn: 5037.0000 - fn: 3332.0000 - accuracy: 0.6209 - precision: 0.6485 - recall: 0.5292 - auc: 0.6560\n",
            " For Batch Number 443 the model has a loss of {'loss': 0.6544774174690247, 'tp': 3750.0, 'fp': 2034.0, 'tn': 5053.0, 'fn': 3339.0, 'accuracy': 0.6209791302680969, 'precision': 0.6483402252197266, 'recall': 0.5289885997772217, 'auc': 0.6559423804283142} \n",
            "\n",
            " For Batch Number 444 the model has a loss of {'loss': 0.6542794108390808, 'tp': 3757.0, 'fp': 2035.0, 'tn': 5069.0, 'fn': 3347.0, 'accuracy': 0.6211993098258972, 'precision': 0.6486533284187317, 'recall': 0.5288569927215576, 'auc': 0.6562548875808716} \n",
            "444/689 [==================>...........] - ETA: 19s - loss: 0.6543 - tp: 3757.0000 - fp: 2035.0000 - tn: 5069.0000 - fn: 3347.0000 - accuracy: 0.6212 - precision: 0.6487 - recall: 0.5289 - auc: 0.6563\n",
            " For Batch Number 445 the model has a loss of {'loss': 0.6542264223098755, 'tp': 3766.0, 'fp': 2035.0, 'tn': 5080.0, 'fn': 3359.0, 'accuracy': 0.6212078928947449, 'precision': 0.6491984128952026, 'recall': 0.5285614132881165, 'auc': 0.6563231945037842} \n",
            "445/689 [==================>...........] - ETA: 19s - loss: 0.6542 - tp: 3766.0000 - fp: 2035.0000 - tn: 5080.0000 - fn: 3359.0000 - accuracy: 0.6212 - precision: 0.6492 - recall: 0.5286 - auc: 0.6563\n",
            " For Batch Number 446 the model has a loss of {'loss': 0.6542099118232727, 'tp': 3771.0, 'fp': 2041.0, 'tn': 5094.0, 'fn': 3366.0, 'accuracy': 0.6211463212966919, 'precision': 0.648829996585846, 'recall': 0.5283732414245605, 'auc': 0.6563144326210022} \n",
            "\n",
            " For Batch Number 447 the model has a loss of {'loss': 0.6542029976844788, 'tp': 3779.0, 'fp': 2043.0, 'tn': 5106.0, 'fn': 3376.0, 'accuracy': 0.6211549043655396, 'precision': 0.6490896344184875, 'recall': 0.5281621217727661, 'auc': 0.6562731862068176} \n",
            "447/689 [==================>...........] - ETA: 19s - loss: 0.6542 - tp: 3779.0000 - fp: 2043.0000 - tn: 5106.0000 - fn: 3376.0000 - accuracy: 0.6212 - precision: 0.6491 - recall: 0.5282 - auc: 0.6563\n",
            " For Batch Number 448 the model has a loss of {'loss': 0.6543899774551392, 'tp': 3785.0, 'fp': 2047.0, 'tn': 5116.0, 'fn': 3388.0, 'accuracy': 0.6208844780921936, 'precision': 0.6490054726600647, 'recall': 0.5276732444763184, 'auc': 0.6560425758361816} \n",
            "448/689 [==================>...........] - ETA: 19s - loss: 0.6544 - tp: 3785.0000 - fp: 2047.0000 - tn: 5116.0000 - fn: 3388.0000 - accuracy: 0.6209 - precision: 0.6490 - recall: 0.5277 - auc: 0.6560\n",
            " For Batch Number 449 the model has a loss of {'loss': 0.6543909907341003, 'tp': 3793.0, 'fp': 2052.0, 'tn': 5130.0, 'fn': 3393.0, 'accuracy': 0.6210328340530396, 'precision': 0.6489307284355164, 'recall': 0.5278319120407104, 'auc': 0.6560792922973633} \n",
            "449/689 [==================>...........] - ETA: 19s - loss: 0.6544 - tp: 3793.0000 - fp: 2052.0000 - tn: 5130.0000 - fn: 3393.0000 - accuracy: 0.6210 - precision: 0.6489 - recall: 0.5278 - auc: 0.6561\n",
            " For Batch Number 450 the model has a loss of {'loss': 0.6544924378395081, 'tp': 3800.0, 'fp': 2057.0, 'tn': 5141.0, 'fn': 3402.0, 'accuracy': 0.6209027767181396, 'precision': 0.6487963199615479, 'recall': 0.5276312232017517, 'auc': 0.6558329463005066} \n",
            "450/689 [==================>...........] - ETA: 19s - loss: 0.6545 - tp: 3800.0000 - fp: 2057.0000 - tn: 5141.0000 - fn: 3402.0000 - accuracy: 0.6209 - precision: 0.6488 - recall: 0.5276 - auc: 0.6558\n",
            " For Batch Number 451 the model has a loss of {'loss': 0.6543105840682983, 'tp': 3807.0, 'fp': 2061.0, 'tn': 5155.0, 'fn': 3409.0, 'accuracy': 0.6209811568260193, 'precision': 0.6487730145454407, 'recall': 0.5275775790214539, 'auc': 0.6560212969779968} \n",
            "451/689 [==================>...........] - ETA: 19s - loss: 0.6543 - tp: 3807.0000 - fp: 2061.0000 - tn: 5155.0000 - fn: 3409.0000 - accuracy: 0.6210 - precision: 0.6488 - recall: 0.5276 - auc: 0.6560\n",
            " For Batch Number 452 the model has a loss of {'loss': 0.6542585492134094, 'tp': 3816.0, 'fp': 2067.0, 'tn': 5165.0, 'fn': 3416.0, 'accuracy': 0.6209208965301514, 'precision': 0.6486486196517944, 'recall': 0.5276548862457275, 'auc': 0.6560624241828918} \n",
            "452/689 [==================>...........] - ETA: 18s - loss: 0.6543 - tp: 3816.0000 - fp: 2067.0000 - tn: 5165.0000 - fn: 3416.0000 - accuracy: 0.6209 - precision: 0.6486 - recall: 0.5277 - auc: 0.6561\n",
            " For Batch Number 453 the model has a loss of {'loss': 0.6543481945991516, 'tp': 3824.0, 'fp': 2071.0, 'tn': 5172.0, 'fn': 3429.0, 'accuracy': 0.6205849647521973, 'precision': 0.6486853361129761, 'recall': 0.5272300839424133, 'auc': 0.6558948755264282} \n",
            "453/689 [==================>...........] - ETA: 18s - loss: 0.6543 - tp: 3824.0000 - fp: 2071.0000 - tn: 5172.0000 - fn: 3429.0000 - accuracy: 0.6206 - precision: 0.6487 - recall: 0.5272 - auc: 0.6559\n",
            " For Batch Number 454 the model has a loss of {'loss': 0.6541886329650879, 'tp': 3831.0, 'fp': 2076.0, 'tn': 5187.0, 'fn': 3434.0, 'accuracy': 0.6207323670387268, 'precision': 0.6485525369644165, 'recall': 0.5273227691650391, 'auc': 0.6560291051864624} \n",
            "454/689 [==================>...........] - ETA: 18s - loss: 0.6542 - tp: 3831.0000 - fp: 2076.0000 - tn: 5187.0000 - fn: 3434.0000 - accuracy: 0.6207 - precision: 0.6486 - recall: 0.5273 - auc: 0.6560\n",
            " For Batch Number 455 the model has a loss of {'loss': 0.654198408126831, 'tp': 3840.0, 'fp': 2080.0, 'tn': 5197.0, 'fn': 3443.0, 'accuracy': 0.6206730604171753, 'precision': 0.6486486196517944, 'recall': 0.5272552371025085, 'auc': 0.6560451984405518} \n",
            "455/689 [==================>...........] - ETA: 18s - loss: 0.6542 - tp: 3840.0000 - fp: 2080.0000 - tn: 5197.0000 - fn: 3443.0000 - accuracy: 0.6207 - precision: 0.6486 - recall: 0.5273 - auc: 0.6560\n",
            " For Batch Number 456 the model has a loss of {'loss': 0.654227614402771, 'tp': 3852.0, 'fp': 2081.0, 'tn': 5203.0, 'fn': 3456.0, 'accuracy': 0.620545506477356, 'precision': 0.6492499709129333, 'recall': 0.5270935893058777, 'auc': 0.6559374332427979} \n",
            "456/689 [==================>...........] - ETA: 18s - loss: 0.6542 - tp: 3852.0000 - fp: 2081.0000 - tn: 5203.0000 - fn: 3456.0000 - accuracy: 0.6205 - precision: 0.6492 - recall: 0.5271 - auc: 0.6559\n",
            " For Batch Number 457 the model has a loss of {'loss': 0.6542628407478333, 'tp': 3860.0, 'fp': 2089.0, 'tn': 5212.0, 'fn': 3463.0, 'accuracy': 0.6203501224517822, 'precision': 0.6488485336303711, 'recall': 0.5271064043045044, 'auc': 0.6558377742767334} \n",
            "457/689 [==================>...........] - ETA: 18s - loss: 0.6543 - tp: 3860.0000 - fp: 2089.0000 - tn: 5212.0000 - fn: 3463.0000 - accuracy: 0.6204 - precision: 0.6488 - recall: 0.5271 - auc: 0.6558\n",
            " For Batch Number 458 the model has a loss of {'loss': 0.6544398665428162, 'tp': 3870.0, 'fp': 2096.0, 'tn': 5222.0, 'fn': 3468.0, 'accuracy': 0.620360255241394, 'precision': 0.6486758589744568, 'recall': 0.5273916721343994, 'auc': 0.655715823173523} \n",
            "458/689 [==================>...........] - ETA: 18s - loss: 0.6544 - tp: 3870.0000 - fp: 2096.0000 - tn: 5222.0000 - fn: 3468.0000 - accuracy: 0.6204 - precision: 0.6487 - recall: 0.5274 - auc: 0.6557\n",
            " For Batch Number 459 the model has a loss of {'loss': 0.6544156074523926, 'tp': 3883.0, 'fp': 2104.0, 'tn': 5230.0, 'fn': 3471.0, 'accuracy': 0.6204384565353394, 'precision': 0.6485719084739685, 'recall': 0.5280119776725769, 'auc': 0.6557663679122925} \n",
            "459/689 [==================>...........] - ETA: 18s - loss: 0.6544 - tp: 3883.0000 - fp: 2104.0000 - tn: 5230.0000 - fn: 3471.0000 - accuracy: 0.6204 - precision: 0.6486 - recall: 0.5280 - auc: 0.6558\n",
            " For Batch Number 460 the model has a loss of {'loss': 0.6545496582984924, 'tp': 3891.0, 'fp': 2116.0, 'tn': 5239.0, 'fn': 3474.0, 'accuracy': 0.620244562625885, 'precision': 0.6477442979812622, 'recall': 0.5283095836639404, 'auc': 0.65553879737854} \n",
            "460/689 [===================>..........] - ETA: 18s - loss: 0.6545 - tp: 3891.0000 - fp: 2116.0000 - tn: 5239.0000 - fn: 3474.0000 - accuracy: 0.6202 - precision: 0.6477 - recall: 0.5283 - auc: 0.6555\n",
            " For Batch Number 461 the model has a loss of {'loss': 0.6546549201011658, 'tp': 3898.0, 'fp': 2127.0, 'tn': 5248.0, 'fn': 3479.0, 'accuracy': 0.6199837327003479, 'precision': 0.6469709277153015, 'recall': 0.5283990502357483, 'auc': 0.6553140878677368} \n",
            "461/689 [===================>..........] - ETA: 18s - loss: 0.6547 - tp: 3898.0000 - fp: 2127.0000 - tn: 5248.0000 - fn: 3479.0000 - accuracy: 0.6200 - precision: 0.6470 - recall: 0.5284 - auc: 0.6553\n",
            " For Batch Number 462 the model has a loss of {'loss': 0.6544816493988037, 'tp': 3909.0, 'fp': 2130.0, 'tn': 5260.0, 'fn': 3485.0, 'accuracy': 0.6201975345611572, 'precision': 0.6472926139831543, 'recall': 0.52867192029953, 'auc': 0.6555315852165222} \n",
            "462/689 [===================>..........] - ETA: 18s - loss: 0.6545 - tp: 3909.0000 - fp: 2130.0000 - tn: 5260.0000 - fn: 3485.0000 - accuracy: 0.6202 - precision: 0.6473 - recall: 0.5287 - auc: 0.6555\n",
            " For Batch Number 463 the model has a loss of {'loss': 0.654375433921814, 'tp': 3915.0, 'fp': 2132.0, 'tn': 5274.0, 'fn': 3495.0, 'accuracy': 0.6202079057693481, 'precision': 0.6474284529685974, 'recall': 0.5283401012420654, 'auc': 0.6556640267372131} \n",
            "463/689 [===================>..........] - ETA: 18s - loss: 0.6544 - tp: 3915.0000 - fp: 2132.0000 - tn: 5274.0000 - fn: 3495.0000 - accuracy: 0.6202 - precision: 0.6474 - recall: 0.5283 - auc: 0.6557\n",
            " For Batch Number 464 the model has a loss of {'loss': 0.6543775200843811, 'tp': 3923.0, 'fp': 2137.0, 'tn': 5286.0, 'fn': 3502.0, 'accuracy': 0.6202182173728943, 'precision': 0.6473597288131714, 'recall': 0.5283501744270325, 'auc': 0.6557278037071228} \n",
            "464/689 [===================>..........] - ETA: 17s - loss: 0.6544 - tp: 3923.0000 - fp: 2137.0000 - tn: 5286.0000 - fn: 3502.0000 - accuracy: 0.6202 - precision: 0.6474 - recall: 0.5284 - auc: 0.6557\n",
            " For Batch Number 465 the model has a loss of {'loss': 0.6544684171676636, 'tp': 3931.0, 'fp': 2141.0, 'tn': 5295.0, 'fn': 3513.0, 'accuracy': 0.6200268864631653, 'precision': 0.6473978757858276, 'recall': 0.5280762910842896, 'auc': 0.6555377244949341} \n",
            "\n",
            " For Batch Number 466 the model has a loss of {'loss': 0.6542007923126221, 'tp': 3939.0, 'fp': 2142.0, 'tn': 5312.0, 'fn': 3519.0, 'accuracy': 0.6203728318214417, 'precision': 0.6477553248405457, 'recall': 0.5281577110290527, 'auc': 0.6559783220291138} \n",
            "466/689 [===================>..........] - ETA: 17s - loss: 0.6542 - tp: 3939.0000 - fp: 2142.0000 - tn: 5312.0000 - fn: 3519.0000 - accuracy: 0.6204 - precision: 0.6478 - recall: 0.5282 - auc: 0.6560\n",
            " For Batch Number 467 the model has a loss of {'loss': 0.6540170907974243, 'tp': 3948.0, 'fp': 2143.0, 'tn': 5327.0, 'fn': 3526.0, 'accuracy': 0.6206504106521606, 'precision': 0.6481694579124451, 'recall': 0.5282312035560608, 'auc': 0.6562623381614685} \n",
            "467/689 [===================>..........] - ETA: 17s - loss: 0.6540 - tp: 3948.0000 - fp: 2143.0000 - tn: 5327.0000 - fn: 3526.0000 - accuracy: 0.6207 - precision: 0.6482 - recall: 0.5282 - auc: 0.6563\n",
            " For Batch Number 468 the model has a loss of {'loss': 0.6540670394897461, 'tp': 3954.0, 'fp': 2148.0, 'tn': 5339.0, 'fn': 3535.0, 'accuracy': 0.6205261945724487, 'precision': 0.6479842662811279, 'recall': 0.5279743671417236, 'auc': 0.6561769843101501} \n",
            "468/689 [===================>..........] - ETA: 17s - loss: 0.6541 - tp: 3954.0000 - fp: 2148.0000 - tn: 5339.0000 - fn: 3535.0000 - accuracy: 0.6205 - precision: 0.6480 - recall: 0.5280 - auc: 0.6562\n",
            " For Batch Number 469 the model has a loss of {'loss': 0.6539706587791443, 'tp': 3962.0, 'fp': 2150.0, 'tn': 5354.0, 'fn': 3542.0, 'accuracy': 0.6207355856895447, 'precision': 0.6482329964637756, 'recall': 0.5279850959777832, 'auc': 0.6563489437103271} \n",
            "469/689 [===================>..........] - ETA: 17s - loss: 0.6540 - tp: 3962.0000 - fp: 2150.0000 - tn: 5354.0000 - fn: 3542.0000 - accuracy: 0.6207 - precision: 0.6482 - recall: 0.5280 - auc: 0.6563\n",
            " For Batch Number 470 the model has a loss of {'loss': 0.6539145708084106, 'tp': 3969.0, 'fp': 2155.0, 'tn': 5366.0, 'fn': 3550.0, 'accuracy': 0.620678186416626, 'precision': 0.648105800151825, 'recall': 0.5278627276420593, 'auc': 0.6563171744346619} \n",
            "470/689 [===================>..........] - ETA: 17s - loss: 0.6539 - tp: 3969.0000 - fp: 2155.0000 - tn: 5366.0000 - fn: 3550.0000 - accuracy: 0.6207 - precision: 0.6481 - recall: 0.5279 - auc: 0.6563\n",
            " For Batch Number 471 the model has a loss of {'loss': 0.6536813378334045, 'tp': 3977.0, 'fp': 2155.0, 'tn': 5382.0, 'fn': 3558.0, 'accuracy': 0.6209527850151062, 'precision': 0.6485649347305298, 'recall': 0.5278035998344421, 'auc': 0.65656977891922} \n",
            "471/689 [===================>..........] - ETA: 17s - loss: 0.6537 - tp: 3977.0000 - fp: 2155.0000 - tn: 5382.0000 - fn: 3558.0000 - accuracy: 0.6210 - precision: 0.6486 - recall: 0.5278 - auc: 0.6566\n",
            " For Batch Number 472 the model has a loss of {'loss': 0.6534706354141235, 'tp': 3987.0, 'fp': 2156.0, 'tn': 5395.0, 'fn': 3566.0, 'accuracy': 0.6211599707603455, 'precision': 0.649031400680542, 'recall': 0.527869701385498, 'auc': 0.6567977666854858} \n",
            "\n",
            " For Batch Number 473 the model has a loss of {'loss': 0.6535792946815491, 'tp': 3993.0, 'fp': 2161.0, 'tn': 5409.0, 'fn': 3573.0, 'accuracy': 0.6211680769920349, 'precision': 0.6488462686538696, 'recall': 0.5277557373046875, 'auc': 0.6566160321235657} \n",
            "473/689 [===================>..........] - ETA: 17s - loss: 0.6536 - tp: 3993.0000 - fp: 2161.0000 - tn: 5409.0000 - fn: 3573.0000 - accuracy: 0.6212 - precision: 0.6488 - recall: 0.5278 - auc: 0.6566\n",
            " For Batch Number 474 the model has a loss of {'loss': 0.6533337831497192, 'tp': 4003.0, 'fp': 2165.0, 'tn': 5421.0, 'fn': 3579.0, 'accuracy': 0.6213080286979675, 'precision': 0.6489948034286499, 'recall': 0.5279609560966492, 'auc': 0.6569724082946777} \n",
            "474/689 [===================>..........] - ETA: 17s - loss: 0.6533 - tp: 4003.0000 - fp: 2165.0000 - tn: 5421.0000 - fn: 3579.0000 - accuracy: 0.6213 - precision: 0.6490 - recall: 0.5280 - auc: 0.6570\n",
            " For Batch Number 475 the model has a loss of {'loss': 0.653302013874054, 'tp': 4014.0, 'fp': 2168.0, 'tn': 5433.0, 'fn': 3585.0, 'accuracy': 0.6215131282806396, 'precision': 0.6493044495582581, 'recall': 0.5282273888587952, 'auc': 0.6570566892623901} \n",
            "475/689 [===================>..........] - ETA: 17s - loss: 0.6533 - tp: 4014.0000 - fp: 2168.0000 - tn: 5433.0000 - fn: 3585.0000 - accuracy: 0.6215 - precision: 0.6493 - recall: 0.5282 - auc: 0.6571\n",
            " For Batch Number 476 the model has a loss of {'loss': 0.6534237265586853, 'tp': 4020.0, 'fp': 2172.0, 'tn': 5445.0, 'fn': 3595.0, 'accuracy': 0.6213892102241516, 'precision': 0.6492248177528381, 'recall': 0.5279054641723633, 'auc': 0.6568850874900818} \n",
            "476/689 [===================>..........] - ETA: 16s - loss: 0.6534 - tp: 4020.0000 - fp: 2172.0000 - tn: 5445.0000 - fn: 3595.0000 - accuracy: 0.6214 - precision: 0.6492 - recall: 0.5279 - auc: 0.6569\n",
            " For Batch Number 477 the model has a loss of {'loss': 0.6535105109214783, 'tp': 4029.0, 'fp': 2177.0, 'tn': 5454.0, 'fn': 3604.0, 'accuracy': 0.621265709400177, 'precision': 0.6492104530334473, 'recall': 0.5278396606445312, 'auc': 0.6567659378051758} \n",
            "477/689 [===================>..........] - ETA: 16s - loss: 0.6535 - tp: 4029.0000 - fp: 2177.0000 - tn: 5454.0000 - fn: 3604.0000 - accuracy: 0.6213 - precision: 0.6492 - recall: 0.5278 - auc: 0.6568\n",
            " For Batch Number 478 the model has a loss of {'loss': 0.6533598303794861, 'tp': 4039.0, 'fp': 2181.0, 'tn': 5465.0, 'fn': 3611.0, 'accuracy': 0.6213389039039612, 'precision': 0.6493569016456604, 'recall': 0.5279738306999207, 'auc': 0.6569643616676331} \n",
            "478/689 [===================>..........] - ETA: 16s - loss: 0.6534 - tp: 4039.0000 - fp: 2181.0000 - tn: 5465.0000 - fn: 3611.0000 - accuracy: 0.6213 - precision: 0.6494 - recall: 0.5280 - auc: 0.6570\n",
            " For Batch Number 479 the model has a loss of {'loss': 0.6532230973243713, 'tp': 4047.0, 'fp': 2189.0, 'tn': 5480.0, 'fn': 3612.0, 'accuracy': 0.6215422749519348, 'precision': 0.6489737033843994, 'recall': 0.5283979773521423, 'auc': 0.6571693420410156} \n",
            "479/689 [===================>..........] - ETA: 16s - loss: 0.6532 - tp: 4047.0000 - fp: 2189.0000 - tn: 5480.0000 - fn: 3612.0000 - accuracy: 0.6215 - precision: 0.6490 - recall: 0.5284 - auc: 0.6572\n",
            " For Batch Number 480 the model has a loss of {'loss': 0.6532027125358582, 'tp': 4058.0, 'fp': 2192.0, 'tn': 5493.0, 'fn': 3617.0, 'accuracy': 0.6218098998069763, 'precision': 0.6492800116539001, 'recall': 0.5287296175956726, 'auc': 0.6572960615158081} \n",
            "480/689 [===================>..........] - ETA: 16s - loss: 0.6532 - tp: 4058.0000 - fp: 2192.0000 - tn: 5493.0000 - fn: 3617.0000 - accuracy: 0.6218 - precision: 0.6493 - recall: 0.5287 - auc: 0.6573\n",
            " For Batch Number 481 the model has a loss of {'loss': 0.653379499912262, 'tp': 4068.0, 'fp': 2197.0, 'tn': 5501.0, 'fn': 3626.0, 'accuracy': 0.621686577796936, 'precision': 0.6493216156959534, 'recall': 0.5287236571311951, 'auc': 0.6570602655410767} \n",
            "481/689 [===================>..........] - ETA: 16s - loss: 0.6534 - tp: 4068.0000 - fp: 2197.0000 - tn: 5501.0000 - fn: 3626.0000 - accuracy: 0.6217 - precision: 0.6493 - recall: 0.5287 - auc: 0.6571\n",
            " For Batch Number 482 the model has a loss of {'loss': 0.6533100605010986, 'tp': 4078.0, 'fp': 2200.0, 'tn': 5516.0, 'fn': 3630.0, 'accuracy': 0.6220176219940186, 'precision': 0.6495699286460876, 'recall': 0.5290607213973999, 'auc': 0.6573486328125} \n",
            "482/689 [===================>..........] - ETA: 16s - loss: 0.6533 - tp: 4078.0000 - fp: 2200.0000 - tn: 5516.0000 - fn: 3630.0000 - accuracy: 0.6220 - precision: 0.6496 - recall: 0.5291 - auc: 0.6573\n",
            " For Batch Number 483 the model has a loss of {'loss': 0.653230607509613, 'tp': 4089.0, 'fp': 2201.0, 'tn': 5526.0, 'fn': 3640.0, 'accuracy': 0.6220884919166565, 'precision': 0.6500794887542725, 'recall': 0.5290464758872986, 'auc': 0.657457709312439} \n",
            "\n",
            " For Batch Number 484 the model has a loss of {'loss': 0.6534644365310669, 'tp': 4095.0, 'fp': 2208.0, 'tn': 5538.0, 'fn': 3647.0, 'accuracy': 0.6219654083251953, 'precision': 0.6496906280517578, 'recall': 0.5289331078529358, 'auc': 0.6571013331413269} \n",
            "484/689 [====================>.........] - ETA: 16s - loss: 0.6535 - tp: 4095.0000 - fp: 2208.0000 - tn: 5538.0000 - fn: 3647.0000 - accuracy: 0.6220 - precision: 0.6497 - recall: 0.5289 - auc: 0.6571\n",
            " For Batch Number 485 the model has a loss of {'loss': 0.6535537838935852, 'tp': 4101.0, 'fp': 2214.0, 'tn': 5548.0, 'fn': 3657.0, 'accuracy': 0.6217139363288879, 'precision': 0.6494061946868896, 'recall': 0.5286155939102173, 'auc': 0.6569765210151672} \n",
            "485/689 [====================>.........] - ETA: 16s - loss: 0.6536 - tp: 4101.0000 - fp: 2214.0000 - tn: 5548.0000 - fn: 3657.0000 - accuracy: 0.6217 - precision: 0.6494 - recall: 0.5286 - auc: 0.6570\n",
            " For Batch Number 486 the model has a loss of {'loss': 0.6535770893096924, 'tp': 4110.0, 'fp': 2218.0, 'tn': 5561.0, 'fn': 3663.0, 'accuracy': 0.6218492984771729, 'precision': 0.6494942903518677, 'recall': 0.528753399848938, 'auc': 0.6569831371307373} \n",
            "486/689 [====================>.........] - ETA: 16s - loss: 0.6536 - tp: 4110.0000 - fp: 2218.0000 - tn: 5561.0000 - fn: 3663.0000 - accuracy: 0.6218 - precision: 0.6495 - recall: 0.5288 - auc: 0.6570\n",
            " For Batch Number 487 the model has a loss of {'loss': 0.6535033583641052, 'tp': 4119.0, 'fp': 2223.0, 'tn': 5573.0, 'fn': 3669.0, 'accuracy': 0.6219199299812317, 'precision': 0.6494796872138977, 'recall': 0.5288906097412109, 'auc': 0.6570101976394653} \n",
            "487/689 [====================>.........] - ETA: 15s - loss: 0.6535 - tp: 4119.0000 - fp: 2223.0000 - tn: 5573.0000 - fn: 3669.0000 - accuracy: 0.6219 - precision: 0.6495 - recall: 0.5289 - auc: 0.6570\n",
            " For Batch Number 488 the model has a loss of {'loss': 0.6534175276756287, 'tp': 4129.0, 'fp': 2225.0, 'tn': 5584.0, 'fn': 3678.0, 'accuracy': 0.6219902634620667, 'precision': 0.6498268842697144, 'recall': 0.5288843512535095, 'auc': 0.6571434140205383} \n",
            "488/689 [====================>.........] - ETA: 15s - loss: 0.6534 - tp: 4129.0000 - fp: 2225.0000 - tn: 5584.0000 - fn: 3678.0000 - accuracy: 0.6220 - precision: 0.6498 - recall: 0.5289 - auc: 0.6571\n",
            " For Batch Number 489 the model has a loss of {'loss': 0.6534684300422668, 'tp': 4139.0, 'fp': 2229.0, 'tn': 5591.0, 'fn': 3689.0, 'accuracy': 0.6218047142028809, 'precision': 0.6499685645103455, 'recall': 0.5287429690361023, 'auc': 0.6570936441421509} \n",
            "489/689 [====================>.........] - ETA: 15s - loss: 0.6535 - tp: 4139.0000 - fp: 2229.0000 - tn: 5591.0000 - fn: 3689.0000 - accuracy: 0.6218 - precision: 0.6500 - recall: 0.5287 - auc: 0.6571\n",
            " For Batch Number 490 the model has a loss of {'loss': 0.6535610556602478, 'tp': 4146.0, 'fp': 2238.0, 'tn': 5599.0, 'fn': 3697.0, 'accuracy': 0.621492326259613, 'precision': 0.6494361162185669, 'recall': 0.5286242365837097, 'auc': 0.6569140553474426} \n",
            "490/689 [====================>.........] - ETA: 15s - loss: 0.6536 - tp: 4146.0000 - fp: 2238.0000 - tn: 5599.0000 - fn: 3697.0000 - accuracy: 0.6215 - precision: 0.6494 - recall: 0.5286 - auc: 0.6569\n",
            " For Batch Number 491 the model has a loss of {'loss': 0.6535264849662781, 'tp': 4159.0, 'fp': 2244.0, 'tn': 5607.0, 'fn': 3702.0, 'accuracy': 0.6215631365776062, 'precision': 0.6495392918586731, 'recall': 0.5290675759315491, 'auc': 0.6569772958755493} \n",
            "491/689 [====================>.........] - ETA: 15s - loss: 0.6535 - tp: 4159.0000 - fp: 2244.0000 - tn: 5607.0000 - fn: 3702.0000 - accuracy: 0.6216 - precision: 0.6495 - recall: 0.5291 - auc: 0.6570\n",
            " For Batch Number 492 the model has a loss of {'loss': 0.653488278388977, 'tp': 4172.0, 'fp': 2254.0, 'tn': 5612.0, 'fn': 3706.0, 'accuracy': 0.6214430928230286, 'precision': 0.6492374539375305, 'recall': 0.5295760631561279, 'auc': 0.6569976806640625} \n",
            "492/689 [====================>.........] - ETA: 15s - loss: 0.6535 - tp: 4172.0000 - fp: 2254.0000 - tn: 5612.0000 - fn: 3706.0000 - accuracy: 0.6214 - precision: 0.6492 - recall: 0.5296 - auc: 0.6570\n",
            " For Batch Number 493 the model has a loss of {'loss': 0.6534603238105774, 'tp': 4185.0, 'fp': 2262.0, 'tn': 5619.0, 'fn': 3710.0, 'accuracy': 0.6214503049850464, 'precision': 0.6491391062736511, 'recall': 0.5300823450088501, 'auc': 0.6570268273353577} \n",
            "493/689 [====================>.........] - ETA: 15s - loss: 0.6535 - tp: 4185.0000 - fp: 2262.0000 - tn: 5619.0000 - fn: 3710.0000 - accuracy: 0.6215 - precision: 0.6491 - recall: 0.5301 - auc: 0.6570\n",
            " For Batch Number 494 the model has a loss of {'loss': 0.6535413861274719, 'tp': 4196.0, 'fp': 2273.0, 'tn': 5626.0, 'fn': 3713.0, 'accuracy': 0.621330976486206, 'precision': 0.6486319303512573, 'recall': 0.5305348634719849, 'auc': 0.6568741798400879} \n",
            "\n",
            " For Batch Number 495 the model has a loss of {'loss': 0.6536104083061218, 'tp': 4205.0, 'fp': 2285.0, 'tn': 5633.0, 'fn': 3717.0, 'accuracy': 0.6210858821868896, 'precision': 0.6479198932647705, 'recall': 0.5308002829551697, 'auc': 0.6566931009292603} \n",
            "495/689 [====================>.........] - ETA: 15s - loss: 0.6536 - tp: 4205.0000 - fp: 2285.0000 - tn: 5633.0000 - fn: 3717.0000 - accuracy: 0.6211 - precision: 0.6479 - recall: 0.5308 - auc: 0.6567\n",
            " For Batch Number 496 the model has a loss of {'loss': 0.6537100672721863, 'tp': 4212.0, 'fp': 2294.0, 'tn': 5643.0, 'fn': 3723.0, 'accuracy': 0.6209047436714172, 'precision': 0.6474024057388306, 'recall': 0.5308128595352173, 'auc': 0.6565350294113159} \n",
            "496/689 [====================>.........] - ETA: 15s - loss: 0.6537 - tp: 4212.0000 - fp: 2294.0000 - tn: 5643.0000 - fn: 3723.0000 - accuracy: 0.6209 - precision: 0.6474 - recall: 0.5308 - auc: 0.6565\n",
            " For Batch Number 497 the model has a loss of {'loss': 0.6535571217536926, 'tp': 4221.0, 'fp': 2296.0, 'tn': 5658.0, 'fn': 3729.0, 'accuracy': 0.6211645007133484, 'precision': 0.6476906538009644, 'recall': 0.5309433937072754, 'auc': 0.6567251682281494} \n",
            "497/689 [====================>.........] - ETA: 15s - loss: 0.6536 - tp: 4221.0000 - fp: 2296.0000 - tn: 5658.0000 - fn: 3729.0000 - accuracy: 0.6212 - precision: 0.6477 - recall: 0.5309 - auc: 0.6567\n",
            " For Batch Number 498 the model has a loss of {'loss': 0.6534197330474854, 'tp': 4230.0, 'fp': 2298.0, 'tn': 5673.0, 'fn': 3735.0, 'accuracy': 0.6214231848716736, 'precision': 0.6479779481887817, 'recall': 0.5310734510421753, 'auc': 0.6569819450378418} \n",
            "498/689 [====================>.........] - ETA: 15s - loss: 0.6534 - tp: 4230.0000 - fp: 2298.0000 - tn: 5673.0000 - fn: 3735.0000 - accuracy: 0.6214 - precision: 0.6480 - recall: 0.5311 - auc: 0.6570\n",
            " For Batch Number 499 the model has a loss of {'loss': 0.653239369392395, 'tp': 4237.0, 'fp': 2299.0, 'tn': 5690.0, 'fn': 3742.0, 'accuracy': 0.6216808557510376, 'precision': 0.6482558250427246, 'recall': 0.5310189127922058, 'auc': 0.6572760343551636} \n",
            "499/689 [====================>.........] - ETA: 14s - loss: 0.6532 - tp: 4237.0000 - fp: 2299.0000 - tn: 5690.0000 - fn: 3742.0000 - accuracy: 0.6217 - precision: 0.6483 - recall: 0.5310 - auc: 0.6573\n",
            " For Batch Number 500 the model has a loss of {'loss': 0.6534605622291565, 'tp': 4242.0, 'fp': 2301.0, 'tn': 5700.0, 'fn': 3757.0, 'accuracy': 0.6213750243186951, 'precision': 0.6483264565467834, 'recall': 0.5303162932395935, 'auc': 0.656960666179657} \n",
            "500/689 [====================>.........] - ETA: 14s - loss: 0.6535 - tp: 4242.0000 - fp: 2301.0000 - tn: 5700.0000 - fn: 3757.0000 - accuracy: 0.6214 - precision: 0.6483 - recall: 0.5303 - auc: 0.6570\n",
            " For Batch Number 501 the model has a loss of {'loss': 0.6536478400230408, 'tp': 4250.0, 'fp': 2304.0, 'tn': 5710.0, 'fn': 3768.0, 'accuracy': 0.621257483959198, 'precision': 0.6484589576721191, 'recall': 0.5300573706626892, 'auc': 0.6567579507827759} \n",
            "501/689 [====================>.........] - ETA: 14s - loss: 0.6536 - tp: 4250.0000 - fp: 2304.0000 - tn: 5710.0000 - fn: 3768.0000 - accuracy: 0.6213 - precision: 0.6485 - recall: 0.5301 - auc: 0.6568\n",
            " For Batch Number 502 the model has a loss of {'loss': 0.6534463167190552, 'tp': 4258.0, 'fp': 2307.0, 'tn': 5726.0, 'fn': 3773.0, 'accuracy': 0.6215139627456665, 'precision': 0.6485910415649414, 'recall': 0.5301954746246338, 'auc': 0.6570752859115601} \n",
            "502/689 [====================>.........] - ETA: 14s - loss: 0.6534 - tp: 4258.0000 - fp: 2307.0000 - tn: 5726.0000 - fn: 3773.0000 - accuracy: 0.6215 - precision: 0.6486 - recall: 0.5302 - auc: 0.6571\n",
            " For Batch Number 503 the model has a loss of {'loss': 0.6535286903381348, 'tp': 4265.0, 'fp': 2315.0, 'tn': 5735.0, 'fn': 3781.0, 'accuracy': 0.6212723851203918, 'precision': 0.6481763124465942, 'recall': 0.5300770401954651, 'auc': 0.6569874286651611} \n",
            "503/689 [====================>.........] - ETA: 14s - loss: 0.6535 - tp: 4265.0000 - fp: 2315.0000 - tn: 5735.0000 - fn: 3781.0000 - accuracy: 0.6213 - precision: 0.6482 - recall: 0.5301 - auc: 0.6570\n",
            " For Batch Number 504 the model has a loss of {'loss': 0.6538053154945374, 'tp': 4274.0, 'fp': 2320.0, 'tn': 5742.0, 'fn': 3792.0, 'accuracy': 0.6210317611694336, 'precision': 0.6481649875640869, 'recall': 0.5298784971237183, 'auc': 0.6565461158752441} \n",
            "504/689 [====================>.........] - ETA: 14s - loss: 0.6538 - tp: 4274.0000 - fp: 2320.0000 - tn: 5742.0000 - fn: 3792.0000 - accuracy: 0.6210 - precision: 0.6482 - recall: 0.5299 - auc: 0.6565\n",
            " For Batch Number 505 the model has a loss of {'loss': 0.6538011431694031, 'tp': 4285.0, 'fp': 2326.0, 'tn': 5750.0, 'fn': 3799.0, 'accuracy': 0.6209776997566223, 'precision': 0.6481621265411377, 'recall': 0.5300593972206116, 'auc': 0.6565121412277222} \n",
            "505/689 [====================>.........] - ETA: 14s - loss: 0.6538 - tp: 4285.0000 - fp: 2326.0000 - tn: 5750.0000 - fn: 3799.0000 - accuracy: 0.6210 - precision: 0.6482 - recall: 0.5301 - auc: 0.6565\n",
            " For Batch Number 506 the model has a loss of {'loss': 0.653652012348175, 'tp': 4299.0, 'fp': 2332.0, 'tn': 5758.0, 'fn': 3803.0, 'accuracy': 0.6211091876029968, 'precision': 0.6483185291290283, 'recall': 0.5306097269058228, 'auc': 0.656719982624054} \n",
            "506/689 [=====================>........] - ETA: 14s - loss: 0.6537 - tp: 4299.0000 - fp: 2332.0000 - tn: 5758.0000 - fn: 3803.0000 - accuracy: 0.6211 - precision: 0.6483 - recall: 0.5306 - auc: 0.6567\n",
            " For Batch Number 507 the model has a loss of {'loss': 0.6537473201751709, 'tp': 4315.0, 'fp': 2342.0, 'tn': 5760.0, 'fn': 3807.0, 'accuracy': 0.6209936141967773, 'precision': 0.648189902305603, 'recall': 0.5312730669975281, 'auc': 0.6567258238792419} \n",
            "507/689 [=====================>........] - ETA: 14s - loss: 0.6537 - tp: 4315.0000 - fp: 2342.0000 - tn: 5760.0000 - fn: 3807.0000 - accuracy: 0.6210 - precision: 0.6482 - recall: 0.5313 - auc: 0.6567\n",
            " For Batch Number 508 the model has a loss of {'loss': 0.653943657875061, 'tp': 4330.0, 'fp': 2356.0, 'tn': 5761.0, 'fn': 3809.0, 'accuracy': 0.6207554340362549, 'precision': 0.6476218700408936, 'recall': 0.5320063829421997, 'auc': 0.6565669775009155} \n",
            "508/689 [=====================>........] - ETA: 14s - loss: 0.6539 - tp: 4330.0000 - fp: 2356.0000 - tn: 5761.0000 - fn: 3809.0000 - accuracy: 0.6208 - precision: 0.6476 - recall: 0.5320 - auc: 0.6566\n",
            " For Batch Number 509 the model has a loss of {'loss': 0.6540206074714661, 'tp': 4341.0, 'fp': 2367.0, 'tn': 5768.0, 'fn': 3812.0, 'accuracy': 0.6206409335136414, 'precision': 0.6471377611160278, 'recall': 0.532442033290863, 'auc': 0.6563695073127747} \n",
            "509/689 [=====================>........] - ETA: 14s - loss: 0.6540 - tp: 4341.0000 - fp: 2367.0000 - tn: 5768.0000 - fn: 3812.0000 - accuracy: 0.6206 - precision: 0.6471 - recall: 0.5324 - auc: 0.6564\n",
            " For Batch Number 510 the model has a loss of {'loss': 0.6540906429290771, 'tp': 4348.0, 'fp': 2375.0, 'tn': 5778.0, 'fn': 3819.0, 'accuracy': 0.6204656958580017, 'precision': 0.6467350721359253, 'recall': 0.5323864221572876, 'auc': 0.6562522649765015} \n",
            "510/689 [=====================>........] - ETA: 14s - loss: 0.6541 - tp: 4348.0000 - fp: 2375.0000 - tn: 5778.0000 - fn: 3819.0000 - accuracy: 0.6205 - precision: 0.6467 - recall: 0.5324 - auc: 0.6563\n",
            " For Batch Number 511 the model has a loss of {'loss': 0.6542049646377563, 'tp': 4357.0, 'fp': 2378.0, 'tn': 5786.0, 'fn': 3831.0, 'accuracy': 0.6202911138534546, 'precision': 0.6469190716743469, 'recall': 0.5321201682090759, 'auc': 0.6560813784599304} \n",
            "511/689 [=====================>........] - ETA: 14s - loss: 0.6542 - tp: 4357.0000 - fp: 2378.0000 - tn: 5786.0000 - fn: 3831.0000 - accuracy: 0.6203 - precision: 0.6469 - recall: 0.5321 - auc: 0.6561\n",
            " For Batch Number 512 the model has a loss of {'loss': 0.6542558073997498, 'tp': 4363.0, 'fp': 2384.0, 'tn': 5800.0, 'fn': 3837.0, 'accuracy': 0.62030029296875, 'precision': 0.6466577649116516, 'recall': 0.5320731997489929, 'auc': 0.6560189723968506} \n",
            "512/689 [=====================>........] - ETA: 13s - loss: 0.6543 - tp: 4363.0000 - fp: 2384.0000 - tn: 5800.0000 - fn: 3837.0000 - accuracy: 0.6203 - precision: 0.6467 - recall: 0.5321 - auc: 0.6560\n",
            " For Batch Number 513 the model has a loss of {'loss': 0.6541702151298523, 'tp': 4369.0, 'fp': 2388.0, 'tn': 5814.0, 'fn': 3845.0, 'accuracy': 0.6203094720840454, 'precision': 0.6465887427330017, 'recall': 0.5318967700004578, 'auc': 0.65610271692276} \n",
            "513/689 [=====================>........] - ETA: 13s - loss: 0.6542 - tp: 4369.0000 - fp: 2388.0000 - tn: 5814.0000 - fn: 3845.0000 - accuracy: 0.6203 - precision: 0.6466 - recall: 0.5319 - auc: 0.6561\n",
            " For Batch Number 514 the model has a loss of {'loss': 0.6542458534240723, 'tp': 4373.0, 'fp': 2392.0, 'tn': 5826.0, 'fn': 3857.0, 'accuracy': 0.6200754046440125, 'precision': 0.6464153528213501, 'recall': 0.531348705291748, 'auc': 0.655982494354248} \n",
            "514/689 [=====================>........] - ETA: 13s - loss: 0.6542 - tp: 4373.0000 - fp: 2392.0000 - tn: 5826.0000 - fn: 3857.0000 - accuracy: 0.6201 - precision: 0.6464 - recall: 0.5313 - auc: 0.6560\n",
            " For Batch Number 515 the model has a loss of {'loss': 0.6543495655059814, 'tp': 4375.0, 'fp': 2400.0, 'tn': 5843.0, 'fn': 3862.0, 'accuracy': 0.6200242638587952, 'precision': 0.6457564830780029, 'recall': 0.5311399698257446, 'auc': 0.6557688117027283} \n",
            "515/689 [=====================>........] - ETA: 13s - loss: 0.6543 - tp: 4375.0000 - fp: 2400.0000 - tn: 5843.0000 - fn: 3862.0000 - accuracy: 0.6200 - precision: 0.6458 - recall: 0.5311 - auc: 0.6558\n",
            " For Batch Number 516 the model has a loss of {'loss': 0.6542071104049683, 'tp': 4382.0, 'fp': 2401.0, 'tn': 5860.0, 'fn': 3869.0, 'accuracy': 0.620276153087616, 'precision': 0.6460268497467041, 'recall': 0.5310871601104736, 'auc': 0.6559937596321106} \n",
            "516/689 [=====================>........] - ETA: 13s - loss: 0.6542 - tp: 4382.0000 - fp: 2401.0000 - tn: 5860.0000 - fn: 3869.0000 - accuracy: 0.6203 - precision: 0.6460 - recall: 0.5311 - auc: 0.6560\n",
            " For Batch Number 517 the model has a loss of {'loss': 0.6540628671646118, 'tp': 4388.0, 'fp': 2404.0, 'tn': 5878.0, 'fn': 3874.0, 'accuracy': 0.6205270886421204, 'precision': 0.646054208278656, 'recall': 0.5311062932014465, 'auc': 0.65621417760849} \n",
            "517/689 [=====================>........] - ETA: 13s - loss: 0.6541 - tp: 4388.0000 - fp: 2404.0000 - tn: 5878.0000 - fn: 3874.0000 - accuracy: 0.6205 - precision: 0.6461 - recall: 0.5311 - auc: 0.6562\n",
            " For Batch Number 518 the model has a loss of {'loss': 0.6540176868438721, 'tp': 4395.0, 'fp': 2405.0, 'tn': 5892.0, 'fn': 3884.0, 'accuracy': 0.6205960512161255, 'precision': 0.6463235020637512, 'recall': 0.5308611989021301, 'auc': 0.6563031077384949} \n",
            "518/689 [=====================>........] - ETA: 13s - loss: 0.6540 - tp: 4395.0000 - fp: 2405.0000 - tn: 5892.0000 - fn: 3884.0000 - accuracy: 0.6206 - precision: 0.6463 - recall: 0.5309 - auc: 0.6563\n",
            " For Batch Number 519 the model has a loss of {'loss': 0.6540446281433105, 'tp': 4398.0, 'fp': 2408.0, 'tn': 5907.0, 'fn': 3895.0, 'accuracy': 0.6204841136932373, 'precision': 0.6461945176124573, 'recall': 0.530326783657074, 'auc': 0.6562981009483337} \n",
            "519/689 [=====================>........] - ETA: 13s - loss: 0.6540 - tp: 4398.0000 - fp: 2408.0000 - tn: 5907.0000 - fn: 3895.0000 - accuracy: 0.6205 - precision: 0.6462 - recall: 0.5303 - auc: 0.6563\n",
            " For Batch Number 520 the model has a loss of {'loss': 0.6539793014526367, 'tp': 4404.0, 'fp': 2409.0, 'tn': 5922.0, 'fn': 3905.0, 'accuracy': 0.6205528974533081, 'precision': 0.6464112997055054, 'recall': 0.5300276875495911, 'auc': 0.6563831567764282} \n",
            "520/689 [=====================>........] - ETA: 13s - loss: 0.6540 - tp: 4404.0000 - fp: 2409.0000 - tn: 5922.0000 - fn: 3905.0000 - accuracy: 0.6206 - precision: 0.6464 - recall: 0.5300 - auc: 0.6564\n",
            " For Batch Number 521 the model has a loss of {'loss': 0.6542298793792725, 'tp': 4409.0, 'fp': 2413.0, 'tn': 5932.0, 'fn': 3918.0, 'accuracy': 0.6202614903450012, 'precision': 0.6462914347648621, 'recall': 0.5294824242591858, 'auc': 0.6560162305831909} \n",
            "521/689 [=====================>........] - ETA: 13s - loss: 0.6542 - tp: 4409.0000 - fp: 2413.0000 - tn: 5932.0000 - fn: 3918.0000 - accuracy: 0.6203 - precision: 0.6463 - recall: 0.5295 - auc: 0.6560\n",
            " For Batch Number 522 the model has a loss of {'loss': 0.6541413068771362, 'tp': 4419.0, 'fp': 2416.0, 'tn': 5944.0, 'fn': 3925.0, 'accuracy': 0.6203902959823608, 'precision': 0.6465252637863159, 'recall': 0.5296021103858948, 'auc': 0.6561715006828308} \n",
            "522/689 [=====================>........] - ETA: 13s - loss: 0.6541 - tp: 4419.0000 - fp: 2416.0000 - tn: 5944.0000 - fn: 3925.0000 - accuracy: 0.6204 - precision: 0.6465 - recall: 0.5296 - auc: 0.6562\n",
            " For Batch Number 523 the model has a loss of {'loss': 0.6543923020362854, 'tp': 4425.0, 'fp': 2434.0, 'tn': 5950.0, 'fn': 3927.0, 'accuracy': 0.6199211478233337, 'precision': 0.6451377868652344, 'recall': 0.5298132300376892, 'auc': 0.655693531036377} \n",
            "523/689 [=====================>........] - ETA: 13s - loss: 0.6544 - tp: 4425.0000 - fp: 2434.0000 - tn: 5950.0000 - fn: 3927.0000 - accuracy: 0.6199 - precision: 0.6451 - recall: 0.5298 - auc: 0.6557\n",
            " For Batch Number 524 the model has a loss of {'loss': 0.6542447209358215, 'tp': 4435.0, 'fp': 2440.0, 'tn': 5961.0, 'fn': 3932.0, 'accuracy': 0.6199904680252075, 'precision': 0.6450909376144409, 'recall': 0.5300585627555847, 'auc': 0.6558927893638611} \n",
            "524/689 [=====================>........] - ETA: 13s - loss: 0.6542 - tp: 4435.0000 - fp: 2440.0000 - tn: 5961.0000 - fn: 3932.0000 - accuracy: 0.6200 - precision: 0.6451 - recall: 0.5301 - auc: 0.6559\n",
            " For Batch Number 525 the model has a loss of {'loss': 0.6543053388595581, 'tp': 4439.0, 'fp': 2442.0, 'tn': 5976.0, 'fn': 3943.0, 'accuracy': 0.619940459728241, 'precision': 0.6451097130775452, 'recall': 0.5295872092247009, 'auc': 0.6557098031044006} \n",
            "525/689 [=====================>........] - ETA: 12s - loss: 0.6543 - tp: 4439.0000 - fp: 2442.0000 - tn: 5976.0000 - fn: 3943.0000 - accuracy: 0.6199 - precision: 0.6451 - recall: 0.5296 - auc: 0.6557\n",
            " For Batch Number 526 the model has a loss of {'loss': 0.654355525970459, 'tp': 4445.0, 'fp': 2444.0, 'tn': 5988.0, 'fn': 3955.0, 'accuracy': 0.6198312640190125, 'precision': 0.6452315449714661, 'recall': 0.5291666388511658, 'auc': 0.655666708946228} \n",
            "526/689 [=====================>........] - ETA: 12s - loss: 0.6544 - tp: 4445.0000 - fp: 2444.0000 - tn: 5988.0000 - fn: 3955.0000 - accuracy: 0.6198 - precision: 0.6452 - recall: 0.5292 - auc: 0.6557\n",
            " For Batch Number 527 the model has a loss of {'loss': 0.6541353464126587, 'tp': 4452.0, 'fp': 2445.0, 'tn': 6006.0, 'fn': 3961.0, 'accuracy': 0.6201375722885132, 'precision': 0.6454980373382568, 'recall': 0.5291810035705566, 'auc': 0.656032145023346} \n",
            "527/689 [=====================>........] - ETA: 12s - loss: 0.6541 - tp: 4452.0000 - fp: 2445.0000 - tn: 6006.0000 - fn: 3961.0000 - accuracy: 0.6201 - precision: 0.6455 - recall: 0.5292 - auc: 0.6560\n",
            " For Batch Number 528 the model has a loss of {'loss': 0.654204249382019, 'tp': 4457.0, 'fp': 2447.0, 'tn': 6019.0, 'fn': 3973.0, 'accuracy': 0.6200284361839294, 'precision': 0.645567774772644, 'recall': 0.5287070274353027, 'auc': 0.6560247540473938} \n",
            "528/689 [=====================>........] - ETA: 12s - loss: 0.6542 - tp: 4457.0000 - fp: 2447.0000 - tn: 6019.0000 - fn: 3973.0000 - accuracy: 0.6200 - precision: 0.6456 - recall: 0.5287 - auc: 0.6560\n",
            " For Batch Number 529 the model has a loss of {'loss': 0.6539040207862854, 'tp': 4468.0, 'fp': 2448.0, 'tn': 6034.0, 'fn': 3978.0, 'accuracy': 0.6203922629356384, 'precision': 0.6460381746292114, 'recall': 0.5290077924728394, 'auc': 0.6564884185791016} \n",
            "529/689 [======================>.......] - ETA: 12s - loss: 0.6539 - tp: 4468.0000 - fp: 2448.0000 - tn: 6034.0000 - fn: 3978.0000 - accuracy: 0.6204 - precision: 0.6460 - recall: 0.5290 - auc: 0.6565\n",
            " For Batch Number 530 the model has a loss of {'loss': 0.6539194583892822, 'tp': 4480.0, 'fp': 2456.0, 'tn': 6043.0, 'fn': 3981.0, 'accuracy': 0.6204599142074585, 'precision': 0.6459054350852966, 'recall': 0.5294882655143738, 'auc': 0.6565101146697998} \n",
            "530/689 [======================>.......] - ETA: 12s - loss: 0.6539 - tp: 4480.0000 - fp: 2456.0000 - tn: 6043.0000 - fn: 3981.0000 - accuracy: 0.6205 - precision: 0.6459 - recall: 0.5295 - auc: 0.6565\n",
            " For Batch Number 531 the model has a loss of {'loss': 0.6538282632827759, 'tp': 4493.0, 'fp': 2460.0, 'tn': 6053.0, 'fn': 3986.0, 'accuracy': 0.6206449866294861, 'precision': 0.6461958885192871, 'recall': 0.5298973917961121, 'auc': 0.656705915927887} \n",
            "531/689 [======================>.......] - ETA: 12s - loss: 0.6538 - tp: 4493.0000 - fp: 2460.0000 - tn: 6053.0000 - fn: 3986.0000 - accuracy: 0.6206 - precision: 0.6462 - recall: 0.5299 - auc: 0.6567\n",
            " For Batch Number 532 the model has a loss of {'loss': 0.6537091732025146, 'tp': 4504.0, 'fp': 2465.0, 'tn': 6065.0, 'fn': 3990.0, 'accuracy': 0.6208294034004211, 'precision': 0.6462907195091248, 'recall': 0.5302566289901733, 'auc': 0.6569047570228577} \n",
            "532/689 [======================>.......] - ETA: 12s - loss: 0.6537 - tp: 4504.0000 - fp: 2465.0000 - tn: 6065.0000 - fn: 3990.0000 - accuracy: 0.6208 - precision: 0.6463 - recall: 0.5303 - auc: 0.6569\n",
            " For Batch Number 533 the model has a loss of {'loss': 0.6536216139793396, 'tp': 4515.0, 'fp': 2469.0, 'tn': 6074.0, 'fn': 3998.0, 'accuracy': 0.6208372712135315, 'precision': 0.6464776396751404, 'recall': 0.5303653478622437, 'auc': 0.6570894122123718} \n",
            "533/689 [======================>.......] - ETA: 12s - loss: 0.6536 - tp: 4515.0000 - fp: 2469.0000 - tn: 6074.0000 - fn: 3998.0000 - accuracy: 0.6208 - precision: 0.6465 - recall: 0.5304 - auc: 0.6571\n",
            " For Batch Number 534 the model has a loss of {'loss': 0.6536065936088562, 'tp': 4525.0, 'fp': 2475.0, 'tn': 6082.0, 'fn': 4006.0, 'accuracy': 0.6207280158996582, 'precision': 0.6464285850524902, 'recall': 0.5304184556007385, 'auc': 0.65719074010849} \n",
            "534/689 [======================>.......] - ETA: 12s - loss: 0.6536 - tp: 4525.0000 - fp: 2475.0000 - tn: 6082.0000 - fn: 4006.0000 - accuracy: 0.6207 - precision: 0.6464 - recall: 0.5304 - auc: 0.6572\n",
            " For Batch Number 535 the model has a loss of {'loss': 0.6537671089172363, 'tp': 4534.0, 'fp': 2484.0, 'tn': 6094.0, 'fn': 4008.0, 'accuracy': 0.620794415473938, 'precision': 0.6460530161857605, 'recall': 0.5307890176773071, 'auc': 0.6570610404014587} \n",
            "535/689 [======================>.......] - ETA: 12s - loss: 0.6538 - tp: 4534.0000 - fp: 2484.0000 - tn: 6094.0000 - fn: 4008.0000 - accuracy: 0.6208 - precision: 0.6461 - recall: 0.5308 - auc: 0.6571\n",
            " For Batch Number 536 the model has a loss of {'loss': 0.6541592478752136, 'tp': 4540.0, 'fp': 2493.0, 'tn': 6102.0, 'fn': 4017.0, 'accuracy': 0.6204524040222168, 'precision': 0.6455281972885132, 'recall': 0.530559778213501, 'auc': 0.6566635966300964} \n",
            "536/689 [======================>.......] - ETA: 12s - loss: 0.6542 - tp: 4540.0000 - fp: 2493.0000 - tn: 6102.0000 - fn: 4017.0000 - accuracy: 0.6205 - precision: 0.6455 - recall: 0.5306 - auc: 0.6567\n",
            " For Batch Number 537 the model has a loss of {'loss': 0.6540114879608154, 'tp': 4548.0, 'fp': 2496.0, 'tn': 6116.0, 'fn': 4024.0, 'accuracy': 0.6205772757530212, 'precision': 0.6456558704376221, 'recall': 0.5305646061897278, 'auc': 0.6568870544433594} \n",
            "537/689 [======================>.......] - ETA: 12s - loss: 0.6540 - tp: 4548.0000 - fp: 2496.0000 - tn: 6116.0000 - fn: 4024.0000 - accuracy: 0.6206 - precision: 0.6457 - recall: 0.5306 - auc: 0.6569\n",
            " For Batch Number 538 the model has a loss of {'loss': 0.6540296673774719, 'tp': 4557.0, 'fp': 2496.0, 'tn': 6127.0, 'fn': 4036.0, 'accuracy': 0.6205855011940002, 'precision': 0.6461080312728882, 'recall': 0.5303153991699219, 'auc': 0.6568890810012817} \n",
            "538/689 [======================>.......] - ETA: 11s - loss: 0.6540 - tp: 4557.0000 - fp: 2496.0000 - tn: 6127.0000 - fn: 4036.0000 - accuracy: 0.6206 - precision: 0.6461 - recall: 0.5303 - auc: 0.6569\n",
            " For Batch Number 539 the model has a loss of {'loss': 0.6541700959205627, 'tp': 4563.0, 'fp': 2500.0, 'tn': 6141.0, 'fn': 4044.0, 'accuracy': 0.6205936670303345, 'precision': 0.6460427641868591, 'recall': 0.5301498770713806, 'auc': 0.656835675239563} \n",
            "539/689 [======================>.......] - ETA: 11s - loss: 0.6542 - tp: 4563.0000 - fp: 2500.0000 - tn: 6141.0000 - fn: 4044.0000 - accuracy: 0.6206 - precision: 0.6460 - recall: 0.5301 - auc: 0.6568\n",
            " For Batch Number 540 the model has a loss of {'loss': 0.6540809869766235, 'tp': 4574.0, 'fp': 2500.0, 'tn': 6153.0, 'fn': 4053.0, 'accuracy': 0.6207754611968994, 'precision': 0.6465931534767151, 'recall': 0.5301958918571472, 'auc': 0.6570383906364441} \n",
            "540/689 [======================>.......] - ETA: 11s - loss: 0.6541 - tp: 4574.0000 - fp: 2500.0000 - tn: 6153.0000 - fn: 4053.0000 - accuracy: 0.6208 - precision: 0.6466 - recall: 0.5302 - auc: 0.6570\n",
            " For Batch Number 541 the model has a loss of {'loss': 0.6539114713668823, 'tp': 4587.0, 'fp': 2502.0, 'tn': 6165.0, 'fn': 4058.0, 'accuracy': 0.6210721135139465, 'precision': 0.6470588445663452, 'recall': 0.5305957198143005, 'auc': 0.6573433876037598} \n",
            "541/689 [======================>.......] - ETA: 11s - loss: 0.6539 - tp: 4587.0000 - fp: 2502.0000 - tn: 6165.0000 - fn: 4058.0000 - accuracy: 0.6211 - precision: 0.6471 - recall: 0.5306 - auc: 0.6573\n",
            " For Batch Number 542 the model has a loss of {'loss': 0.6538659334182739, 'tp': 4596.0, 'fp': 2510.0, 'tn': 6176.0, 'fn': 4062.0, 'accuracy': 0.6210793256759644, 'precision': 0.6467773914337158, 'recall': 0.5308385491371155, 'auc': 0.6572719812393188} \n",
            "542/689 [======================>.......] - ETA: 11s - loss: 0.6539 - tp: 4596.0000 - fp: 2510.0000 - tn: 6176.0000 - fn: 4062.0000 - accuracy: 0.6211 - precision: 0.6468 - recall: 0.5308 - auc: 0.6573\n",
            " For Batch Number 543 the model has a loss of {'loss': 0.6536967158317566, 'tp': 4609.0, 'fp': 2515.0, 'tn': 6183.0, 'fn': 4069.0, 'accuracy': 0.6210865378379822, 'precision': 0.6469680070877075, 'recall': 0.5311131477355957, 'auc': 0.6575180888175964} \n",
            "543/689 [======================>.......] - ETA: 11s - loss: 0.6537 - tp: 4609.0000 - fp: 2515.0000 - tn: 6183.0000 - fn: 4069.0000 - accuracy: 0.6211 - precision: 0.6470 - recall: 0.5311 - auc: 0.6575\n",
            " For Batch Number 544 the model has a loss of {'loss': 0.6536363959312439, 'tp': 4622.0, 'fp': 2524.0, 'tn': 6190.0, 'fn': 4072.0, 'accuracy': 0.62109375, 'precision': 0.646795392036438, 'recall': 0.5316309928894043, 'auc': 0.6575504541397095} \n",
            "544/689 [======================>.......] - ETA: 11s - loss: 0.6536 - tp: 4622.0000 - fp: 2524.0000 - tn: 6190.0000 - fn: 4072.0000 - accuracy: 0.6211 - precision: 0.6468 - recall: 0.5316 - auc: 0.6576\n",
            " For Batch Number 545 the model has a loss of {'loss': 0.653626561164856, 'tp': 4633.0, 'fp': 2532.0, 'tn': 6198.0, 'fn': 4077.0, 'accuracy': 0.6210435628890991, 'precision': 0.6466155052185059, 'recall': 0.5319173336029053, 'auc': 0.657576858997345} \n",
            "545/689 [======================>.......] - ETA: 11s - loss: 0.6536 - tp: 4633.0000 - fp: 2532.0000 - tn: 6198.0000 - fn: 4077.0000 - accuracy: 0.6210 - precision: 0.6466 - recall: 0.5319 - auc: 0.6576\n",
            " For Batch Number 546 the model has a loss of {'loss': 0.6534519791603088, 'tp': 4644.0, 'fp': 2538.0, 'tn': 6210.0, 'fn': 4080.0, 'accuracy': 0.6212225556373596, 'precision': 0.646616518497467, 'recall': 0.5323246121406555, 'auc': 0.657830536365509} \n",
            "546/689 [======================>.......] - ETA: 11s - loss: 0.6535 - tp: 4644.0000 - fp: 2538.0000 - tn: 6210.0000 - fn: 4080.0000 - accuracy: 0.6212 - precision: 0.6466 - recall: 0.5323 - auc: 0.6578\n",
            " For Batch Number 547 the model has a loss of {'loss': 0.6533007621765137, 'tp': 4653.0, 'fp': 2541.0, 'tn': 6224.0, 'fn': 4086.0, 'accuracy': 0.6214008331298828, 'precision': 0.646789014339447, 'recall': 0.5324407815933228, 'auc': 0.6580845713615417} \n",
            "547/689 [======================>.......] - ETA: 11s - loss: 0.6533 - tp: 4653.0000 - fp: 2541.0000 - tn: 6224.0000 - fn: 4086.0000 - accuracy: 0.6214 - precision: 0.6468 - recall: 0.5324 - auc: 0.6581\n",
            " For Batch Number 548 the model has a loss of {'loss': 0.6529216766357422, 'tp': 4664.0, 'fp': 2542.0, 'tn': 6238.0, 'fn': 4092.0, 'accuracy': 0.6216925382614136, 'precision': 0.6472384333610535, 'recall': 0.5326633453369141, 'auc': 0.6586768627166748} \n",
            "548/689 [======================>.......] - ETA: 11s - loss: 0.6529 - tp: 4664.0000 - fp: 2542.0000 - tn: 6238.0000 - fn: 4092.0000 - accuracy: 0.6217 - precision: 0.6472 - recall: 0.5327 - auc: 0.6587\n",
            " For Batch Number 549 the model has a loss of {'loss': 0.6530165672302246, 'tp': 4673.0, 'fp': 2543.0, 'tn': 6248.0, 'fn': 4104.0, 'accuracy': 0.6216416358947754, 'precision': 0.6475886702537537, 'recall': 0.5324142575263977, 'auc': 0.6586422324180603} \n",
            "549/689 [======================>.......] - ETA: 11s - loss: 0.6530 - tp: 4673.0000 - fp: 2543.0000 - tn: 6248.0000 - fn: 4104.0000 - accuracy: 0.6216 - precision: 0.6476 - recall: 0.5324 - auc: 0.6586\n",
            " For Batch Number 550 the model has a loss of {'loss': 0.652820348739624, 'tp': 4682.0, 'fp': 2545.0, 'tn': 6263.0, 'fn': 4110.0, 'accuracy': 0.621874988079071, 'precision': 0.64784836769104, 'recall': 0.5325295925140381, 'auc': 0.6589692234992981} \n",
            "550/689 [======================>.......] - ETA: 10s - loss: 0.6528 - tp: 4682.0000 - fp: 2545.0000 - tn: 6263.0000 - fn: 4110.0000 - accuracy: 0.6219 - precision: 0.6478 - recall: 0.5325 - auc: 0.6590\n",
            " For Batch Number 551 the model has a loss of {'loss': 0.6526461243629456, 'tp': 4694.0, 'fp': 2546.0, 'tn': 6272.0, 'fn': 4120.0, 'accuracy': 0.6219373941421509, 'precision': 0.6483425498008728, 'recall': 0.5325618386268616, 'auc': 0.6592530012130737} \n",
            "551/689 [======================>.......] - ETA: 10s - loss: 0.6526 - tp: 4694.0000 - fp: 2546.0000 - tn: 6272.0000 - fn: 4120.0000 - accuracy: 0.6219 - precision: 0.6483 - recall: 0.5326 - auc: 0.6593\n",
            " For Batch Number 552 the model has a loss of {'loss': 0.652410089969635, 'tp': 4707.0, 'fp': 2549.0, 'tn': 6284.0, 'fn': 4124.0, 'accuracy': 0.6222259998321533, 'precision': 0.6487045288085938, 'recall': 0.5330086946487427, 'auc': 0.6596909165382385} \n",
            "552/689 [=======================>......] - ETA: 10s - loss: 0.6524 - tp: 4707.0000 - fp: 2549.0000 - tn: 6284.0000 - fn: 4124.0000 - accuracy: 0.6222 - precision: 0.6487 - recall: 0.5330 - auc: 0.6597\n",
            " For Batch Number 553 the model has a loss of {'loss': 0.6523955464363098, 'tp': 4719.0, 'fp': 2557.0, 'tn': 6293.0, 'fn': 4127.0, 'accuracy': 0.6222875118255615, 'precision': 0.6485706567764282, 'recall': 0.5334614515304565, 'auc': 0.659804105758667} \n",
            "553/689 [=======================>......] - ETA: 10s - loss: 0.6524 - tp: 4719.0000 - fp: 2557.0000 - tn: 6293.0000 - fn: 4127.0000 - accuracy: 0.6223 - precision: 0.6486 - recall: 0.5335 - auc: 0.6598\n",
            " For Batch Number 554 the model has a loss of {'loss': 0.6524165272712708, 'tp': 4733.0, 'fp': 2565.0, 'tn': 6300.0, 'fn': 4130.0, 'accuracy': 0.6223488450050354, 'precision': 0.648533821105957, 'recall': 0.53401780128479, 'auc': 0.6599760055541992} \n",
            "554/689 [=======================>......] - ETA: 10s - loss: 0.6524 - tp: 4733.0000 - fp: 2565.0000 - tn: 6300.0000 - fn: 4130.0000 - accuracy: 0.6223 - precision: 0.6485 - recall: 0.5340 - auc: 0.6600\n",
            " For Batch Number 555 the model has a loss of {'loss': 0.6523829102516174, 'tp': 4746.0, 'fp': 2570.0, 'tn': 6309.0, 'fn': 4135.0, 'accuracy': 0.6224662065505981, 'precision': 0.6487151384353638, 'recall': 0.5343992710113525, 'auc': 0.6601638793945312} \n",
            "555/689 [=======================>......] - ETA: 10s - loss: 0.6524 - tp: 4746.0000 - fp: 2570.0000 - tn: 6309.0000 - fn: 4135.0000 - accuracy: 0.6225 - precision: 0.6487 - recall: 0.5344 - auc: 0.6602\n",
            " For Batch Number 556 the model has a loss of {'loss': 0.6526042819023132, 'tp': 4757.0, 'fp': 2580.0, 'tn': 6317.0, 'fn': 4138.0, 'accuracy': 0.6224145889282227, 'precision': 0.648357629776001, 'recall': 0.534794807434082, 'auc': 0.6600672602653503} \n",
            "556/689 [=======================>......] - ETA: 10s - loss: 0.6526 - tp: 4757.0000 - fp: 2580.0000 - tn: 6317.0000 - fn: 4138.0000 - accuracy: 0.6224 - precision: 0.6484 - recall: 0.5348 - auc: 0.6601\n",
            " For Batch Number 557 the model has a loss of {'loss': 0.652494490146637, 'tp': 4767.0, 'fp': 2586.0, 'tn': 6329.0, 'fn': 4142.0, 'accuracy': 0.6225314140319824, 'precision': 0.6483067870140076, 'recall': 0.535076916217804, 'auc': 0.6603390574455261} \n",
            "557/689 [=======================>......] - ETA: 10s - loss: 0.6525 - tp: 4767.0000 - fp: 2586.0000 - tn: 6329.0000 - fn: 4142.0000 - accuracy: 0.6225 - precision: 0.6483 - recall: 0.5351 - auc: 0.6603\n",
            " For Batch Number 558 the model has a loss of {'loss': 0.6529214978218079, 'tp': 4773.0, 'fp': 2594.0, 'tn': 6338.0, 'fn': 4151.0, 'accuracy': 0.622255802154541, 'precision': 0.647889256477356, 'recall': 0.5348498225212097, 'auc': 0.6598666906356812} \n",
            "558/689 [=======================>......] - ETA: 10s - loss: 0.6529 - tp: 4773.0000 - fp: 2594.0000 - tn: 6338.0000 - fn: 4151.0000 - accuracy: 0.6223 - precision: 0.6479 - recall: 0.5348 - auc: 0.6599\n",
            " For Batch Number 559 the model has a loss of {'loss': 0.6529616713523865, 'tp': 4779.0, 'fp': 2597.0, 'tn': 6352.0, 'fn': 4160.0, 'accuracy': 0.6222607493400574, 'precision': 0.6479121446609497, 'recall': 0.5346235632896423, 'auc': 0.6598713397979736} \n",
            "559/689 [=======================>......] - ETA: 10s - loss: 0.6530 - tp: 4779.0000 - fp: 2597.0000 - tn: 6352.0000 - fn: 4160.0000 - accuracy: 0.6223 - precision: 0.6479 - recall: 0.5346 - auc: 0.6599\n",
            " For Batch Number 560 the model has a loss of {'loss': 0.652866780757904, 'tp': 4785.0, 'fp': 2599.0, 'tn': 6370.0, 'fn': 4166.0, 'accuracy': 0.6224888563156128, 'precision': 0.6480227708816528, 'recall': 0.5345771312713623, 'auc': 0.660088837146759} \n",
            "560/689 [=======================>......] - ETA: 10s - loss: 0.6529 - tp: 4785.0000 - fp: 2599.0000 - tn: 6370.0000 - fn: 4166.0000 - accuracy: 0.6225 - precision: 0.6480 - recall: 0.5346 - auc: 0.6601\n",
            " For Batch Number 561 the model has a loss of {'loss': 0.6530309319496155, 'tp': 4787.0, 'fp': 2602.0, 'tn': 6385.0, 'fn': 4178.0, 'accuracy': 0.6223261952400208, 'precision': 0.6478549242019653, 'recall': 0.5339654088020325, 'auc': 0.6599481701850891} \n",
            "561/689 [=======================>......] - ETA: 10s - loss: 0.6530 - tp: 4787.0000 - fp: 2602.0000 - tn: 6385.0000 - fn: 4178.0000 - accuracy: 0.6223 - precision: 0.6479 - recall: 0.5340 - auc: 0.6599\n",
            " For Batch Number 562 the model has a loss of {'loss': 0.6529089212417603, 'tp': 4792.0, 'fp': 2604.0, 'tn': 6403.0, 'fn': 4185.0, 'accuracy': 0.6224977970123291, 'precision': 0.6479178071022034, 'recall': 0.5338086485862732, 'auc': 0.6601411700248718} \n",
            "562/689 [=======================>......] - ETA: 10s - loss: 0.6529 - tp: 4792.0000 - fp: 2604.0000 - tn: 6403.0000 - fn: 4185.0000 - accuracy: 0.6225 - precision: 0.6479 - recall: 0.5338 - auc: 0.6601\n",
            " For Batch Number 563 the model has a loss of {'loss': 0.6529578566551208, 'tp': 4795.0, 'fp': 2607.0, 'tn': 6418.0, 'fn': 4196.0, 'accuracy': 0.6223912239074707, 'precision': 0.6477978825569153, 'recall': 0.5333110690116882, 'auc': 0.6600285172462463} \n",
            "563/689 [=======================>......] - ETA: 10s - loss: 0.6530 - tp: 4795.0000 - fp: 2607.0000 - tn: 6418.0000 - fn: 4196.0000 - accuracy: 0.6224 - precision: 0.6478 - recall: 0.5333 - auc: 0.6600\n",
            " For Batch Number 564 the model has a loss of {'loss': 0.6529919505119324, 'tp': 4800.0, 'fp': 2610.0, 'tn': 6431.0, 'fn': 4207.0, 'accuracy': 0.622285008430481, 'precision': 0.647773265838623, 'recall': 0.5329188704490662, 'auc': 0.65996915102005} \n",
            "564/689 [=======================>......] - ETA: 9s - loss: 0.6530 - tp: 4800.0000 - fp: 2610.0000 - tn: 6431.0000 - fn: 4207.0000 - accuracy: 0.6223 - precision: 0.6478 - recall: 0.5329 - auc: 0.6600 \n",
            " For Batch Number 565 the model has a loss of {'loss': 0.6529039740562439, 'tp': 4810.0, 'fp': 2613.0, 'tn': 6443.0, 'fn': 4214.0, 'accuracy': 0.6224004626274109, 'precision': 0.6479859948158264, 'recall': 0.5330230593681335, 'auc': 0.6600662469863892} \n",
            "565/689 [=======================>......] - ETA: 9s - loss: 0.6529 - tp: 4810.0000 - fp: 2613.0000 - tn: 6443.0000 - fn: 4214.0000 - accuracy: 0.6224 - precision: 0.6480 - recall: 0.5330 - auc: 0.6601\n",
            " For Batch Number 566 the model has a loss of {'loss': 0.6529284119606018, 'tp': 4818.0, 'fp': 2625.0, 'tn': 6452.0, 'fn': 4217.0, 'accuracy': 0.6222394108772278, 'precision': 0.6473196148872375, 'recall': 0.5332595705986023, 'auc': 0.6599240303039551} \n",
            "566/689 [=======================>......] - ETA: 9s - loss: 0.6529 - tp: 4818.0000 - fp: 2625.0000 - tn: 6452.0000 - fn: 4217.0000 - accuracy: 0.6222 - precision: 0.6473 - recall: 0.5333 - auc: 0.6599\n",
            " For Batch Number 567 the model has a loss of {'loss': 0.65297931432724, 'tp': 4833.0, 'fp': 2631.0, 'tn': 6455.0, 'fn': 4225.0, 'accuracy': 0.6221340298652649, 'precision': 0.6475080251693726, 'recall': 0.5335614681243896, 'auc': 0.659966766834259} \n",
            "567/689 [=======================>......] - ETA: 9s - loss: 0.6530 - tp: 4833.0000 - fp: 2631.0000 - tn: 6455.0000 - fn: 4225.0000 - accuracy: 0.6221 - precision: 0.6475 - recall: 0.5336 - auc: 0.6600\n",
            " For Batch Number 568 the model has a loss of {'loss': 0.6530761122703552, 'tp': 4847.0, 'fp': 2641.0, 'tn': 6462.0, 'fn': 4226.0, 'accuracy': 0.6221941113471985, 'precision': 0.6473023295402527, 'recall': 0.534222424030304, 'auc': 0.6599134802818298} \n",
            "568/689 [=======================>......] - ETA: 9s - loss: 0.6531 - tp: 4847.0000 - fp: 2641.0000 - tn: 6462.0000 - fn: 4226.0000 - accuracy: 0.6222 - precision: 0.6473 - recall: 0.5342 - auc: 0.6599\n",
            " For Batch Number 569 the model has a loss of {'loss': 0.6530758738517761, 'tp': 4861.0, 'fp': 2652.0, 'tn': 6468.0, 'fn': 4227.0, 'accuracy': 0.6221990585327148, 'precision': 0.6470118165016174, 'recall': 0.5348811745643616, 'auc': 0.6598995327949524} \n",
            "569/689 [=======================>......] - ETA: 9s - loss: 0.6531 - tp: 4861.0000 - fp: 2652.0000 - tn: 6468.0000 - fn: 4227.0000 - accuracy: 0.6222 - precision: 0.6470 - recall: 0.5349 - auc: 0.6599\n",
            " For Batch Number 570 the model has a loss of {'loss': 0.6531463861465454, 'tp': 4870.0, 'fp': 2659.0, 'tn': 6479.0, 'fn': 4232.0, 'accuracy': 0.6222039461135864, 'precision': 0.6468322277069092, 'recall': 0.5350472331047058, 'auc': 0.6598021984100342} \n",
            "570/689 [=======================>......] - ETA: 9s - loss: 0.6531 - tp: 4870.0000 - fp: 2659.0000 - tn: 6479.0000 - fn: 4232.0000 - accuracy: 0.6222 - precision: 0.6468 - recall: 0.5350 - auc: 0.6598\n",
            " For Batch Number 571 the model has a loss of {'loss': 0.6531183123588562, 'tp': 4880.0, 'fp': 2661.0, 'tn': 6488.0, 'fn': 4243.0, 'accuracy': 0.6221541166305542, 'precision': 0.6471289992332458, 'recall': 0.5349117517471313, 'auc': 0.6598953008651733} \n",
            "571/689 [=======================>......] - ETA: 9s - loss: 0.6531 - tp: 4880.0000 - fp: 2661.0000 - tn: 6488.0000 - fn: 4243.0000 - accuracy: 0.6222 - precision: 0.6471 - recall: 0.5349 - auc: 0.6599\n",
            " For Batch Number 572 the model has a loss of {'loss': 0.6531398892402649, 'tp': 4887.0, 'fp': 2662.0, 'tn': 6500.0, 'fn': 4255.0, 'accuracy': 0.6221044659614563, 'precision': 0.6473705172538757, 'recall': 0.5345657467842102, 'auc': 0.659832775592804} \n",
            "572/689 [=======================>......] - ETA: 9s - loss: 0.6531 - tp: 4887.0000 - fp: 2662.0000 - tn: 6500.0000 - fn: 4255.0000 - accuracy: 0.6221 - precision: 0.6474 - recall: 0.5346 - auc: 0.6598\n",
            " For Batch Number 573 the model has a loss of {'loss': 0.6531494855880737, 'tp': 4892.0, 'fp': 2669.0, 'tn': 6515.0, 'fn': 4260.0, 'accuracy': 0.6221095323562622, 'precision': 0.6470043659210205, 'recall': 0.5345279574394226, 'auc': 0.6597810387611389} \n",
            "573/689 [=======================>......] - ETA: 9s - loss: 0.6531 - tp: 4892.0000 - fp: 2669.0000 - tn: 6515.0000 - fn: 4260.0000 - accuracy: 0.6221 - precision: 0.6470 - recall: 0.5345 - auc: 0.6598\n",
            " For Batch Number 574 the model has a loss of {'loss': 0.653200089931488, 'tp': 4901.0, 'fp': 2673.0, 'tn': 6526.0, 'fn': 4268.0, 'accuracy': 0.6221145391464233, 'precision': 0.6470821499824524, 'recall': 0.5345184803009033, 'auc': 0.6597070693969727} \n",
            "574/689 [=======================>......] - ETA: 9s - loss: 0.6532 - tp: 4901.0000 - fp: 2673.0000 - tn: 6526.0000 - fn: 4268.0000 - accuracy: 0.6221 - precision: 0.6471 - recall: 0.5345 - auc: 0.6597\n",
            " For Batch Number 575 the model has a loss of {'loss': 0.653083086013794, 'tp': 4909.0, 'fp': 2678.0, 'tn': 6539.0, 'fn': 4274.0, 'accuracy': 0.6221739053726196, 'precision': 0.6470277905464172, 'recall': 0.5345747470855713, 'auc': 0.6598687767982483} \n",
            "575/689 [========================>.....] - ETA: 9s - loss: 0.6531 - tp: 4909.0000 - fp: 2678.0000 - tn: 6539.0000 - fn: 4274.0000 - accuracy: 0.6222 - precision: 0.6470 - recall: 0.5346 - auc: 0.6599\n",
            " For Batch Number 576 the model has a loss of {'loss': 0.6529075503349304, 'tp': 4917.0, 'fp': 2681.0, 'tn': 6554.0, 'fn': 4280.0, 'accuracy': 0.6223415732383728, 'precision': 0.6471439599990845, 'recall': 0.5346308350563049, 'auc': 0.6601344347000122} \n",
            "576/689 [========================>.....] - ETA: 9s - loss: 0.6529 - tp: 4917.0000 - fp: 2681.0000 - tn: 6554.0000 - fn: 4280.0000 - accuracy: 0.6223 - precision: 0.6471 - recall: 0.5346 - auc: 0.6601\n",
            " For Batch Number 577 the model has a loss of {'loss': 0.653048038482666, 'tp': 4925.0, 'fp': 2682.0, 'tn': 6564.0, 'fn': 4293.0, 'accuracy': 0.6222378611564636, 'precision': 0.6474300026893616, 'recall': 0.5342807769775391, 'auc': 0.6598929166793823} \n",
            "577/689 [========================>.....] - ETA: 9s - loss: 0.6530 - tp: 4925.0000 - fp: 2682.0000 - tn: 6564.0000 - fn: 4293.0000 - accuracy: 0.6222 - precision: 0.6474 - recall: 0.5343 - auc: 0.6599\n",
            " For Batch Number 578 the model has a loss of {'loss': 0.6529738306999207, 'tp': 4933.0, 'fp': 2689.0, 'tn': 6577.0, 'fn': 4297.0, 'accuracy': 0.6222966909408569, 'precision': 0.6472054719924927, 'recall': 0.5344528555870056, 'auc': 0.6599999666213989} \n",
            "578/689 [========================>.....] - ETA: 8s - loss: 0.6530 - tp: 4933.0000 - fp: 2689.0000 - tn: 6577.0000 - fn: 4297.0000 - accuracy: 0.6223 - precision: 0.6472 - recall: 0.5345 - auc: 0.6600\n",
            " For Batch Number 579 the model has a loss of {'loss': 0.6529467701911926, 'tp': 4942.0, 'fp': 2693.0, 'tn': 6588.0, 'fn': 4305.0, 'accuracy': 0.6223013997077942, 'precision': 0.6472822427749634, 'recall': 0.5344436168670654, 'auc': 0.6600226759910583} \n",
            "579/689 [========================>.....] - ETA: 8s - loss: 0.6529 - tp: 4942.0000 - fp: 2693.0000 - tn: 6588.0000 - fn: 4305.0000 - accuracy: 0.6223 - precision: 0.6473 - recall: 0.5344 - auc: 0.6600\n",
            " For Batch Number 580 the model has a loss of {'loss': 0.6529038548469543, 'tp': 4953.0, 'fp': 2697.0, 'tn': 6597.0, 'fn': 4313.0, 'accuracy': 0.6223060488700867, 'precision': 0.6474509835243225, 'recall': 0.5345348715782166, 'auc': 0.6600194573402405} \n",
            "580/689 [========================>.....] - ETA: 8s - loss: 0.6529 - tp: 4953.0000 - fp: 2697.0000 - tn: 6597.0000 - fn: 4313.0000 - accuracy: 0.6223 - precision: 0.6475 - recall: 0.5345 - auc: 0.6600\n",
            " For Batch Number 581 the model has a loss of {'loss': 0.6528304815292358, 'tp': 4965.0, 'fp': 2701.0, 'tn': 6607.0, 'fn': 4319.0, 'accuracy': 0.622418224811554, 'precision': 0.6476650238037109, 'recall': 0.5347910523414612, 'auc': 0.6600685715675354} \n",
            "581/689 [========================>.....] - ETA: 8s - loss: 0.6528 - tp: 4965.0000 - fp: 2701.0000 - tn: 6607.0000 - fn: 4319.0000 - accuracy: 0.6224 - precision: 0.6477 - recall: 0.5348 - auc: 0.6601\n",
            " For Batch Number 582 the model has a loss of {'loss': 0.6528673768043518, 'tp': 4977.0, 'fp': 2706.0, 'tn': 6612.0, 'fn': 4329.0, 'accuracy': 0.6222615838050842, 'precision': 0.6477938294410706, 'recall': 0.5348162651062012, 'auc': 0.6600701808929443} \n",
            "582/689 [========================>.....] - ETA: 8s - loss: 0.6529 - tp: 4977.0000 - fp: 2706.0000 - tn: 6612.0000 - fn: 4329.0000 - accuracy: 0.6223 - precision: 0.6478 - recall: 0.5348 - auc: 0.6601\n",
            " For Batch Number 583 the model has a loss of {'loss': 0.653041422367096, 'tp': 4989.0, 'fp': 2716.0, 'tn': 6619.0, 'fn': 4332.0, 'accuracy': 0.6222127079963684, 'precision': 0.6475016474723816, 'recall': 0.5352429747581482, 'auc': 0.6599408984184265} \n",
            "583/689 [========================>.....] - ETA: 8s - loss: 0.6530 - tp: 4989.0000 - fp: 2716.0000 - tn: 6619.0000 - fn: 4332.0000 - accuracy: 0.6222 - precision: 0.6475 - recall: 0.5352 - auc: 0.6599\n",
            " For Batch Number 584 the model has a loss of {'loss': 0.6531597375869751, 'tp': 5001.0, 'fp': 2729.0, 'tn': 6625.0, 'fn': 4333.0, 'accuracy': 0.6221104264259338, 'precision': 0.6469599008560181, 'recall': 0.5357831716537476, 'auc': 0.6598373055458069} \n",
            "584/689 [========================>.....] - ETA: 8s - loss: 0.6532 - tp: 5001.0000 - fp: 2729.0000 - tn: 6625.0000 - fn: 4333.0000 - accuracy: 0.6221 - precision: 0.6470 - recall: 0.5358 - auc: 0.6598\n",
            " For Batch Number 585 the model has a loss of {'loss': 0.6531383991241455, 'tp': 5014.0, 'fp': 2738.0, 'tn': 6631.0, 'fn': 4337.0, 'accuracy': 0.6220619678497314, 'precision': 0.6468008160591125, 'recall': 0.5361993312835693, 'auc': 0.6597815752029419} \n",
            "585/689 [========================>.....] - ETA: 8s - loss: 0.6531 - tp: 5014.0000 - fp: 2738.0000 - tn: 6631.0000 - fn: 4337.0000 - accuracy: 0.6221 - precision: 0.6468 - recall: 0.5362 - auc: 0.6598\n",
            " For Batch Number 586 the model has a loss of {'loss': 0.6529895067214966, 'tp': 5027.0, 'fp': 2740.0, 'tn': 6640.0, 'fn': 4345.0, 'accuracy': 0.6221736073493958, 'precision': 0.6472254395484924, 'recall': 0.5363849997520447, 'auc': 0.6600123643875122} \n",
            "586/689 [========================>.....] - ETA: 8s - loss: 0.6530 - tp: 5027.0000 - fp: 2740.0000 - tn: 6640.0000 - fn: 4345.0000 - accuracy: 0.6222 - precision: 0.6472 - recall: 0.5364 - auc: 0.6600\n",
            " For Batch Number 587 the model has a loss of {'loss': 0.6529750823974609, 'tp': 5037.0, 'fp': 2746.0, 'tn': 6649.0, 'fn': 4352.0, 'accuracy': 0.6221252083778381, 'precision': 0.6471797227859497, 'recall': 0.5364788770675659, 'auc': 0.660078227519989} \n",
            "587/689 [========================>.....] - ETA: 8s - loss: 0.6530 - tp: 5037.0000 - fp: 2746.0000 - tn: 6649.0000 - fn: 4352.0000 - accuracy: 0.6221 - precision: 0.6472 - recall: 0.5365 - auc: 0.6601\n",
            " For Batch Number 588 the model has a loss of {'loss': 0.6529180407524109, 'tp': 5048.0, 'fp': 2751.0, 'tn': 6660.0, 'fn': 4357.0, 'accuracy': 0.6222363710403442, 'precision': 0.647262454032898, 'recall': 0.5367357730865479, 'auc': 0.6601477861404419} \n",
            "588/689 [========================>.....] - ETA: 8s - loss: 0.6529 - tp: 5048.0000 - fp: 2751.0000 - tn: 6660.0000 - fn: 4357.0000 - accuracy: 0.6222 - precision: 0.6473 - recall: 0.5367 - auc: 0.6601\n",
            " For Batch Number 589 the model has a loss of {'loss': 0.6528612971305847, 'tp': 5060.0, 'fp': 2756.0, 'tn': 6669.0, 'fn': 4363.0, 'accuracy': 0.6222941279411316, 'precision': 0.6473899483680725, 'recall': 0.5369839668273926, 'auc': 0.6602732539176941} \n",
            "589/689 [========================>.....] - ETA: 8s - loss: 0.6529 - tp: 5060.0000 - fp: 2756.0000 - tn: 6669.0000 - fn: 4363.0000 - accuracy: 0.6223 - precision: 0.6474 - recall: 0.5370 - auc: 0.6603\n",
            " For Batch Number 590 the model has a loss of {'loss': 0.6526988744735718, 'tp': 5070.0, 'fp': 2758.0, 'tn': 6680.0, 'fn': 4372.0, 'accuracy': 0.6223517060279846, 'precision': 0.6476750373840332, 'recall': 0.5369625091552734, 'auc': 0.6605269312858582} \n",
            "590/689 [========================>.....] - ETA: 8s - loss: 0.6527 - tp: 5070.0000 - fp: 2758.0000 - tn: 6680.0000 - fn: 4372.0000 - accuracy: 0.6224 - precision: 0.6477 - recall: 0.5370 - auc: 0.6605\n",
            " For Batch Number 591 the model has a loss of {'loss': 0.6527627110481262, 'tp': 5079.0, 'fp': 2764.0, 'tn': 6690.0, 'fn': 4379.0, 'accuracy': 0.622303307056427, 'precision': 0.6475838422775269, 'recall': 0.5370057225227356, 'auc': 0.6604045629501343} \n",
            "591/689 [========================>.....] - ETA: 7s - loss: 0.6528 - tp: 5079.0000 - fp: 2764.0000 - tn: 6690.0000 - fn: 4379.0000 - accuracy: 0.6223 - precision: 0.6476 - recall: 0.5370 - auc: 0.6604\n",
            " For Batch Number 592 the model has a loss of {'loss': 0.6527685523033142, 'tp': 5091.0, 'fp': 2770.0, 'tn': 6702.0, 'fn': 4381.0, 'accuracy': 0.6225190162658691, 'precision': 0.6476275324821472, 'recall': 0.5374788641929626, 'auc': 0.6605425477027893} \n",
            "592/689 [========================>.....] - ETA: 7s - loss: 0.6528 - tp: 5091.0000 - fp: 2770.0000 - tn: 6702.0000 - fn: 4381.0000 - accuracy: 0.6225 - precision: 0.6476 - recall: 0.5375 - auc: 0.6605\n",
            " For Batch Number 593 the model has a loss of {'loss': 0.6527425646781921, 'tp': 5100.0, 'fp': 2775.0, 'tn': 6714.0, 'fn': 4387.0, 'accuracy': 0.6225758790969849, 'precision': 0.6476190686225891, 'recall': 0.537577748298645, 'auc': 0.6605927348136902} \n",
            "593/689 [========================>.....] - ETA: 7s - loss: 0.6527 - tp: 5100.0000 - fp: 2775.0000 - tn: 6714.0000 - fn: 4387.0000 - accuracy: 0.6226 - precision: 0.6476 - recall: 0.5376 - auc: 0.6606\n",
            " For Batch Number 594 the model has a loss of {'loss': 0.6525464653968811, 'tp': 5111.0, 'fp': 2777.0, 'tn': 6726.0, 'fn': 4394.0, 'accuracy': 0.6227377653121948, 'precision': 0.6479462385177612, 'recall': 0.5377169847488403, 'auc': 0.6608588099479675} \n",
            "594/689 [========================>.....] - ETA: 7s - loss: 0.6525 - tp: 5111.0000 - fp: 2777.0000 - tn: 6726.0000 - fn: 4394.0000 - accuracy: 0.6227 - precision: 0.6479 - recall: 0.5377 - auc: 0.6609\n",
            " For Batch Number 595 the model has a loss of {'loss': 0.6525165438652039, 'tp': 5118.0, 'fp': 2781.0, 'tn': 6743.0, 'fn': 4398.0, 'accuracy': 0.6229516863822937, 'precision': 0.6479301452636719, 'recall': 0.5378310084342957, 'auc': 0.6609545946121216} \n",
            "595/689 [========================>.....] - ETA: 7s - loss: 0.6525 - tp: 5118.0000 - fp: 2781.0000 - tn: 6743.0000 - fn: 4398.0000 - accuracy: 0.6230 - precision: 0.6479 - recall: 0.5378 - auc: 0.6610\n",
            " For Batch Number 596 the model has a loss of {'loss': 0.6523826122283936, 'tp': 5128.0, 'fp': 2784.0, 'tn': 6756.0, 'fn': 4404.0, 'accuracy': 0.6231124401092529, 'precision': 0.648129403591156, 'recall': 0.5379773378372192, 'auc': 0.6611455082893372} \n",
            "596/689 [========================>.....] - ETA: 7s - loss: 0.6524 - tp: 5128.0000 - fp: 2784.0000 - tn: 6756.0000 - fn: 4404.0000 - accuracy: 0.6231 - precision: 0.6481 - recall: 0.5380 - auc: 0.6611\n",
            " For Batch Number 597 the model has a loss of {'loss': 0.6522886157035828, 'tp': 5136.0, 'fp': 2786.0, 'tn': 6772.0, 'fn': 4410.0, 'accuracy': 0.6233249306678772, 'precision': 0.6483211517333984, 'recall': 0.5380263924598694, 'auc': 0.6613337397575378} \n",
            "597/689 [========================>.....] - ETA: 7s - loss: 0.6523 - tp: 5136.0000 - fp: 2786.0000 - tn: 6772.0000 - fn: 4410.0000 - accuracy: 0.6233 - precision: 0.6483 - recall: 0.5380 - auc: 0.6613\n",
            " For Batch Number 598 the model has a loss of {'loss': 0.6522879600524902, 'tp': 5144.0, 'fp': 2787.0, 'tn': 6785.0, 'fn': 4420.0, 'accuracy': 0.6233800053596497, 'precision': 0.6485941410064697, 'recall': 0.5378502607345581, 'auc': 0.6613950133323669} \n",
            "598/689 [=========================>....] - ETA: 7s - loss: 0.6523 - tp: 5144.0000 - fp: 2787.0000 - tn: 6785.0000 - fn: 4420.0000 - accuracy: 0.6234 - precision: 0.6486 - recall: 0.5379 - auc: 0.6614\n",
            " For Batch Number 599 the model has a loss of {'loss': 0.652182936668396, 'tp': 5150.0, 'fp': 2790.0, 'tn': 6803.0, 'fn': 4425.0, 'accuracy': 0.623591423034668, 'precision': 0.6486145853996277, 'recall': 0.5378590226173401, 'auc': 0.661518394947052} \n",
            "599/689 [=========================>....] - ETA: 7s - loss: 0.6522 - tp: 5150.0000 - fp: 2790.0000 - tn: 6803.0000 - fn: 4425.0000 - accuracy: 0.6236 - precision: 0.6486 - recall: 0.5379 - auc: 0.6615\n",
            " For Batch Number 600 the model has a loss of {'loss': 0.6521852612495422, 'tp': 5158.0, 'fp': 2794.0, 'tn': 6817.0, 'fn': 4431.0, 'accuracy': 0.6236979365348816, 'precision': 0.64864182472229, 'recall': 0.5379080176353455, 'auc': 0.6615758538246155} \n",
            "600/689 [=========================>....] - ETA: 7s - loss: 0.6522 - tp: 5158.0000 - fp: 2794.0000 - tn: 6817.0000 - fn: 4431.0000 - accuracy: 0.6237 - precision: 0.6486 - recall: 0.5379 - auc: 0.6616\n",
            " For Batch Number 601 the model has a loss of {'loss': 0.6521615982055664, 'tp': 5168.0, 'fp': 2795.0, 'tn': 6827.0, 'fn': 4442.0, 'accuracy': 0.6237000823020935, 'precision': 0.6490016579627991, 'recall': 0.5377731323242188, 'auc': 0.661611795425415} \n",
            "601/689 [=========================>....] - ETA: 7s - loss: 0.6522 - tp: 5168.0000 - fp: 2795.0000 - tn: 6827.0000 - fn: 4442.0000 - accuracy: 0.6237 - precision: 0.6490 - recall: 0.5378 - auc: 0.6616\n",
            " For Batch Number 602 the model has a loss of {'loss': 0.6520939469337463, 'tp': 5173.0, 'fp': 2801.0, 'tn': 6843.0, 'fn': 4447.0, 'accuracy': 0.6237541437149048, 'precision': 0.648733377456665, 'recall': 0.5377339124679565, 'auc': 0.6616823673248291} \n",
            "602/689 [=========================>....] - ETA: 7s - loss: 0.6521 - tp: 5173.0000 - fp: 2801.0000 - tn: 6843.0000 - fn: 4447.0000 - accuracy: 0.6238 - precision: 0.6487 - recall: 0.5377 - auc: 0.6617\n",
            " For Batch Number 603 the model has a loss of {'loss': 0.6521887183189392, 'tp': 5180.0, 'fp': 2803.0, 'tn': 6855.0, 'fn': 4458.0, 'accuracy': 0.6237043738365173, 'precision': 0.6488788723945618, 'recall': 0.5374559164047241, 'auc': 0.6615729928016663} \n",
            "603/689 [=========================>....] - ETA: 7s - loss: 0.6522 - tp: 5180.0000 - fp: 2803.0000 - tn: 6855.0000 - fn: 4458.0000 - accuracy: 0.6237 - precision: 0.6489 - recall: 0.5375 - auc: 0.6616\n",
            " For Batch Number 604 the model has a loss of {'loss': 0.6520465612411499, 'tp': 5195.0, 'fp': 2803.0, 'tn': 6864.0, 'fn': 4466.0, 'accuracy': 0.6239134669303894, 'precision': 0.6495373845100403, 'recall': 0.537729024887085, 'auc': 0.6618379354476929} \n",
            "604/689 [=========================>....] - ETA: 6s - loss: 0.6520 - tp: 5195.0000 - fp: 2803.0000 - tn: 6864.0000 - fn: 4466.0000 - accuracy: 0.6239 - precision: 0.6495 - recall: 0.5377 - auc: 0.6618\n",
            " For Batch Number 605 the model has a loss of {'loss': 0.6520144939422607, 'tp': 5205.0, 'fp': 2809.0, 'tn': 6875.0, 'fn': 4471.0, 'accuracy': 0.6239669322967529, 'precision': 0.6494883894920349, 'recall': 0.5379288792610168, 'auc': 0.6618543863296509} \n",
            "605/689 [=========================>....] - ETA: 6s - loss: 0.6520 - tp: 5205.0000 - fp: 2809.0000 - tn: 6875.0000 - fn: 4471.0000 - accuracy: 0.6240 - precision: 0.6495 - recall: 0.5379 - auc: 0.6619\n",
            " For Batch Number 606 the model has a loss of {'loss': 0.6521101593971252, 'tp': 5214.0, 'fp': 2816.0, 'tn': 6881.0, 'fn': 4481.0, 'accuracy': 0.6237108111381531, 'precision': 0.6493150591850281, 'recall': 0.5378029942512512, 'auc': 0.6617152094841003} \n",
            "606/689 [=========================>....] - ETA: 6s - loss: 0.6521 - tp: 5214.0000 - fp: 2816.0000 - tn: 6881.0000 - fn: 4481.0000 - accuracy: 0.6237 - precision: 0.6493 - recall: 0.5378 - auc: 0.6617\n",
            " For Batch Number 607 the model has a loss of {'loss': 0.6522397994995117, 'tp': 5226.0, 'fp': 2823.0, 'tn': 6892.0, 'fn': 4483.0, 'accuracy': 0.623867392539978, 'precision': 0.6492732167243958, 'recall': 0.5382634401321411, 'auc': 0.6616162061691284} \n",
            "607/689 [=========================>....] - ETA: 6s - loss: 0.6522 - tp: 5226.0000 - fp: 2823.0000 - tn: 6892.0000 - fn: 4483.0000 - accuracy: 0.6239 - precision: 0.6493 - recall: 0.5383 - auc: 0.6616\n",
            " For Batch Number 608 the model has a loss of {'loss': 0.6522871851921082, 'tp': 5239.0, 'fp': 2831.0, 'tn': 6899.0, 'fn': 4487.0, 'accuracy': 0.6238692402839661, 'precision': 0.6491945385932922, 'recall': 0.5386592745780945, 'auc': 0.6616644859313965} \n",
            "608/689 [=========================>....] - ETA: 6s - loss: 0.6523 - tp: 5239.0000 - fp: 2831.0000 - tn: 6899.0000 - fn: 4487.0000 - accuracy: 0.6239 - precision: 0.6492 - recall: 0.5387 - auc: 0.6617\n",
            " For Batch Number 609 the model has a loss of {'loss': 0.6522530317306519, 'tp': 5253.0, 'fp': 2837.0, 'tn': 6907.0, 'fn': 4491.0, 'accuracy': 0.6239737272262573, 'precision': 0.649320125579834, 'recall': 0.5391010046005249, 'auc': 0.6617449522018433} \n",
            "609/689 [=========================>....] - ETA: 6s - loss: 0.6523 - tp: 5253.0000 - fp: 2837.0000 - tn: 6907.0000 - fn: 4491.0000 - accuracy: 0.6240 - precision: 0.6493 - recall: 0.5391 - auc: 0.6617\n",
            " For Batch Number 610 the model has a loss of {'loss': 0.6521703004837036, 'tp': 5265.0, 'fp': 2843.0, 'tn': 6916.0, 'fn': 4496.0, 'accuracy': 0.6240266561508179, 'precision': 0.6493586301803589, 'recall': 0.5393914580345154, 'auc': 0.6618850231170654} \n",
            "610/689 [=========================>....] - ETA: 6s - loss: 0.6522 - tp: 5265.0000 - fp: 2843.0000 - tn: 6916.0000 - fn: 4496.0000 - accuracy: 0.6240 - precision: 0.6494 - recall: 0.5394 - auc: 0.6619\n",
            " For Batch Number 611 the model has a loss of {'loss': 0.6522637605667114, 'tp': 5273.0, 'fp': 2853.0, 'tn': 6925.0, 'fn': 4501.0, 'accuracy': 0.6238747835159302, 'precision': 0.6489047408103943, 'recall': 0.5394925475120544, 'auc': 0.6617274284362793} \n",
            "611/689 [=========================>....] - ETA: 6s - loss: 0.6523 - tp: 5273.0000 - fp: 2853.0000 - tn: 6925.0000 - fn: 4501.0000 - accuracy: 0.6239 - precision: 0.6489 - recall: 0.5395 - auc: 0.6617\n",
            " For Batch Number 612 the model has a loss of {'loss': 0.652222216129303, 'tp': 5282.0, 'fp': 2857.0, 'tn': 6937.0, 'fn': 4508.0, 'accuracy': 0.6239277124404907, 'precision': 0.6489740610122681, 'recall': 0.5395301580429077, 'auc': 0.6617987751960754} \n",
            "612/689 [=========================>....] - ETA: 6s - loss: 0.6522 - tp: 5282.0000 - fp: 2857.0000 - tn: 6937.0000 - fn: 4508.0000 - accuracy: 0.6239 - precision: 0.6490 - recall: 0.5395 - auc: 0.6618\n",
            " For Batch Number 613 the model has a loss of {'loss': 0.6521853804588318, 'tp': 5288.0, 'fp': 2860.0, 'tn': 6950.0, 'fn': 4518.0, 'accuracy': 0.6238784790039062, 'precision': 0.6489936113357544, 'recall': 0.5392616987228394, 'auc': 0.6618455052375793} \n",
            "613/689 [=========================>....] - ETA: 6s - loss: 0.6522 - tp: 5288.0000 - fp: 2860.0000 - tn: 6950.0000 - fn: 4518.0000 - accuracy: 0.6239 - precision: 0.6490 - recall: 0.5393 - auc: 0.6618\n",
            " For Batch Number 614 the model has a loss of {'loss': 0.6522293090820312, 'tp': 5294.0, 'fp': 2863.0, 'tn': 6960.0, 'fn': 4531.0, 'accuracy': 0.6236767172813416, 'precision': 0.649013102054596, 'recall': 0.538829505443573, 'auc': 0.6617690920829773} \n",
            "614/689 [=========================>....] - ETA: 6s - loss: 0.6522 - tp: 5294.0000 - fp: 2863.0000 - tn: 6960.0000 - fn: 4531.0000 - accuracy: 0.6237 - precision: 0.6490 - recall: 0.5388 - auc: 0.6618\n",
            " For Batch Number 615 the model has a loss of {'loss': 0.6520781517028809, 'tp': 5305.0, 'fp': 2864.0, 'tn': 6974.0, 'fn': 4537.0, 'accuracy': 0.6239328980445862, 'precision': 0.6494063138961792, 'recall': 0.5390164852142334, 'auc': 0.6620378494262695} \n",
            "615/689 [=========================>....] - ETA: 6s - loss: 0.6521 - tp: 5305.0000 - fp: 2864.0000 - tn: 6974.0000 - fn: 4537.0000 - accuracy: 0.6239 - precision: 0.6494 - recall: 0.5390 - auc: 0.6620\n",
            " For Batch Number 616 the model has a loss of {'loss': 0.6519516110420227, 'tp': 5319.0, 'fp': 2865.0, 'tn': 6982.0, 'fn': 4546.0, 'accuracy': 0.6240361332893372, 'precision': 0.6499266624450684, 'recall': 0.5391789078712463, 'auc': 0.6622509360313416} \n",
            "616/689 [=========================>....] - ETA: 5s - loss: 0.6520 - tp: 5319.0000 - fp: 2865.0000 - tn: 6982.0000 - fn: 4546.0000 - accuracy: 0.6240 - precision: 0.6499 - recall: 0.5392 - auc: 0.6623\n",
            " For Batch Number 617 the model has a loss of {'loss': 0.6519941091537476, 'tp': 5330.0, 'fp': 2873.0, 'tn': 6990.0, 'fn': 4551.0, 'accuracy': 0.6239870190620422, 'precision': 0.6497622728347778, 'recall': 0.5394191145896912, 'auc': 0.6621791124343872} \n",
            "617/689 [=========================>....] - ETA: 5s - loss: 0.6520 - tp: 5330.0000 - fp: 2873.0000 - tn: 6990.0000 - fn: 4551.0000 - accuracy: 0.6240 - precision: 0.6498 - recall: 0.5394 - auc: 0.6622\n",
            " For Batch Number 618 the model has a loss of {'loss': 0.651944637298584, 'tp': 5346.0, 'fp': 2881.0, 'tn': 6996.0, 'fn': 4553.0, 'accuracy': 0.624089777469635, 'precision': 0.6498116254806519, 'recall': 0.5400545597076416, 'auc': 0.6623019576072693} \n",
            "618/689 [=========================>....] - ETA: 5s - loss: 0.6519 - tp: 5346.0000 - fp: 2881.0000 - tn: 6996.0000 - fn: 4553.0000 - accuracy: 0.6241 - precision: 0.6498 - recall: 0.5401 - auc: 0.6623\n",
            " For Batch Number 619 the model has a loss of {'loss': 0.6520964503288269, 'tp': 5358.0, 'fp': 2892.0, 'tn': 7002.0, 'fn': 4556.0, 'accuracy': 0.6239902973175049, 'precision': 0.6494545340538025, 'recall': 0.5404478311538696, 'auc': 0.6622207760810852} \n",
            "619/689 [=========================>....] - ETA: 5s - loss: 0.6521 - tp: 5358.0000 - fp: 2892.0000 - tn: 7002.0000 - fn: 4556.0000 - accuracy: 0.6240 - precision: 0.6495 - recall: 0.5404 - auc: 0.6622\n",
            " For Batch Number 620 the model has a loss of {'loss': 0.6521387100219727, 'tp': 5370.0, 'fp': 2901.0, 'tn': 7009.0, 'fn': 4560.0, 'accuracy': 0.6239415407180786, 'precision': 0.6492564678192139, 'recall': 0.5407854914665222, 'auc': 0.6622265577316284} \n",
            "620/689 [=========================>....] - ETA: 5s - loss: 0.6521 - tp: 5370.0000 - fp: 2901.0000 - tn: 7009.0000 - fn: 4560.0000 - accuracy: 0.6239 - precision: 0.6493 - recall: 0.5408 - auc: 0.6622\n",
            " For Batch Number 621 the model has a loss of {'loss': 0.6524724960327148, 'tp': 5377.0, 'fp': 2911.0, 'tn': 7017.0, 'fn': 4567.0, 'accuracy': 0.6236916184425354, 'precision': 0.6487693190574646, 'recall': 0.5407280921936035, 'auc': 0.6618799567222595} \n",
            "621/689 [==========================>...] - ETA: 5s - loss: 0.6525 - tp: 5377.0000 - fp: 2911.0000 - tn: 7017.0000 - fn: 4567.0000 - accuracy: 0.6237 - precision: 0.6488 - recall: 0.5407 - auc: 0.6619\n",
            " For Batch Number 622 the model has a loss of {'loss': 0.6521638631820679, 'tp': 5387.0, 'fp': 2912.0, 'tn': 7032.0, 'fn': 4573.0, 'accuracy': 0.6239449381828308, 'precision': 0.6491143703460693, 'recall': 0.5408634543418884, 'auc': 0.6622450351715088} \n",
            "622/689 [==========================>...] - ETA: 5s - loss: 0.6522 - tp: 5387.0000 - fp: 2912.0000 - tn: 7032.0000 - fn: 4573.0000 - accuracy: 0.6239 - precision: 0.6491 - recall: 0.5409 - auc: 0.6622\n",
            " For Batch Number 623 the model has a loss of {'loss': 0.6521954536437988, 'tp': 5395.0, 'fp': 2915.0, 'tn': 7045.0, 'fn': 4581.0, 'accuracy': 0.6239967942237854, 'precision': 0.6492177844047546, 'recall': 0.5407978892326355, 'auc': 0.662311315536499} \n",
            "623/689 [==========================>...] - ETA: 5s - loss: 0.6522 - tp: 5395.0000 - fp: 2915.0000 - tn: 7045.0000 - fn: 4581.0000 - accuracy: 0.6240 - precision: 0.6492 - recall: 0.5408 - auc: 0.6623\n",
            " For Batch Number 624 the model has a loss of {'loss': 0.6522783041000366, 'tp': 5403.0, 'fp': 2918.0, 'tn': 7056.0, 'fn': 4591.0, 'accuracy': 0.623948335647583, 'precision': 0.6493210196495056, 'recall': 0.5406243801116943, 'auc': 0.6622632145881653} \n",
            "624/689 [==========================>...] - ETA: 5s - loss: 0.6523 - tp: 5403.0000 - fp: 2918.0000 - tn: 7056.0000 - fn: 4591.0000 - accuracy: 0.6239 - precision: 0.6493 - recall: 0.5406 - auc: 0.6623\n",
            " For Batch Number 625 the model has a loss of {'loss': 0.652092456817627, 'tp': 5414.0, 'fp': 2920.0, 'tn': 7069.0, 'fn': 4597.0, 'accuracy': 0.6241499781608582, 'precision': 0.6496280431747437, 'recall': 0.5408051013946533, 'auc': 0.6625509858131409} \n",
            "625/689 [==========================>...] - ETA: 5s - loss: 0.6521 - tp: 5414.0000 - fp: 2920.0000 - tn: 7069.0000 - fn: 4597.0000 - accuracy: 0.6241 - precision: 0.6496 - recall: 0.5408 - auc: 0.6626\n",
            " For Batch Number 626 the model has a loss of {'loss': 0.6520130038261414, 'tp': 5425.0, 'fp': 2923.0, 'tn': 7081.0, 'fn': 4603.0, 'accuracy': 0.6243011355400085, 'precision': 0.6498562693595886, 'recall': 0.5409852266311646, 'auc': 0.6626622676849365} \n",
            "626/689 [==========================>...] - ETA: 5s - loss: 0.6520 - tp: 5425.0000 - fp: 2923.0000 - tn: 7081.0000 - fn: 4603.0000 - accuracy: 0.6243 - precision: 0.6499 - recall: 0.5410 - auc: 0.6627\n",
            " For Batch Number 627 the model has a loss of {'loss': 0.6518802642822266, 'tp': 5439.0, 'fp': 2929.0, 'tn': 7087.0, 'fn': 4609.0, 'accuracy': 0.6243022084236145, 'precision': 0.6499760746955872, 'recall': 0.5413017272949219, 'auc': 0.6628044843673706} \n",
            "627/689 [==========================>...] - ETA: 5s - loss: 0.6519 - tp: 5439.0000 - fp: 2929.0000 - tn: 7087.0000 - fn: 4609.0000 - accuracy: 0.6243 - precision: 0.6500 - recall: 0.5413 - auc: 0.6628\n",
            " For Batch Number 628 the model has a loss of {'loss': 0.651919424533844, 'tp': 5455.0, 'fp': 2939.0, 'tn': 7090.0, 'fn': 4612.0, 'accuracy': 0.6242535710334778, 'precision': 0.6498689651489258, 'recall': 0.5418694615364075, 'auc': 0.6628542542457581} \n",
            "628/689 [==========================>...] - ETA: 5s - loss: 0.6519 - tp: 5455.0000 - fp: 2939.0000 - tn: 7090.0000 - fn: 4612.0000 - accuracy: 0.6243 - precision: 0.6499 - recall: 0.5419 - auc: 0.6629\n",
            " For Batch Number 629 the model has a loss of {'loss': 0.6517909169197083, 'tp': 5474.0, 'fp': 2949.0, 'tn': 7092.0, 'fn': 4613.0, 'accuracy': 0.624304473400116, 'precision': 0.649887204170227, 'recall': 0.542678713798523, 'auc': 0.6630356311798096} \n",
            "629/689 [==========================>...] - ETA: 4s - loss: 0.6518 - tp: 5474.0000 - fp: 2949.0000 - tn: 7092.0000 - fn: 4613.0000 - accuracy: 0.6243 - precision: 0.6499 - recall: 0.5427 - auc: 0.6630\n",
            " For Batch Number 630 the model has a loss of {'loss': 0.6518036127090454, 'tp': 5488.0, 'fp': 2959.0, 'tn': 7098.0, 'fn': 4615.0, 'accuracy': 0.6243055462837219, 'precision': 0.6496981382369995, 'recall': 0.5432049632072449, 'auc': 0.6630721688270569} \n",
            "630/689 [==========================>...] - ETA: 4s - loss: 0.6518 - tp: 5488.0000 - fp: 2959.0000 - tn: 7098.0000 - fn: 4615.0000 - accuracy: 0.6243 - precision: 0.6497 - recall: 0.5432 - auc: 0.6631\n",
            " For Batch Number 631 the model has a loss of {'loss': 0.6520084142684937, 'tp': 5497.0, 'fp': 2966.0, 'tn': 7108.0, 'fn': 4621.0, 'accuracy': 0.6242571473121643, 'precision': 0.6495332717895508, 'recall': 0.5432891845703125, 'auc': 0.6628804206848145} \n",
            "631/689 [==========================>...] - ETA: 4s - loss: 0.6520 - tp: 5497.0000 - fp: 2966.0000 - tn: 7108.0000 - fn: 4621.0000 - accuracy: 0.6243 - precision: 0.6495 - recall: 0.5433 - auc: 0.6629\n",
            " For Batch Number 632 the model has a loss of {'loss': 0.6519268751144409, 'tp': 5509.0, 'fp': 2967.0, 'tn': 7121.0, 'fn': 4627.0, 'accuracy': 0.6245055198669434, 'precision': 0.6499528288841248, 'recall': 0.5435082912445068, 'auc': 0.6631377935409546} \n",
            "632/689 [==========================>...] - ETA: 4s - loss: 0.6519 - tp: 5509.0000 - fp: 2967.0000 - tn: 7121.0000 - fn: 4627.0000 - accuracy: 0.6245 - precision: 0.6500 - recall: 0.5435 - auc: 0.6631\n",
            " For Batch Number 633 the model has a loss of {'loss': 0.6524704694747925, 'tp': 5516.0, 'fp': 2968.0, 'tn': 7128.0, 'fn': 4644.0, 'accuracy': 0.6242101192474365, 'precision': 0.6501650214195251, 'recall': 0.5429133772850037, 'auc': 0.6627423167228699} \n",
            "633/689 [==========================>...] - ETA: 4s - loss: 0.6525 - tp: 5516.0000 - fp: 2968.0000 - tn: 7128.0000 - fn: 4644.0000 - accuracy: 0.6242 - precision: 0.6502 - recall: 0.5429 - auc: 0.6627\n",
            " For Batch Number 634 the model has a loss of {'loss': 0.6524253487586975, 'tp': 5527.0, 'fp': 2970.0, 'tn': 7139.0, 'fn': 4652.0, 'accuracy': 0.6243099570274353, 'precision': 0.6504648923873901, 'recall': 0.5429806709289551, 'auc': 0.6628451347351074} \n",
            "634/689 [==========================>...] - ETA: 4s - loss: 0.6524 - tp: 5527.0000 - fp: 2970.0000 - tn: 7139.0000 - fn: 4652.0000 - accuracy: 0.6243 - precision: 0.6505 - recall: 0.5430 - auc: 0.6628\n",
            " For Batch Number 635 the model has a loss of {'loss': 0.6526319980621338, 'tp': 5533.0, 'fp': 2982.0, 'tn': 7149.0, 'fn': 4656.0, 'accuracy': 0.6241141557693481, 'precision': 0.6497944593429565, 'recall': 0.5430365800857544, 'auc': 0.6625639200210571} \n",
            "635/689 [==========================>...] - ETA: 4s - loss: 0.6526 - tp: 5533.0000 - fp: 2982.0000 - tn: 7149.0000 - fn: 4656.0000 - accuracy: 0.6241 - precision: 0.6498 - recall: 0.5430 - auc: 0.6626\n",
            " For Batch Number 636 the model has a loss of {'loss': 0.6525518894195557, 'tp': 5545.0, 'fp': 2987.0, 'tn': 7160.0, 'fn': 4660.0, 'accuracy': 0.6242629885673523, 'precision': 0.6499062180519104, 'recall': 0.5433610677719116, 'auc': 0.6626516580581665} \n",
            "636/689 [==========================>...] - ETA: 4s - loss: 0.6526 - tp: 5545.0000 - fp: 2987.0000 - tn: 7160.0000 - fn: 4660.0000 - accuracy: 0.6243 - precision: 0.6499 - recall: 0.5434 - auc: 0.6627\n",
            " For Batch Number 637 the model has a loss of {'loss': 0.6525516510009766, 'tp': 5555.0, 'fp': 2991.0, 'tn': 7169.0, 'fn': 4669.0, 'accuracy': 0.6242150664329529, 'precision': 0.6500117182731628, 'recall': 0.5433294177055359, 'auc': 0.662642776966095} \n",
            "637/689 [==========================>...] - ETA: 4s - loss: 0.6526 - tp: 5555.0000 - fp: 2991.0000 - tn: 7169.0000 - fn: 4669.0000 - accuracy: 0.6242 - precision: 0.6500 - recall: 0.5433 - auc: 0.6626\n",
            " For Batch Number 638 the model has a loss of {'loss': 0.6524863839149475, 'tp': 5569.0, 'fp': 2997.0, 'tn': 7176.0, 'fn': 4674.0, 'accuracy': 0.6242652535438538, 'precision': 0.6501284241676331, 'recall': 0.5436883568763733, 'auc': 0.6627140641212463} \n",
            "638/689 [==========================>...] - ETA: 4s - loss: 0.6525 - tp: 5569.0000 - fp: 2997.0000 - tn: 7176.0000 - fn: 4674.0000 - accuracy: 0.6243 - precision: 0.6501 - recall: 0.5437 - auc: 0.6627\n",
            " For Batch Number 639 the model has a loss of {'loss': 0.6525905728340149, 'tp': 5576.0, 'fp': 3005.0, 'tn': 7185.0, 'fn': 4682.0, 'accuracy': 0.6240708231925964, 'precision': 0.6498076915740967, 'recall': 0.5435757637023926, 'auc': 0.6625553965568542} \n",
            "639/689 [==========================>...] - ETA: 4s - loss: 0.6526 - tp: 5576.0000 - fp: 3005.0000 - tn: 7185.0000 - fn: 4682.0000 - accuracy: 0.6241 - precision: 0.6498 - recall: 0.5436 - auc: 0.6626\n",
            " For Batch Number 640 the model has a loss of {'loss': 0.6527531743049622, 'tp': 5583.0, 'fp': 3012.0, 'tn': 7195.0, 'fn': 4690.0, 'accuracy': 0.6239258050918579, 'precision': 0.6495636701583862, 'recall': 0.5434634685516357, 'auc': 0.6623644828796387} \n",
            "640/689 [==========================>...] - ETA: 4s - loss: 0.6528 - tp: 5583.0000 - fp: 3012.0000 - tn: 7195.0000 - fn: 4690.0000 - accuracy: 0.6239 - precision: 0.6496 - recall: 0.5435 - auc: 0.6624\n",
            " For Batch Number 641 the model has a loss of {'loss': 0.6527488231658936, 'tp': 5590.0, 'fp': 3018.0, 'tn': 7210.0, 'fn': 4694.0, 'accuracy': 0.6240249872207642, 'precision': 0.6493958830833435, 'recall': 0.5435628294944763, 'auc': 0.6623238325119019} \n",
            "641/689 [==========================>...] - ETA: 3s - loss: 0.6527 - tp: 5590.0000 - fp: 3018.0000 - tn: 7210.0000 - fn: 4694.0000 - accuracy: 0.6240 - precision: 0.6494 - recall: 0.5436 - auc: 0.6623\n",
            " For Batch Number 642 the model has a loss of {'loss': 0.6529297232627869, 'tp': 5596.0, 'fp': 3023.0, 'tn': 7221.0, 'fn': 4704.0, 'accuracy': 0.6238804459571838, 'precision': 0.6492632627487183, 'recall': 0.543300986289978, 'auc': 0.6621135473251343} \n",
            "642/689 [==========================>...] - ETA: 3s - loss: 0.6529 - tp: 5596.0000 - fp: 3023.0000 - tn: 7221.0000 - fn: 4704.0000 - accuracy: 0.6239 - precision: 0.6493 - recall: 0.5433 - auc: 0.6621\n",
            " For Batch Number 643 the model has a loss of {'loss': 0.6528477668762207, 'tp': 5601.0, 'fp': 3025.0, 'tn': 7237.0, 'fn': 4713.0, 'accuracy': 0.623930811882019, 'precision': 0.6493160128593445, 'recall': 0.5430482625961304, 'auc': 0.6622247099876404} \n",
            "643/689 [==========================>...] - ETA: 3s - loss: 0.6528 - tp: 5601.0000 - fp: 3025.0000 - tn: 7237.0000 - fn: 4713.0000 - accuracy: 0.6239 - precision: 0.6493 - recall: 0.5430 - auc: 0.6622\n",
            " For Batch Number 644 the model has a loss of {'loss': 0.6529510021209717, 'tp': 5606.0, 'fp': 3025.0, 'tn': 7250.0, 'fn': 4727.0, 'accuracy': 0.6238353848457336, 'precision': 0.649519145488739, 'recall': 0.5425336360931396, 'auc': 0.6620673537254333} \n",
            "644/689 [===========================>..] - ETA: 3s - loss: 0.6530 - tp: 5606.0000 - fp: 3025.0000 - tn: 7250.0000 - fn: 4727.0000 - accuracy: 0.6238 - precision: 0.6495 - recall: 0.5425 - auc: 0.6621\n",
            " For Batch Number 645 the model has a loss of {'loss': 0.6530303955078125, 'tp': 5613.0, 'fp': 3025.0, 'tn': 7261.0, 'fn': 4741.0, 'accuracy': 0.6237403154373169, 'precision': 0.6498032212257385, 'recall': 0.5421093106269836, 'auc': 0.6619475483894348} \n",
            "645/689 [===========================>..] - ETA: 3s - loss: 0.6530 - tp: 5613.0000 - fp: 3025.0000 - tn: 7261.0000 - fn: 4741.0000 - accuracy: 0.6237 - precision: 0.6498 - recall: 0.5421 - auc: 0.6619\n",
            " For Batch Number 646 the model has a loss of {'loss': 0.6528241038322449, 'tp': 5624.0, 'fp': 3027.0, 'tn': 7274.0, 'fn': 4747.0, 'accuracy': 0.6239357590675354, 'precision': 0.6500982642173767, 'recall': 0.5422813892364502, 'auc': 0.6622526049613953} \n",
            "646/689 [===========================>..] - ETA: 3s - loss: 0.6528 - tp: 5624.0000 - fp: 3027.0000 - tn: 7274.0000 - fn: 4747.0000 - accuracy: 0.6239 - precision: 0.6501 - recall: 0.5423 - auc: 0.6623\n",
            " For Batch Number 647 the model has a loss of {'loss': 0.6528157591819763, 'tp': 5633.0, 'fp': 3035.0, 'tn': 7286.0, 'fn': 4750.0, 'accuracy': 0.6239857077598572, 'precision': 0.6498615741729736, 'recall': 0.5425214171409607, 'auc': 0.6623085737228394} \n",
            "647/689 [===========================>..] - ETA: 3s - loss: 0.6528 - tp: 5633.0000 - fp: 3035.0000 - tn: 7286.0000 - fn: 4750.0000 - accuracy: 0.6240 - precision: 0.6499 - recall: 0.5425 - auc: 0.6623\n",
            " For Batch Number 648 the model has a loss of {'loss': 0.6526297926902771, 'tp': 5645.0, 'fp': 3041.0, 'tn': 7298.0, 'fn': 4752.0, 'accuracy': 0.6241801977157593, 'precision': 0.6498963832855225, 'recall': 0.5429450869560242, 'auc': 0.6625083088874817} \n",
            "648/689 [===========================>..] - ETA: 3s - loss: 0.6526 - tp: 5645.0000 - fp: 3041.0000 - tn: 7298.0000 - fn: 4752.0000 - accuracy: 0.6242 - precision: 0.6499 - recall: 0.5429 - auc: 0.6625\n",
            " For Batch Number 649 the model has a loss of {'loss': 0.6525035500526428, 'tp': 5658.0, 'fp': 3046.0, 'tn': 7308.0, 'fn': 4756.0, 'accuracy': 0.6243258714675903, 'precision': 0.6500459313392639, 'recall': 0.5433070659637451, 'auc': 0.6627528071403503} \n",
            "649/689 [===========================>..] - ETA: 3s - loss: 0.6525 - tp: 5658.0000 - fp: 3046.0000 - tn: 7308.0000 - fn: 4756.0000 - accuracy: 0.6243 - precision: 0.6500 - recall: 0.5433 - auc: 0.6628\n",
            " For Batch Number 650 the model has a loss of {'loss': 0.6525425910949707, 'tp': 5667.0, 'fp': 3054.0, 'tn': 7317.0, 'fn': 4762.0, 'accuracy': 0.6242307424545288, 'precision': 0.649810791015625, 'recall': 0.5433886051177979, 'auc': 0.6626796722412109} \n",
            "650/689 [===========================>..] - ETA: 3s - loss: 0.6525 - tp: 5667.0000 - fp: 3054.0000 - tn: 7317.0000 - fn: 4762.0000 - accuracy: 0.6242 - precision: 0.6498 - recall: 0.5434 - auc: 0.6627\n",
            " For Batch Number 651 the model has a loss of {'loss': 0.6522848010063171, 'tp': 5680.0, 'fp': 3058.0, 'tn': 7328.0, 'fn': 4766.0, 'accuracy': 0.6244239807128906, 'precision': 0.6500343084335327, 'recall': 0.5437487959861755, 'auc': 0.6629919409751892} \n",
            "651/689 [===========================>..] - ETA: 3s - loss: 0.6523 - tp: 5680.0000 - fp: 3058.0000 - tn: 7328.0000 - fn: 4766.0000 - accuracy: 0.6244 - precision: 0.6500 - recall: 0.5437 - auc: 0.6630\n",
            " For Batch Number 652 the model has a loss of {'loss': 0.6519854664802551, 'tp': 5692.0, 'fp': 3061.0, 'tn': 7343.0, 'fn': 4768.0, 'accuracy': 0.6247603297233582, 'precision': 0.6502913236618042, 'recall': 0.54416823387146, 'auc': 0.6633971929550171} \n",
            "652/689 [===========================>..] - ETA: 3s - loss: 0.6520 - tp: 5692.0000 - fp: 3061.0000 - tn: 7343.0000 - fn: 4768.0000 - accuracy: 0.6248 - precision: 0.6503 - recall: 0.5442 - auc: 0.6634\n",
            " For Batch Number 653 the model has a loss of {'loss': 0.651549756526947, 'tp': 5702.0, 'fp': 3063.0, 'tn': 7360.0, 'fn': 4771.0, 'accuracy': 0.6250957250595093, 'precision': 0.6505419015884399, 'recall': 0.5444476008415222, 'auc': 0.6639364361763} \n",
            "653/689 [===========================>..] - ETA: 3s - loss: 0.6515 - tp: 5702.0000 - fp: 3063.0000 - tn: 7360.0000 - fn: 4771.0000 - accuracy: 0.6251 - precision: 0.6505 - recall: 0.5444 - auc: 0.6639\n",
            " For Batch Number 654 the model has a loss of {'loss': 0.6513344049453735, 'tp': 5712.0, 'fp': 3066.0, 'tn': 7376.0, 'fn': 4774.0, 'accuracy': 0.6253822445869446, 'precision': 0.6507176756858826, 'recall': 0.5447263121604919, 'auc': 0.6643601059913635} \n",
            "654/689 [===========================>..] - ETA: 2s - loss: 0.6513 - tp: 5712.0000 - fp: 3066.0000 - tn: 7376.0000 - fn: 4774.0000 - accuracy: 0.6254 - precision: 0.6507 - recall: 0.5447 - auc: 0.6644\n",
            " For Batch Number 655 the model has a loss of {'loss': 0.651338517665863, 'tp': 5723.0, 'fp': 3068.0, 'tn': 7389.0, 'fn': 4780.0, 'accuracy': 0.6255725026130676, 'precision': 0.6510066986083984, 'recall': 0.5448919534683228, 'auc': 0.6645819544792175} \n",
            "655/689 [===========================>..] - ETA: 2s - loss: 0.6513 - tp: 5723.0000 - fp: 3068.0000 - tn: 7389.0000 - fn: 4780.0000 - accuracy: 0.6256 - precision: 0.6510 - recall: 0.5449 - auc: 0.6646\n",
            " For Batch Number 656 the model has a loss of {'loss': 0.6513505578041077, 'tp': 5732.0, 'fp': 3073.0, 'tn': 7402.0, 'fn': 4785.0, 'accuracy': 0.6256669163703918, 'precision': 0.6509937644004822, 'recall': 0.5450223684310913, 'auc': 0.6647284626960754} \n",
            "656/689 [===========================>..] - ETA: 2s - loss: 0.6514 - tp: 5732.0000 - fp: 3073.0000 - tn: 7402.0000 - fn: 4785.0000 - accuracy: 0.6257 - precision: 0.6510 - recall: 0.5450 - auc: 0.6647\n",
            " For Batch Number 657 the model has a loss of {'loss': 0.6513240933418274, 'tp': 5743.0, 'fp': 3076.0, 'tn': 7415.0, 'fn': 4790.0, 'accuracy': 0.6258561611175537, 'precision': 0.6512076258659363, 'recall': 0.5452387928962708, 'auc': 0.6649175882339478} \n",
            "657/689 [===========================>..] - ETA: 2s - loss: 0.6513 - tp: 5743.0000 - fp: 3076.0000 - tn: 7415.0000 - fn: 4790.0000 - accuracy: 0.6259 - precision: 0.6512 - recall: 0.5452 - auc: 0.6649\n",
            " For Batch Number 658 the model has a loss of {'loss': 0.6515071988105774, 'tp': 5752.0, 'fp': 3081.0, 'tn': 7427.0, 'fn': 4796.0, 'accuracy': 0.6259023547172546, 'precision': 0.6511943936347961, 'recall': 0.5453166365623474, 'auc': 0.6648775935173035} \n",
            "658/689 [===========================>..] - ETA: 2s - loss: 0.6515 - tp: 5752.0000 - fp: 3081.0000 - tn: 7427.0000 - fn: 4796.0000 - accuracy: 0.6259 - precision: 0.6512 - recall: 0.5453 - auc: 0.6649\n",
            " For Batch Number 659 the model has a loss of {'loss': 0.6519741415977478, 'tp': 5757.0, 'fp': 3089.0, 'tn': 7437.0, 'fn': 4805.0, 'accuracy': 0.6256638765335083, 'precision': 0.6508026123046875, 'recall': 0.5450672507286072, 'auc': 0.6645448207855225} \n",
            "659/689 [===========================>..] - ETA: 2s - loss: 0.6520 - tp: 5757.0000 - fp: 3089.0000 - tn: 7437.0000 - fn: 4805.0000 - accuracy: 0.6257 - precision: 0.6508 - recall: 0.5451 - auc: 0.6645\n",
            " For Batch Number 660 the model has a loss of {'loss': 0.6519023776054382, 'tp': 5767.0, 'fp': 3094.0, 'tn': 7448.0, 'fn': 4811.0, 'accuracy': 0.6257102489471436, 'precision': 0.6508294939994812, 'recall': 0.5451881289482117, 'auc': 0.664699137210846} \n",
            "660/689 [===========================>..] - ETA: 2s - loss: 0.6519 - tp: 5767.0000 - fp: 3094.0000 - tn: 7448.0000 - fn: 4811.0000 - accuracy: 0.6257 - precision: 0.6508 - recall: 0.5452 - auc: 0.6647\n",
            " For Batch Number 661 the model has a loss of {'loss': 0.6518324017524719, 'tp': 5773.0, 'fp': 3098.0, 'tn': 7463.0, 'fn': 4818.0, 'accuracy': 0.6257564425468445, 'precision': 0.6507721543312073, 'recall': 0.5450854301452637, 'auc': 0.6647368669509888} \n",
            "661/689 [===========================>..] - ETA: 2s - loss: 0.6518 - tp: 5773.0000 - fp: 3098.0000 - tn: 7463.0000 - fn: 4818.0000 - accuracy: 0.6258 - precision: 0.6508 - recall: 0.5451 - auc: 0.6647\n",
            " For Batch Number 662 the model has a loss of {'loss': 0.6518001556396484, 'tp': 5781.0, 'fp': 3102.0, 'tn': 7479.0, 'fn': 4822.0, 'accuracy': 0.6259441375732422, 'precision': 0.6507936716079712, 'recall': 0.54522305727005, 'auc': 0.6647610664367676} \n",
            "662/689 [===========================>..] - ETA: 2s - loss: 0.6518 - tp: 5781.0000 - fp: 3102.0000 - tn: 7479.0000 - fn: 4822.0000 - accuracy: 0.6259 - precision: 0.6508 - recall: 0.5452 - auc: 0.6648\n",
            " For Batch Number 663 the model has a loss of {'loss': 0.6516919136047363, 'tp': 5790.0, 'fp': 3107.0, 'tn': 7495.0, 'fn': 4824.0, 'accuracy': 0.6261783838272095, 'precision': 0.6507811546325684, 'recall': 0.545505940914154, 'auc': 0.6648943424224854} \n",
            "663/689 [===========================>..] - ETA: 2s - loss: 0.6517 - tp: 5790.0000 - fp: 3107.0000 - tn: 7495.0000 - fn: 4824.0000 - accuracy: 0.6262 - precision: 0.6508 - recall: 0.5455 - auc: 0.6649\n",
            " For Batch Number 664 the model has a loss of {'loss': 0.6516523361206055, 'tp': 5801.0, 'fp': 3109.0, 'tn': 7505.0, 'fn': 4833.0, 'accuracy': 0.626223623752594, 'precision': 0.651066243648529, 'recall': 0.5455144047737122, 'auc': 0.6649567484855652} \n",
            "664/689 [===========================>..] - ETA: 2s - loss: 0.6517 - tp: 5801.0000 - fp: 3109.0000 - tn: 7505.0000 - fn: 4833.0000 - accuracy: 0.6262 - precision: 0.6511 - recall: 0.5455 - auc: 0.6650\n",
            " For Batch Number 665 the model has a loss of {'loss': 0.651542603969574, 'tp': 5809.0, 'fp': 3111.0, 'tn': 7520.0, 'fn': 4840.0, 'accuracy': 0.6263628005981445, 'precision': 0.6512331962585449, 'recall': 0.5454972386360168, 'auc': 0.6650901436805725} \n",
            "665/689 [===========================>..] - ETA: 2s - loss: 0.6515 - tp: 5809.0000 - fp: 3111.0000 - tn: 7520.0000 - fn: 4840.0000 - accuracy: 0.6264 - precision: 0.6512 - recall: 0.5455 - auc: 0.6651\n",
            " For Batch Number 666 the model has a loss of {'loss': 0.6515165567398071, 'tp': 5818.0, 'fp': 3113.0, 'tn': 7532.0, 'fn': 4849.0, 'accuracy': 0.6264076828956604, 'precision': 0.65143883228302, 'recall': 0.5454204678535461, 'auc': 0.6651129722595215} \n",
            "666/689 [===========================>..] - ETA: 1s - loss: 0.6515 - tp: 5818.0000 - fp: 3113.0000 - tn: 7532.0000 - fn: 4849.0000 - accuracy: 0.6264 - precision: 0.6514 - recall: 0.5454 - auc: 0.6651\n",
            " For Batch Number 667 the model has a loss of {'loss': 0.6514712572097778, 'tp': 5827.0, 'fp': 3118.0, 'tn': 7543.0, 'fn': 4856.0, 'accuracy': 0.6264055371284485, 'precision': 0.6514253616333008, 'recall': 0.5454460382461548, 'auc': 0.6651543378829956} \n",
            "667/689 [============================>.] - ETA: 1s - loss: 0.6515 - tp: 5827.0000 - fp: 3118.0000 - tn: 7543.0000 - fn: 4856.0000 - accuracy: 0.6264 - precision: 0.6514 - recall: 0.5454 - auc: 0.6652\n",
            " For Batch Number 668 the model has a loss of {'loss': 0.651332676410675, 'tp': 5836.0, 'fp': 3122.0, 'tn': 7555.0, 'fn': 4863.0, 'accuracy': 0.62645024061203, 'precision': 0.6514847278594971, 'recall': 0.5454715490341187, 'auc': 0.6653716564178467} \n",
            "668/689 [============================>.] - ETA: 1s - loss: 0.6513 - tp: 5836.0000 - fp: 3122.0000 - tn: 7555.0000 - fn: 4863.0000 - accuracy: 0.6265 - precision: 0.6515 - recall: 0.5455 - auc: 0.6654\n",
            " For Batch Number 669 the model has a loss of {'loss': 0.651547908782959, 'tp': 5842.0, 'fp': 3130.0, 'tn': 7567.0, 'fn': 4869.0, 'accuracy': 0.6263546347618103, 'precision': 0.6511368751525879, 'recall': 0.5454205870628357, 'auc': 0.665179431438446} \n",
            "669/689 [============================>.] - ETA: 1s - loss: 0.6515 - tp: 5842.0000 - fp: 3130.0000 - tn: 7567.0000 - fn: 4869.0000 - accuracy: 0.6264 - precision: 0.6511 - recall: 0.5454 - auc: 0.6652\n",
            " For Batch Number 670 the model has a loss of {'loss': 0.6513063311576843, 'tp': 5853.0, 'fp': 3132.0, 'tn': 7581.0, 'fn': 4874.0, 'accuracy': 0.626585841178894, 'precision': 0.6514190435409546, 'recall': 0.545632541179657, 'auc': 0.665492057800293} \n",
            "670/689 [============================>.] - ETA: 1s - loss: 0.6513 - tp: 5853.0000 - fp: 3132.0000 - tn: 7581.0000 - fn: 4874.0000 - accuracy: 0.6266 - precision: 0.6514 - recall: 0.5456 - auc: 0.6655\n",
            " For Batch Number 671 the model has a loss of {'loss': 0.6512344479560852, 'tp': 5862.0, 'fp': 3135.0, 'tn': 7590.0, 'fn': 4885.0, 'accuracy': 0.6264902949333191, 'precision': 0.6515505313873291, 'recall': 0.5454545617103577, 'auc': 0.6655734181404114} \n",
            "671/689 [============================>.] - ETA: 1s - loss: 0.6512 - tp: 5862.0000 - fp: 3135.0000 - tn: 7590.0000 - fn: 4885.0000 - accuracy: 0.6265 - precision: 0.6516 - recall: 0.5455 - auc: 0.6656\n",
            " For Batch Number 672 the model has a loss of {'loss': 0.6513584852218628, 'tp': 5868.0, 'fp': 3143.0, 'tn': 7601.0, 'fn': 4892.0, 'accuracy': 0.626348614692688, 'precision': 0.6512041091918945, 'recall': 0.5453531742095947, 'auc': 0.6654018759727478} \n",
            "672/689 [============================>.] - ETA: 1s - loss: 0.6514 - tp: 5868.0000 - fp: 3143.0000 - tn: 7601.0000 - fn: 4892.0000 - accuracy: 0.6263 - precision: 0.6512 - recall: 0.5454 - auc: 0.6654\n",
            " For Batch Number 673 the model has a loss of {'loss': 0.6514953970909119, 'tp': 5874.0, 'fp': 3152.0, 'tn': 7612.0, 'fn': 4898.0, 'accuracy': 0.6262072920799255, 'precision': 0.6507866382598877, 'recall': 0.5453026294708252, 'auc': 0.6653445959091187} \n",
            "673/689 [============================>.] - ETA: 1s - loss: 0.6515 - tp: 5874.0000 - fp: 3152.0000 - tn: 7612.0000 - fn: 4898.0000 - accuracy: 0.6262 - precision: 0.6508 - recall: 0.5453 - auc: 0.6653\n",
            " For Batch Number 674 the model has a loss of {'loss': 0.6514329314231873, 'tp': 5882.0, 'fp': 3157.0, 'tn': 7624.0, 'fn': 4905.0, 'accuracy': 0.6262055039405823, 'precision': 0.6507356762886047, 'recall': 0.5452859997749329, 'auc': 0.6653633713722229} \n",
            "674/689 [============================>.] - ETA: 1s - loss: 0.6514 - tp: 5882.0000 - fp: 3157.0000 - tn: 7624.0000 - fn: 4905.0000 - accuracy: 0.6262 - precision: 0.6507 - recall: 0.5453 - auc: 0.6654\n",
            " For Batch Number 675 the model has a loss of {'loss': 0.6516675353050232, 'tp': 5888.0, 'fp': 3161.0, 'tn': 7633.0, 'fn': 4918.0, 'accuracy': 0.6259722113609314, 'precision': 0.6506796479225159, 'recall': 0.5448824763298035, 'auc': 0.6650221943855286} \n",
            "675/689 [============================>.] - ETA: 1s - loss: 0.6517 - tp: 5888.0000 - fp: 3161.0000 - tn: 7633.0000 - fn: 4918.0000 - accuracy: 0.6260 - precision: 0.6507 - recall: 0.5449 - auc: 0.6650\n",
            " For Batch Number 676 the model has a loss of {'loss': 0.6516000628471375, 'tp': 5894.0, 'fp': 3164.0, 'tn': 7648.0, 'fn': 4926.0, 'accuracy': 0.6260170340538025, 'precision': 0.6506955027580261, 'recall': 0.5447319746017456, 'auc': 0.6650258302688599} \n",
            "676/689 [============================>.] - ETA: 1s - loss: 0.6516 - tp: 5894.0000 - fp: 3164.0000 - tn: 7648.0000 - fn: 4926.0000 - accuracy: 0.6260 - precision: 0.6507 - recall: 0.5447 - auc: 0.6650\n",
            " For Batch Number 677 the model has a loss of {'loss': 0.6517614722251892, 'tp': 5901.0, 'fp': 3166.0, 'tn': 7657.0, 'fn': 4940.0, 'accuracy': 0.625830888748169, 'precision': 0.6508216857910156, 'recall': 0.5443224906921387, 'auc': 0.6647548079490662} \n",
            "677/689 [============================>.] - ETA: 1s - loss: 0.6518 - tp: 5901.0000 - fp: 3166.0000 - tn: 7657.0000 - fn: 4940.0000 - accuracy: 0.6258 - precision: 0.6508 - recall: 0.5443 - auc: 0.6648\n",
            " For Batch Number 678 the model has a loss of {'loss': 0.6517519950866699, 'tp': 5907.0, 'fp': 3170.0, 'tn': 7670.0, 'fn': 4949.0, 'accuracy': 0.6257835626602173, 'precision': 0.6507656574249268, 'recall': 0.5441230535507202, 'auc': 0.664663553237915} \n",
            "678/689 [============================>.] - ETA: 0s - loss: 0.6518 - tp: 5907.0000 - fp: 3170.0000 - tn: 7670.0000 - fn: 4949.0000 - accuracy: 0.6258 - precision: 0.6508 - recall: 0.5441 - auc: 0.6647\n",
            " For Batch Number 679 the model has a loss of {'loss': 0.6518069505691528, 'tp': 5913.0, 'fp': 3174.0, 'tn': 7686.0, 'fn': 4955.0, 'accuracy': 0.6258744597434998, 'precision': 0.6507098078727722, 'recall': 0.5440743565559387, 'auc': 0.6646659970283508} \n",
            "679/689 [============================>.] - ETA: 0s - loss: 0.6518 - tp: 5913.0000 - fp: 3174.0000 - tn: 7686.0000 - fn: 4955.0000 - accuracy: 0.6259 - precision: 0.6507 - recall: 0.5441 - auc: 0.6647\n",
            " For Batch Number 680 the model has a loss of {'loss': 0.6518325805664062, 'tp': 5923.0, 'fp': 3178.0, 'tn': 7696.0, 'fn': 4963.0, 'accuracy': 0.6258731484413147, 'precision': 0.6508076190948486, 'recall': 0.5440933108329773, 'auc': 0.6646143794059753} \n",
            "680/689 [============================>.] - ETA: 0s - loss: 0.6518 - tp: 5923.0000 - fp: 3178.0000 - tn: 7696.0000 - fn: 4963.0000 - accuracy: 0.6259 - precision: 0.6508 - recall: 0.5441 - auc: 0.6646\n",
            " For Batch Number 681 the model has a loss of {'loss': 0.6517230272293091, 'tp': 5932.0, 'fp': 3185.0, 'tn': 7710.0, 'fn': 4965.0, 'accuracy': 0.6260095238685608, 'precision': 0.6506526470184326, 'recall': 0.5443699955940247, 'auc': 0.6647647023200989} \n",
            "681/689 [============================>.] - ETA: 0s - loss: 0.6517 - tp: 5932.0000 - fp: 3185.0000 - tn: 7710.0000 - fn: 4965.0000 - accuracy: 0.6260 - precision: 0.6507 - recall: 0.5444 - auc: 0.6648\n",
            " For Batch Number 682 the model has a loss of {'loss': 0.651697039604187, 'tp': 5946.0, 'fp': 3191.0, 'tn': 7717.0, 'fn': 4970.0, 'accuracy': 0.6260538697242737, 'precision': 0.6507606506347656, 'recall': 0.5447050333023071, 'auc': 0.6648796796798706} \n",
            "682/689 [============================>.] - ETA: 0s - loss: 0.6517 - tp: 5946.0000 - fp: 3191.0000 - tn: 7717.0000 - fn: 4970.0000 - accuracy: 0.6261 - precision: 0.6508 - recall: 0.5447 - auc: 0.6649\n",
            " For Batch Number 683 the model has a loss of {'loss': 0.6522310376167297, 'tp': 5950.0, 'fp': 3202.0, 'tn': 7724.0, 'fn': 4980.0, 'accuracy': 0.6256405711174011, 'precision': 0.650131106376648, 'recall': 0.5443732738494873, 'auc': 0.6642913818359375} \n",
            "683/689 [============================>.] - ETA: 0s - loss: 0.6522 - tp: 5950.0000 - fp: 3202.0000 - tn: 7724.0000 - fn: 4980.0000 - accuracy: 0.6256 - precision: 0.6501 - recall: 0.5444 - auc: 0.6643\n",
            " For Batch Number 684 the model has a loss of {'loss': 0.6524759531021118, 'tp': 5958.0, 'fp': 3208.0, 'tn': 7732.0, 'fn': 4990.0, 'accuracy': 0.6254568696022034, 'precision': 0.650010883808136, 'recall': 0.5442090034484863, 'auc': 0.6640340089797974} \n",
            "684/689 [============================>.] - ETA: 0s - loss: 0.6525 - tp: 5958.0000 - fp: 3208.0000 - tn: 7732.0000 - fn: 4990.0000 - accuracy: 0.6255 - precision: 0.6500 - recall: 0.5442 - auc: 0.6640\n",
            " For Batch Number 685 the model has a loss of {'loss': 0.6522542238235474, 'tp': 5971.0, 'fp': 3209.0, 'tn': 7747.0, 'fn': 4993.0, 'accuracy': 0.6258211731910706, 'precision': 0.650435745716095, 'recall': 0.5446004867553711, 'auc': 0.66439288854599} \n",
            "685/689 [============================>.] - ETA: 0s - loss: 0.6523 - tp: 5971.0000 - fp: 3209.0000 - tn: 7747.0000 - fn: 4993.0000 - accuracy: 0.6258 - precision: 0.6504 - recall: 0.5446 - auc: 0.6644\n",
            " For Batch Number 686 the model has a loss of {'loss': 0.6522017121315002, 'tp': 5980.0, 'fp': 3214.0, 'tn': 7758.0, 'fn': 5000.0, 'accuracy': 0.625819981098175, 'precision': 0.6504241824150085, 'recall': 0.5446265935897827, 'auc': 0.664430558681488} \n",
            "686/689 [============================>.] - ETA: 0s - loss: 0.6522 - tp: 5980.0000 - fp: 3214.0000 - tn: 7758.0000 - fn: 5000.0000 - accuracy: 0.6258 - precision: 0.6504 - recall: 0.5446 - auc: 0.6644\n",
            " For Batch Number 687 the model has a loss of {'loss': 0.6521194577217102, 'tp': 5985.0, 'fp': 3218.0, 'tn': 7772.0, 'fn': 5009.0, 'accuracy': 0.6257733106613159, 'precision': 0.650331437587738, 'recall': 0.5443878769874573, 'auc': 0.6644895076751709} \n",
            "687/689 [============================>.] - ETA: 0s - loss: 0.6521 - tp: 5985.0000 - fp: 3218.0000 - tn: 7772.0000 - fn: 5009.0000 - accuracy: 0.6258 - precision: 0.6503 - recall: 0.5444 - auc: 0.6645\n",
            " For Batch Number 688 the model has a loss of {'loss': 0.651954174041748, 'tp': 5995.0, 'fp': 3222.0, 'tn': 7785.0, 'fn': 5014.0, 'accuracy': 0.6259084343910217, 'precision': 0.6504285335540771, 'recall': 0.5445544719696045, 'auc': 0.6647182106971741} \n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.6520 - tp: 5995.0000 - fp: 3222.0000 - tn: 7785.0000 - fn: 5014.0000 - accuracy: 0.6259 - precision: 0.6504 - recall: 0.5446 - auc: 0.6647\n",
            " For Batch Number 689 the model has a loss of {'loss': 0.6518306136131287, 'tp': 6005.0, 'fp': 3224.0, 'tn': 7799.0, 'fn': 5018.0, 'accuracy': 0.6261453032493591, 'precision': 0.650666356086731, 'recall': 0.5447700023651123, 'auc': 0.6649149656295776} \n",
            "689/689 [==============================] - ETA: 0s - loss: 0.6518 - tp: 6005.0000 - fp: 3224.0000 - tn: 7799.0000 - fn: 5018.0000 - accuracy: 0.6261 - precision: 0.6507 - recall: 0.5448 - auc: 0.6649\n",
            " For Epoch Number 2 the model has a loss of 0.6518306136131287\n",
            "689/689 [==============================] - 59s 85ms/step - loss: 0.6518 - tp: 6005.0000 - fp: 3224.0000 - tn: 7799.0000 - fn: 5018.0000 - accuracy: 0.6261 - precision: 0.6507 - recall: 0.5448 - auc: 0.6649\n",
            "Epoch 3/3\n",
            "\n",
            " For Batch Number 1 the model has a loss of {'loss': 0.6554446220397949, 'tp': 8.0, 'fp': 5.0, 'tn': 11.0, 'fn': 8.0, 'accuracy': 0.59375, 'precision': 0.6153846383094788, 'recall': 0.5, 'auc': 0.65625} \n",
            "  1/689 [..............................] - ETA: 2:13 - loss: 0.6554 - tp: 8.0000 - fp: 5.0000 - tn: 11.0000 - fn: 8.0000 - accuracy: 0.5938 - precision: 0.6154 - recall: 0.5000 - auc: 0.6562\n",
            " For Batch Number 2 the model has a loss of {'loss': 0.644711971282959, 'tp': 17.0, 'fp': 9.0, 'tn': 21.0, 'fn': 17.0, 'accuracy': 0.59375, 'precision': 0.6538461446762085, 'recall': 0.5, 'auc': 0.6539216041564941} \n",
            "  2/689 [..............................] - ETA: 42s - loss: 0.6447 - tp: 17.0000 - fp: 9.0000 - tn: 21.0000 - fn: 17.0000 - accuracy: 0.5938 - precision: 0.6538 - recall: 0.5000 - auc: 0.6539\n",
            " For Batch Number 3 the model has a loss of {'loss': 0.5942161083221436, 'tp': 28.0, 'fp': 12.0, 'tn': 35.0, 'fn': 21.0, 'accuracy': 0.65625, 'precision': 0.699999988079071, 'recall': 0.5714285969734192, 'auc': 0.7194962501525879} \n",
            "  3/689 [..............................] - ETA: 47s - loss: 0.5942 - tp: 28.0000 - fp: 12.0000 - tn: 35.0000 - fn: 21.0000 - accuracy: 0.6562 - precision: 0.7000 - recall: 0.5714 - auc: 0.7195\n",
            " For Batch Number 4 the model has a loss of {'loss': 0.5777784585952759, 'tp': 38.0, 'fp': 13.0, 'tn': 49.0, 'fn': 28.0, 'accuracy': 0.6796875, 'precision': 0.7450980544090271, 'recall': 0.5757575631141663, 'auc': 0.7256842255592346} \n",
            "  4/689 [..............................] - ETA: 55s - loss: 0.5778 - tp: 38.0000 - fp: 13.0000 - tn: 49.0000 - fn: 28.0000 - accuracy: 0.6797 - precision: 0.7451 - recall: 0.5758 - auc: 0.7257\n",
            " For Batch Number 5 the model has a loss of {'loss': 0.6055164933204651, 'tp': 46.0, 'fp': 18.0, 'tn': 59.0, 'fn': 37.0, 'accuracy': 0.65625, 'precision': 0.71875, 'recall': 0.5542168617248535, 'auc': 0.6960569024085999} \n",
            "  5/689 [..............................] - ETA: 54s - loss: 0.6055 - tp: 46.0000 - fp: 18.0000 - tn: 59.0000 - fn: 37.0000 - accuracy: 0.6562 - precision: 0.7188 - recall: 0.5542 - auc: 0.6961\n",
            " For Batch Number 6 the model has a loss of {'loss': 0.6026529669761658, 'tp': 59.0, 'fp': 21.0, 'tn': 68.0, 'fn': 44.0, 'accuracy': 0.6614583134651184, 'precision': 0.737500011920929, 'recall': 0.5728155374526978, 'auc': 0.7033926248550415} \n",
            "  6/689 [..............................] - ETA: 55s - loss: 0.6027 - tp: 59.0000 - fp: 21.0000 - tn: 68.0000 - fn: 44.0000 - accuracy: 0.6615 - precision: 0.7375 - recall: 0.5728 - auc: 0.7034\n",
            " For Batch Number 7 the model has a loss of {'loss': 0.6204622387886047, 'tp': 66.0, 'fp': 26.0, 'tn': 81.0, 'fn': 51.0, 'accuracy': 0.65625, 'precision': 0.717391312122345, 'recall': 0.5641025900840759, 'auc': 0.6852385401725769} \n",
            "  7/689 [..............................] - ETA: 1:04 - loss: 0.6205 - tp: 66.0000 - fp: 26.0000 - tn: 81.0000 - fn: 51.0000 - accuracy: 0.6562 - precision: 0.7174 - recall: 0.5641 - auc: 0.6852\n",
            " For Batch Number 8 the model has a loss of {'loss': 0.6198571920394897, 'tp': 78.0, 'fp': 30.0, 'tn': 91.0, 'fn': 57.0, 'accuracy': 0.66015625, 'precision': 0.7222222089767456, 'recall': 0.5777778029441833, 'auc': 0.6905417442321777} \n",
            "  8/689 [..............................] - ETA: 1:03 - loss: 0.6199 - tp: 78.0000 - fp: 30.0000 - tn: 91.0000 - fn: 57.0000 - accuracy: 0.6602 - precision: 0.7222 - recall: 0.5778 - auc: 0.6905\n",
            " For Batch Number 9 the model has a loss of {'loss': 0.6164588928222656, 'tp': 89.0, 'fp': 34.0, 'tn': 103.0, 'fn': 62.0, 'accuracy': 0.6666666865348816, 'precision': 0.7235772609710693, 'recall': 0.5894039869308472, 'auc': 0.6984580159187317} \n",
            "  9/689 [..............................] - ETA: 1:08 - loss: 0.6165 - tp: 89.0000 - fp: 34.0000 - tn: 103.0000 - fn: 62.0000 - accuracy: 0.6667 - precision: 0.7236 - recall: 0.5894 - auc: 0.6985\n",
            " For Batch Number 10 the model has a loss of {'loss': 0.6281818747520447, 'tp': 96.0, 'fp': 41.0, 'tn': 114.0, 'fn': 69.0, 'accuracy': 0.65625, 'precision': 0.7007299065589905, 'recall': 0.581818163394928, 'auc': 0.6898728609085083} \n",
            " 10/689 [..............................] - ETA: 1:14 - loss: 0.6282 - tp: 96.0000 - fp: 41.0000 - tn: 114.0000 - fn: 69.0000 - accuracy: 0.6562 - precision: 0.7007 - recall: 0.5818 - auc: 0.6899\n",
            " For Batch Number 11 the model has a loss of {'loss': 0.6193053722381592, 'tp': 107.0, 'fp': 45.0, 'tn': 123.0, 'fn': 77.0, 'accuracy': 0.6534090638160706, 'precision': 0.7039473652839661, 'recall': 0.58152174949646, 'auc': 0.7017178535461426} \n",
            " 11/689 [..............................] - ETA: 1:23 - loss: 0.6193 - tp: 107.0000 - fp: 45.0000 - tn: 123.0000 - fn: 77.0000 - accuracy: 0.6534 - precision: 0.7039 - recall: 0.5815 - auc: 0.7017\n",
            " For Batch Number 12 the model has a loss of {'loss': 0.6217029690742493, 'tp': 122.0, 'fp': 48.0, 'tn': 131.0, 'fn': 83.0, 'accuracy': 0.6588541865348816, 'precision': 0.7176470756530762, 'recall': 0.5951219797134399, 'auc': 0.7044011354446411} \n",
            " 12/689 [..............................] - ETA: 1:23 - loss: 0.6217 - tp: 122.0000 - fp: 48.0000 - tn: 131.0000 - fn: 83.0000 - accuracy: 0.6589 - precision: 0.7176 - recall: 0.5951 - auc: 0.7044\n",
            " For Batch Number 13 the model has a loss of {'loss': 0.6179174780845642, 'tp': 136.0, 'fp': 50.0, 'tn': 138.0, 'fn': 92.0, 'accuracy': 0.6586538553237915, 'precision': 0.7311828136444092, 'recall': 0.5964912176132202, 'auc': 0.7086016535758972} \n",
            " 13/689 [..............................] - ETA: 1:26 - loss: 0.6179 - tp: 136.0000 - fp: 50.0000 - tn: 138.0000 - fn: 92.0000 - accuracy: 0.6587 - precision: 0.7312 - recall: 0.5965 - auc: 0.7086\n",
            " For Batch Number 14 the model has a loss of {'loss': 0.6225686073303223, 'tp': 145.0, 'fp': 62.0, 'tn': 145.0, 'fn': 96.0, 'accuracy': 0.6473214030265808, 'precision': 0.7004830837249756, 'recall': 0.6016597747802734, 'auc': 0.7010543346405029} \n",
            " 14/689 [..............................] - ETA: 1:29 - loss: 0.6226 - tp: 145.0000 - fp: 62.0000 - tn: 145.0000 - fn: 96.0000 - accuracy: 0.6473 - precision: 0.7005 - recall: 0.6017 - auc: 0.7011\n",
            " For Batch Number 15 the model has a loss of {'loss': 0.6330137848854065, 'tp': 153.0, 'fp': 74.0, 'tn': 153.0, 'fn': 100.0, 'accuracy': 0.637499988079071, 'precision': 0.6740087866783142, 'recall': 0.6047430634498596, 'auc': 0.6905068159103394} \n",
            " 15/689 [..............................] - ETA: 1:30 - loss: 0.6330 - tp: 153.0000 - fp: 74.0000 - tn: 153.0000 - fn: 100.0000 - accuracy: 0.6375 - precision: 0.6740 - recall: 0.6047 - auc: 0.6905\n",
            " For Batch Number 16 the model has a loss of {'loss': 0.6290228962898254, 'tp': 163.0, 'fp': 82.0, 'tn': 164.0, 'fn': 103.0, 'accuracy': 0.638671875, 'precision': 0.6653061509132385, 'recall': 0.6127819418907166, 'auc': 0.6936549544334412} \n",
            " 16/689 [..............................] - ETA: 1:32 - loss: 0.6290 - tp: 163.0000 - fp: 82.0000 - tn: 164.0000 - fn: 103.0000 - accuracy: 0.6387 - precision: 0.6653 - recall: 0.6128 - auc: 0.6937\n",
            " For Batch Number 17 the model has a loss of {'loss': 0.6290670037269592, 'tp': 172.0, 'fp': 84.0, 'tn': 176.0, 'fn': 112.0, 'accuracy': 0.6397058963775635, 'precision': 0.671875, 'recall': 0.6056337952613831, 'auc': 0.6913259029388428} \n",
            " 17/689 [..............................] - ETA: 1:34 - loss: 0.6291 - tp: 172.0000 - fp: 84.0000 - tn: 176.0000 - fn: 112.0000 - accuracy: 0.6397 - precision: 0.6719 - recall: 0.6056 - auc: 0.6913\n",
            " For Batch Number 18 the model has a loss of {'loss': 0.6246318221092224, 'tp': 179.0, 'fp': 86.0, 'tn': 194.0, 'fn': 117.0, 'accuracy': 0.6475694179534912, 'precision': 0.6754717230796814, 'recall': 0.6047297120094299, 'auc': 0.6968508958816528} \n",
            " 18/689 [..............................] - ETA: 1:34 - loss: 0.6246 - tp: 179.0000 - fp: 86.0000 - tn: 194.0000 - fn: 117.0000 - accuracy: 0.6476 - precision: 0.6755 - recall: 0.6047 - auc: 0.6969\n",
            " For Batch Number 19 the model has a loss of {'loss': 0.6234476566314697, 'tp': 188.0, 'fp': 86.0, 'tn': 208.0, 'fn': 126.0, 'accuracy': 0.6513158082962036, 'precision': 0.6861313581466675, 'recall': 0.5987260937690735, 'auc': 0.6961740255355835} \n",
            " 19/689 [..............................] - ETA: 1:35 - loss: 0.6234 - tp: 188.0000 - fp: 86.0000 - tn: 208.0000 - fn: 126.0000 - accuracy: 0.6513 - precision: 0.6861 - recall: 0.5987 - auc: 0.6962\n",
            " For Batch Number 20 the model has a loss of {'loss': 0.6225457191467285, 'tp': 194.0, 'fp': 91.0, 'tn': 223.0, 'fn': 132.0, 'accuracy': 0.651562511920929, 'precision': 0.680701732635498, 'recall': 0.5950919985771179, 'auc': 0.6977941393852234} \n",
            " 20/689 [..............................] - ETA: 1:35 - loss: 0.6225 - tp: 194.0000 - fp: 91.0000 - tn: 223.0000 - fn: 132.0000 - accuracy: 0.6516 - precision: 0.6807 - recall: 0.5951 - auc: 0.6978\n",
            " For Batch Number 21 the model has a loss of {'loss': 0.61772221326828, 'tp': 203.0, 'fp': 93.0, 'tn': 239.0, 'fn': 137.0, 'accuracy': 0.6577380895614624, 'precision': 0.6858108043670654, 'recall': 0.5970588326454163, 'auc': 0.7045844793319702} \n",
            " 21/689 [..............................] - ETA: 1:35 - loss: 0.6177 - tp: 203.0000 - fp: 93.0000 - tn: 239.0000 - fn: 137.0000 - accuracy: 0.6577 - precision: 0.6858 - recall: 0.5971 - auc: 0.7046\n",
            " For Batch Number 22 the model has a loss of {'loss': 0.6165889501571655, 'tp': 213.0, 'fp': 93.0, 'tn': 252.0, 'fn': 146.0, 'accuracy': 0.6605113744735718, 'precision': 0.6960784196853638, 'recall': 0.5933147668838501, 'auc': 0.7059464454650879} \n",
            " 22/689 [..............................] - ETA: 1:35 - loss: 0.6166 - tp: 213.0000 - fp: 93.0000 - tn: 252.0000 - fn: 146.0000 - accuracy: 0.6605 - precision: 0.6961 - recall: 0.5933 - auc: 0.7059\n",
            " For Batch Number 23 the model has a loss of {'loss': 0.6189181804656982, 'tp': 222.0, 'fp': 93.0, 'tn': 263.0, 'fn': 158.0, 'accuracy': 0.6589673757553101, 'precision': 0.7047619223594666, 'recall': 0.5842105150222778, 'auc': 0.7021474242210388} \n",
            " 23/689 [>.............................] - ETA: 1:33 - loss: 0.6189 - tp: 222.0000 - fp: 93.0000 - tn: 263.0000 - fn: 158.0000 - accuracy: 0.6590 - precision: 0.7048 - recall: 0.5842 - auc: 0.7021\n",
            " For Batch Number 24 the model has a loss of {'loss': 0.6202999353408813, 'tp': 230.0, 'fp': 97.0, 'tn': 276.0, 'fn': 165.0, 'accuracy': 0.6588541865348816, 'precision': 0.7033638954162598, 'recall': 0.5822784900665283, 'auc': 0.7012556195259094} \n",
            " 24/689 [>.............................] - ETA: 1:32 - loss: 0.6203 - tp: 230.0000 - fp: 97.0000 - tn: 276.0000 - fn: 165.0000 - accuracy: 0.6589 - precision: 0.7034 - recall: 0.5823 - auc: 0.7013\n",
            " For Batch Number 25 the model has a loss of {'loss': 0.6125174164772034, 'tp': 240.0, 'fp': 100.0, 'tn': 294.0, 'fn': 166.0, 'accuracy': 0.6675000190734863, 'precision': 0.7058823704719543, 'recall': 0.5911329984664917, 'auc': 0.7075341939926147} \n",
            " 25/689 [>.............................] - ETA: 1:32 - loss: 0.6125 - tp: 240.0000 - fp: 100.0000 - tn: 294.0000 - fn: 166.0000 - accuracy: 0.6675 - precision: 0.7059 - recall: 0.5911 - auc: 0.7075\n",
            " For Batch Number 26 the model has a loss of {'loss': 0.6126900315284729, 'tp': 248.0, 'fp': 105.0, 'tn': 307.0, 'fn': 172.0, 'accuracy': 0.667067289352417, 'precision': 0.7025495767593384, 'recall': 0.5904762148857117, 'auc': 0.7069261074066162} \n",
            " 26/689 [>.............................] - ETA: 1:31 - loss: 0.6127 - tp: 248.0000 - fp: 105.0000 - tn: 307.0000 - fn: 172.0000 - accuracy: 0.6671 - precision: 0.7025 - recall: 0.5905 - auc: 0.7069\n",
            " For Batch Number 27 the model has a loss of {'loss': 0.6132736802101135, 'tp': 258.0, 'fp': 109.0, 'tn': 317.0, 'fn': 180.0, 'accuracy': 0.6655092835426331, 'precision': 0.7029972672462463, 'recall': 0.5890411138534546, 'auc': 0.7073927521705627} \n",
            " 27/689 [>.............................] - ETA: 1:29 - loss: 0.6133 - tp: 258.0000 - fp: 109.0000 - tn: 317.0000 - fn: 180.0000 - accuracy: 0.6655 - precision: 0.7030 - recall: 0.5890 - auc: 0.7074\n",
            " For Batch Number 28 the model has a loss of {'loss': 0.6170626878738403, 'tp': 264.0, 'fp': 115.0, 'tn': 329.0, 'fn': 188.0, 'accuracy': 0.6618303656578064, 'precision': 0.6965699195861816, 'recall': 0.5840708017349243, 'auc': 0.7047207355499268} \n",
            " 28/689 [>.............................] - ETA: 1:28 - loss: 0.6171 - tp: 264.0000 - fp: 115.0000 - tn: 329.0000 - fn: 188.0000 - accuracy: 0.6618 - precision: 0.6966 - recall: 0.5841 - auc: 0.7047\n",
            " For Batch Number 29 the model has a loss of {'loss': 0.6159850358963013, 'tp': 272.0, 'fp': 115.0, 'tn': 341.0, 'fn': 200.0, 'accuracy': 0.6605603694915771, 'precision': 0.7028423547744751, 'recall': 0.5762711763381958, 'auc': 0.7048255205154419} \n",
            " 29/689 [>.............................] - ETA: 1:27 - loss: 0.6160 - tp: 272.0000 - fp: 115.0000 - tn: 341.0000 - fn: 200.0000 - accuracy: 0.6606 - precision: 0.7028 - recall: 0.5763 - auc: 0.7048\n",
            " For Batch Number 30 the model has a loss of {'loss': 0.61323082447052, 'tp': 280.0, 'fp': 117.0, 'tn': 355.0, 'fn': 208.0, 'accuracy': 0.6614583134651184, 'precision': 0.7052896618843079, 'recall': 0.5737704634666443, 'auc': 0.7064658403396606} \n",
            " 30/689 [>.............................] - ETA: 1:26 - loss: 0.6132 - tp: 280.0000 - fp: 117.0000 - tn: 355.0000 - fn: 208.0000 - accuracy: 0.6615 - precision: 0.7053 - recall: 0.5738 - auc: 0.7065\n",
            " For Batch Number 31 the model has a loss of {'loss': 0.6101032495498657, 'tp': 290.0, 'fp': 117.0, 'tn': 370.0, 'fn': 215.0, 'accuracy': 0.6653226017951965, 'precision': 0.7125307321548462, 'recall': 0.5742574334144592, 'auc': 0.708833634853363} \n",
            " 31/689 [>.............................] - ETA: 1:26 - loss: 0.6101 - tp: 290.0000 - fp: 117.0000 - tn: 370.0000 - fn: 215.0000 - accuracy: 0.6653 - precision: 0.7125 - recall: 0.5743 - auc: 0.7088\n",
            " For Batch Number 32 the model has a loss of {'loss': 0.6078510880470276, 'tp': 300.0, 'fp': 117.0, 'tn': 382.0, 'fn': 225.0, 'accuracy': 0.666015625, 'precision': 0.7194244861602783, 'recall': 0.5714285969734192, 'auc': 0.7110755443572998} \n",
            " 32/689 [>.............................] - ETA: 1:25 - loss: 0.6079 - tp: 300.0000 - fp: 117.0000 - tn: 382.0000 - fn: 225.0000 - accuracy: 0.6660 - precision: 0.7194 - recall: 0.5714 - auc: 0.7111\n",
            " For Batch Number 33 the model has a loss of {'loss': 0.603792130947113, 'tp': 307.0, 'fp': 119.0, 'tn': 399.0, 'fn': 231.0, 'accuracy': 0.6685606241226196, 'precision': 0.7206572890281677, 'recall': 0.5706319808959961, 'auc': 0.7144867181777954} \n",
            " 33/689 [>.............................] - ETA: 1:23 - loss: 0.6038 - tp: 307.0000 - fp: 119.0000 - tn: 399.0000 - fn: 231.0000 - accuracy: 0.6686 - precision: 0.7207 - recall: 0.5706 - auc: 0.7145\n",
            " For Batch Number 34 the model has a loss of {'loss': 0.6043592095375061, 'tp': 314.0, 'fp': 123.0, 'tn': 411.0, 'fn': 240.0, 'accuracy': 0.6663603186607361, 'precision': 0.7185354828834534, 'recall': 0.5667870044708252, 'auc': 0.7132329940795898} \n",
            " 34/689 [>.............................] - ETA: 1:22 - loss: 0.6044 - tp: 314.0000 - fp: 123.0000 - tn: 411.0000 - fn: 240.0000 - accuracy: 0.6664 - precision: 0.7185 - recall: 0.5668 - auc: 0.7132\n",
            " For Batch Number 35 the model has a loss of {'loss': 0.6083678007125854, 'tp': 322.0, 'fp': 127.0, 'tn': 419.0, 'fn': 252.0, 'accuracy': 0.6616071462631226, 'precision': 0.7171491980552673, 'recall': 0.5609756112098694, 'auc': 0.7111937999725342} \n",
            " 35/689 [>.............................] - ETA: 1:22 - loss: 0.6084 - tp: 322.0000 - fp: 127.0000 - tn: 419.0000 - fn: 252.0000 - accuracy: 0.6616 - precision: 0.7171 - recall: 0.5610 - auc: 0.7112\n",
            " For Batch Number 36 the model has a loss of {'loss': 0.6068771481513977, 'tp': 333.0, 'fp': 129.0, 'tn': 429.0, 'fn': 261.0, 'accuracy': 0.6614583134651184, 'precision': 0.7207792401313782, 'recall': 0.560606062412262, 'auc': 0.7128407955169678} \n",
            " 36/689 [>.............................] - ETA: 1:22 - loss: 0.6069 - tp: 333.0000 - fp: 129.0000 - tn: 429.0000 - fn: 261.0000 - accuracy: 0.6615 - precision: 0.7208 - recall: 0.5606 - auc: 0.7128\n",
            " For Batch Number 37 the model has a loss of {'loss': 0.6054647564888, 'tp': 346.0, 'fp': 133.0, 'tn': 438.0, 'fn': 267.0, 'accuracy': 0.662162184715271, 'precision': 0.7223381996154785, 'recall': 0.564437210559845, 'auc': 0.7143973112106323} \n",
            " 37/689 [>.............................] - ETA: 1:22 - loss: 0.6055 - tp: 346.0000 - fp: 133.0000 - tn: 438.0000 - fn: 267.0000 - accuracy: 0.6622 - precision: 0.7223 - recall: 0.5644 - auc: 0.7144\n",
            " For Batch Number 38 the model has a loss of {'loss': 0.6031503677368164, 'tp': 362.0, 'fp': 134.0, 'tn': 446.0, 'fn': 274.0, 'accuracy': 0.6644737124443054, 'precision': 0.7298387289047241, 'recall': 0.5691823959350586, 'auc': 0.7175992131233215} \n",
            " 38/689 [>.............................] - ETA: 1:21 - loss: 0.6032 - tp: 362.0000 - fp: 134.0000 - tn: 446.0000 - fn: 274.0000 - accuracy: 0.6645 - precision: 0.7298 - recall: 0.5692 - auc: 0.7176\n",
            " For Batch Number 39 the model has a loss of {'loss': 0.6013184189796448, 'tp': 378.0, 'fp': 139.0, 'tn': 454.0, 'fn': 277.0, 'accuracy': 0.6666666865348816, 'precision': 0.731141209602356, 'recall': 0.5770992636680603, 'auc': 0.7198446989059448} \n",
            " 39/689 [>.............................] - ETA: 1:21 - loss: 0.6013 - tp: 378.0000 - fp: 139.0000 - tn: 454.0000 - fn: 277.0000 - accuracy: 0.6667 - precision: 0.7311 - recall: 0.5771 - auc: 0.7198\n",
            " For Batch Number 40 the model has a loss of {'loss': 0.6013740301132202, 'tp': 394.0, 'fp': 148.0, 'tn': 459.0, 'fn': 279.0, 'accuracy': 0.6664062738418579, 'precision': 0.7269372940063477, 'recall': 0.5854383111000061, 'auc': 0.7197737693786621} \n",
            " 40/689 [>.............................] - ETA: 1:20 - loss: 0.6014 - tp: 394.0000 - fp: 148.0000 - tn: 459.0000 - fn: 279.0000 - accuracy: 0.6664 - precision: 0.7269 - recall: 0.5854 - auc: 0.7198\n",
            " For Batch Number 41 the model has a loss of {'loss': 0.6070225238800049, 'tp': 405.0, 'fp': 165.0, 'tn': 463.0, 'fn': 279.0, 'accuracy': 0.6615853905677795, 'precision': 0.7105262875556946, 'recall': 0.5921052694320679, 'auc': 0.7152347564697266} \n",
            " 41/689 [>.............................] - ETA: 1:20 - loss: 0.6070 - tp: 405.0000 - fp: 165.0000 - tn: 463.0000 - fn: 279.0000 - accuracy: 0.6616 - precision: 0.7105 - recall: 0.5921 - auc: 0.7152\n",
            " For Batch Number 42 the model has a loss of {'loss': 0.6066645979881287, 'tp': 422.0, 'fp': 170.0, 'tn': 468.0, 'fn': 284.0, 'accuracy': 0.6622023582458496, 'precision': 0.712837815284729, 'recall': 0.597733736038208, 'auc': 0.7158857583999634} \n",
            " 42/689 [>.............................] - ETA: 1:19 - loss: 0.6067 - tp: 422.0000 - fp: 170.0000 - tn: 468.0000 - fn: 284.0000 - accuracy: 0.6622 - precision: 0.7128 - recall: 0.5977 - auc: 0.7159\n",
            " For Batch Number 43 the model has a loss of {'loss': 0.6077300310134888, 'tp': 432.0, 'fp': 175.0, 'tn': 475.0, 'fn': 294.0, 'accuracy': 0.6591569781303406, 'precision': 0.7116968631744385, 'recall': 0.5950413346290588, 'auc': 0.7159599661827087} \n",
            " 43/689 [>.............................] - ETA: 1:19 - loss: 0.6077 - tp: 432.0000 - fp: 175.0000 - tn: 475.0000 - fn: 294.0000 - accuracy: 0.6592 - precision: 0.7117 - recall: 0.5950 - auc: 0.7160\n",
            " For Batch Number 44 the model has a loss of {'loss': 0.6102753281593323, 'tp': 441.0, 'fp': 182.0, 'tn': 488.0, 'fn': 297.0, 'accuracy': 0.6598011255264282, 'precision': 0.7078651785850525, 'recall': 0.5975610017776489, 'auc': 0.7146422863006592} \n",
            " 44/689 [>.............................] - ETA: 1:18 - loss: 0.6103 - tp: 441.0000 - fp: 182.0000 - tn: 488.0000 - fn: 297.0000 - accuracy: 0.6598 - precision: 0.7079 - recall: 0.5976 - auc: 0.7146\n",
            " For Batch Number 45 the model has a loss of {'loss': 0.6133328676223755, 'tp': 450.0, 'fp': 188.0, 'tn': 498.0, 'fn': 304.0, 'accuracy': 0.6583333611488342, 'precision': 0.705329179763794, 'recall': 0.5968169569969177, 'auc': 0.7119290232658386} \n",
            " 45/689 [>.............................] - ETA: 1:17 - loss: 0.6133 - tp: 450.0000 - fp: 188.0000 - tn: 498.0000 - fn: 304.0000 - accuracy: 0.6583 - precision: 0.7053 - recall: 0.5968 - auc: 0.7119\n",
            " For Batch Number 46 the model has a loss of {'loss': 0.6113590002059937, 'tp': 460.0, 'fp': 189.0, 'tn': 512.0, 'fn': 311.0, 'accuracy': 0.6603260636329651, 'precision': 0.7087827324867249, 'recall': 0.5966277718544006, 'auc': 0.7140604853630066} \n",
            " 46/689 [=>............................] - ETA: 1:17 - loss: 0.6114 - tp: 460.0000 - fp: 189.0000 - tn: 512.0000 - fn: 311.0000 - accuracy: 0.6603 - precision: 0.7088 - recall: 0.5966 - auc: 0.7141\n",
            " For Batch Number 47 the model has a loss of {'loss': 0.6132100820541382, 'tp': 466.0, 'fp': 194.0, 'tn': 528.0, 'fn': 316.0, 'accuracy': 0.6609042286872864, 'precision': 0.7060605883598328, 'recall': 0.5959079265594482, 'auc': 0.7129589915275574} \n",
            " 47/689 [=>............................] - ETA: 1:16 - loss: 0.6132 - tp: 466.0000 - fp: 194.0000 - tn: 528.0000 - fn: 316.0000 - accuracy: 0.6609 - precision: 0.7061 - recall: 0.5959 - auc: 0.7130\n",
            " For Batch Number 48 the model has a loss of {'loss': 0.6137227416038513, 'tp': 473.0, 'fp': 196.0, 'tn': 543.0, 'fn': 324.0, 'accuracy': 0.6614583134651184, 'precision': 0.707025408744812, 'recall': 0.5934755206108093, 'auc': 0.7115698456764221} \n",
            " 48/689 [=>............................] - ETA: 1:16 - loss: 0.6137 - tp: 473.0000 - fp: 196.0000 - tn: 543.0000 - fn: 324.0000 - accuracy: 0.6615 - precision: 0.7070 - recall: 0.5935 - auc: 0.7116\n",
            " For Batch Number 49 the model has a loss of {'loss': 0.61503666639328, 'tp': 480.0, 'fp': 198.0, 'tn': 556.0, 'fn': 334.0, 'accuracy': 0.6607142686843872, 'precision': 0.7079645991325378, 'recall': 0.5896806120872498, 'auc': 0.710121750831604} \n",
            " 49/689 [=>............................] - ETA: 1:16 - loss: 0.6150 - tp: 480.0000 - fp: 198.0000 - tn: 556.0000 - fn: 334.0000 - accuracy: 0.6607 - precision: 0.7080 - recall: 0.5897 - auc: 0.7101\n",
            " For Batch Number 50 the model has a loss of {'loss': 0.6172953844070435, 'tp': 490.0, 'fp': 198.0, 'tn': 565.0, 'fn': 347.0, 'accuracy': 0.659375011920929, 'precision': 0.7122092843055725, 'recall': 0.5854241251945496, 'auc': 0.7074061036109924} \n",
            " 50/689 [=>............................] - ETA: 1:15 - loss: 0.6173 - tp: 490.0000 - fp: 198.0000 - tn: 565.0000 - fn: 347.0000 - accuracy: 0.6594 - precision: 0.7122 - recall: 0.5854 - auc: 0.7074\n",
            " For Batch Number 51 the model has a loss of {'loss': 0.6204444169998169, 'tp': 496.0, 'fp': 202.0, 'tn': 576.0, 'fn': 358.0, 'accuracy': 0.656862735748291, 'precision': 0.7106017470359802, 'recall': 0.5807962417602539, 'auc': 0.7030637860298157} \n",
            " 51/689 [=>............................] - ETA: 1:15 - loss: 0.6204 - tp: 496.0000 - fp: 202.0000 - tn: 576.0000 - fn: 358.0000 - accuracy: 0.6569 - precision: 0.7106 - recall: 0.5808 - auc: 0.7031\n",
            " For Batch Number 52 the model has a loss of {'loss': 0.6202808618545532, 'tp': 508.0, 'fp': 206.0, 'tn': 586.0, 'fn': 364.0, 'accuracy': 0.6574519276618958, 'precision': 0.7114846110343933, 'recall': 0.5825688242912292, 'auc': 0.7030641436576843} \n",
            " 52/689 [=>............................] - ETA: 1:15 - loss: 0.6203 - tp: 508.0000 - fp: 206.0000 - tn: 586.0000 - fn: 364.0000 - accuracy: 0.6575 - precision: 0.7115 - recall: 0.5826 - auc: 0.7031\n",
            " For Batch Number 53 the model has a loss of {'loss': 0.6210620999336243, 'tp': 523.0, 'fp': 220.0, 'tn': 589.0, 'fn': 364.0, 'accuracy': 0.6556603908538818, 'precision': 0.703903079032898, 'recall': 0.5896279811859131, 'auc': 0.7017579078674316} \n",
            " 53/689 [=>............................] - ETA: 1:14 - loss: 0.6211 - tp: 523.0000 - fp: 220.0000 - tn: 589.0000 - fn: 364.0000 - accuracy: 0.6557 - precision: 0.7039 - recall: 0.5896 - auc: 0.7018\n",
            " For Batch Number 54 the model has a loss of {'loss': 0.6224529147148132, 'tp': 539.0, 'fp': 235.0, 'tn': 589.0, 'fn': 365.0, 'accuracy': 0.6527777910232544, 'precision': 0.6963824033737183, 'recall': 0.596238911151886, 'auc': 0.700482964515686} \n",
            " 54/689 [=>............................] - ETA: 1:14 - loss: 0.6225 - tp: 539.0000 - fp: 235.0000 - tn: 589.0000 - fn: 365.0000 - accuracy: 0.6528 - precision: 0.6964 - recall: 0.5962 - auc: 0.7005\n",
            " For Batch Number 55 the model has a loss of {'loss': 0.6249744892120361, 'tp': 552.0, 'fp': 253.0, 'tn': 590.0, 'fn': 365.0, 'accuracy': 0.6488636136054993, 'precision': 0.6857143044471741, 'recall': 0.6019629240036011, 'auc': 0.6979713439941406} \n",
            " 55/689 [=>............................] - ETA: 1:14 - loss: 0.6250 - tp: 552.0000 - fp: 253.0000 - tn: 590.0000 - fn: 365.0000 - accuracy: 0.6489 - precision: 0.6857 - recall: 0.6020 - auc: 0.6980\n",
            " For Batch Number 56 the model has a loss of {'loss': 0.624599814414978, 'tp': 564.0, 'fp': 258.0, 'tn': 599.0, 'fn': 371.0, 'accuracy': 0.6489955186843872, 'precision': 0.6861313581466675, 'recall': 0.6032085418701172, 'auc': 0.6981984972953796} \n",
            " 56/689 [=>............................] - ETA: 1:14 - loss: 0.6246 - tp: 564.0000 - fp: 258.0000 - tn: 599.0000 - fn: 371.0000 - accuracy: 0.6490 - precision: 0.6861 - recall: 0.6032 - auc: 0.6982\n",
            " For Batch Number 57 the model has a loss of {'loss': 0.623975396156311, 'tp': 571.0, 'fp': 259.0, 'tn': 614.0, 'fn': 380.0, 'accuracy': 0.6496710777282715, 'precision': 0.6879518032073975, 'recall': 0.6004205942153931, 'auc': 0.6986448168754578} \n",
            " 57/689 [=>............................] - ETA: 1:13 - loss: 0.6240 - tp: 571.0000 - fp: 259.0000 - tn: 614.0000 - fn: 380.0000 - accuracy: 0.6497 - precision: 0.6880 - recall: 0.6004 - auc: 0.6986\n",
            " For Batch Number 58 the model has a loss of {'loss': 0.6228559017181396, 'tp': 578.0, 'fp': 260.0, 'tn': 632.0, 'fn': 386.0, 'accuracy': 0.6519396305084229, 'precision': 0.6897374987602234, 'recall': 0.5995850563049316, 'auc': 0.7001742720603943} \n",
            " 58/689 [=>............................] - ETA: 1:13 - loss: 0.6229 - tp: 578.0000 - fp: 260.0000 - tn: 632.0000 - fn: 386.0000 - accuracy: 0.6519 - precision: 0.6897 - recall: 0.5996 - auc: 0.7002\n",
            " For Batch Number 59 the model has a loss of {'loss': 0.6226904392242432, 'tp': 584.0, 'fp': 262.0, 'tn': 647.0, 'fn': 395.0, 'accuracy': 0.6520127058029175, 'precision': 0.6903073191642761, 'recall': 0.5965270400047302, 'auc': 0.7005662322044373} \n",
            " 59/689 [=>............................] - ETA: 1:12 - loss: 0.6227 - tp: 584.0000 - fp: 262.0000 - tn: 647.0000 - fn: 395.0000 - accuracy: 0.6520 - precision: 0.6903 - recall: 0.5965 - auc: 0.7006\n",
            " For Batch Number 60 the model has a loss of {'loss': 0.6218903660774231, 'tp': 591.0, 'fp': 263.0, 'tn': 664.0, 'fn': 402.0, 'accuracy': 0.6536458134651184, 'precision': 0.6920374631881714, 'recall': 0.5951661467552185, 'auc': 0.7018253207206726} \n",
            " 60/689 [=>............................] - ETA: 1:12 - loss: 0.6219 - tp: 591.0000 - fp: 263.0000 - tn: 664.0000 - fn: 402.0000 - accuracy: 0.6536 - precision: 0.6920 - recall: 0.5952 - auc: 0.7018\n",
            " For Batch Number 61 the model has a loss of {'loss': 0.6220632791519165, 'tp': 595.0, 'fp': 265.0, 'tn': 680.0, 'fn': 412.0, 'accuracy': 0.6531762480735779, 'precision': 0.6918604373931885, 'recall': 0.5908639430999756, 'auc': 0.7014260292053223} \n",
            " 61/689 [=>............................] - ETA: 1:12 - loss: 0.6221 - tp: 595.0000 - fp: 265.0000 - tn: 680.0000 - fn: 412.0000 - accuracy: 0.6532 - precision: 0.6919 - recall: 0.5909 - auc: 0.7014\n",
            " For Batch Number 62 the model has a loss of {'loss': 0.6225498914718628, 'tp': 604.0, 'fp': 265.0, 'tn': 693.0, 'fn': 422.0, 'accuracy': 0.6537298560142517, 'precision': 0.6950517892837524, 'recall': 0.5886939764022827, 'auc': 0.7010757327079773} \n",
            " 62/689 [=>............................] - ETA: 1:11 - loss: 0.6225 - tp: 604.0000 - fp: 265.0000 - tn: 693.0000 - fn: 422.0000 - accuracy: 0.6537 - precision: 0.6951 - recall: 0.5887 - auc: 0.7011\n",
            " For Batch Number 63 the model has a loss of {'loss': 0.6205064654350281, 'tp': 613.0, 'fp': 268.0, 'tn': 709.0, 'fn': 426.0, 'accuracy': 0.6557539701461792, 'precision': 0.695800244808197, 'recall': 0.5899903774261475, 'auc': 0.7036734223365784} \n",
            " 63/689 [=>............................] - ETA: 1:11 - loss: 0.6205 - tp: 613.0000 - fp: 268.0000 - tn: 709.0000 - fn: 426.0000 - accuracy: 0.6558 - precision: 0.6958 - recall: 0.5900 - auc: 0.7037\n",
            " For Batch Number 64 the model has a loss of {'loss': 0.6213545203208923, 'tp': 623.0, 'fp': 270.0, 'tn': 721.0, 'fn': 434.0, 'accuracy': 0.65625, 'precision': 0.6976484060287476, 'recall': 0.5894039869308472, 'auc': 0.7027127742767334} \n",
            " 64/689 [=>............................] - ETA: 1:11 - loss: 0.6214 - tp: 623.0000 - fp: 270.0000 - tn: 721.0000 - fn: 434.0000 - accuracy: 0.6562 - precision: 0.6976 - recall: 0.5894 - auc: 0.7027\n",
            " For Batch Number 65 the model has a loss of {'loss': 0.6205965876579285, 'tp': 637.0, 'fp': 274.0, 'tn': 730.0, 'fn': 439.0, 'accuracy': 0.6572115421295166, 'precision': 0.6992316246032715, 'recall': 0.5920074582099915, 'auc': 0.7031859159469604} \n",
            " 65/689 [=>............................] - ETA: 1:10 - loss: 0.6206 - tp: 637.0000 - fp: 274.0000 - tn: 730.0000 - fn: 439.0000 - accuracy: 0.6572 - precision: 0.6992 - recall: 0.5920 - auc: 0.7032\n",
            " For Batch Number 66 the model has a loss of {'loss': 0.6193918585777283, 'tp': 654.0, 'fp': 276.0, 'tn': 737.0, 'fn': 445.0, 'accuracy': 0.6586174368858337, 'precision': 0.7032257914543152, 'recall': 0.5950864553451538, 'auc': 0.7045451998710632} \n",
            " 66/689 [=>............................] - ETA: 1:10 - loss: 0.6194 - tp: 654.0000 - fp: 276.0000 - tn: 737.0000 - fn: 445.0000 - accuracy: 0.6586 - precision: 0.7032 - recall: 0.5951 - auc: 0.7045\n",
            " For Batch Number 67 the model has a loss of {'loss': 0.621431291103363, 'tp': 667.0, 'fp': 295.0, 'tn': 737.0, 'fn': 445.0, 'accuracy': 0.6548507213592529, 'precision': 0.6933472156524658, 'recall': 0.5998201370239258, 'auc': 0.7019913196563721} \n",
            " 67/689 [=>............................] - ETA: 1:10 - loss: 0.6214 - tp: 667.0000 - fp: 295.0000 - tn: 737.0000 - fn: 445.0000 - accuracy: 0.6549 - precision: 0.6933 - recall: 0.5998 - auc: 0.7020\n",
            " For Batch Number 68 the model has a loss of {'loss': 0.621213436126709, 'tp': 681.0, 'fp': 305.0, 'tn': 742.0, 'fn': 448.0, 'accuracy': 0.6539521813392639, 'precision': 0.6906693577766418, 'recall': 0.6031886339187622, 'auc': 0.7018390893936157} \n",
            " 68/689 [=>............................] - ETA: 1:10 - loss: 0.6212 - tp: 681.0000 - fp: 305.0000 - tn: 742.0000 - fn: 448.0000 - accuracy: 0.6540 - precision: 0.6907 - recall: 0.6032 - auc: 0.7018\n",
            " For Batch Number 69 the model has a loss of {'loss': 0.6208012700080872, 'tp': 690.0, 'fp': 309.0, 'tn': 751.0, 'fn': 458.0, 'accuracy': 0.6526268124580383, 'precision': 0.6906906962394714, 'recall': 0.6010453104972839, 'auc': 0.7015169858932495} \n",
            " 69/689 [==>...........................] - ETA: 1:10 - loss: 0.6208 - tp: 690.0000 - fp: 309.0000 - tn: 751.0000 - fn: 458.0000 - accuracy: 0.6526 - precision: 0.6907 - recall: 0.6010 - auc: 0.7015\n",
            " For Batch Number 70 the model has a loss of {'loss': 0.6194062232971191, 'tp': 700.0, 'fp': 310.0, 'tn': 764.0, 'fn': 466.0, 'accuracy': 0.6535714268684387, 'precision': 0.6930692791938782, 'recall': 0.6003430485725403, 'auc': 0.7028509974479675} \n",
            " 70/689 [==>...........................] - ETA: 1:10 - loss: 0.6194 - tp: 700.0000 - fp: 310.0000 - tn: 764.0000 - fn: 466.0000 - accuracy: 0.6536 - precision: 0.6931 - recall: 0.6003 - auc: 0.7029\n",
            " For Batch Number 71 the model has a loss of {'loss': 0.6201364994049072, 'tp': 707.0, 'fp': 314.0, 'tn': 779.0, 'fn': 472.0, 'accuracy': 0.654049277305603, 'precision': 0.6924583911895752, 'recall': 0.5996607542037964, 'auc': 0.7033776640892029} \n",
            " 71/689 [==>...........................] - ETA: 1:10 - loss: 0.6201 - tp: 707.0000 - fp: 314.0000 - tn: 779.0000 - fn: 472.0000 - accuracy: 0.6540 - precision: 0.6925 - recall: 0.5997 - auc: 0.7034\n",
            " For Batch Number 72 the model has a loss of {'loss': 0.6211526393890381, 'tp': 718.0, 'fp': 315.0, 'tn': 789.0, 'fn': 482.0, 'accuracy': 0.6540798544883728, 'precision': 0.6950629353523254, 'recall': 0.5983333587646484, 'auc': 0.7026785016059875} \n",
            " 72/689 [==>...........................] - ETA: 1:09 - loss: 0.6212 - tp: 718.0000 - fp: 315.0000 - tn: 789.0000 - fn: 482.0000 - accuracy: 0.6541 - precision: 0.6951 - recall: 0.5983 - auc: 0.7027\n",
            " For Batch Number 73 the model has a loss of {'loss': 0.6213778257369995, 'tp': 727.0, 'fp': 317.0, 'tn': 801.0, 'fn': 491.0, 'accuracy': 0.6541095972061157, 'precision': 0.696360170841217, 'recall': 0.5968801379203796, 'auc': 0.7027062773704529} \n",
            " 73/689 [==>...........................] - ETA: 1:09 - loss: 0.6214 - tp: 727.0000 - fp: 317.0000 - tn: 801.0000 - fn: 491.0000 - accuracy: 0.6541 - precision: 0.6964 - recall: 0.5969 - auc: 0.7027\n",
            " For Batch Number 74 the model has a loss of {'loss': 0.6237375140190125, 'tp': 732.0, 'fp': 323.0, 'tn': 814.0, 'fn': 499.0, 'accuracy': 0.6528716087341309, 'precision': 0.6938388347625732, 'recall': 0.5946385264396667, 'auc': 0.700506329536438} \n",
            " 74/689 [==>...........................] - ETA: 1:09 - loss: 0.6237 - tp: 732.0000 - fp: 323.0000 - tn: 814.0000 - fn: 499.0000 - accuracy: 0.6529 - precision: 0.6938 - recall: 0.5946 - auc: 0.7005\n",
            " For Batch Number 75 the model has a loss of {'loss': 0.6233863830566406, 'tp': 740.0, 'fp': 326.0, 'tn': 828.0, 'fn': 506.0, 'accuracy': 0.653333306312561, 'precision': 0.694183886051178, 'recall': 0.5939005017280579, 'auc': 0.7007780075073242} \n",
            " 75/689 [==>...........................] - ETA: 1:08 - loss: 0.6234 - tp: 740.0000 - fp: 326.0000 - tn: 828.0000 - fn: 506.0000 - accuracy: 0.6533 - precision: 0.6942 - recall: 0.5939 - auc: 0.7008\n",
            " For Batch Number 76 the model has a loss of {'loss': 0.622154712677002, 'tp': 751.0, 'fp': 326.0, 'tn': 840.0, 'fn': 515.0, 'accuracy': 0.6541940569877625, 'precision': 0.6973073482513428, 'recall': 0.5932069420814514, 'auc': 0.7018098831176758} \n",
            " 76/689 [==>...........................] - ETA: 1:08 - loss: 0.6222 - tp: 751.0000 - fp: 326.0000 - tn: 840.0000 - fn: 515.0000 - accuracy: 0.6542 - precision: 0.6973 - recall: 0.5932 - auc: 0.7018\n",
            " For Batch Number 77 the model has a loss of {'loss': 0.6218255758285522, 'tp': 762.0, 'fp': 329.0, 'tn': 852.0, 'fn': 521.0, 'accuracy': 0.6550324559211731, 'precision': 0.6984418034553528, 'recall': 0.5939204692840576, 'auc': 0.7024391889572144} \n",
            " 77/689 [==>...........................] - ETA: 1:08 - loss: 0.6218 - tp: 762.0000 - fp: 329.0000 - tn: 852.0000 - fn: 521.0000 - accuracy: 0.6550 - precision: 0.6984 - recall: 0.5939 - auc: 0.7024\n",
            " For Batch Number 78 the model has a loss of {'loss': 0.6223775148391724, 'tp': 771.0, 'fp': 336.0, 'tn': 865.0, 'fn': 524.0, 'accuracy': 0.6554487347602844, 'precision': 0.696476936340332, 'recall': 0.5953667759895325, 'auc': 0.7025278210639954} \n",
            " 78/689 [==>...........................] - ETA: 1:07 - loss: 0.6224 - tp: 771.0000 - fp: 336.0000 - tn: 865.0000 - fn: 524.0000 - accuracy: 0.6554 - precision: 0.6965 - recall: 0.5954 - auc: 0.7025\n",
            " For Batch Number 79 the model has a loss of {'loss': 0.6217558979988098, 'tp': 782.0, 'fp': 342.0, 'tn': 876.0, 'fn': 528.0, 'accuracy': 0.6558544039726257, 'precision': 0.6957295536994934, 'recall': 0.5969465374946594, 'auc': 0.7028281092643738} \n",
            " 79/689 [==>...........................] - ETA: 1:07 - loss: 0.6218 - tp: 782.0000 - fp: 342.0000 - tn: 876.0000 - fn: 528.0000 - accuracy: 0.6559 - precision: 0.6957 - recall: 0.5969 - auc: 0.7028\n",
            " For Batch Number 80 the model has a loss of {'loss': 0.6242599487304688, 'tp': 789.0, 'fp': 346.0, 'tn': 885.0, 'fn': 540.0, 'accuracy': 0.6539062261581421, 'precision': 0.6951541900634766, 'recall': 0.5936794877052307, 'auc': 0.7005025744438171} \n",
            " 80/689 [==>...........................] - ETA: 1:07 - loss: 0.6243 - tp: 789.0000 - fp: 346.0000 - tn: 885.0000 - fn: 540.0000 - accuracy: 0.6539 - precision: 0.6952 - recall: 0.5937 - auc: 0.7005\n",
            " For Batch Number 81 the model has a loss of {'loss': 0.6242127418518066, 'tp': 798.0, 'fp': 346.0, 'tn': 897.0, 'fn': 551.0, 'accuracy': 0.6539351940155029, 'precision': 0.6975524425506592, 'recall': 0.591549277305603, 'auc': 0.700031042098999} \n",
            " 81/689 [==>...........................] - ETA: 1:07 - loss: 0.6242 - tp: 798.0000 - fp: 346.0000 - tn: 897.0000 - fn: 551.0000 - accuracy: 0.6539 - precision: 0.6976 - recall: 0.5915 - auc: 0.7000\n",
            " For Batch Number 82 the model has a loss of {'loss': 0.6224650144577026, 'tp': 807.0, 'fp': 347.0, 'tn': 914.0, 'fn': 556.0, 'accuracy': 0.6558688879013062, 'precision': 0.6993067860603333, 'recall': 0.592076301574707, 'auc': 0.7020463943481445} \n",
            " 82/689 [==>...........................] - ETA: 1:07 - loss: 0.6225 - tp: 807.0000 - fp: 347.0000 - tn: 914.0000 - fn: 556.0000 - accuracy: 0.6559 - precision: 0.6993 - recall: 0.5921 - auc: 0.7020\n",
            " For Batch Number 83 the model has a loss of {'loss': 0.6222324967384338, 'tp': 816.0, 'fp': 349.0, 'tn': 926.0, 'fn': 565.0, 'accuracy': 0.6558734774589539, 'precision': 0.7004292011260986, 'recall': 0.5908761620521545, 'auc': 0.7018015384674072} \n",
            " 83/689 [==>...........................] - ETA: 1:06 - loss: 0.6222 - tp: 816.0000 - fp: 349.0000 - tn: 926.0000 - fn: 565.0000 - accuracy: 0.6559 - precision: 0.7004 - recall: 0.5909 - auc: 0.7018\n",
            " For Batch Number 84 the model has a loss of {'loss': 0.621886670589447, 'tp': 827.0, 'fp': 352.0, 'tn': 936.0, 'fn': 573.0, 'accuracy': 0.655877947807312, 'precision': 0.7014418840408325, 'recall': 0.5907142758369446, 'auc': 0.7023116946220398} \n",
            " 84/689 [==>...........................] - ETA: 1:06 - loss: 0.6219 - tp: 827.0000 - fp: 352.0000 - tn: 936.0000 - fn: 573.0000 - accuracy: 0.6559 - precision: 0.7014 - recall: 0.5907 - auc: 0.7023\n",
            " For Batch Number 85 the model has a loss of {'loss': 0.6223134994506836, 'tp': 835.0, 'fp': 359.0, 'tn': 948.0, 'fn': 578.0, 'accuracy': 0.6555147171020508, 'precision': 0.6993299722671509, 'recall': 0.5909412503242493, 'auc': 0.7014034390449524} \n",
            " 85/689 [==>...........................] - ETA: 1:06 - loss: 0.6223 - tp: 835.0000 - fp: 359.0000 - tn: 948.0000 - fn: 578.0000 - accuracy: 0.6555 - precision: 0.6993 - recall: 0.5909 - auc: 0.7014\n",
            " For Batch Number 86 the model has a loss of {'loss': 0.6249732375144958, 'tp': 841.0, 'fp': 368.0, 'tn': 957.0, 'fn': 586.0, 'accuracy': 0.6533430218696594, 'precision': 0.6956161856651306, 'recall': 0.5893482565879822, 'auc': 0.6991347670555115} \n",
            " 86/689 [==>...........................] - ETA: 1:06 - loss: 0.6250 - tp: 841.0000 - fp: 368.0000 - tn: 957.0000 - fn: 586.0000 - accuracy: 0.6533 - precision: 0.6956 - recall: 0.5893 - auc: 0.6991\n",
            " For Batch Number 87 the model has a loss of {'loss': 0.6246081590652466, 'tp': 852.0, 'fp': 372.0, 'tn': 969.0, 'fn': 591.0, 'accuracy': 0.6540948152542114, 'precision': 0.6960784196853638, 'recall': 0.590436577796936, 'auc': 0.6993891596794128} \n",
            " 87/689 [==>...........................] - ETA: 1:06 - loss: 0.6246 - tp: 852.0000 - fp: 372.0000 - tn: 969.0000 - fn: 591.0000 - accuracy: 0.6541 - precision: 0.6961 - recall: 0.5904 - auc: 0.6994\n",
            " For Batch Number 88 the model has a loss of {'loss': 0.6244634389877319, 'tp': 860.0, 'fp': 376.0, 'tn': 980.0, 'fn': 600.0, 'accuracy': 0.6534090638160706, 'precision': 0.6957928538322449, 'recall': 0.5890411138534546, 'auc': 0.6993421316146851} \n",
            " 88/689 [==>...........................] - ETA: 1:06 - loss: 0.6245 - tp: 860.0000 - fp: 376.0000 - tn: 980.0000 - fn: 600.0000 - accuracy: 0.6534 - precision: 0.6958 - recall: 0.5890 - auc: 0.6993\n",
            " For Batch Number 89 the model has a loss of {'loss': 0.6241713762283325, 'tp': 868.0, 'fp': 380.0, 'tn': 992.0, 'fn': 608.0, 'accuracy': 0.6530898809432983, 'precision': 0.6955128312110901, 'recall': 0.5880758762359619, 'auc': 0.6993582248687744} \n",
            " 89/689 [==>...........................] - ETA: 1:06 - loss: 0.6242 - tp: 868.0000 - fp: 380.0000 - tn: 992.0000 - fn: 608.0000 - accuracy: 0.6531 - precision: 0.6955 - recall: 0.5881 - auc: 0.6994\n",
            " For Batch Number 90 the model has a loss of {'loss': 0.625331461429596, 'tp': 872.0, 'fp': 388.0, 'tn': 1005.0, 'fn': 615.0, 'accuracy': 0.6517361402511597, 'precision': 0.6920635104179382, 'recall': 0.5864155888557434, 'auc': 0.697945237159729} \n",
            " 90/689 [==>...........................] - ETA: 1:05 - loss: 0.6253 - tp: 872.0000 - fp: 388.0000 - tn: 1005.0000 - fn: 615.0000 - accuracy: 0.6517 - precision: 0.6921 - recall: 0.5864 - auc: 0.6979\n",
            " For Batch Number 91 the model has a loss of {'loss': 0.6248930096626282, 'tp': 879.0, 'fp': 390.0, 'tn': 1021.0, 'fn': 622.0, 'accuracy': 0.6524725556373596, 'precision': 0.6926714181900024, 'recall': 0.5856096148490906, 'auc': 0.6983699798583984} \n",
            " 91/689 [==>...........................] - ETA: 1:05 - loss: 0.6249 - tp: 879.0000 - fp: 390.0000 - tn: 1021.0000 - fn: 622.0000 - accuracy: 0.6525 - precision: 0.6927 - recall: 0.5856 - auc: 0.6984\n",
            " For Batch Number 92 the model has a loss of {'loss': 0.624153733253479, 'tp': 885.0, 'fp': 391.0, 'tn': 1037.0, 'fn': 631.0, 'accuracy': 0.65285325050354, 'precision': 0.6935736536979675, 'recall': 0.5837730765342712, 'auc': 0.6992470026016235} \n",
            " 92/689 [===>..........................] - ETA: 1:05 - loss: 0.6242 - tp: 885.0000 - fp: 391.0000 - tn: 1037.0000 - fn: 631.0000 - accuracy: 0.6529 - precision: 0.6936 - recall: 0.5838 - auc: 0.6992\n",
            " For Batch Number 93 the model has a loss of {'loss': 0.6245172023773193, 'tp': 889.0, 'fp': 394.0, 'tn': 1051.0, 'fn': 642.0, 'accuracy': 0.6518816947937012, 'precision': 0.6929072737693787, 'recall': 0.5806662440299988, 'auc': 0.6984683275222778} \n",
            " 93/689 [===>..........................] - ETA: 1:05 - loss: 0.6245 - tp: 889.0000 - fp: 394.0000 - tn: 1051.0000 - fn: 642.0000 - accuracy: 0.6519 - precision: 0.6929 - recall: 0.5807 - auc: 0.6985\n",
            " For Batch Number 94 the model has a loss of {'loss': 0.6258591413497925, 'tp': 892.0, 'fp': 397.0, 'tn': 1062.0, 'fn': 657.0, 'accuracy': 0.6496010422706604, 'precision': 0.6920093297958374, 'recall': 0.5758553743362427, 'auc': 0.6964724063873291} \n",
            " 94/689 [===>..........................] - ETA: 1:05 - loss: 0.6259 - tp: 892.0000 - fp: 397.0000 - tn: 1062.0000 - fn: 657.0000 - accuracy: 0.6496 - precision: 0.6920 - recall: 0.5759 - auc: 0.6965\n",
            " For Batch Number 95 the model has a loss of {'loss': 0.6261093020439148, 'tp': 897.0, 'fp': 400.0, 'tn': 1076.0, 'fn': 667.0, 'accuracy': 0.6490131616592407, 'precision': 0.6915959715843201, 'recall': 0.5735294222831726, 'auc': 0.6955951452255249} \n",
            " 95/689 [===>..........................] - ETA: 1:05 - loss: 0.6261 - tp: 897.0000 - fp: 400.0000 - tn: 1076.0000 - fn: 667.0000 - accuracy: 0.6490 - precision: 0.6916 - recall: 0.5735 - auc: 0.6956\n",
            " For Batch Number 96 the model has a loss of {'loss': 0.626440167427063, 'tp': 904.0, 'fp': 403.0, 'tn': 1089.0, 'fn': 676.0, 'accuracy': 0.6487630009651184, 'precision': 0.6916602849960327, 'recall': 0.5721518993377686, 'auc': 0.6952007412910461} \n",
            " 96/689 [===>..........................] - ETA: 1:05 - loss: 0.6264 - tp: 904.0000 - fp: 403.0000 - tn: 1089.0000 - fn: 676.0000 - accuracy: 0.6488 - precision: 0.6917 - recall: 0.5722 - auc: 0.6952\n",
            " For Batch Number 97 the model has a loss of {'loss': 0.625573456287384, 'tp': 912.0, 'fp': 405.0, 'tn': 1106.0, 'fn': 681.0, 'accuracy': 0.6501288414001465, 'precision': 0.6924828886985779, 'recall': 0.5725046992301941, 'auc': 0.6963028907775879} \n",
            " 97/689 [===>..........................] - ETA: 1:05 - loss: 0.6256 - tp: 912.0000 - fp: 405.0000 - tn: 1106.0000 - fn: 681.0000 - accuracy: 0.6501 - precision: 0.6925 - recall: 0.5725 - auc: 0.6963\n",
            " For Batch Number 98 the model has a loss of {'loss': 0.6257272958755493, 'tp': 917.0, 'fp': 410.0, 'tn': 1121.0, 'fn': 688.0, 'accuracy': 0.6498724222183228, 'precision': 0.6910324096679688, 'recall': 0.5713395476341248, 'auc': 0.6964179873466492} \n",
            " 98/689 [===>..........................] - ETA: 1:05 - loss: 0.6257 - tp: 917.0000 - fp: 410.0000 - tn: 1121.0000 - fn: 688.0000 - accuracy: 0.6499 - precision: 0.6910 - recall: 0.5713 - auc: 0.6964\n",
            " For Batch Number 99 the model has a loss of {'loss': 0.6258597373962402, 'tp': 924.0, 'fp': 414.0, 'tn': 1135.0, 'fn': 695.0, 'accuracy': 0.649936854839325, 'precision': 0.6905829310417175, 'recall': 0.5707226395606995, 'auc': 0.6961530447006226} \n",
            " 99/689 [===>..........................] - ETA: 1:05 - loss: 0.6259 - tp: 924.0000 - fp: 414.0000 - tn: 1135.0000 - fn: 695.0000 - accuracy: 0.6499 - precision: 0.6906 - recall: 0.5707 - auc: 0.6962\n",
            " For Batch Number 100 the model has a loss of {'loss': 0.6258142590522766, 'tp': 932.0, 'fp': 416.0, 'tn': 1147.0, 'fn': 705.0, 'accuracy': 0.6496875286102295, 'precision': 0.6913946866989136, 'recall': 0.5693341493606567, 'auc': 0.6958829164505005} \n",
            "100/689 [===>..........................] - ETA: 1:05 - loss: 0.6258 - tp: 932.0000 - fp: 416.0000 - tn: 1147.0000 - fn: 705.0000 - accuracy: 0.6497 - precision: 0.6914 - recall: 0.5693 - auc: 0.6959\n",
            " For Batch Number 101 the model has a loss of {'loss': 0.6259303092956543, 'tp': 942.0, 'fp': 418.0, 'tn': 1160.0, 'fn': 712.0, 'accuracy': 0.6503713130950928, 'precision': 0.6926470398902893, 'recall': 0.5695284008979797, 'auc': 0.6960820555686951} \n",
            "101/689 [===>..........................] - ETA: 1:05 - loss: 0.6259 - tp: 942.0000 - fp: 418.0000 - tn: 1160.0000 - fn: 712.0000 - accuracy: 0.6504 - precision: 0.6926 - recall: 0.5695 - auc: 0.6961\n",
            " For Batch Number 102 the model has a loss of {'loss': 0.62767493724823, 'tp': 949.0, 'fp': 424.0, 'tn': 1170.0, 'fn': 721.0, 'accuracy': 0.6492034196853638, 'precision': 0.6911872029304504, 'recall': 0.5682634711265564, 'auc': 0.6949173808097839} \n",
            "102/689 [===>..........................] - ETA: 1:05 - loss: 0.6277 - tp: 949.0000 - fp: 424.0000 - tn: 1170.0000 - fn: 721.0000 - accuracy: 0.6492 - precision: 0.6912 - recall: 0.5683 - auc: 0.6949\n",
            " For Batch Number 103 the model has a loss of {'loss': 0.6271015405654907, 'tp': 958.0, 'fp': 427.0, 'tn': 1185.0, 'fn': 726.0, 'accuracy': 0.6501820683479309, 'precision': 0.6916967630386353, 'recall': 0.5688835978507996, 'auc': 0.6952553987503052} \n",
            "103/689 [===>..........................] - ETA: 1:04 - loss: 0.6271 - tp: 958.0000 - fp: 427.0000 - tn: 1185.0000 - fn: 726.0000 - accuracy: 0.6502 - precision: 0.6917 - recall: 0.5689 - auc: 0.6953\n",
            " For Batch Number 104 the model has a loss of {'loss': 0.6289101839065552, 'tp': 961.0, 'fp': 439.0, 'tn': 1197.0, 'fn': 731.0, 'accuracy': 0.6484375, 'precision': 0.6864285469055176, 'recall': 0.567966878414154, 'auc': 0.6933233141899109} \n",
            "104/689 [===>..........................] - ETA: 1:04 - loss: 0.6289 - tp: 961.0000 - fp: 439.0000 - tn: 1197.0000 - fn: 731.0000 - accuracy: 0.6484 - precision: 0.6864 - recall: 0.5680 - auc: 0.6933\n",
            " For Batch Number 105 the model has a loss of {'loss': 0.6290602087974548, 'tp': 969.0, 'fp': 443.0, 'tn': 1209.0, 'fn': 739.0, 'accuracy': 0.6482142806053162, 'precision': 0.6862606406211853, 'recall': 0.5673301815986633, 'auc': 0.6930910348892212} \n",
            "105/689 [===>..........................] - ETA: 1:04 - loss: 0.6291 - tp: 969.0000 - fp: 443.0000 - tn: 1209.0000 - fn: 739.0000 - accuracy: 0.6482 - precision: 0.6863 - recall: 0.5673 - auc: 0.6931\n",
            " For Batch Number 106 the model has a loss of {'loss': 0.6298468112945557, 'tp': 975.0, 'fp': 445.0, 'tn': 1218.0, 'fn': 754.0, 'accuracy': 0.6465212106704712, 'precision': 0.6866196990013123, 'recall': 0.5639097690582275, 'auc': 0.692040205001831} \n",
            "106/689 [===>..........................] - ETA: 1:04 - loss: 0.6298 - tp: 975.0000 - fp: 445.0000 - tn: 1218.0000 - fn: 754.0000 - accuracy: 0.6465 - precision: 0.6866 - recall: 0.5639 - auc: 0.6920\n",
            " For Batch Number 107 the model has a loss of {'loss': 0.6299760341644287, 'tp': 980.0, 'fp': 449.0, 'tn': 1231.0, 'fn': 764.0, 'accuracy': 0.6457359790802002, 'precision': 0.6857942342758179, 'recall': 0.5619266033172607, 'auc': 0.6916207671165466} \n",
            "107/689 [===>..........................] - ETA: 1:04 - loss: 0.6300 - tp: 980.0000 - fp: 449.0000 - tn: 1231.0000 - fn: 764.0000 - accuracy: 0.6457 - precision: 0.6858 - recall: 0.5619 - auc: 0.6916\n",
            " For Batch Number 108 the model has a loss of {'loss': 0.6293190717697144, 'tp': 986.0, 'fp': 452.0, 'tn': 1247.0, 'fn': 771.0, 'accuracy': 0.6461226940155029, 'precision': 0.6856745481491089, 'recall': 0.5611838102340698, 'auc': 0.6922561526298523} \n",
            "108/689 [===>..........................] - ETA: 1:04 - loss: 0.6293 - tp: 986.0000 - fp: 452.0000 - tn: 1247.0000 - fn: 771.0000 - accuracy: 0.6461 - precision: 0.6857 - recall: 0.5612 - auc: 0.6923\n",
            " For Batch Number 109 the model has a loss of {'loss': 0.6294217109680176, 'tp': 991.0, 'fp': 454.0, 'tn': 1261.0, 'fn': 782.0, 'accuracy': 0.6456422209739685, 'precision': 0.6858131289482117, 'recall': 0.5589396357536316, 'auc': 0.6919412016868591} \n",
            "109/689 [===>..........................] - ETA: 1:04 - loss: 0.6294 - tp: 991.0000 - fp: 454.0000 - tn: 1261.0000 - fn: 782.0000 - accuracy: 0.6456 - precision: 0.6858 - recall: 0.5589 - auc: 0.6919\n",
            " For Batch Number 110 the model has a loss of {'loss': 0.6296878457069397, 'tp': 996.0, 'fp': 457.0, 'tn': 1273.0, 'fn': 794.0, 'accuracy': 0.6446022987365723, 'precision': 0.6854783296585083, 'recall': 0.5564245581626892, 'auc': 0.6914305090904236} \n",
            "110/689 [===>..........................] - ETA: 1:03 - loss: 0.6297 - tp: 996.0000 - fp: 457.0000 - tn: 1273.0000 - fn: 794.0000 - accuracy: 0.6446 - precision: 0.6855 - recall: 0.5564 - auc: 0.6914\n",
            " For Batch Number 111 the model has a loss of {'loss': 0.6296697854995728, 'tp': 1002.0, 'fp': 460.0, 'tn': 1288.0, 'fn': 802.0, 'accuracy': 0.644707202911377, 'precision': 0.6853625178337097, 'recall': 0.5554323792457581, 'auc': 0.691074013710022} \n",
            "111/689 [===>..........................] - ETA: 1:03 - loss: 0.6297 - tp: 1002.0000 - fp: 460.0000 - tn: 1288.0000 - fn: 802.0000 - accuracy: 0.6447 - precision: 0.6854 - recall: 0.5554 - auc: 0.6911\n",
            " For Batch Number 112 the model has a loss of {'loss': 0.6298041343688965, 'tp': 1007.0, 'fp': 463.0, 'tn': 1305.0, 'fn': 809.0, 'accuracy': 0.6450892686843872, 'precision': 0.6850340366363525, 'recall': 0.5545154213905334, 'auc': 0.6906322240829468} \n",
            "112/689 [===>..........................] - ETA: 1:03 - loss: 0.6298 - tp: 1007.0000 - fp: 463.0000 - tn: 1305.0000 - fn: 809.0000 - accuracy: 0.6451 - precision: 0.6850 - recall: 0.5545 - auc: 0.6906\n",
            " For Batch Number 113 the model has a loss of {'loss': 0.6298996806144714, 'tp': 1016.0, 'fp': 466.0, 'tn': 1316.0, 'fn': 818.0, 'accuracy': 0.644911527633667, 'precision': 0.6855600476264954, 'recall': 0.5539803504943848, 'auc': 0.6904598474502563} \n",
            "113/689 [===>..........................] - ETA: 1:03 - loss: 0.6299 - tp: 1016.0000 - fp: 466.0000 - tn: 1316.0000 - fn: 818.0000 - accuracy: 0.6449 - precision: 0.6856 - recall: 0.5540 - auc: 0.6905\n",
            " For Batch Number 114 the model has a loss of {'loss': 0.6297492384910583, 'tp': 1026.0, 'fp': 467.0, 'tn': 1328.0, 'fn': 827.0, 'accuracy': 0.6452850699424744, 'precision': 0.6872069835662842, 'recall': 0.5536966919898987, 'auc': 0.690731406211853} \n",
            "114/689 [===>..........................] - ETA: 1:03 - loss: 0.6297 - tp: 1026.0000 - fp: 467.0000 - tn: 1328.0000 - fn: 827.0000 - accuracy: 0.6453 - precision: 0.6872 - recall: 0.5537 - auc: 0.6907\n",
            " For Batch Number 115 the model has a loss of {'loss': 0.6292608976364136, 'tp': 1037.0, 'fp': 468.0, 'tn': 1340.0, 'fn': 835.0, 'accuracy': 0.645923912525177, 'precision': 0.6890365481376648, 'recall': 0.5539529919624329, 'auc': 0.6915658712387085} \n",
            "115/689 [====>.........................] - ETA: 1:03 - loss: 0.6293 - tp: 1037.0000 - fp: 468.0000 - tn: 1340.0000 - fn: 835.0000 - accuracy: 0.6459 - precision: 0.6890 - recall: 0.5540 - auc: 0.6916\n",
            " For Batch Number 116 the model has a loss of {'loss': 0.6293092370033264, 'tp': 1046.0, 'fp': 475.0, 'tn': 1351.0, 'fn': 840.0, 'accuracy': 0.6457435488700867, 'precision': 0.6877054572105408, 'recall': 0.554612934589386, 'auc': 0.6910297274589539} \n",
            "116/689 [====>.........................] - ETA: 1:03 - loss: 0.6293 - tp: 1046.0000 - fp: 475.0000 - tn: 1351.0000 - fn: 840.0000 - accuracy: 0.6457 - precision: 0.6877 - recall: 0.5546 - auc: 0.6910\n",
            " For Batch Number 117 the model has a loss of {'loss': 0.6292054653167725, 'tp': 1058.0, 'fp': 482.0, 'tn': 1359.0, 'fn': 845.0, 'accuracy': 0.6455662250518799, 'precision': 0.6870129704475403, 'recall': 0.5559642910957336, 'auc': 0.6910415291786194} \n",
            "117/689 [====>.........................] - ETA: 1:03 - loss: 0.6292 - tp: 1058.0000 - fp: 482.0000 - tn: 1359.0000 - fn: 845.0000 - accuracy: 0.6456 - precision: 0.6870 - recall: 0.5560 - auc: 0.6910\n",
            " For Batch Number 118 the model has a loss of {'loss': 0.6288151144981384, 'tp': 1069.0, 'fp': 487.0, 'tn': 1372.0, 'fn': 848.0, 'accuracy': 0.6464512944221497, 'precision': 0.6870179772377014, 'recall': 0.5576421618461609, 'auc': 0.6912747025489807} \n",
            "118/689 [====>.........................] - ETA: 1:02 - loss: 0.6288 - tp: 1069.0000 - fp: 487.0000 - tn: 1372.0000 - fn: 848.0000 - accuracy: 0.6465 - precision: 0.6870 - recall: 0.5576 - auc: 0.6913\n",
            " For Batch Number 119 the model has a loss of {'loss': 0.6290547251701355, 'tp': 1080.0, 'fp': 495.0, 'tn': 1383.0, 'fn': 850.0, 'accuracy': 0.6467962265014648, 'precision': 0.6857143044471741, 'recall': 0.5595855116844177, 'auc': 0.6911463737487793} \n",
            "119/689 [====>.........................] - ETA: 1:02 - loss: 0.6291 - tp: 1080.0000 - fp: 495.0000 - tn: 1383.0000 - fn: 850.0000 - accuracy: 0.6468 - precision: 0.6857 - recall: 0.5596 - auc: 0.6911\n",
            " For Batch Number 120 the model has a loss of {'loss': 0.6297118663787842, 'tp': 1088.0, 'fp': 502.0, 'tn': 1395.0, 'fn': 855.0, 'accuracy': 0.6466146111488342, 'precision': 0.6842767000198364, 'recall': 0.559958815574646, 'auc': 0.6902692914009094} \n",
            "120/689 [====>.........................] - ETA: 1:02 - loss: 0.6297 - tp: 1088.0000 - fp: 502.0000 - tn: 1395.0000 - fn: 855.0000 - accuracy: 0.6466 - precision: 0.6843 - recall: 0.5600 - auc: 0.6903\n",
            " For Batch Number 121 the model has a loss of {'loss': 0.6298830509185791, 'tp': 1094.0, 'fp': 507.0, 'tn': 1408.0, 'fn': 863.0, 'accuracy': 0.6461777091026306, 'precision': 0.6833229064941406, 'recall': 0.5590189099311829, 'auc': 0.6899943351745605} \n",
            "121/689 [====>.........................] - ETA: 1:02 - loss: 0.6299 - tp: 1094.0000 - fp: 507.0000 - tn: 1408.0000 - fn: 863.0000 - accuracy: 0.6462 - precision: 0.6833 - recall: 0.5590 - auc: 0.6900\n",
            " For Batch Number 122 the model has a loss of {'loss': 0.6301469206809998, 'tp': 1105.0, 'fp': 510.0, 'tn': 1418.0, 'fn': 871.0, 'accuracy': 0.6462602615356445, 'precision': 0.6842105388641357, 'recall': 0.5592105388641357, 'auc': 0.6899381875991821} \n",
            "122/689 [====>.........................] - ETA: 1:02 - loss: 0.6301 - tp: 1105.0000 - fp: 510.0000 - tn: 1418.0000 - fn: 871.0000 - accuracy: 0.6463 - precision: 0.6842 - recall: 0.5592 - auc: 0.6899\n",
            " For Batch Number 123 the model has a loss of {'loss': 0.631471574306488, 'tp': 1110.0, 'fp': 515.0, 'tn': 1432.0, 'fn': 879.0, 'accuracy': 0.6458333134651184, 'precision': 0.6830769181251526, 'recall': 0.5580694079399109, 'auc': 0.6883430480957031} \n",
            "123/689 [====>.........................] - ETA: 1:02 - loss: 0.6315 - tp: 1110.0000 - fp: 515.0000 - tn: 1432.0000 - fn: 879.0000 - accuracy: 0.6458 - precision: 0.6831 - recall: 0.5581 - auc: 0.6883\n",
            " For Batch Number 124 the model has a loss of {'loss': 0.6313748955726624, 'tp': 1116.0, 'fp': 518.0, 'tn': 1451.0, 'fn': 883.0, 'accuracy': 0.6469253897666931, 'precision': 0.6829865574836731, 'recall': 0.5582791566848755, 'auc': 0.6890354752540588} \n",
            "124/689 [====>.........................] - ETA: 1:02 - loss: 0.6314 - tp: 1116.0000 - fp: 518.0000 - tn: 1451.0000 - fn: 883.0000 - accuracy: 0.6469 - precision: 0.6830 - recall: 0.5583 - auc: 0.6890\n",
            " For Batch Number 125 the model has a loss of {'loss': 0.63172847032547, 'tp': 1121.0, 'fp': 522.0, 'tn': 1465.0, 'fn': 892.0, 'accuracy': 0.6464999914169312, 'precision': 0.6822884678840637, 'recall': 0.5568802952766418, 'auc': 0.6887129545211792} \n",
            "125/689 [====>.........................] - ETA: 1:02 - loss: 0.6317 - tp: 1121.0000 - fp: 522.0000 - tn: 1465.0000 - fn: 892.0000 - accuracy: 0.6465 - precision: 0.6823 - recall: 0.5569 - auc: 0.6887\n",
            " For Batch Number 126 the model has a loss of {'loss': 0.632101833820343, 'tp': 1126.0, 'fp': 523.0, 'tn': 1481.0, 'fn': 902.0, 'accuracy': 0.6465773582458496, 'precision': 0.6828380823135376, 'recall': 0.5552268028259277, 'auc': 0.6879826188087463} \n",
            "126/689 [====>.........................] - ETA: 1:01 - loss: 0.6321 - tp: 1126.0000 - fp: 523.0000 - tn: 1481.0000 - fn: 902.0000 - accuracy: 0.6466 - precision: 0.6828 - recall: 0.5552 - auc: 0.6880\n",
            " For Batch Number 127 the model has a loss of {'loss': 0.6327821016311646, 'tp': 1132.0, 'fp': 527.0, 'tn': 1492.0, 'fn': 913.0, 'accuracy': 0.6456692814826965, 'precision': 0.6823387742042542, 'recall': 0.5535452365875244, 'auc': 0.686678946018219} \n",
            "127/689 [====>.........................] - ETA: 1:01 - loss: 0.6328 - tp: 1132.0000 - fp: 527.0000 - tn: 1492.0000 - fn: 913.0000 - accuracy: 0.6457 - precision: 0.6823 - recall: 0.5535 - auc: 0.6867\n",
            " For Batch Number 128 the model has a loss of {'loss': 0.6331092715263367, 'tp': 1138.0, 'fp': 531.0, 'tn': 1504.0, 'fn': 923.0, 'accuracy': 0.64501953125, 'precision': 0.6818454265594482, 'recall': 0.5521591305732727, 'auc': 0.6858815550804138} \n",
            "128/689 [====>.........................] - ETA: 1:01 - loss: 0.6331 - tp: 1138.0000 - fp: 531.0000 - tn: 1504.0000 - fn: 923.0000 - accuracy: 0.6450 - precision: 0.6818 - recall: 0.5522 - auc: 0.6859\n",
            " For Batch Number 129 the model has a loss of {'loss': 0.6333406567573547, 'tp': 1146.0, 'fp': 533.0, 'tn': 1513.0, 'fn': 936.0, 'accuracy': 0.6441376209259033, 'precision': 0.6825491189956665, 'recall': 0.5504322648048401, 'auc': 0.685539722442627} \n",
            "129/689 [====>.........................] - ETA: 1:01 - loss: 0.6333 - tp: 1146.0000 - fp: 533.0000 - tn: 1513.0000 - fn: 936.0000 - accuracy: 0.6441 - precision: 0.6825 - recall: 0.5504 - auc: 0.6855\n",
            " For Batch Number 130 the model has a loss of {'loss': 0.6339694261550903, 'tp': 1151.0, 'fp': 536.0, 'tn': 1528.0, 'fn': 945.0, 'accuracy': 0.6439903974533081, 'precision': 0.6822762489318848, 'recall': 0.5491412281990051, 'auc': 0.6849145293235779} \n",
            "130/689 [====>.........................] - ETA: 1:01 - loss: 0.6340 - tp: 1151.0000 - fp: 536.0000 - tn: 1528.0000 - fn: 945.0000 - accuracy: 0.6440 - precision: 0.6823 - recall: 0.5491 - auc: 0.6849\n",
            " For Batch Number 131 the model has a loss of {'loss': 0.6345015168190002, 'tp': 1159.0, 'fp': 549.0, 'tn': 1534.0, 'fn': 950.0, 'accuracy': 0.6424140930175781, 'precision': 0.6785714030265808, 'recall': 0.5495495200157166, 'auc': 0.6839960217475891} \n",
            "131/689 [====>.........................] - ETA: 1:01 - loss: 0.6345 - tp: 1159.0000 - fp: 549.0000 - tn: 1534.0000 - fn: 950.0000 - accuracy: 0.6424 - precision: 0.6786 - recall: 0.5495 - auc: 0.6840\n",
            " For Batch Number 132 the model has a loss of {'loss': 0.6345203518867493, 'tp': 1167.0, 'fp': 557.0, 'tn': 1544.0, 'fn': 956.0, 'accuracy': 0.6418086886405945, 'precision': 0.6769141554832458, 'recall': 0.5496938228607178, 'auc': 0.6835324764251709} \n",
            "132/689 [====>.........................] - ETA: 1:01 - loss: 0.6345 - tp: 1167.0000 - fp: 557.0000 - tn: 1544.0000 - fn: 956.0000 - accuracy: 0.6418 - precision: 0.6769 - recall: 0.5497 - auc: 0.6835\n",
            " For Batch Number 133 the model has a loss of {'loss': 0.6345238089561462, 'tp': 1172.0, 'fp': 559.0, 'tn': 1559.0, 'fn': 966.0, 'accuracy': 0.6416823267936707, 'precision': 0.6770652532577515, 'recall': 0.5481758713722229, 'auc': 0.6831546425819397} \n",
            "133/689 [====>.........................] - ETA: 1:00 - loss: 0.6345 - tp: 1172.0000 - fp: 559.0000 - tn: 1559.0000 - fn: 966.0000 - accuracy: 0.6417 - precision: 0.6771 - recall: 0.5482 - auc: 0.6832\n",
            " For Batch Number 134 the model has a loss of {'loss': 0.6350535750389099, 'tp': 1177.0, 'fp': 561.0, 'tn': 1572.0, 'fn': 978.0, 'accuracy': 0.6410914063453674, 'precision': 0.6772152185440063, 'recall': 0.5461716651916504, 'auc': 0.6827281713485718} \n",
            "134/689 [====>.........................] - ETA: 1:00 - loss: 0.6351 - tp: 1177.0000 - fp: 561.0000 - tn: 1572.0000 - fn: 978.0000 - accuracy: 0.6411 - precision: 0.6772 - recall: 0.5462 - auc: 0.6827\n",
            " For Batch Number 135 the model has a loss of {'loss': 0.634948194026947, 'tp': 1184.0, 'fp': 564.0, 'tn': 1586.0, 'fn': 986.0, 'accuracy': 0.6412037014961243, 'precision': 0.6773455142974854, 'recall': 0.5456221103668213, 'auc': 0.6829286217689514} \n",
            "135/689 [====>.........................] - ETA: 1:00 - loss: 0.6349 - tp: 1184.0000 - fp: 564.0000 - tn: 1586.0000 - fn: 986.0000 - accuracy: 0.6412 - precision: 0.6773 - recall: 0.5456 - auc: 0.6829\n",
            " For Batch Number 136 the model has a loss of {'loss': 0.6348950862884521, 'tp': 1191.0, 'fp': 564.0, 'tn': 1601.0, 'fn': 996.0, 'accuracy': 0.6415441036224365, 'precision': 0.6786324977874756, 'recall': 0.5445815920829773, 'auc': 0.6827926635742188} \n",
            "136/689 [====>.........................] - ETA: 1:00 - loss: 0.6349 - tp: 1191.0000 - fp: 564.0000 - tn: 1601.0000 - fn: 996.0000 - accuracy: 0.6415 - precision: 0.6786 - recall: 0.5446 - auc: 0.6828\n",
            " For Batch Number 137 the model has a loss of {'loss': 0.635030210018158, 'tp': 1200.0, 'fp': 565.0, 'tn': 1611.0, 'fn': 1008.0, 'accuracy': 0.6411952376365662, 'precision': 0.6798866987228394, 'recall': 0.54347825050354, 'auc': 0.6827809810638428} \n",
            "137/689 [====>.........................] - ETA: 1:00 - loss: 0.6350 - tp: 1200.0000 - fp: 565.0000 - tn: 1611.0000 - fn: 1008.0000 - accuracy: 0.6412 - precision: 0.6799 - recall: 0.5435 - auc: 0.6828\n",
            " For Batch Number 138 the model has a loss of {'loss': 0.635145902633667, 'tp': 1208.0, 'fp': 570.0, 'tn': 1621.0, 'fn': 1017.0, 'accuracy': 0.640625, 'precision': 0.6794150471687317, 'recall': 0.5429213643074036, 'auc': 0.6824689507484436} \n",
            "138/689 [=====>........................] - ETA: 59s - loss: 0.6351 - tp: 1208.0000 - fp: 570.0000 - tn: 1621.0000 - fn: 1017.0000 - accuracy: 0.6406 - precision: 0.6794 - recall: 0.5429 - auc: 0.6825 \n",
            " For Batch Number 139 the model has a loss of {'loss': 0.6352027654647827, 'tp': 1218.0, 'fp': 579.0, 'tn': 1632.0, 'fn': 1019.0, 'accuracy': 0.6407374143600464, 'precision': 0.6777963042259216, 'recall': 0.5444791913032532, 'auc': 0.682487964630127} \n",
            "139/689 [=====>........................] - ETA: 59s - loss: 0.6352 - tp: 1218.0000 - fp: 579.0000 - tn: 1632.0000 - fn: 1019.0000 - accuracy: 0.6407 - precision: 0.6778 - recall: 0.5445 - auc: 0.6825\n",
            " For Batch Number 140 the model has a loss of {'loss': 0.6346277594566345, 'tp': 1234.0, 'fp': 584.0, 'tn': 1639.0, 'fn': 1023.0, 'accuracy': 0.6412946581840515, 'precision': 0.6787678599357605, 'recall': 0.5467434525489807, 'auc': 0.6834810972213745} \n",
            "140/689 [=====>........................] - ETA: 59s - loss: 0.6346 - tp: 1234.0000 - fp: 584.0000 - tn: 1639.0000 - fn: 1023.0000 - accuracy: 0.6413 - precision: 0.6788 - recall: 0.5467 - auc: 0.6835\n",
            " For Batch Number 141 the model has a loss of {'loss': 0.6343907117843628, 'tp': 1247.0, 'fp': 588.0, 'tn': 1649.0, 'fn': 1028.0, 'accuracy': 0.6418439745903015, 'precision': 0.6795640587806702, 'recall': 0.5481318831443787, 'auc': 0.6839565634727478} \n",
            "141/689 [=====>........................] - ETA: 59s - loss: 0.6344 - tp: 1247.0000 - fp: 588.0000 - tn: 1649.0000 - fn: 1028.0000 - accuracy: 0.6418 - precision: 0.6796 - recall: 0.5481 - auc: 0.6840\n",
            " For Batch Number 142 the model has a loss of {'loss': 0.6353287696838379, 'tp': 1257.0, 'fp': 597.0, 'tn': 1658.0, 'fn': 1032.0, 'accuracy': 0.6415053009986877, 'precision': 0.6779935359954834, 'recall': 0.5491480827331543, 'auc': 0.6835801005363464} \n",
            "142/689 [=====>........................] - ETA: 59s - loss: 0.6353 - tp: 1257.0000 - fp: 597.0000 - tn: 1658.0000 - fn: 1032.0000 - accuracy: 0.6415 - precision: 0.6780 - recall: 0.5491 - auc: 0.6836\n",
            " For Batch Number 143 the model has a loss of {'loss': 0.6356782913208008, 'tp': 1268.0, 'fp': 608.0, 'tn': 1666.0, 'fn': 1034.0, 'accuracy': 0.6411713361740112, 'precision': 0.6759061813354492, 'recall': 0.5508253574371338, 'auc': 0.6835041046142578} \n",
            "143/689 [=====>........................] - ETA: 59s - loss: 0.6357 - tp: 1268.0000 - fp: 608.0000 - tn: 1666.0000 - fn: 1034.0000 - accuracy: 0.6412 - precision: 0.6759 - recall: 0.5508 - auc: 0.6835\n",
            " For Batch Number 144 the model has a loss of {'loss': 0.6357422471046448, 'tp': 1280.0, 'fp': 613.0, 'tn': 1675.0, 'fn': 1040.0, 'accuracy': 0.6412760615348816, 'precision': 0.6761753559112549, 'recall': 0.5517241358757019, 'auc': 0.6833857297897339} \n",
            "144/689 [=====>........................] - ETA: 58s - loss: 0.6357 - tp: 1280.0000 - fp: 613.0000 - tn: 1675.0000 - fn: 1040.0000 - accuracy: 0.6413 - precision: 0.6762 - recall: 0.5517 - auc: 0.6834\n",
            " For Batch Number 145 the model has a loss of {'loss': 0.6356332302093506, 'tp': 1288.0, 'fp': 616.0, 'tn': 1687.0, 'fn': 1049.0, 'accuracy': 0.6411637663841248, 'precision': 0.6764705777168274, 'recall': 0.551133930683136, 'auc': 0.6836737394332886} \n",
            "145/689 [=====>........................] - ETA: 58s - loss: 0.6356 - tp: 1288.0000 - fp: 616.0000 - tn: 1687.0000 - fn: 1049.0000 - accuracy: 0.6412 - precision: 0.6765 - recall: 0.5511 - auc: 0.6837\n",
            " For Batch Number 146 the model has a loss of {'loss': 0.6347299814224243, 'tp': 1298.0, 'fp': 619.0, 'tn': 1700.0, 'fn': 1055.0, 'accuracy': 0.6416952013969421, 'precision': 0.6770996451377869, 'recall': 0.5516362190246582, 'auc': 0.6850571632385254} \n",
            "146/689 [=====>........................] - ETA: 58s - loss: 0.6347 - tp: 1298.0000 - fp: 619.0000 - tn: 1700.0000 - fn: 1055.0000 - accuracy: 0.6417 - precision: 0.6771 - recall: 0.5516 - auc: 0.6851\n",
            " For Batch Number 147 the model has a loss of {'loss': 0.6359596252441406, 'tp': 1305.0, 'fp': 626.0, 'tn': 1709.0, 'fn': 1064.0, 'accuracy': 0.6407312750816345, 'precision': 0.6758156418800354, 'recall': 0.5508653521537781, 'auc': 0.6837739944458008} \n",
            "147/689 [=====>........................] - ETA: 58s - loss: 0.6360 - tp: 1305.0000 - fp: 626.0000 - tn: 1709.0000 - fn: 1064.0000 - accuracy: 0.6407 - precision: 0.6758 - recall: 0.5509 - auc: 0.6838\n",
            " For Batch Number 148 the model has a loss of {'loss': 0.6371852159500122, 'tp': 1310.0, 'fp': 631.0, 'tn': 1720.0, 'fn': 1075.0, 'accuracy': 0.6397804021835327, 'precision': 0.6749098300933838, 'recall': 0.5492662191390991, 'auc': 0.6828793287277222} \n",
            "148/689 [=====>........................] - ETA: 58s - loss: 0.6372 - tp: 1310.0000 - fp: 631.0000 - tn: 1720.0000 - fn: 1075.0000 - accuracy: 0.6398 - precision: 0.6749 - recall: 0.5493 - auc: 0.6829\n",
            " For Batch Number 149 the model has a loss of {'loss': 0.6377496719360352, 'tp': 1319.0, 'fp': 633.0, 'tn': 1730.0, 'fn': 1086.0, 'accuracy': 0.6394714713096619, 'precision': 0.6757172346115112, 'recall': 0.5484407544136047, 'auc': 0.6822561025619507} \n",
            "149/689 [=====>........................] - ETA: 58s - loss: 0.6377 - tp: 1319.0000 - fp: 633.0000 - tn: 1730.0000 - fn: 1086.0000 - accuracy: 0.6395 - precision: 0.6757 - recall: 0.5484 - auc: 0.6823\n",
            " For Batch Number 150 the model has a loss of {'loss': 0.6374202966690063, 'tp': 1330.0, 'fp': 635.0, 'tn': 1743.0, 'fn': 1092.0, 'accuracy': 0.6402083039283752, 'precision': 0.6768447756767273, 'recall': 0.5491329431533813, 'auc': 0.6826624870300293} \n",
            "150/689 [=====>........................] - ETA: 57s - loss: 0.6374 - tp: 1330.0000 - fp: 635.0000 - tn: 1743.0000 - fn: 1092.0000 - accuracy: 0.6402 - precision: 0.6768 - recall: 0.5491 - auc: 0.6827\n",
            " For Batch Number 151 the model has a loss of {'loss': 0.6371347904205322, 'tp': 1341.0, 'fp': 639.0, 'tn': 1755.0, 'fn': 1097.0, 'accuracy': 0.6407284736633301, 'precision': 0.6772727370262146, 'recall': 0.5500410199165344, 'auc': 0.6830797791481018} \n",
            "151/689 [=====>........................] - ETA: 57s - loss: 0.6371 - tp: 1341.0000 - fp: 639.0000 - tn: 1755.0000 - fn: 1097.0000 - accuracy: 0.6407 - precision: 0.6773 - recall: 0.5500 - auc: 0.6831\n",
            " For Batch Number 152 the model has a loss of {'loss': 0.6366017460823059, 'tp': 1357.0, 'fp': 642.0, 'tn': 1765.0, 'fn': 1100.0, 'accuracy': 0.6418585777282715, 'precision': 0.6788394451141357, 'recall': 0.5522995591163635, 'auc': 0.6840857863426208} \n",
            "152/689 [=====>........................] - ETA: 57s - loss: 0.6366 - tp: 1357.0000 - fp: 642.0000 - tn: 1765.0000 - fn: 1100.0000 - accuracy: 0.6419 - precision: 0.6788 - recall: 0.5523 - auc: 0.6841\n",
            " For Batch Number 153 the model has a loss of {'loss': 0.6366397142410278, 'tp': 1368.0, 'fp': 649.0, 'tn': 1776.0, 'fn': 1103.0, 'accuracy': 0.6421568393707275, 'precision': 0.6782349944114685, 'recall': 0.5536220073699951, 'auc': 0.6841411590576172} \n",
            "153/689 [=====>........................] - ETA: 57s - loss: 0.6366 - tp: 1368.0000 - fp: 649.0000 - tn: 1776.0000 - fn: 1103.0000 - accuracy: 0.6422 - precision: 0.6782 - recall: 0.5536 - auc: 0.6841\n",
            " For Batch Number 154 the model has a loss of {'loss': 0.6372650265693665, 'tp': 1378.0, 'fp': 659.0, 'tn': 1783.0, 'fn': 1108.0, 'accuracy': 0.6414366960525513, 'precision': 0.676485002040863, 'recall': 0.5543041229248047, 'auc': 0.6834361553192139} \n",
            "154/689 [=====>........................] - ETA: 57s - loss: 0.6373 - tp: 1378.0000 - fp: 659.0000 - tn: 1783.0000 - fn: 1108.0000 - accuracy: 0.6414 - precision: 0.6765 - recall: 0.5543 - auc: 0.6834\n",
            " For Batch Number 155 the model has a loss of {'loss': 0.6373990178108215, 'tp': 1389.0, 'fp': 667.0, 'tn': 1791.0, 'fn': 1113.0, 'accuracy': 0.6411290168762207, 'precision': 0.6755836606025696, 'recall': 0.555155873298645, 'auc': 0.6832103133201599} \n",
            "155/689 [=====>........................] - ETA: 56s - loss: 0.6374 - tp: 1389.0000 - fp: 667.0000 - tn: 1791.0000 - fn: 1113.0000 - accuracy: 0.6411 - precision: 0.6756 - recall: 0.5552 - auc: 0.6832\n",
            " For Batch Number 156 the model has a loss of {'loss': 0.6372154951095581, 'tp': 1398.0, 'fp': 673.0, 'tn': 1803.0, 'fn': 1118.0, 'accuracy': 0.6412259340286255, 'precision': 0.6750361919403076, 'recall': 0.5556438565254211, 'auc': 0.6832138299942017} \n",
            "156/689 [=====>........................] - ETA: 56s - loss: 0.6372 - tp: 1398.0000 - fp: 673.0000 - tn: 1803.0000 - fn: 1118.0000 - accuracy: 0.6412 - precision: 0.6750 - recall: 0.5556 - auc: 0.6832\n",
            " For Batch Number 157 the model has a loss of {'loss': 0.6370452642440796, 'tp': 1406.0, 'fp': 678.0, 'tn': 1817.0, 'fn': 1123.0, 'accuracy': 0.6415206789970398, 'precision': 0.6746640801429749, 'recall': 0.555950939655304, 'auc': 0.6834003925323486} \n",
            "157/689 [=====>........................] - ETA: 56s - loss: 0.6370 - tp: 1406.0000 - fp: 678.0000 - tn: 1817.0000 - fn: 1123.0000 - accuracy: 0.6415 - precision: 0.6747 - recall: 0.5560 - auc: 0.6834\n",
            " For Batch Number 158 the model has a loss of {'loss': 0.6363599300384521, 'tp': 1416.0, 'fp': 679.0, 'tn': 1833.0, 'fn': 1128.0, 'accuracy': 0.6426028609275818, 'precision': 0.6758949756622314, 'recall': 0.5566037893295288, 'auc': 0.6845951080322266} \n",
            "158/689 [=====>........................] - ETA: 56s - loss: 0.6364 - tp: 1416.0000 - fp: 679.0000 - tn: 1833.0000 - fn: 1128.0000 - accuracy: 0.6426 - precision: 0.6759 - recall: 0.5566 - auc: 0.6846\n",
            " For Batch Number 159 the model has a loss of {'loss': 0.637421727180481, 'tp': 1420.0, 'fp': 681.0, 'tn': 1845.0, 'fn': 1142.0, 'accuracy': 0.6417059898376465, 'precision': 0.6758686304092407, 'recall': 0.5542544722557068, 'auc': 0.6829221844673157} \n",
            "159/689 [=====>........................] - ETA: 55s - loss: 0.6374 - tp: 1420.0000 - fp: 681.0000 - tn: 1845.0000 - fn: 1142.0000 - accuracy: 0.6417 - precision: 0.6759 - recall: 0.5543 - auc: 0.6829\n",
            " For Batch Number 160 the model has a loss of {'loss': 0.6373833417892456, 'tp': 1428.0, 'fp': 682.0, 'tn': 1859.0, 'fn': 1151.0, 'accuracy': 0.6419922113418579, 'precision': 0.6767772436141968, 'recall': 0.5537030100822449, 'auc': 0.6830787658691406} \n",
            "160/689 [=====>........................] - ETA: 55s - loss: 0.6374 - tp: 1428.0000 - fp: 682.0000 - tn: 1859.0000 - fn: 1151.0000 - accuracy: 0.6420 - precision: 0.6768 - recall: 0.5537 - auc: 0.6831\n",
            " For Batch Number 161 the model has a loss of {'loss': 0.6369174718856812, 'tp': 1434.0, 'fp': 685.0, 'tn': 1876.0, 'fn': 1157.0, 'accuracy': 0.6424689292907715, 'precision': 0.6767343282699585, 'recall': 0.5534542798995972, 'auc': 0.683486819267273} \n",
            "161/689 [======>.......................] - ETA: 55s - loss: 0.6369 - tp: 1434.0000 - fp: 685.0000 - tn: 1876.0000 - fn: 1157.0000 - accuracy: 0.6425 - precision: 0.6767 - recall: 0.5535 - auc: 0.6835\n",
            " For Batch Number 162 the model has a loss of {'loss': 0.6365893483161926, 'tp': 1444.0, 'fp': 688.0, 'tn': 1888.0, 'fn': 1164.0, 'accuracy': 0.6427469253540039, 'precision': 0.6772983074188232, 'recall': 0.553680956363678, 'auc': 0.683921217918396} \n",
            "162/689 [======>.......................] - ETA: 55s - loss: 0.6366 - tp: 1444.0000 - fp: 688.0000 - tn: 1888.0000 - fn: 1164.0000 - accuracy: 0.6427 - precision: 0.6773 - recall: 0.5537 - auc: 0.6839\n",
            " For Batch Number 163 the model has a loss of {'loss': 0.6364527940750122, 'tp': 1458.0, 'fp': 692.0, 'tn': 1896.0, 'fn': 1170.0, 'accuracy': 0.6430214643478394, 'precision': 0.6781395077705383, 'recall': 0.5547945499420166, 'auc': 0.6841204762458801} \n",
            "163/689 [======>.......................] - ETA: 55s - loss: 0.6365 - tp: 1458.0000 - fp: 692.0000 - tn: 1896.0000 - fn: 1170.0000 - accuracy: 0.6430 - precision: 0.6781 - recall: 0.5548 - auc: 0.6841\n",
            " For Batch Number 164 the model has a loss of {'loss': 0.6362077593803406, 'tp': 1470.0, 'fp': 694.0, 'tn': 1904.0, 'fn': 1180.0, 'accuracy': 0.6429116129875183, 'precision': 0.6792976260185242, 'recall': 0.5547170042991638, 'auc': 0.6844989061355591} \n",
            "164/689 [======>.......................] - ETA: 54s - loss: 0.6362 - tp: 1470.0000 - fp: 694.0000 - tn: 1904.0000 - fn: 1180.0000 - accuracy: 0.6429 - precision: 0.6793 - recall: 0.5547 - auc: 0.6845\n",
            " For Batch Number 165 the model has a loss of {'loss': 0.6366050243377686, 'tp': 1479.0, 'fp': 702.0, 'tn': 1915.0, 'fn': 1184.0, 'accuracy': 0.6428030133247375, 'precision': 0.6781293153762817, 'recall': 0.5553886890411377, 'auc': 0.6840721964836121} \n",
            "165/689 [======>.......................] - ETA: 54s - loss: 0.6366 - tp: 1479.0000 - fp: 702.0000 - tn: 1915.0000 - fn: 1184.0000 - accuracy: 0.6428 - precision: 0.6781 - recall: 0.5554 - auc: 0.6841\n",
            " For Batch Number 166 the model has a loss of {'loss': 0.6368343830108643, 'tp': 1491.0, 'fp': 712.0, 'tn': 1922.0, 'fn': 1187.0, 'accuracy': 0.6425075531005859, 'precision': 0.6768043637275696, 'recall': 0.5567587614059448, 'auc': 0.6838364601135254} \n",
            "166/689 [======>.......................] - ETA: 54s - loss: 0.6368 - tp: 1491.0000 - fp: 712.0000 - tn: 1922.0000 - fn: 1187.0000 - accuracy: 0.6425 - precision: 0.6768 - recall: 0.5568 - auc: 0.6838\n",
            " For Batch Number 167 the model has a loss of {'loss': 0.6372480392456055, 'tp': 1503.0, 'fp': 722.0, 'tn': 1927.0, 'fn': 1192.0, 'accuracy': 0.6418412923812866, 'precision': 0.6755056381225586, 'recall': 0.55769944190979, 'auc': 0.6833417415618896} \n",
            "167/689 [======>.......................] - ETA: 54s - loss: 0.6372 - tp: 1503.0000 - fp: 722.0000 - tn: 1927.0000 - fn: 1192.0000 - accuracy: 0.6418 - precision: 0.6755 - recall: 0.5577 - auc: 0.6833\n",
            " For Batch Number 168 the model has a loss of {'loss': 0.6377110481262207, 'tp': 1512.0, 'fp': 733.0, 'tn': 1935.0, 'fn': 1196.0, 'accuracy': 0.6411830186843872, 'precision': 0.673496663570404, 'recall': 0.5583456158638, 'auc': 0.6827064752578735} \n",
            "168/689 [======>.......................] - ETA: 53s - loss: 0.6377 - tp: 1512.0000 - fp: 733.0000 - tn: 1935.0000 - fn: 1196.0000 - accuracy: 0.6412 - precision: 0.6735 - recall: 0.5583 - auc: 0.6827\n",
            " For Batch Number 169 the model has a loss of {'loss': 0.6377409100532532, 'tp': 1521.0, 'fp': 739.0, 'tn': 1945.0, 'fn': 1203.0, 'accuracy': 0.6409023404121399, 'precision': 0.6730088591575623, 'recall': 0.558370053768158, 'auc': 0.6827530264854431} \n",
            "169/689 [======>.......................] - ETA: 53s - loss: 0.6377 - tp: 1521.0000 - fp: 739.0000 - tn: 1945.0000 - fn: 1203.0000 - accuracy: 0.6409 - precision: 0.6730 - recall: 0.5584 - auc: 0.6828\n",
            " For Batch Number 170 the model has a loss of {'loss': 0.6380133032798767, 'tp': 1531.0, 'fp': 743.0, 'tn': 1955.0, 'fn': 1211.0, 'accuracy': 0.6408088207244873, 'precision': 0.6732629537582397, 'recall': 0.5583515763282776, 'auc': 0.6825007200241089} \n",
            "170/689 [======>.......................] - ETA: 53s - loss: 0.6380 - tp: 1531.0000 - fp: 743.0000 - tn: 1955.0000 - fn: 1211.0000 - accuracy: 0.6408 - precision: 0.6733 - recall: 0.5584 - auc: 0.6825\n",
            " For Batch Number 171 the model has a loss of {'loss': 0.6388077139854431, 'tp': 1535.0, 'fp': 748.0, 'tn': 1966.0, 'fn': 1223.0, 'accuracy': 0.6398026347160339, 'precision': 0.6723609566688538, 'recall': 0.5565627217292786, 'auc': 0.6811910271644592} \n",
            "171/689 [======>.......................] - ETA: 53s - loss: 0.6388 - tp: 1535.0000 - fp: 748.0000 - tn: 1966.0000 - fn: 1223.0000 - accuracy: 0.6398 - precision: 0.6724 - recall: 0.5566 - auc: 0.6812\n",
            " For Batch Number 172 the model has a loss of {'loss': 0.6390784978866577, 'tp': 1542.0, 'fp': 749.0, 'tn': 1980.0, 'fn': 1233.0, 'accuracy': 0.6398982405662537, 'precision': 0.6730685234069824, 'recall': 0.5556756854057312, 'auc': 0.6807929873466492} \n",
            "172/689 [======>.......................] - ETA: 53s - loss: 0.6391 - tp: 1542.0000 - fp: 749.0000 - tn: 1980.0000 - fn: 1233.0000 - accuracy: 0.6399 - precision: 0.6731 - recall: 0.5557 - auc: 0.6808\n",
            " For Batch Number 173 the model has a loss of {'loss': 0.6386256217956543, 'tp': 1549.0, 'fp': 752.0, 'tn': 1995.0, 'fn': 1240.0, 'accuracy': 0.6401734352111816, 'precision': 0.6731855869293213, 'recall': 0.5553961992263794, 'auc': 0.6812667846679688} \n",
            "173/689 [======>.......................] - ETA: 52s - loss: 0.6386 - tp: 1549.0000 - fp: 752.0000 - tn: 1995.0000 - fn: 1240.0000 - accuracy: 0.6402 - precision: 0.6732 - recall: 0.5554 - auc: 0.6813\n",
            " For Batch Number 174 the model has a loss of {'loss': 0.6385055780410767, 'tp': 1555.0, 'fp': 759.0, 'tn': 2006.0, 'fn': 1248.0, 'accuracy': 0.6395474076271057, 'precision': 0.671996533870697, 'recall': 0.5547627806663513, 'auc': 0.6812018156051636} \n",
            "174/689 [======>.......................] - ETA: 52s - loss: 0.6385 - tp: 1555.0000 - fp: 759.0000 - tn: 2006.0000 - fn: 1248.0000 - accuracy: 0.6395 - precision: 0.6720 - recall: 0.5548 - auc: 0.6812\n",
            " For Batch Number 175 the model has a loss of {'loss': 0.6384003162384033, 'tp': 1563.0, 'fp': 763.0, 'tn': 2020.0, 'fn': 1254.0, 'accuracy': 0.6398214101791382, 'precision': 0.6719690561294556, 'recall': 0.5548455715179443, 'auc': 0.6813032627105713} \n",
            "175/689 [======>.......................] - ETA: 52s - loss: 0.6384 - tp: 1563.0000 - fp: 763.0000 - tn: 2020.0000 - fn: 1254.0000 - accuracy: 0.6398 - precision: 0.6720 - recall: 0.5548 - auc: 0.6813\n",
            " For Batch Number 176 the model has a loss of {'loss': 0.6384872794151306, 'tp': 1571.0, 'fp': 770.0, 'tn': 2030.0, 'fn': 1261.0, 'accuracy': 0.6393821239471436, 'precision': 0.6710807085037231, 'recall': 0.5547316670417786, 'auc': 0.6809627413749695} \n",
            "176/689 [======>.......................] - ETA: 52s - loss: 0.6385 - tp: 1571.0000 - fp: 770.0000 - tn: 2030.0000 - fn: 1261.0000 - accuracy: 0.6394 - precision: 0.6711 - recall: 0.5547 - auc: 0.6810\n",
            " For Batch Number 177 the model has a loss of {'loss': 0.6385089159011841, 'tp': 1576.0, 'fp': 774.0, 'tn': 2045.0, 'fn': 1269.0, 'accuracy': 0.6393008232116699, 'precision': 0.6706383228302002, 'recall': 0.5539543032646179, 'auc': 0.6808380484580994} \n",
            "177/689 [======>.......................] - ETA: 52s - loss: 0.6385 - tp: 1576.0000 - fp: 774.0000 - tn: 2045.0000 - fn: 1269.0000 - accuracy: 0.6393 - precision: 0.6706 - recall: 0.5540 - auc: 0.6808\n",
            " For Batch Number 178 the model has a loss of {'loss': 0.6382628083229065, 'tp': 1582.0, 'fp': 776.0, 'tn': 2060.0, 'fn': 1278.0, 'accuracy': 0.639396071434021, 'precision': 0.6709075570106506, 'recall': 0.5531468391418457, 'auc': 0.6811805963516235} \n",
            "178/689 [======>.......................] - ETA: 51s - loss: 0.6383 - tp: 1582.0000 - fp: 776.0000 - tn: 2060.0000 - fn: 1278.0000 - accuracy: 0.6394 - precision: 0.6709 - recall: 0.5531 - auc: 0.6812\n",
            " For Batch Number 179 the model has a loss of {'loss': 0.6383857727050781, 'tp': 1587.0, 'fp': 779.0, 'tn': 2074.0, 'fn': 1288.0, 'accuracy': 0.6391410827636719, 'precision': 0.6707523465156555, 'recall': 0.5519999861717224, 'auc': 0.6807816028594971} \n",
            "\n",
            " For Batch Number 180 the model has a loss of {'loss': 0.6388164162635803, 'tp': 1594.0, 'fp': 781.0, 'tn': 2084.0, 'fn': 1301.0, 'accuracy': 0.6385416388511658, 'precision': 0.6711578965187073, 'recall': 0.5506044626235962, 'auc': 0.6801604628562927} \n",
            "180/689 [======>.......................] - ETA: 51s - loss: 0.6388 - tp: 1594.0000 - fp: 781.0000 - tn: 2084.0000 - fn: 1301.0000 - accuracy: 0.6385 - precision: 0.6712 - recall: 0.5506 - auc: 0.6802\n",
            " For Batch Number 181 the model has a loss of {'loss': 0.6388683319091797, 'tp': 1600.0, 'fp': 788.0, 'tn': 2098.0, 'fn': 1306.0, 'accuracy': 0.6384668350219727, 'precision': 0.6700167655944824, 'recall': 0.5505849719047546, 'auc': 0.679852306842804} \n",
            "181/689 [======>.......................] - ETA: 51s - loss: 0.6389 - tp: 1600.0000 - fp: 788.0000 - tn: 2098.0000 - fn: 1306.0000 - accuracy: 0.6385 - precision: 0.6700 - recall: 0.5506 - auc: 0.6799\n",
            " For Batch Number 182 the model has a loss of {'loss': 0.6390248537063599, 'tp': 1611.0, 'fp': 794.0, 'tn': 2104.0, 'fn': 1315.0, 'accuracy': 0.6378777623176575, 'precision': 0.669854462146759, 'recall': 0.5505809783935547, 'auc': 0.6794108748435974} \n",
            "182/689 [======>.......................] - ETA: 50s - loss: 0.6390 - tp: 1611.0000 - fp: 794.0000 - tn: 2104.0000 - fn: 1315.0000 - accuracy: 0.6379 - precision: 0.6699 - recall: 0.5506 - auc: 0.6794\n",
            " For Batch Number 183 the model has a loss of {'loss': 0.6392483711242676, 'tp': 1620.0, 'fp': 803.0, 'tn': 2113.0, 'fn': 1320.0, 'accuracy': 0.6374658346176147, 'precision': 0.668592631816864, 'recall': 0.5510203838348389, 'auc': 0.6790962219238281} \n",
            "183/689 [======>.......................] - ETA: 50s - loss: 0.6392 - tp: 1620.0000 - fp: 803.0000 - tn: 2113.0000 - fn: 1320.0000 - accuracy: 0.6375 - precision: 0.6686 - recall: 0.5510 - auc: 0.6791\n",
            " For Batch Number 184 the model has a loss of {'loss': 0.6392084956169128, 'tp': 1632.0, 'fp': 808.0, 'tn': 2123.0, 'fn': 1325.0, 'accuracy': 0.6377377510070801, 'precision': 0.6688524484634399, 'recall': 0.5519106984138489, 'auc': 0.6793661117553711} \n",
            "184/689 [=======>......................] - ETA: 50s - loss: 0.6392 - tp: 1632.0000 - fp: 808.0000 - tn: 2123.0000 - fn: 1325.0000 - accuracy: 0.6377 - precision: 0.6689 - recall: 0.5519 - auc: 0.6794\n",
            " For Batch Number 185 the model has a loss of {'loss': 0.639092743396759, 'tp': 1641.0, 'fp': 811.0, 'tn': 2138.0, 'fn': 1330.0, 'accuracy': 0.6383445858955383, 'precision': 0.6692495942115784, 'recall': 0.5523392558097839, 'auc': 0.6796390414237976} \n",
            "\n",
            " For Batch Number 186 the model has a loss of {'loss': 0.638938844203949, 'tp': 1648.0, 'fp': 813.0, 'tn': 2151.0, 'fn': 1340.0, 'accuracy': 0.6382728219032288, 'precision': 0.6696465015411377, 'recall': 0.5515394806861877, 'auc': 0.6796401739120483} \n",
            "186/689 [=======>......................] - ETA: 50s - loss: 0.6389 - tp: 1648.0000 - fp: 813.0000 - tn: 2151.0000 - fn: 1340.0000 - accuracy: 0.6383 - precision: 0.6696 - recall: 0.5515 - auc: 0.6796\n",
            " For Batch Number 187 the model has a loss of {'loss': 0.6384053230285645, 'tp': 1658.0, 'fp': 813.0, 'tn': 2165.0, 'fn': 1348.0, 'accuracy': 0.6388702988624573, 'precision': 0.6709834337234497, 'recall': 0.551563560962677, 'auc': 0.6802731156349182} \n",
            "187/689 [=======>......................] - ETA: 50s - loss: 0.6384 - tp: 1658.0000 - fp: 813.0000 - tn: 2165.0000 - fn: 1348.0000 - accuracy: 0.6389 - precision: 0.6710 - recall: 0.5516 - auc: 0.6803\n",
            " For Batch Number 188 the model has a loss of {'loss': 0.6381834149360657, 'tp': 1667.0, 'fp': 814.0, 'tn': 2177.0, 'fn': 1358.0, 'accuracy': 0.6389627456665039, 'precision': 0.6719064712524414, 'recall': 0.5510743856430054, 'auc': 0.6804639101028442} \n",
            "188/689 [=======>......................] - ETA: 50s - loss: 0.6382 - tp: 1667.0000 - fp: 814.0000 - tn: 2177.0000 - fn: 1358.0000 - accuracy: 0.6390 - precision: 0.6719 - recall: 0.5511 - auc: 0.6805\n",
            " For Batch Number 189 the model has a loss of {'loss': 0.638034462928772, 'tp': 1676.0, 'fp': 815.0, 'tn': 2190.0, 'fn': 1367.0, 'accuracy': 0.6392195820808411, 'precision': 0.6728221774101257, 'recall': 0.5507722496986389, 'auc': 0.6805672645568848} \n",
            "189/689 [=======>......................] - ETA: 49s - loss: 0.6380 - tp: 1676.0000 - fp: 815.0000 - tn: 2190.0000 - fn: 1367.0000 - accuracy: 0.6392 - precision: 0.6728 - recall: 0.5508 - auc: 0.6806\n",
            " For Batch Number 190 the model has a loss of {'loss': 0.6375486850738525, 'tp': 1687.0, 'fp': 816.0, 'tn': 2202.0, 'fn': 1375.0, 'accuracy': 0.6396381855010986, 'precision': 0.6739912033081055, 'recall': 0.5509470701217651, 'auc': 0.6809590458869934} \n",
            "190/689 [=======>......................] - ETA: 49s - loss: 0.6375 - tp: 1687.0000 - fp: 816.0000 - tn: 2202.0000 - fn: 1375.0000 - accuracy: 0.6396 - precision: 0.6740 - recall: 0.5509 - auc: 0.6810\n",
            " For Batch Number 191 the model has a loss of {'loss': 0.6374816298484802, 'tp': 1698.0, 'fp': 818.0, 'tn': 2213.0, 'fn': 1383.0, 'accuracy': 0.6398887634277344, 'precision': 0.6748807430267334, 'recall': 0.5511197447776794, 'auc': 0.681230366230011} \n",
            "191/689 [=======>......................] - ETA: 49s - loss: 0.6375 - tp: 1698.0000 - fp: 818.0000 - tn: 2213.0000 - fn: 1383.0000 - accuracy: 0.6399 - precision: 0.6749 - recall: 0.5511 - auc: 0.6812\n",
            " For Batch Number 192 the model has a loss of {'loss': 0.6380200386047363, 'tp': 1709.0, 'fp': 823.0, 'tn': 2226.0, 'fn': 1386.0, 'accuracy': 0.6404622197151184, 'precision': 0.6749604940414429, 'recall': 0.5521809458732605, 'auc': 0.681220293045044} \n",
            "192/689 [=======>......................] - ETA: 49s - loss: 0.6380 - tp: 1709.0000 - fp: 823.0000 - tn: 2226.0000 - fn: 1386.0000 - accuracy: 0.6405 - precision: 0.6750 - recall: 0.5522 - auc: 0.6812\n",
            " For Batch Number 193 the model has a loss of {'loss': 0.6373923420906067, 'tp': 1724.0, 'fp': 824.0, 'tn': 2237.0, 'fn': 1391.0, 'accuracy': 0.6413536071777344, 'precision': 0.6766090989112854, 'recall': 0.5534510612487793, 'auc': 0.681915819644928} \n",
            "193/689 [=======>......................] - ETA: 49s - loss: 0.6374 - tp: 1724.0000 - fp: 824.0000 - tn: 2237.0000 - fn: 1391.0000 - accuracy: 0.6414 - precision: 0.6766 - recall: 0.5535 - auc: 0.6819\n",
            " For Batch Number 194 the model has a loss of {'loss': 0.6379055380821228, 'tp': 1734.0, 'fp': 832.0, 'tn': 2247.0, 'fn': 1395.0, 'accuracy': 0.641269326210022, 'precision': 0.6757599115371704, 'recall': 0.5541706681251526, 'auc': 0.6815001964569092} \n",
            "194/689 [=======>......................] - ETA: 49s - loss: 0.6379 - tp: 1734.0000 - fp: 832.0000 - tn: 2247.0000 - fn: 1395.0000 - accuracy: 0.6413 - precision: 0.6758 - recall: 0.5542 - auc: 0.6815\n",
            " For Batch Number 195 the model has a loss of {'loss': 0.6375294923782349, 'tp': 1747.0, 'fp': 839.0, 'tn': 2257.0, 'fn': 1397.0, 'accuracy': 0.6416666507720947, 'precision': 0.675560712814331, 'recall': 0.5556615591049194, 'auc': 0.6819291114807129} \n",
            "195/689 [=======>......................] - ETA: 49s - loss: 0.6375 - tp: 1747.0000 - fp: 839.0000 - tn: 2257.0000 - fn: 1397.0000 - accuracy: 0.6417 - precision: 0.6756 - recall: 0.5557 - auc: 0.6819\n",
            " For Batch Number 196 the model has a loss of {'loss': 0.6378998756408691, 'tp': 1755.0, 'fp': 845.0, 'tn': 2265.0, 'fn': 1407.0, 'accuracy': 0.6409438848495483, 'precision': 0.675000011920929, 'recall': 0.5550284385681152, 'auc': 0.6814510226249695} \n",
            "196/689 [=======>......................] - ETA: 49s - loss: 0.6379 - tp: 1755.0000 - fp: 845.0000 - tn: 2265.0000 - fn: 1407.0000 - accuracy: 0.6409 - precision: 0.6750 - recall: 0.5550 - auc: 0.6815\n",
            " For Batch Number 197 the model has a loss of {'loss': 0.6380463242530823, 'tp': 1765.0, 'fp': 848.0, 'tn': 2276.0, 'fn': 1415.0, 'accuracy': 0.6410215497016907, 'precision': 0.6754688024520874, 'recall': 0.555031418800354, 'auc': 0.6813927888870239} \n",
            "197/689 [=======>......................] - ETA: 48s - loss: 0.6380 - tp: 1765.0000 - fp: 848.0000 - tn: 2276.0000 - fn: 1415.0000 - accuracy: 0.6410 - precision: 0.6755 - recall: 0.5550 - auc: 0.6814\n",
            " For Batch Number 198 the model has a loss of {'loss': 0.6379567980766296, 'tp': 1777.0, 'fp': 850.0, 'tn': 2286.0, 'fn': 1423.0, 'accuracy': 0.6412563323974609, 'precision': 0.6764370203018188, 'recall': 0.5553125143051147, 'auc': 0.6814717054367065} \n",
            "198/689 [=======>......................] - ETA: 48s - loss: 0.6380 - tp: 1777.0000 - fp: 850.0000 - tn: 2286.0000 - fn: 1423.0000 - accuracy: 0.6413 - precision: 0.6764 - recall: 0.5553 - auc: 0.6815\n",
            " For Batch Number 199 the model has a loss of {'loss': 0.6382520794868469, 'tp': 1785.0, 'fp': 857.0, 'tn': 2296.0, 'fn': 1430.0, 'accuracy': 0.6408605575561523, 'precision': 0.6756245493888855, 'recall': 0.5552099347114563, 'auc': 0.6810590624809265} \n",
            "199/689 [=======>......................] - ETA: 48s - loss: 0.6383 - tp: 1785.0000 - fp: 857.0000 - tn: 2296.0000 - fn: 1430.0000 - accuracy: 0.6409 - precision: 0.6756 - recall: 0.5552 - auc: 0.6811\n",
            " For Batch Number 200 the model has a loss of {'loss': 0.6379448175430298, 'tp': 1796.0, 'fp': 862.0, 'tn': 2308.0, 'fn': 1434.0, 'accuracy': 0.6412500143051147, 'precision': 0.6756960153579712, 'recall': 0.5560371279716492, 'auc': 0.6815085411071777} \n",
            "200/689 [=======>......................] - ETA: 48s - loss: 0.6379 - tp: 1796.0000 - fp: 862.0000 - tn: 2308.0000 - fn: 1434.0000 - accuracy: 0.6413 - precision: 0.6757 - recall: 0.5560 - auc: 0.6815\n",
            " For Batch Number 201 the model has a loss of {'loss': 0.6386666893959045, 'tp': 1802.0, 'fp': 870.0, 'tn': 2318.0, 'fn': 1442.0, 'accuracy': 0.6405472755432129, 'precision': 0.6744012236595154, 'recall': 0.5554870367050171, 'auc': 0.6806792616844177} \n",
            "201/689 [=======>......................] - ETA: 48s - loss: 0.6387 - tp: 1802.0000 - fp: 870.0000 - tn: 2318.0000 - fn: 1442.0000 - accuracy: 0.6405 - precision: 0.6744 - recall: 0.5555 - auc: 0.6807\n",
            " For Batch Number 202 the model has a loss of {'loss': 0.638585090637207, 'tp': 1813.0, 'fp': 873.0, 'tn': 2330.0, 'fn': 1448.0, 'accuracy': 0.640934407711029, 'precision': 0.6749813556671143, 'recall': 0.5559644103050232, 'auc': 0.6812266707420349} \n",
            "202/689 [=======>......................] - ETA: 48s - loss: 0.6386 - tp: 1813.0000 - fp: 873.0000 - tn: 2330.0000 - fn: 1448.0000 - accuracy: 0.6409 - precision: 0.6750 - recall: 0.5560 - auc: 0.6812\n",
            " For Batch Number 203 the model has a loss of {'loss': 0.6389515399932861, 'tp': 1823.0, 'fp': 876.0, 'tn': 2339.0, 'fn': 1458.0, 'accuracy': 0.640701949596405, 'precision': 0.6754353642463684, 'recall': 0.5556232929229736, 'auc': 0.6809599995613098} \n",
            "203/689 [=======>......................] - ETA: 48s - loss: 0.6390 - tp: 1823.0000 - fp: 876.0000 - tn: 2339.0000 - fn: 1458.0000 - accuracy: 0.6407 - precision: 0.6754 - recall: 0.5556 - auc: 0.6810\n",
            " For Batch Number 204 the model has a loss of {'loss': 0.6389843225479126, 'tp': 1833.0, 'fp': 879.0, 'tn': 2349.0, 'fn': 1467.0, 'accuracy': 0.640625, 'precision': 0.6758849620819092, 'recall': 0.5554545521736145, 'auc': 0.680822491645813} \n",
            "204/689 [=======>......................] - ETA: 48s - loss: 0.6390 - tp: 1833.0000 - fp: 879.0000 - tn: 2349.0000 - fn: 1467.0000 - accuracy: 0.6406 - precision: 0.6759 - recall: 0.5555 - auc: 0.6808\n",
            " For Batch Number 205 the model has a loss of {'loss': 0.6392748355865479, 'tp': 1841.0, 'fp': 882.0, 'tn': 2362.0, 'fn': 1475.0, 'accuracy': 0.6407012343406677, 'precision': 0.6760925650596619, 'recall': 0.5551869869232178, 'auc': 0.6806321740150452} \n",
            "205/689 [=======>......................] - ETA: 48s - loss: 0.6393 - tp: 1841.0000 - fp: 882.0000 - tn: 2362.0000 - fn: 1475.0000 - accuracy: 0.6407 - precision: 0.6761 - recall: 0.5552 - auc: 0.6806\n",
            " For Batch Number 206 the model has a loss of {'loss': 0.6394022703170776, 'tp': 1848.0, 'fp': 892.0, 'tn': 2372.0, 'fn': 1480.0, 'accuracy': 0.6401699185371399, 'precision': 0.674452543258667, 'recall': 0.5552884340286255, 'auc': 0.6803317666053772} \n",
            "206/689 [=======>......................] - ETA: 47s - loss: 0.6394 - tp: 1848.0000 - fp: 892.0000 - tn: 2372.0000 - fn: 1480.0000 - accuracy: 0.6402 - precision: 0.6745 - recall: 0.5553 - auc: 0.6803\n",
            " For Batch Number 207 the model has a loss of {'loss': 0.6392395496368408, 'tp': 1858.0, 'fp': 897.0, 'tn': 2384.0, 'fn': 1485.0, 'accuracy': 0.6403985619544983, 'precision': 0.6744101643562317, 'recall': 0.5557882189750671, 'auc': 0.6804764270782471} \n",
            "207/689 [========>.....................] - ETA: 47s - loss: 0.6392 - tp: 1858.0000 - fp: 897.0000 - tn: 2384.0000 - fn: 1485.0000 - accuracy: 0.6404 - precision: 0.6744 - recall: 0.5558 - auc: 0.6805\n",
            " For Batch Number 208 the model has a loss of {'loss': 0.6398440599441528, 'tp': 1862.0, 'fp': 905.0, 'tn': 2397.0, 'fn': 1492.0, 'accuracy': 0.6398738026618958, 'precision': 0.6729309558868408, 'recall': 0.5551580190658569, 'auc': 0.6796212196350098} \n",
            "208/689 [========>.....................] - ETA: 47s - loss: 0.6398 - tp: 1862.0000 - fp: 905.0000 - tn: 2397.0000 - fn: 1492.0000 - accuracy: 0.6399 - precision: 0.6729 - recall: 0.5552 - auc: 0.6796\n",
            " For Batch Number 209 the model has a loss of {'loss': 0.6404076814651489, 'tp': 1866.0, 'fp': 912.0, 'tn': 2410.0, 'fn': 1500.0, 'accuracy': 0.6393540501594543, 'precision': 0.6717062592506409, 'recall': 0.554367184638977, 'auc': 0.678916871547699} \n",
            "209/689 [========>.....................] - ETA: 47s - loss: 0.6404 - tp: 1866.0000 - fp: 912.0000 - tn: 2410.0000 - fn: 1500.0000 - accuracy: 0.6394 - precision: 0.6717 - recall: 0.5544 - auc: 0.6789\n",
            " For Batch Number 210 the model has a loss of {'loss': 0.6403086185455322, 'tp': 1875.0, 'fp': 913.0, 'tn': 2423.0, 'fn': 1509.0, 'accuracy': 0.6395833492279053, 'precision': 0.6725251078605652, 'recall': 0.5540780425071716, 'auc': 0.6789552569389343} \n",
            "210/689 [========>.....................] - ETA: 47s - loss: 0.6403 - tp: 1875.0000 - fp: 913.0000 - tn: 2423.0000 - fn: 1509.0000 - accuracy: 0.6396 - precision: 0.6725 - recall: 0.5541 - auc: 0.6790\n",
            " For Batch Number 211 the model has a loss of {'loss': 0.640018105506897, 'tp': 1882.0, 'fp': 916.0, 'tn': 2439.0, 'fn': 1515.0, 'accuracy': 0.6399585604667664, 'precision': 0.6726232767105103, 'recall': 0.5540182590484619, 'auc': 0.6794446110725403} \n",
            "211/689 [========>.....................] - ETA: 47s - loss: 0.6400 - tp: 1882.0000 - fp: 916.0000 - tn: 2439.0000 - fn: 1515.0000 - accuracy: 0.6400 - precision: 0.6726 - recall: 0.5540 - auc: 0.6794\n",
            " For Batch Number 212 the model has a loss of {'loss': 0.6398491859436035, 'tp': 1888.0, 'fp': 920.0, 'tn': 2454.0, 'fn': 1522.0, 'accuracy': 0.6400353908538818, 'precision': 0.6723646521568298, 'recall': 0.5536656975746155, 'auc': 0.6795886754989624} \n",
            "212/689 [========>.....................] - ETA: 47s - loss: 0.6398 - tp: 1888.0000 - fp: 920.0000 - tn: 2454.0000 - fn: 1522.0000 - accuracy: 0.6400 - precision: 0.6724 - recall: 0.5537 - auc: 0.6796\n",
            " For Batch Number 213 the model has a loss of {'loss': 0.6399286389350891, 'tp': 1892.0, 'fp': 924.0, 'tn': 2471.0, 'fn': 1529.0, 'accuracy': 0.64011150598526, 'precision': 0.671875, 'recall': 0.553054690361023, 'auc': 0.6792104840278625} \n",
            "213/689 [========>.....................] - ETA: 47s - loss: 0.6399 - tp: 1892.0000 - fp: 924.0000 - tn: 2471.0000 - fn: 1529.0000 - accuracy: 0.6401 - precision: 0.6719 - recall: 0.5531 - auc: 0.6792\n",
            " For Batch Number 214 the model has a loss of {'loss': 0.6401060819625854, 'tp': 1897.0, 'fp': 926.0, 'tn': 2486.0, 'fn': 1539.0, 'accuracy': 0.6400408744812012, 'precision': 0.6719801425933838, 'recall': 0.5520954728126526, 'auc': 0.678788423538208} \n",
            "214/689 [========>.....................] - ETA: 47s - loss: 0.6401 - tp: 1897.0000 - fp: 926.0000 - tn: 2486.0000 - fn: 1539.0000 - accuracy: 0.6400 - precision: 0.6720 - recall: 0.5521 - auc: 0.6788\n",
            " For Batch Number 215 the model has a loss of {'loss': 0.6403135657310486, 'tp': 1899.0, 'fp': 929.0, 'tn': 2502.0, 'fn': 1550.0, 'accuracy': 0.6396802067756653, 'precision': 0.6714993119239807, 'recall': 0.5505943894386292, 'auc': 0.678369402885437} \n",
            "215/689 [========>.....................] - ETA: 46s - loss: 0.6403 - tp: 1899.0000 - fp: 929.0000 - tn: 2502.0000 - fn: 1550.0000 - accuracy: 0.6397 - precision: 0.6715 - recall: 0.5506 - auc: 0.6784\n",
            " For Batch Number 216 the model has a loss of {'loss': 0.6405665278434753, 'tp': 1905.0, 'fp': 930.0, 'tn': 2514.0, 'fn': 1563.0, 'accuracy': 0.6393229365348816, 'precision': 0.6719576716423035, 'recall': 0.5493079423904419, 'auc': 0.6780414581298828} \n",
            "216/689 [========>.....................] - ETA: 46s - loss: 0.6406 - tp: 1905.0000 - fp: 930.0000 - tn: 2514.0000 - fn: 1563.0000 - accuracy: 0.6393 - precision: 0.6720 - recall: 0.5493 - auc: 0.6780\n",
            " For Batch Number 217 the model has a loss of {'loss': 0.6403030753135681, 'tp': 1912.0, 'fp': 933.0, 'tn': 2530.0, 'fn': 1569.0, 'accuracy': 0.6396889686584473, 'precision': 0.672056257724762, 'recall': 0.5492674708366394, 'auc': 0.6782761812210083} \n",
            "217/689 [========>.....................] - ETA: 46s - loss: 0.6403 - tp: 1912.0000 - fp: 933.0000 - tn: 2530.0000 - fn: 1569.0000 - accuracy: 0.6397 - precision: 0.6721 - recall: 0.5493 - auc: 0.6783\n",
            " For Batch Number 218 the model has a loss of {'loss': 0.6404308080673218, 'tp': 1921.0, 'fp': 935.0, 'tn': 2541.0, 'fn': 1579.0, 'accuracy': 0.6396215558052063, 'precision': 0.6726190447807312, 'recall': 0.5488571524620056, 'auc': 0.6782782673835754} \n",
            "218/689 [========>.....................] - ETA: 46s - loss: 0.6404 - tp: 1921.0000 - fp: 935.0000 - tn: 2541.0000 - fn: 1579.0000 - accuracy: 0.6396 - precision: 0.6726 - recall: 0.5489 - auc: 0.6783\n",
            " For Batch Number 219 the model has a loss of {'loss': 0.6405900120735168, 'tp': 1933.0, 'fp': 947.0, 'tn': 2547.0, 'fn': 1581.0, 'accuracy': 0.6392694115638733, 'precision': 0.6711805462837219, 'recall': 0.5500853657722473, 'auc': 0.6779882907867432} \n",
            "219/689 [========>.....................] - ETA: 46s - loss: 0.6406 - tp: 1933.0000 - fp: 947.0000 - tn: 2547.0000 - fn: 1581.0000 - accuracy: 0.6393 - precision: 0.6712 - recall: 0.5501 - auc: 0.6780\n",
            " For Batch Number 220 the model has a loss of {'loss': 0.6405288577079773, 'tp': 1943.0, 'fp': 955.0, 'tn': 2553.0, 'fn': 1589.0, 'accuracy': 0.6386363506317139, 'precision': 0.6704623699188232, 'recall': 0.5501132607460022, 'auc': 0.6780397295951843} \n",
            "220/689 [========>.....................] - ETA: 46s - loss: 0.6405 - tp: 1943.0000 - fp: 955.0000 - tn: 2553.0000 - fn: 1589.0000 - accuracy: 0.6386 - precision: 0.6705 - recall: 0.5501 - auc: 0.6780\n",
            " For Batch Number 221 the model has a loss of {'loss': 0.6403298377990723, 'tp': 1957.0, 'fp': 959.0, 'tn': 2561.0, 'fn': 1595.0, 'accuracy': 0.6388574838638306, 'precision': 0.6711248159408569, 'recall': 0.550957202911377, 'auc': 0.6784036755561829} \n",
            "221/689 [========>.....................] - ETA: 46s - loss: 0.6403 - tp: 1957.0000 - fp: 959.0000 - tn: 2561.0000 - fn: 1595.0000 - accuracy: 0.6389 - precision: 0.6711 - recall: 0.5510 - auc: 0.6784\n",
            " For Batch Number 222 the model has a loss of {'loss': 0.6401018500328064, 'tp': 1972.0, 'fp': 966.0, 'tn': 2567.0, 'fn': 1599.0, 'accuracy': 0.6389358043670654, 'precision': 0.6712049245834351, 'recall': 0.5522262454032898, 'auc': 0.67872554063797} \n",
            "222/689 [========>.....................] - ETA: 46s - loss: 0.6401 - tp: 1972.0000 - fp: 966.0000 - tn: 2567.0000 - fn: 1599.0000 - accuracy: 0.6389 - precision: 0.6712 - recall: 0.5522 - auc: 0.6787\n",
            " For Batch Number 223 the model has a loss of {'loss': 0.6406353712081909, 'tp': 1987.0, 'fp': 982.0, 'tn': 2568.0, 'fn': 1599.0, 'accuracy': 0.6383127570152283, 'precision': 0.6692488789558411, 'recall': 0.5540992617607117, 'auc': 0.6781261563301086} \n",
            "223/689 [========>.....................] - ETA: 46s - loss: 0.6406 - tp: 1987.0000 - fp: 982.0000 - tn: 2568.0000 - fn: 1599.0000 - accuracy: 0.6383 - precision: 0.6692 - recall: 0.5541 - auc: 0.6781\n",
            " For Batch Number 224 the model has a loss of {'loss': 0.6406110525131226, 'tp': 1997.0, 'fp': 989.0, 'tn': 2576.0, 'fn': 1606.0, 'accuracy': 0.6379743218421936, 'precision': 0.6687876582145691, 'recall': 0.5542603135108948, 'auc': 0.6780411005020142} \n",
            "224/689 [========>.....................] - ETA: 46s - loss: 0.6406 - tp: 1997.0000 - fp: 989.0000 - tn: 2576.0000 - fn: 1606.0000 - accuracy: 0.6380 - precision: 0.6688 - recall: 0.5543 - auc: 0.6780\n",
            " For Batch Number 225 the model has a loss of {'loss': 0.6406489610671997, 'tp': 2004.0, 'fp': 993.0, 'tn': 2588.0, 'fn': 1615.0, 'accuracy': 0.6377778053283691, 'precision': 0.6686686873435974, 'recall': 0.5537441372871399, 'auc': 0.6778841614723206} \n",
            "225/689 [========>.....................] - ETA: 46s - loss: 0.6406 - tp: 2004.0000 - fp: 993.0000 - tn: 2588.0000 - fn: 1615.0000 - accuracy: 0.6378 - precision: 0.6687 - recall: 0.5537 - auc: 0.6779\n",
            " For Batch Number 226 the model has a loss of {'loss': 0.6407678723335266, 'tp': 2010.0, 'fp': 996.0, 'tn': 2601.0, 'fn': 1625.0, 'accuracy': 0.6375829577445984, 'precision': 0.6686626672744751, 'recall': 0.5529573559761047, 'auc': 0.6776571869850159} \n",
            "226/689 [========>.....................] - ETA: 46s - loss: 0.6408 - tp: 2010.0000 - fp: 996.0000 - tn: 2601.0000 - fn: 1625.0000 - accuracy: 0.6376 - precision: 0.6687 - recall: 0.5530 - auc: 0.6777\n",
            " For Batch Number 227 the model has a loss of {'loss': 0.6410700082778931, 'tp': 2015.0, 'fp': 999.0, 'tn': 2614.0, 'fn': 1636.0, 'accuracy': 0.6372522115707397, 'precision': 0.6685467958450317, 'recall': 0.5519036054611206, 'auc': 0.6772335767745972} \n",
            "227/689 [========>.....................] - ETA: 45s - loss: 0.6411 - tp: 2015.0000 - fp: 999.0000 - tn: 2614.0000 - fn: 1636.0000 - accuracy: 0.6373 - precision: 0.6685 - recall: 0.5519 - auc: 0.6772\n",
            " For Batch Number 228 the model has a loss of {'loss': 0.6408313512802124, 'tp': 2020.0, 'fp': 1004.0, 'tn': 2632.0, 'fn': 1640.0, 'accuracy': 0.6376096606254578, 'precision': 0.6679894328117371, 'recall': 0.5519125461578369, 'auc': 0.6775098443031311} \n",
            "228/689 [========>.....................] - ETA: 45s - loss: 0.6408 - tp: 2020.0000 - fp: 1004.0000 - tn: 2632.0000 - fn: 1640.0000 - accuracy: 0.6376 - precision: 0.6680 - recall: 0.5519 - auc: 0.6775\n",
            " For Batch Number 229 the model has a loss of {'loss': 0.6409845948219299, 'tp': 2025.0, 'fp': 1007.0, 'tn': 2646.0, 'fn': 1650.0, 'accuracy': 0.6374181509017944, 'precision': 0.6678760051727295, 'recall': 0.5510203838348389, 'auc': 0.6772755980491638} \n",
            "229/689 [========>.....................] - ETA: 45s - loss: 0.6410 - tp: 2025.0000 - fp: 1007.0000 - tn: 2646.0000 - fn: 1650.0000 - accuracy: 0.6374 - precision: 0.6679 - recall: 0.5510 - auc: 0.6773\n",
            " For Batch Number 230 the model has a loss of {'loss': 0.640576958656311, 'tp': 2033.0, 'fp': 1007.0, 'tn': 2664.0, 'fn': 1656.0, 'accuracy': 0.638179361820221, 'precision': 0.668749988079071, 'recall': 0.5510978698730469, 'auc': 0.6779563426971436} \n",
            "230/689 [=========>....................] - ETA: 45s - loss: 0.6406 - tp: 2033.0000 - fp: 1007.0000 - tn: 2664.0000 - fn: 1656.0000 - accuracy: 0.6382 - precision: 0.6687 - recall: 0.5511 - auc: 0.6780\n",
            " For Batch Number 231 the model has a loss of {'loss': 0.6409346461296082, 'tp': 2035.0, 'fp': 1011.0, 'tn': 2678.0, 'fn': 1668.0, 'accuracy': 0.6375811696052551, 'precision': 0.6680892705917358, 'recall': 0.5495544075965881, 'auc': 0.6774462461471558} \n",
            "231/689 [=========>....................] - ETA: 45s - loss: 0.6409 - tp: 2035.0000 - fp: 1011.0000 - tn: 2678.0000 - fn: 1668.0000 - accuracy: 0.6376 - precision: 0.6681 - recall: 0.5496 - auc: 0.6774\n",
            " For Batch Number 232 the model has a loss of {'loss': 0.6411934494972229, 'tp': 2040.0, 'fp': 1013.0, 'tn': 2693.0, 'fn': 1678.0, 'accuracy': 0.6375269293785095, 'precision': 0.6681951880455017, 'recall': 0.5486820936203003, 'auc': 0.6770959496498108} \n",
            "232/689 [=========>....................] - ETA: 45s - loss: 0.6412 - tp: 2040.0000 - fp: 1013.0000 - tn: 2693.0000 - fn: 1678.0000 - accuracy: 0.6375 - precision: 0.6682 - recall: 0.5487 - auc: 0.6771\n",
            " For Batch Number 233 the model has a loss of {'loss': 0.6408308148384094, 'tp': 2048.0, 'fp': 1015.0, 'tn': 2709.0, 'fn': 1684.0, 'accuracy': 0.6380096673965454, 'precision': 0.66862553358078, 'recall': 0.5487673878669739, 'auc': 0.6776420474052429} \n",
            "233/689 [=========>....................] - ETA: 45s - loss: 0.6408 - tp: 2048.0000 - fp: 1015.0000 - tn: 2709.0000 - fn: 1684.0000 - accuracy: 0.6380 - precision: 0.6686 - recall: 0.5488 - auc: 0.6776\n",
            " For Batch Number 234 the model has a loss of {'loss': 0.6410119533538818, 'tp': 2056.0, 'fp': 1018.0, 'tn': 2720.0, 'fn': 1694.0, 'accuracy': 0.6378205418586731, 'precision': 0.6688354015350342, 'recall': 0.5482666492462158, 'auc': 0.6773389577865601} \n",
            "234/689 [=========>....................] - ETA: 45s - loss: 0.6410 - tp: 2056.0000 - fp: 1018.0000 - tn: 2720.0000 - fn: 1694.0000 - accuracy: 0.6378 - precision: 0.6688 - recall: 0.5483 - auc: 0.6773\n",
            " For Batch Number 235 the model has a loss of {'loss': 0.6408860087394714, 'tp': 2069.0, 'fp': 1020.0, 'tn': 2728.0, 'fn': 1703.0, 'accuracy': 0.6378989219665527, 'precision': 0.6697960495948792, 'recall': 0.5485153794288635, 'auc': 0.6776720285415649} \n",
            "235/689 [=========>....................] - ETA: 44s - loss: 0.6409 - tp: 2069.0000 - fp: 1020.0000 - tn: 2728.0000 - fn: 1703.0000 - accuracy: 0.6379 - precision: 0.6698 - recall: 0.5485 - auc: 0.6777\n",
            " For Batch Number 236 the model has a loss of {'loss': 0.6408765316009521, 'tp': 2082.0, 'fp': 1028.0, 'tn': 2736.0, 'fn': 1706.0, 'accuracy': 0.6379767060279846, 'precision': 0.6694533824920654, 'recall': 0.5496304035186768, 'auc': 0.6776456236839294} \n",
            "236/689 [=========>....................] - ETA: 44s - loss: 0.6409 - tp: 2082.0000 - fp: 1028.0000 - tn: 2736.0000 - fn: 1706.0000 - accuracy: 0.6380 - precision: 0.6695 - recall: 0.5496 - auc: 0.6776\n",
            " For Batch Number 237 the model has a loss of {'loss': 0.6416253447532654, 'tp': 2094.0, 'fp': 1047.0, 'tn': 2737.0, 'fn': 1706.0, 'accuracy': 0.6369989514350891, 'precision': 0.6666666865348816, 'recall': 0.5510526299476624, 'auc': 0.6767471432685852} \n",
            "237/689 [=========>....................] - ETA: 44s - loss: 0.6416 - tp: 2094.0000 - fp: 1047.0000 - tn: 2737.0000 - fn: 1706.0000 - accuracy: 0.6370 - precision: 0.6667 - recall: 0.5511 - auc: 0.6767\n",
            " For Batch Number 238 the model has a loss of {'loss': 0.6415497064590454, 'tp': 2108.0, 'fp': 1056.0, 'tn': 2742.0, 'fn': 1710.0, 'accuracy': 0.636817216873169, 'precision': 0.6662452816963196, 'recall': 0.5521215200424194, 'auc': 0.6768485903739929} \n",
            "238/689 [=========>....................] - ETA: 44s - loss: 0.6415 - tp: 2108.0000 - fp: 1056.0000 - tn: 2742.0000 - fn: 1710.0000 - accuracy: 0.6368 - precision: 0.6662 - recall: 0.5521 - auc: 0.6768\n",
            " For Batch Number 239 the model has a loss of {'loss': 0.641654372215271, 'tp': 2118.0, 'fp': 1061.0, 'tn': 2753.0, 'fn': 1716.0, 'accuracy': 0.6368985176086426, 'precision': 0.6662472486495972, 'recall': 0.5524256825447083, 'auc': 0.6768350601196289} \n",
            "239/689 [=========>....................] - ETA: 44s - loss: 0.6417 - tp: 2118.0000 - fp: 1061.0000 - tn: 2753.0000 - fn: 1716.0000 - accuracy: 0.6369 - precision: 0.6662 - recall: 0.5524 - auc: 0.6768\n",
            " For Batch Number 240 the model has a loss of {'loss': 0.6413365006446838, 'tp': 2127.0, 'fp': 1064.0, 'tn': 2765.0, 'fn': 1724.0, 'accuracy': 0.6369791626930237, 'precision': 0.6665621995925903, 'recall': 0.5523240566253662, 'auc': 0.6772499084472656} \n",
            "240/689 [=========>....................] - ETA: 44s - loss: 0.6413 - tp: 2127.0000 - fp: 1064.0000 - tn: 2765.0000 - fn: 1724.0000 - accuracy: 0.6370 - precision: 0.6666 - recall: 0.5523 - auc: 0.6772\n",
            " For Batch Number 241 the model has a loss of {'loss': 0.6414145231246948, 'tp': 2134.0, 'fp': 1068.0, 'tn': 2778.0, 'fn': 1732.0, 'accuracy': 0.636929452419281, 'precision': 0.6664584875106812, 'recall': 0.5519917011260986, 'auc': 0.6770108938217163} \n",
            "241/689 [=========>....................] - ETA: 44s - loss: 0.6414 - tp: 2134.0000 - fp: 1068.0000 - tn: 2778.0000 - fn: 1732.0000 - accuracy: 0.6369 - precision: 0.6665 - recall: 0.5520 - auc: 0.6770\n",
            " For Batch Number 242 the model has a loss of {'loss': 0.6414769887924194, 'tp': 2142.0, 'fp': 1070.0, 'tn': 2791.0, 'fn': 1741.0, 'accuracy': 0.63700932264328, 'precision': 0.6668742299079895, 'recall': 0.5516353249549866, 'auc': 0.6768654584884644} \n",
            "242/689 [=========>....................] - ETA: 44s - loss: 0.6415 - tp: 2142.0000 - fp: 1070.0000 - tn: 2791.0000 - fn: 1741.0000 - accuracy: 0.6370 - precision: 0.6669 - recall: 0.5516 - auc: 0.6769\n",
            " For Batch Number 243 the model has a loss of {'loss': 0.6416957974433899, 'tp': 2148.0, 'fp': 1074.0, 'tn': 2804.0, 'fn': 1750.0, 'accuracy': 0.6368312835693359, 'precision': 0.6666666865348816, 'recall': 0.5510517954826355, 'auc': 0.676578938961029} \n",
            "243/689 [=========>....................] - ETA: 44s - loss: 0.6417 - tp: 2148.0000 - fp: 1074.0000 - tn: 2804.0000 - fn: 1750.0000 - accuracy: 0.6368 - precision: 0.6667 - recall: 0.5511 - auc: 0.6766\n",
            " For Batch Number 244 the model has a loss of {'loss': 0.64180988073349, 'tp': 2155.0, 'fp': 1076.0, 'tn': 2816.0, 'fn': 1761.0, 'accuracy': 0.6366547346115112, 'precision': 0.6669761538505554, 'recall': 0.5503064393997192, 'auc': 0.6765738725662231} \n",
            "244/689 [=========>....................] - ETA: 43s - loss: 0.6418 - tp: 2155.0000 - fp: 1076.0000 - tn: 2816.0000 - fn: 1761.0000 - accuracy: 0.6367 - precision: 0.6670 - recall: 0.5503 - auc: 0.6766\n",
            " For Batch Number 245 the model has a loss of {'loss': 0.6419581770896912, 'tp': 2163.0, 'fp': 1079.0, 'tn': 2826.0, 'fn': 1772.0, 'accuracy': 0.6363520622253418, 'precision': 0.6671807765960693, 'recall': 0.5496823191642761, 'auc': 0.6762665510177612} \n",
            "245/689 [=========>....................] - ETA: 43s - loss: 0.6420 - tp: 2163.0000 - fp: 1079.0000 - tn: 2826.0000 - fn: 1772.0000 - accuracy: 0.6364 - precision: 0.6672 - recall: 0.5497 - auc: 0.6763\n",
            " For Batch Number 246 the model has a loss of {'loss': 0.6415913701057434, 'tp': 2174.0, 'fp': 1080.0, 'tn': 2839.0, 'fn': 1779.0, 'accuracy': 0.6368139982223511, 'precision': 0.6681007742881775, 'recall': 0.549962043762207, 'auc': 0.6767555475234985} \n",
            "246/689 [=========>....................] - ETA: 43s - loss: 0.6416 - tp: 2174.0000 - fp: 1080.0000 - tn: 2839.0000 - fn: 1779.0000 - accuracy: 0.6368 - precision: 0.6681 - recall: 0.5500 - auc: 0.6768\n",
            " For Batch Number 247 the model has a loss of {'loss': 0.6417030096054077, 'tp': 2184.0, 'fp': 1088.0, 'tn': 2850.0, 'fn': 1782.0, 'accuracy': 0.6368927359580994, 'precision': 0.6674816608428955, 'recall': 0.5506808161735535, 'auc': 0.6766329407691956} \n",
            "247/689 [=========>....................] - ETA: 43s - loss: 0.6417 - tp: 2184.0000 - fp: 1088.0000 - tn: 2850.0000 - fn: 1782.0000 - accuracy: 0.6369 - precision: 0.6675 - recall: 0.5507 - auc: 0.6766\n",
            " For Batch Number 248 the model has a loss of {'loss': 0.6416837573051453, 'tp': 2193.0, 'fp': 1097.0, 'tn': 2860.0, 'fn': 1786.0, 'accuracy': 0.63671875, 'precision': 0.6665653586387634, 'recall': 0.5511435270309448, 'auc': 0.6764726638793945} \n",
            "248/689 [=========>....................] - ETA: 43s - loss: 0.6417 - tp: 2193.0000 - fp: 1097.0000 - tn: 2860.0000 - fn: 1786.0000 - accuracy: 0.6367 - precision: 0.6666 - recall: 0.5511 - auc: 0.6765\n",
            " For Batch Number 249 the model has a loss of {'loss': 0.6417633891105652, 'tp': 2204.0, 'fp': 1102.0, 'tn': 2869.0, 'fn': 1793.0, 'accuracy': 0.6366716623306274, 'precision': 0.6666666865348816, 'recall': 0.5514135360717773, 'auc': 0.6766401529312134} \n",
            "249/689 [=========>....................] - ETA: 43s - loss: 0.6418 - tp: 2204.0000 - fp: 1102.0000 - tn: 2869.0000 - fn: 1793.0000 - accuracy: 0.6367 - precision: 0.6667 - recall: 0.5514 - auc: 0.6766\n",
            " For Batch Number 250 the model has a loss of {'loss': 0.6418552398681641, 'tp': 2215.0, 'fp': 1107.0, 'tn': 2878.0, 'fn': 1800.0, 'accuracy': 0.6366249918937683, 'precision': 0.6667670011520386, 'recall': 0.5516812205314636, 'auc': 0.6765315532684326} \n",
            "250/689 [=========>....................] - ETA: 43s - loss: 0.6419 - tp: 2215.0000 - fp: 1107.0000 - tn: 2878.0000 - fn: 1800.0000 - accuracy: 0.6366 - precision: 0.6668 - recall: 0.5517 - auc: 0.6765\n",
            " For Batch Number 251 the model has a loss of {'loss': 0.6416256427764893, 'tp': 2224.0, 'fp': 1111.0, 'tn': 2890.0, 'fn': 1807.0, 'accuracy': 0.6367031931877136, 'precision': 0.6668665409088135, 'recall': 0.5517241358757019, 'auc': 0.6767147183418274} \n",
            "251/689 [=========>....................] - ETA: 43s - loss: 0.6416 - tp: 2224.0000 - fp: 1111.0000 - tn: 2890.0000 - fn: 1807.0000 - accuracy: 0.6367 - precision: 0.6669 - recall: 0.5517 - auc: 0.6767\n",
            " For Batch Number 252 the model has a loss of {'loss': 0.641944944858551, 'tp': 2231.0, 'fp': 1114.0, 'tn': 2902.0, 'fn': 1817.0, 'accuracy': 0.636532723903656, 'precision': 0.6669656038284302, 'recall': 0.5511363744735718, 'auc': 0.6764581203460693} \n",
            "252/689 [=========>....................] - ETA: 43s - loss: 0.6419 - tp: 2231.0000 - fp: 1114.0000 - tn: 2902.0000 - fn: 1817.0000 - accuracy: 0.6365 - precision: 0.6670 - recall: 0.5511 - auc: 0.6765\n",
            " For Batch Number 253 the model has a loss of {'loss': 0.6420571804046631, 'tp': 2237.0, 'fp': 1119.0, 'tn': 2915.0, 'fn': 1825.0, 'accuracy': 0.6363636255264282, 'precision': 0.666567325592041, 'recall': 0.5507139563560486, 'auc': 0.6763384342193604} \n",
            "253/689 [==========>...................] - ETA: 43s - loss: 0.6421 - tp: 2237.0000 - fp: 1119.0000 - tn: 2915.0000 - fn: 1825.0000 - accuracy: 0.6364 - precision: 0.6666 - recall: 0.5507 - auc: 0.6763\n",
            " For Batch Number 254 the model has a loss of {'loss': 0.6418808102607727, 'tp': 2244.0, 'fp': 1124.0, 'tn': 2930.0, 'fn': 1830.0, 'accuracy': 0.6365649700164795, 'precision': 0.6662707924842834, 'recall': 0.5508100390434265, 'auc': 0.6765143275260925} \n",
            "254/689 [==========>...................] - ETA: 42s - loss: 0.6419 - tp: 2244.0000 - fp: 1124.0000 - tn: 2930.0000 - fn: 1830.0000 - accuracy: 0.6366 - precision: 0.6663 - recall: 0.5508 - auc: 0.6765\n",
            " For Batch Number 255 the model has a loss of {'loss': 0.6416991353034973, 'tp': 2251.0, 'fp': 1128.0, 'tn': 2948.0, 'fn': 1833.0, 'accuracy': 0.6371323466300964, 'precision': 0.6661733984947205, 'recall': 0.5511752963066101, 'auc': 0.6768923997879028} \n",
            "255/689 [==========>...................] - ETA: 42s - loss: 0.6417 - tp: 2251.0000 - fp: 1128.0000 - tn: 2948.0000 - fn: 1833.0000 - accuracy: 0.6371 - precision: 0.6662 - recall: 0.5512 - auc: 0.6769\n",
            " For Batch Number 256 the model has a loss of {'loss': 0.6418291330337524, 'tp': 2260.0, 'fp': 1130.0, 'tn': 2957.0, 'fn': 1845.0, 'accuracy': 0.6368408203125, 'precision': 0.6666666865348816, 'recall': 0.5505481362342834, 'auc': 0.6766994595527649} \n",
            "256/689 [==========>...................] - ETA: 42s - loss: 0.6418 - tp: 2260.0000 - fp: 1130.0000 - tn: 2957.0000 - fn: 1845.0000 - accuracy: 0.6368 - precision: 0.6667 - recall: 0.5505 - auc: 0.6767\n",
            " For Batch Number 257 the model has a loss of {'loss': 0.6417614221572876, 'tp': 2269.0, 'fp': 1131.0, 'tn': 2969.0, 'fn': 1855.0, 'accuracy': 0.6369163393974304, 'precision': 0.6673529148101807, 'recall': 0.5501939654350281, 'auc': 0.6767628192901611} \n",
            "257/689 [==========>...................] - ETA: 42s - loss: 0.6418 - tp: 2269.0000 - fp: 1131.0000 - tn: 2969.0000 - fn: 1855.0000 - accuracy: 0.6369 - precision: 0.6674 - recall: 0.5502 - auc: 0.6768\n",
            " For Batch Number 258 the model has a loss of {'loss': 0.6415681838989258, 'tp': 2276.0, 'fp': 1133.0, 'tn': 2982.0, 'fn': 1865.0, 'accuracy': 0.6368701457977295, 'precision': 0.6676444411277771, 'recall': 0.5496256947517395, 'auc': 0.6769530177116394} \n",
            "258/689 [==========>...................] - ETA: 42s - loss: 0.6416 - tp: 2276.0000 - fp: 1133.0000 - tn: 2982.0000 - fn: 1865.0000 - accuracy: 0.6369 - precision: 0.6676 - recall: 0.5496 - auc: 0.6770\n",
            " For Batch Number 259 the model has a loss of {'loss': 0.6416910886764526, 'tp': 2285.0, 'fp': 1137.0, 'tn': 2993.0, 'fn': 1873.0, 'accuracy': 0.6368243098258972, 'precision': 0.667738139629364, 'recall': 0.549543023109436, 'auc': 0.6767871379852295} \n",
            "259/689 [==========>...................] - ETA: 42s - loss: 0.6417 - tp: 2285.0000 - fp: 1137.0000 - tn: 2993.0000 - fn: 1873.0000 - accuracy: 0.6368 - precision: 0.6677 - recall: 0.5495 - auc: 0.6768\n",
            " For Batch Number 260 the model has a loss of {'loss': 0.6414406299591064, 'tp': 2295.0, 'fp': 1142.0, 'tn': 3006.0, 'fn': 1877.0, 'accuracy': 0.6371394395828247, 'precision': 0.6677334904670715, 'recall': 0.5500958561897278, 'auc': 0.6770678162574768} \n",
            "260/689 [==========>...................] - ETA: 42s - loss: 0.6414 - tp: 2295.0000 - fp: 1142.0000 - tn: 3006.0000 - fn: 1877.0000 - accuracy: 0.6371 - precision: 0.6677 - recall: 0.5501 - auc: 0.6771\n",
            " For Batch Number 261 the model has a loss of {'loss': 0.6413698196411133, 'tp': 2306.0, 'fp': 1146.0, 'tn': 3016.0, 'fn': 1884.0, 'accuracy': 0.6372126340866089, 'precision': 0.6680185198783875, 'recall': 0.55035799741745, 'auc': 0.6772363781929016} \n",
            "261/689 [==========>...................] - ETA: 42s - loss: 0.6414 - tp: 2306.0000 - fp: 1146.0000 - tn: 3016.0000 - fn: 1884.0000 - accuracy: 0.6372 - precision: 0.6680 - recall: 0.5504 - auc: 0.6772\n",
            " For Batch Number 262 the model has a loss of {'loss': 0.6417056918144226, 'tp': 2313.0, 'fp': 1154.0, 'tn': 3027.0, 'fn': 1890.0, 'accuracy': 0.6369274854660034, 'precision': 0.6671473979949951, 'recall': 0.5503212213516235, 'auc': 0.6768651008605957} \n",
            "262/689 [==========>...................] - ETA: 42s - loss: 0.6417 - tp: 2313.0000 - fp: 1154.0000 - tn: 3027.0000 - fn: 1890.0000 - accuracy: 0.6369 - precision: 0.6671 - recall: 0.5503 - auc: 0.6769\n",
            " For Batch Number 263 the model has a loss of {'loss': 0.6417779922485352, 'tp': 2321.0, 'fp': 1160.0, 'tn': 3041.0, 'fn': 1894.0, 'accuracy': 0.6371197700500488, 'precision': 0.6667624115943909, 'recall': 0.5506524443626404, 'auc': 0.6767998337745667} \n",
            "263/689 [==========>...................] - ETA: 42s - loss: 0.6418 - tp: 2321.0000 - fp: 1160.0000 - tn: 3041.0000 - fn: 1894.0000 - accuracy: 0.6371 - precision: 0.6668 - recall: 0.5507 - auc: 0.6768\n",
            " For Batch Number 264 the model has a loss of {'loss': 0.6417202949523926, 'tp': 2329.0, 'fp': 1164.0, 'tn': 3052.0, 'fn': 1903.0, 'accuracy': 0.6369554996490479, 'precision': 0.666762113571167, 'recall': 0.5503308176994324, 'auc': 0.6768068671226501} \n",
            "264/689 [==========>...................] - ETA: 41s - loss: 0.6417 - tp: 2329.0000 - fp: 1164.0000 - tn: 3052.0000 - fn: 1903.0000 - accuracy: 0.6370 - precision: 0.6668 - recall: 0.5503 - auc: 0.6768\n",
            " For Batch Number 265 the model has a loss of {'loss': 0.6416817903518677, 'tp': 2337.0, 'fp': 1169.0, 'tn': 3062.0, 'fn': 1912.0, 'accuracy': 0.6366745233535767, 'precision': 0.6665716171264648, 'recall': 0.5500117540359497, 'auc': 0.6769352555274963} \n",
            "265/689 [==========>...................] - ETA: 41s - loss: 0.6417 - tp: 2337.0000 - fp: 1169.0000 - tn: 3062.0000 - fn: 1912.0000 - accuracy: 0.6367 - precision: 0.6666 - recall: 0.5500 - auc: 0.6769\n",
            " For Batch Number 266 the model has a loss of {'loss': 0.6419264674186707, 'tp': 2342.0, 'fp': 1171.0, 'tn': 3075.0, 'fn': 1924.0, 'accuracy': 0.6363956928253174, 'precision': 0.6666666865348816, 'recall': 0.5489920377731323, 'auc': 0.6767164468765259} \n",
            "266/689 [==========>...................] - ETA: 41s - loss: 0.6419 - tp: 2342.0000 - fp: 1171.0000 - tn: 3075.0000 - fn: 1924.0000 - accuracy: 0.6364 - precision: 0.6667 - recall: 0.5490 - auc: 0.6767\n",
            " For Batch Number 267 the model has a loss of {'loss': 0.6419649124145508, 'tp': 2347.0, 'fp': 1175.0, 'tn': 3089.0, 'fn': 1933.0, 'accuracy': 0.6362359523773193, 'precision': 0.6663827300071716, 'recall': 0.5483644604682922, 'auc': 0.6767261624336243} \n",
            "267/689 [==========>...................] - ETA: 41s - loss: 0.6420 - tp: 2347.0000 - fp: 1175.0000 - tn: 3089.0000 - fn: 1933.0000 - accuracy: 0.6362 - precision: 0.6664 - recall: 0.5484 - auc: 0.6767\n",
            " For Batch Number 268 the model has a loss of {'loss': 0.641977071762085, 'tp': 2356.0, 'fp': 1180.0, 'tn': 3101.0, 'fn': 1939.0, 'accuracy': 0.6363106369972229, 'precision': 0.6662895679473877, 'recall': 0.5485448241233826, 'auc': 0.6767935752868652} \n",
            "268/689 [==========>...................] - ETA: 41s - loss: 0.6420 - tp: 2356.0000 - fp: 1180.0000 - tn: 3101.0000 - fn: 1939.0000 - accuracy: 0.6363 - precision: 0.6663 - recall: 0.5485 - auc: 0.6768\n",
            " For Batch Number 269 the model has a loss of {'loss': 0.6416227221488953, 'tp': 2369.0, 'fp': 1183.0, 'tn': 3113.0, 'fn': 1943.0, 'accuracy': 0.6368494629859924, 'precision': 0.6669481992721558, 'recall': 0.5493970513343811, 'auc': 0.6774268746376038} \n",
            "269/689 [==========>...................] - ETA: 41s - loss: 0.6416 - tp: 2369.0000 - fp: 1183.0000 - tn: 3113.0000 - fn: 1943.0000 - accuracy: 0.6368 - precision: 0.6669 - recall: 0.5494 - auc: 0.6774\n",
            " For Batch Number 270 the model has a loss of {'loss': 0.641435980796814, 'tp': 2379.0, 'fp': 1185.0, 'tn': 3125.0, 'fn': 1951.0, 'accuracy': 0.6370370388031006, 'precision': 0.6675084233283997, 'recall': 0.5494226217269897, 'auc': 0.677702784538269} \n",
            "270/689 [==========>...................] - ETA: 41s - loss: 0.6414 - tp: 2379.0000 - fp: 1185.0000 - tn: 3125.0000 - fn: 1951.0000 - accuracy: 0.6370 - precision: 0.6675 - recall: 0.5494 - auc: 0.6777\n",
            " For Batch Number 271 the model has a loss of {'loss': 0.6414207220077515, 'tp': 2388.0, 'fp': 1188.0, 'tn': 3135.0, 'fn': 1961.0, 'accuracy': 0.6368772983551025, 'precision': 0.6677852272987366, 'recall': 0.5490917563438416, 'auc': 0.677772045135498} \n",
            "271/689 [==========>...................] - ETA: 41s - loss: 0.6414 - tp: 2388.0000 - fp: 1188.0000 - tn: 3135.0000 - fn: 1961.0000 - accuracy: 0.6369 - precision: 0.6678 - recall: 0.5491 - auc: 0.6778\n",
            " For Batch Number 272 the model has a loss of {'loss': 0.6411823034286499, 'tp': 2402.0, 'fp': 1191.0, 'tn': 3145.0, 'fn': 1966.0, 'accuracy': 0.6372932195663452, 'precision': 0.6685221195220947, 'recall': 0.5499083995819092, 'auc': 0.6781551241874695} \n",
            "272/689 [==========>...................] - ETA: 41s - loss: 0.6412 - tp: 2402.0000 - fp: 1191.0000 - tn: 3145.0000 - fn: 1966.0000 - accuracy: 0.6373 - precision: 0.6685 - recall: 0.5499 - auc: 0.6782\n",
            " For Batch Number 273 the model has a loss of {'loss': 0.6409313082695007, 'tp': 2414.0, 'fp': 1196.0, 'tn': 3157.0, 'fn': 1969.0, 'accuracy': 0.6377060413360596, 'precision': 0.6686980724334717, 'recall': 0.5507643222808838, 'auc': 0.6784862279891968} \n",
            "273/689 [==========>...................] - ETA: 41s - loss: 0.6409 - tp: 2414.0000 - fp: 1196.0000 - tn: 3157.0000 - fn: 1969.0000 - accuracy: 0.6377 - precision: 0.6687 - recall: 0.5508 - auc: 0.6785\n",
            " For Batch Number 274 the model has a loss of {'loss': 0.6410890221595764, 'tp': 2423.0, 'fp': 1204.0, 'tn': 3165.0, 'fn': 1976.0, 'accuracy': 0.6373175382614136, 'precision': 0.6680452227592468, 'recall': 0.550806999206543, 'auc': 0.6782047152519226} \n",
            "274/689 [==========>...................] - ETA: 41s - loss: 0.6411 - tp: 2423.0000 - fp: 1204.0000 - tn: 3165.0000 - fn: 1976.0000 - accuracy: 0.6373 - precision: 0.6680 - recall: 0.5508 - auc: 0.6782\n",
            " For Batch Number 275 the model has a loss of {'loss': 0.6411537528038025, 'tp': 2433.0, 'fp': 1212.0, 'tn': 3174.0, 'fn': 1981.0, 'accuracy': 0.6371591091156006, 'precision': 0.6674897074699402, 'recall': 0.5512007474899292, 'auc': 0.6781584620475769} \n",
            "275/689 [==========>...................] - ETA: 41s - loss: 0.6412 - tp: 2433.0000 - fp: 1212.0000 - tn: 3174.0000 - fn: 1981.0000 - accuracy: 0.6372 - precision: 0.6675 - recall: 0.5512 - auc: 0.6782\n",
            " For Batch Number 276 the model has a loss of {'loss': 0.6408186554908752, 'tp': 2445.0, 'fp': 1214.0, 'tn': 3183.0, 'fn': 1990.0, 'accuracy': 0.63722825050354, 'precision': 0.6682153344154358, 'recall': 0.5512965321540833, 'auc': 0.6785038709640503} \n",
            "276/689 [===========>..................] - ETA: 41s - loss: 0.6408 - tp: 2445.0000 - fp: 1214.0000 - tn: 3183.0000 - fn: 1990.0000 - accuracy: 0.6372 - precision: 0.6682 - recall: 0.5513 - auc: 0.6785\n",
            " For Batch Number 277 the model has a loss of {'loss': 0.6413766145706177, 'tp': 2449.0, 'fp': 1227.0, 'tn': 3195.0, 'fn': 1993.0, 'accuracy': 0.6367328763008118, 'precision': 0.6662132740020752, 'recall': 0.5513282418251038, 'auc': 0.6781495213508606} \n",
            "277/689 [===========>..................] - ETA: 41s - loss: 0.6414 - tp: 2449.0000 - fp: 1227.0000 - tn: 3195.0000 - fn: 1993.0000 - accuracy: 0.6367 - precision: 0.6662 - recall: 0.5513 - auc: 0.6781\n",
            " For Batch Number 278 the model has a loss of {'loss': 0.6410707831382751, 'tp': 2461.0, 'fp': 1230.0, 'tn': 3207.0, 'fn': 1998.0, 'accuracy': 0.6371402740478516, 'precision': 0.6667569875717163, 'recall': 0.5519174933433533, 'auc': 0.678464412689209} \n",
            "278/689 [===========>..................] - ETA: 41s - loss: 0.6411 - tp: 2461.0000 - fp: 1230.0000 - tn: 3207.0000 - fn: 1998.0000 - accuracy: 0.6371 - precision: 0.6668 - recall: 0.5519 - auc: 0.6785\n",
            " For Batch Number 279 the model has a loss of {'loss': 0.6416239738464355, 'tp': 2468.0, 'fp': 1238.0, 'tn': 3214.0, 'fn': 2008.0, 'accuracy': 0.636424720287323, 'precision': 0.6659471392631531, 'recall': 0.5513851642608643, 'auc': 0.6776002645492554} \n",
            "279/689 [===========>..................] - ETA: 41s - loss: 0.6416 - tp: 2468.0000 - fp: 1238.0000 - tn: 3214.0000 - fn: 2008.0000 - accuracy: 0.6364 - precision: 0.6659 - recall: 0.5514 - auc: 0.6776\n",
            " For Batch Number 280 the model has a loss of {'loss': 0.6412412524223328, 'tp': 2477.0, 'fp': 1240.0, 'tn': 3229.0, 'fn': 2014.0, 'accuracy': 0.6368303298950195, 'precision': 0.6663976311683655, 'recall': 0.5515475273132324, 'auc': 0.6781113147735596} \n",
            "280/689 [===========>..................] - ETA: 41s - loss: 0.6412 - tp: 2477.0000 - fp: 1240.0000 - tn: 3229.0000 - fn: 2014.0000 - accuracy: 0.6368 - precision: 0.6664 - recall: 0.5515 - auc: 0.6781\n",
            " For Batch Number 281 the model has a loss of {'loss': 0.6409358978271484, 'tp': 2485.0, 'fp': 1241.0, 'tn': 3244.0, 'fn': 2022.0, 'accuracy': 0.6371219158172607, 'precision': 0.6669350266456604, 'recall': 0.551364541053772, 'auc': 0.678429901599884} \n",
            "281/689 [===========>..................] - ETA: 41s - loss: 0.6409 - tp: 2485.0000 - fp: 1241.0000 - tn: 3244.0000 - fn: 2022.0000 - accuracy: 0.6371 - precision: 0.6669 - recall: 0.5514 - auc: 0.6784\n",
            " For Batch Number 282 the model has a loss of {'loss': 0.6408536434173584, 'tp': 2493.0, 'fp': 1244.0, 'tn': 3257.0, 'fn': 2030.0, 'accuracy': 0.6371897459030151, 'precision': 0.6671126484870911, 'recall': 0.5511828660964966, 'auc': 0.6785463690757751} \n",
            "282/689 [===========>..................] - ETA: 41s - loss: 0.6409 - tp: 2493.0000 - fp: 1244.0000 - tn: 3257.0000 - fn: 2030.0000 - accuracy: 0.6372 - precision: 0.6671 - recall: 0.5512 - auc: 0.6785\n",
            " For Batch Number 283 the model has a loss of {'loss': 0.6407119631767273, 'tp': 2501.0, 'fp': 1248.0, 'tn': 3272.0, 'fn': 2035.0, 'accuracy': 0.6374779343605042, 'precision': 0.6671112179756165, 'recall': 0.5513668656349182, 'auc': 0.6787723898887634} \n",
            "283/689 [===========>..................] - ETA: 41s - loss: 0.6407 - tp: 2501.0000 - fp: 1248.0000 - tn: 3272.0000 - fn: 2035.0000 - accuracy: 0.6375 - precision: 0.6671 - recall: 0.5514 - auc: 0.6788\n",
            " For Batch Number 284 the model has a loss of {'loss': 0.6404996514320374, 'tp': 2514.0, 'fp': 1249.0, 'tn': 3284.0, 'fn': 2041.0, 'accuracy': 0.6379841566085815, 'precision': 0.6680839657783508, 'recall': 0.5519209504127502, 'auc': 0.6790257096290588} \n",
            "284/689 [===========>..................] - ETA: 41s - loss: 0.6405 - tp: 2514.0000 - fp: 1249.0000 - tn: 3284.0000 - fn: 2041.0000 - accuracy: 0.6380 - precision: 0.6681 - recall: 0.5519 - auc: 0.6790\n",
            " For Batch Number 285 the model has a loss of {'loss': 0.6404200792312622, 'tp': 2522.0, 'fp': 1256.0, 'tn': 3296.0, 'fn': 2046.0, 'accuracy': 0.6379386186599731, 'precision': 0.6675489544868469, 'recall': 0.5521015524864197, 'auc': 0.6792569160461426} \n",
            "285/689 [===========>..................] - ETA: 41s - loss: 0.6404 - tp: 2522.0000 - fp: 1256.0000 - tn: 3296.0000 - fn: 2046.0000 - accuracy: 0.6379 - precision: 0.6675 - recall: 0.5521 - auc: 0.6793\n",
            " For Batch Number 286 the model has a loss of {'loss': 0.6404997706413269, 'tp': 2532.0, 'fp': 1260.0, 'tn': 3304.0, 'fn': 2056.0, 'accuracy': 0.6376748085021973, 'precision': 0.6677215099334717, 'recall': 0.5518744587898254, 'auc': 0.6790241599082947} \n",
            "286/689 [===========>..................] - ETA: 41s - loss: 0.6405 - tp: 2532.0000 - fp: 1260.0000 - tn: 3304.0000 - fn: 2056.0000 - accuracy: 0.6377 - precision: 0.6677 - recall: 0.5519 - auc: 0.6790\n",
            " For Batch Number 287 the model has a loss of {'loss': 0.6401143074035645, 'tp': 2547.0, 'fp': 1263.0, 'tn': 3316.0, 'fn': 2058.0, 'accuracy': 0.6383928656578064, 'precision': 0.6685039401054382, 'recall': 0.5530944466590881, 'auc': 0.6795831322669983} \n",
            "287/689 [===========>..................] - ETA: 41s - loss: 0.6401 - tp: 2547.0000 - fp: 1263.0000 - tn: 3316.0000 - fn: 2058.0000 - accuracy: 0.6384 - precision: 0.6685 - recall: 0.5531 - auc: 0.6796\n",
            " For Batch Number 288 the model has a loss of {'loss': 0.6400907039642334, 'tp': 2560.0, 'fp': 1273.0, 'tn': 3323.0, 'fn': 2060.0, 'accuracy': 0.6383463740348816, 'precision': 0.6678841710090637, 'recall': 0.5541125535964966, 'auc': 0.6796852350234985} \n",
            "288/689 [===========>..................] - ETA: 41s - loss: 0.6401 - tp: 2560.0000 - fp: 1273.0000 - tn: 3323.0000 - fn: 2060.0000 - accuracy: 0.6383 - precision: 0.6679 - recall: 0.5541 - auc: 0.6797\n",
            " For Batch Number 289 the model has a loss of {'loss': 0.6397729516029358, 'tp': 2572.0, 'fp': 1280.0, 'tn': 3334.0, 'fn': 2062.0, 'accuracy': 0.6386245489120483, 'precision': 0.6677050590515137, 'recall': 0.5550280809402466, 'auc': 0.6800146698951721} \n",
            "289/689 [===========>..................] - ETA: 41s - loss: 0.6398 - tp: 2572.0000 - fp: 1280.0000 - tn: 3334.0000 - fn: 2062.0000 - accuracy: 0.6386 - precision: 0.6677 - recall: 0.5550 - auc: 0.6800\n",
            " For Batch Number 290 the model has a loss of {'loss': 0.6394148468971252, 'tp': 2579.0, 'fp': 1288.0, 'tn': 3350.0, 'fn': 2063.0, 'accuracy': 0.638900876045227, 'precision': 0.6669252514839172, 'recall': 0.5555794835090637, 'auc': 0.6803544163703918} \n",
            "290/689 [===========>..................] - ETA: 41s - loss: 0.6394 - tp: 2579.0000 - fp: 1288.0000 - tn: 3350.0000 - fn: 2063.0000 - accuracy: 0.6389 - precision: 0.6669 - recall: 0.5556 - auc: 0.6804\n",
            " For Batch Number 291 the model has a loss of {'loss': 0.6396860480308533, 'tp': 2586.0, 'fp': 1291.0, 'tn': 3361.0, 'fn': 2074.0, 'accuracy': 0.6386383175849915, 'precision': 0.6670105457305908, 'recall': 0.5549356341362, 'auc': 0.6799721121788025} \n",
            "291/689 [===========>..................] - ETA: 40s - loss: 0.6397 - tp: 2586.0000 - fp: 1291.0000 - tn: 3361.0000 - fn: 2074.0000 - accuracy: 0.6386 - precision: 0.6670 - recall: 0.5549 - auc: 0.6800\n",
            " For Batch Number 292 the model has a loss of {'loss': 0.639390766620636, 'tp': 2594.0, 'fp': 1293.0, 'tn': 3376.0, 'fn': 2081.0, 'accuracy': 0.6389126777648926, 'precision': 0.6673527359962463, 'recall': 0.5548663139343262, 'auc': 0.6804152131080627} \n",
            "292/689 [===========>..................] - ETA: 40s - loss: 0.6394 - tp: 2594.0000 - fp: 1293.0000 - tn: 3376.0000 - fn: 2081.0000 - accuracy: 0.6389 - precision: 0.6674 - recall: 0.5549 - auc: 0.6804\n",
            " For Batch Number 293 the model has a loss of {'loss': 0.6394305229187012, 'tp': 2601.0, 'fp': 1295.0, 'tn': 3389.0, 'fn': 2091.0, 'accuracy': 0.6388651728630066, 'precision': 0.6676077842712402, 'recall': 0.554347813129425, 'auc': 0.6804513931274414} \n",
            "293/689 [===========>..................] - ETA: 40s - loss: 0.6394 - tp: 2601.0000 - fp: 1295.0000 - tn: 3389.0000 - fn: 2091.0000 - accuracy: 0.6389 - precision: 0.6676 - recall: 0.5543 - auc: 0.6805\n",
            " For Batch Number 294 the model has a loss of {'loss': 0.6395668983459473, 'tp': 2610.0, 'fp': 1298.0, 'tn': 3398.0, 'fn': 2102.0, 'accuracy': 0.6386054158210754, 'precision': 0.6678608059883118, 'recall': 0.5539049506187439, 'auc': 0.6803310513496399} \n",
            "294/689 [===========>..................] - ETA: 40s - loss: 0.6396 - tp: 2610.0000 - fp: 1298.0000 - tn: 3398.0000 - fn: 2102.0000 - accuracy: 0.6386 - precision: 0.6679 - recall: 0.5539 - auc: 0.6803\n",
            " For Batch Number 295 the model has a loss of {'loss': 0.6394834518432617, 'tp': 2620.0, 'fp': 1302.0, 'tn': 3411.0, 'fn': 2107.0, 'accuracy': 0.6388770937919617, 'precision': 0.6680265069007874, 'recall': 0.5542627573013306, 'auc': 0.6803894639015198} \n",
            "295/689 [===========>..................] - ETA: 40s - loss: 0.6395 - tp: 2620.0000 - fp: 1302.0000 - tn: 3411.0000 - fn: 2107.0000 - accuracy: 0.6389 - precision: 0.6680 - recall: 0.5543 - auc: 0.6804\n",
            " For Batch Number 296 the model has a loss of {'loss': 0.6396176815032959, 'tp': 2632.0, 'fp': 1312.0, 'tn': 3419.0, 'fn': 2109.0, 'accuracy': 0.6388302445411682, 'precision': 0.6673427820205688, 'recall': 0.5551571249961853, 'auc': 0.6802465915679932} \n",
            "296/689 [===========>..................] - ETA: 40s - loss: 0.6396 - tp: 2632.0000 - fp: 1312.0000 - tn: 3419.0000 - fn: 2109.0000 - accuracy: 0.6388 - precision: 0.6673 - recall: 0.5552 - auc: 0.6802\n",
            " For Batch Number 297 the model has a loss of {'loss': 0.6397576332092285, 'tp': 2642.0, 'fp': 1318.0, 'tn': 3431.0, 'fn': 2113.0, 'accuracy': 0.6389940977096558, 'precision': 0.6671717166900635, 'recall': 0.5556256771087646, 'auc': 0.6800932288169861} \n",
            "297/689 [===========>..................] - ETA: 40s - loss: 0.6398 - tp: 2642.0000 - fp: 1318.0000 - tn: 3431.0000 - fn: 2113.0000 - accuracy: 0.6390 - precision: 0.6672 - recall: 0.5556 - auc: 0.6801\n",
            " For Batch Number 298 the model has a loss of {'loss': 0.6401969790458679, 'tp': 2649.0, 'fp': 1325.0, 'tn': 3445.0, 'fn': 2117.0, 'accuracy': 0.6390520334243774, 'precision': 0.6665827631950378, 'recall': 0.5558120012283325, 'auc': 0.6800305247306824} \n",
            "298/689 [===========>..................] - ETA: 40s - loss: 0.6402 - tp: 2649.0000 - fp: 1325.0000 - tn: 3445.0000 - fn: 2117.0000 - accuracy: 0.6391 - precision: 0.6666 - recall: 0.5558 - auc: 0.6800\n",
            " For Batch Number 299 the model has a loss of {'loss': 0.6408630013465881, 'tp': 2658.0, 'fp': 1327.0, 'tn': 3450.0, 'fn': 2133.0, 'accuracy': 0.6383779048919678, 'precision': 0.6670012474060059, 'recall': 0.5547902584075928, 'auc': 0.6789758801460266} \n",
            "299/689 [============>.................] - ETA: 40s - loss: 0.6409 - tp: 2658.0000 - fp: 1327.0000 - tn: 3450.0000 - fn: 2133.0000 - accuracy: 0.6384 - precision: 0.6670 - recall: 0.5548 - auc: 0.6790\n",
            " For Batch Number 300 the model has a loss of {'loss': 0.6404770016670227, 'tp': 2666.0, 'fp': 1328.0, 'tn': 3465.0, 'fn': 2141.0, 'accuracy': 0.6386458277702332, 'precision': 0.6675012707710266, 'recall': 0.5546078681945801, 'auc': 0.6794751286506653} \n",
            "300/689 [============>.................] - ETA: 40s - loss: 0.6405 - tp: 2666.0000 - fp: 1328.0000 - tn: 3465.0000 - fn: 2141.0000 - accuracy: 0.6386 - precision: 0.6675 - recall: 0.5546 - auc: 0.6795\n",
            " For Batch Number 301 the model has a loss of {'loss': 0.6408145427703857, 'tp': 2674.0, 'fp': 1331.0, 'tn': 3477.0, 'fn': 2150.0, 'accuracy': 0.6386004686355591, 'precision': 0.667665421962738, 'recall': 0.5543117523193359, 'auc': 0.6790248155593872} \n",
            "301/689 [============>.................] - ETA: 40s - loss: 0.6408 - tp: 2674.0000 - fp: 1331.0000 - tn: 3477.0000 - fn: 2150.0000 - accuracy: 0.6386 - precision: 0.6677 - recall: 0.5543 - auc: 0.6790\n",
            " For Batch Number 302 the model has a loss of {'loss': 0.6406493782997131, 'tp': 2684.0, 'fp': 1333.0, 'tn': 3490.0, 'fn': 2157.0, 'accuracy': 0.6388658881187439, 'precision': 0.6681603193283081, 'recall': 0.5544309020042419, 'auc': 0.6792914867401123} \n",
            "302/689 [============>.................] - ETA: 39s - loss: 0.6406 - tp: 2684.0000 - fp: 1333.0000 - tn: 3490.0000 - fn: 2157.0000 - accuracy: 0.6389 - precision: 0.6682 - recall: 0.5544 - auc: 0.6793\n",
            " For Batch Number 303 the model has a loss of {'loss': 0.6403396129608154, 'tp': 2696.0, 'fp': 1333.0, 'tn': 3501.0, 'fn': 2166.0, 'accuracy': 0.6391295194625854, 'precision': 0.6691486835479736, 'recall': 0.5545043349266052, 'auc': 0.6797800064086914} \n",
            "303/689 [============>.................] - ETA: 39s - loss: 0.6403 - tp: 2696.0000 - fp: 1333.0000 - tn: 3501.0000 - fn: 2166.0000 - accuracy: 0.6391 - precision: 0.6691 - recall: 0.5545 - auc: 0.6798\n",
            " For Batch Number 304 the model has a loss of {'loss': 0.6401770710945129, 'tp': 2707.0, 'fp': 1338.0, 'tn': 3513.0, 'fn': 2170.0, 'accuracy': 0.6393914222717285, 'precision': 0.6692212820053101, 'recall': 0.5550543069839478, 'auc': 0.6799655556678772} \n",
            "304/689 [============>.................] - ETA: 39s - loss: 0.6402 - tp: 2707.0000 - fp: 1338.0000 - tn: 3513.0000 - fn: 2170.0000 - accuracy: 0.6394 - precision: 0.6692 - recall: 0.5551 - auc: 0.6800\n",
            " For Batch Number 305 the model has a loss of {'loss': 0.6405588984489441, 'tp': 2715.0, 'fp': 1349.0, 'tn': 3521.0, 'fn': 2175.0, 'accuracy': 0.6389344334602356, 'precision': 0.6680610179901123, 'recall': 0.5552147030830383, 'auc': 0.6794739365577698} \n",
            "305/689 [============>.................] - ETA: 39s - loss: 0.6406 - tp: 2715.0000 - fp: 1349.0000 - tn: 3521.0000 - fn: 2175.0000 - accuracy: 0.6389 - precision: 0.6681 - recall: 0.5552 - auc: 0.6795\n",
            " For Batch Number 306 the model has a loss of {'loss': 0.6410968899726868, 'tp': 2720.0, 'fp': 1360.0, 'tn': 3534.0, 'fn': 2178.0, 'accuracy': 0.6386846303939819, 'precision': 0.6666666865348816, 'recall': 0.5553287267684937, 'auc': 0.6788043975830078} \n",
            "306/689 [============>.................] - ETA: 39s - loss: 0.6411 - tp: 2720.0000 - fp: 1360.0000 - tn: 3534.0000 - fn: 2178.0000 - accuracy: 0.6387 - precision: 0.6667 - recall: 0.5553 - auc: 0.6788\n",
            " For Batch Number 307 the model has a loss of {'loss': 0.6412163376808167, 'tp': 2727.0, 'fp': 1365.0, 'tn': 3546.0, 'fn': 2186.0, 'accuracy': 0.6385383009910583, 'precision': 0.6664223074913025, 'recall': 0.5550580024719238, 'auc': 0.6785810589790344} \n",
            "307/689 [============>.................] - ETA: 39s - loss: 0.6412 - tp: 2727.0000 - fp: 1365.0000 - tn: 3546.0000 - fn: 2186.0000 - accuracy: 0.6385 - precision: 0.6664 - recall: 0.5551 - auc: 0.6786\n",
            " For Batch Number 308 the model has a loss of {'loss': 0.6414307951927185, 'tp': 2733.0, 'fp': 1368.0, 'tn': 3560.0, 'fn': 2195.0, 'accuracy': 0.6384943127632141, 'precision': 0.6664228439331055, 'recall': 0.5545860528945923, 'auc': 0.6784183979034424} \n",
            "308/689 [============>.................] - ETA: 39s - loss: 0.6414 - tp: 2733.0000 - fp: 1368.0000 - tn: 3560.0000 - fn: 2195.0000 - accuracy: 0.6385 - precision: 0.6664 - recall: 0.5546 - auc: 0.6784\n",
            " For Batch Number 309 the model has a loss of {'loss': 0.6415069103240967, 'tp': 2739.0, 'fp': 1370.0, 'tn': 3572.0, 'fn': 2207.0, 'accuracy': 0.6382483839988708, 'precision': 0.6665855646133423, 'recall': 0.5537808537483215, 'auc': 0.6783168911933899} \n",
            "309/689 [============>.................] - ETA: 39s - loss: 0.6415 - tp: 2739.0000 - fp: 1370.0000 - tn: 3572.0000 - fn: 2207.0000 - accuracy: 0.6382 - precision: 0.6666 - recall: 0.5538 - auc: 0.6783\n",
            " For Batch Number 310 the model has a loss of {'loss': 0.6416300535202026, 'tp': 2747.0, 'fp': 1374.0, 'tn': 3583.0, 'fn': 2216.0, 'accuracy': 0.6381048560142517, 'precision': 0.6665858030319214, 'recall': 0.5534958839416504, 'auc': 0.6780293583869934} \n",
            "310/689 [============>.................] - ETA: 39s - loss: 0.6416 - tp: 2747.0000 - fp: 1374.0000 - tn: 3583.0000 - fn: 2216.0000 - accuracy: 0.6381 - precision: 0.6666 - recall: 0.5535 - auc: 0.6780\n",
            " For Batch Number 311 the model has a loss of {'loss': 0.6414651274681091, 'tp': 2757.0, 'fp': 1376.0, 'tn': 3597.0, 'fn': 2222.0, 'accuracy': 0.638464629650116, 'precision': 0.6670699119567871, 'recall': 0.5537256598472595, 'auc': 0.6782225370407104} \n",
            "311/689 [============>.................] - ETA: 38s - loss: 0.6415 - tp: 2757.0000 - fp: 1376.0000 - tn: 3597.0000 - fn: 2222.0000 - accuracy: 0.6385 - precision: 0.6671 - recall: 0.5537 - auc: 0.6782\n",
            " For Batch Number 312 the model has a loss of {'loss': 0.6414209604263306, 'tp': 2768.0, 'fp': 1382.0, 'tn': 3606.0, 'fn': 2228.0, 'accuracy': 0.6384214758872986, 'precision': 0.666987955570221, 'recall': 0.5540432333946228, 'auc': 0.6782931685447693} \n",
            "312/689 [============>.................] - ETA: 38s - loss: 0.6414 - tp: 2768.0000 - fp: 1382.0000 - tn: 3606.0000 - fn: 2228.0000 - accuracy: 0.6384 - precision: 0.6670 - recall: 0.5540 - auc: 0.6783\n",
            " For Batch Number 313 the model has a loss of {'loss': 0.6414414644241333, 'tp': 2784.0, 'fp': 1398.0, 'tn': 3606.0, 'fn': 2228.0, 'accuracy': 0.6379792094230652, 'precision': 0.6657102108001709, 'recall': 0.555466890335083, 'auc': 0.6782259941101074} \n",
            "313/689 [============>.................] - ETA: 38s - loss: 0.6414 - tp: 2784.0000 - fp: 1398.0000 - tn: 3606.0000 - fn: 2228.0000 - accuracy: 0.6380 - precision: 0.6657 - recall: 0.5555 - auc: 0.6782\n",
            " For Batch Number 314 the model has a loss of {'loss': 0.6414732336997986, 'tp': 2801.0, 'fp': 1412.0, 'tn': 3606.0, 'fn': 2229.0, 'accuracy': 0.6376393437385559, 'precision': 0.6648468971252441, 'recall': 0.5568588376045227, 'auc': 0.6782261729240417} \n",
            "314/689 [============>.................] - ETA: 38s - loss: 0.6415 - tp: 2801.0000 - fp: 1412.0000 - tn: 3606.0000 - fn: 2229.0000 - accuracy: 0.6376 - precision: 0.6648 - recall: 0.5569 - auc: 0.6782\n",
            " For Batch Number 315 the model has a loss of {'loss': 0.6413119435310364, 'tp': 2815.0, 'fp': 1419.0, 'tn': 3613.0, 'fn': 2233.0, 'accuracy': 0.6376984119415283, 'precision': 0.66485595703125, 'recall': 0.5576465725898743, 'auc': 0.6783714890480042} \n",
            "315/689 [============>.................] - ETA: 38s - loss: 0.6413 - tp: 2815.0000 - fp: 1419.0000 - tn: 3613.0000 - fn: 2233.0000 - accuracy: 0.6377 - precision: 0.6649 - recall: 0.5576 - auc: 0.6784\n",
            " For Batch Number 316 the model has a loss of {'loss': 0.641185998916626, 'tp': 2823.0, 'fp': 1424.0, 'tn': 3627.0, 'fn': 2238.0, 'accuracy': 0.6378560066223145, 'precision': 0.6647045016288757, 'recall': 0.5577949285507202, 'auc': 0.6783775687217712} \n",
            "316/689 [============>.................] - ETA: 38s - loss: 0.6412 - tp: 2823.0000 - fp: 1424.0000 - tn: 3627.0000 - fn: 2238.0000 - accuracy: 0.6379 - precision: 0.6647 - recall: 0.5578 - auc: 0.6784\n",
            " For Batch Number 317 the model has a loss of {'loss': 0.6409279704093933, 'tp': 2833.0, 'fp': 1425.0, 'tn': 3641.0, 'fn': 2245.0, 'accuracy': 0.6382097601890564, 'precision': 0.6653358340263367, 'recall': 0.5578967928886414, 'auc': 0.678705632686615} \n",
            "317/689 [============>.................] - ETA: 38s - loss: 0.6409 - tp: 2833.0000 - fp: 1425.0000 - tn: 3641.0000 - fn: 2245.0000 - accuracy: 0.6382 - precision: 0.6653 - recall: 0.5579 - auc: 0.6787\n",
            " For Batch Number 318 the model has a loss of {'loss': 0.6408018469810486, 'tp': 2842.0, 'fp': 1427.0, 'tn': 3655.0, 'fn': 2252.0, 'accuracy': 0.6384630799293518, 'precision': 0.6657297015190125, 'recall': 0.5579112768173218, 'auc': 0.6790414452552795} \n",
            "318/689 [============>.................] - ETA: 38s - loss: 0.6408 - tp: 2842.0000 - fp: 1427.0000 - tn: 3655.0000 - fn: 2252.0000 - accuracy: 0.6385 - precision: 0.6657 - recall: 0.5579 - auc: 0.6790\n",
            " For Batch Number 319 the model has a loss of {'loss': 0.6409800052642822, 'tp': 2851.0, 'fp': 1428.0, 'tn': 3667.0, 'fn': 2262.0, 'accuracy': 0.6385188102722168, 'precision': 0.6662771701812744, 'recall': 0.5575982928276062, 'auc': 0.6789220571517944} \n",
            "319/689 [============>.................] - ETA: 37s - loss: 0.6410 - tp: 2851.0000 - fp: 1428.0000 - tn: 3667.0000 - fn: 2262.0000 - accuracy: 0.6385 - precision: 0.6663 - recall: 0.5576 - auc: 0.6789\n",
            " For Batch Number 320 the model has a loss of {'loss': 0.6409811973571777, 'tp': 2860.0, 'fp': 1431.0, 'tn': 3678.0, 'fn': 2271.0, 'accuracy': 0.638476550579071, 'precision': 0.6665112972259521, 'recall': 0.5573962330818176, 'auc': 0.6788777709007263} \n",
            "320/689 [============>.................] - ETA: 37s - loss: 0.6410 - tp: 2860.0000 - fp: 1431.0000 - tn: 3678.0000 - fn: 2271.0000 - accuracy: 0.6385 - precision: 0.6665 - recall: 0.5574 - auc: 0.6789\n",
            " For Batch Number 321 the model has a loss of {'loss': 0.6408092379570007, 'tp': 2870.0, 'fp': 1437.0, 'tn': 3691.0, 'fn': 2274.0, 'accuracy': 0.6387266516685486, 'precision': 0.6663571000099182, 'recall': 0.5579315423965454, 'auc': 0.6789721846580505} \n",
            "321/689 [============>.................] - ETA: 37s - loss: 0.6408 - tp: 2870.0000 - fp: 1437.0000 - tn: 3691.0000 - fn: 2274.0000 - accuracy: 0.6387 - precision: 0.6664 - recall: 0.5579 - auc: 0.6790\n",
            " For Batch Number 322 the model has a loss of {'loss': 0.6408875584602356, 'tp': 2879.0, 'fp': 1442.0, 'tn': 3701.0, 'fn': 2282.0, 'accuracy': 0.6385869383811951, 'precision': 0.6662809252738953, 'recall': 0.5578376054763794, 'auc': 0.6788604259490967} \n",
            "322/689 [=============>................] - ETA: 37s - loss: 0.6409 - tp: 2879.0000 - fp: 1442.0000 - tn: 3701.0000 - fn: 2282.0000 - accuracy: 0.6386 - precision: 0.6663 - recall: 0.5578 - auc: 0.6789\n",
            " For Batch Number 323 the model has a loss of {'loss': 0.6407389640808105, 'tp': 2889.0, 'fp': 1449.0, 'tn': 3714.0, 'fn': 2284.0, 'accuracy': 0.6388351321220398, 'precision': 0.6659750938415527, 'recall': 0.5584766864776611, 'auc': 0.6791810989379883} \n",
            "323/689 [=============>................] - ETA: 37s - loss: 0.6407 - tp: 2889.0000 - fp: 1449.0000 - tn: 3714.0000 - fn: 2284.0000 - accuracy: 0.6388 - precision: 0.6660 - recall: 0.5585 - auc: 0.6792\n",
            " For Batch Number 324 the model has a loss of {'loss': 0.6405925750732422, 'tp': 2896.0, 'fp': 1453.0, 'tn': 3730.0, 'fn': 2289.0, 'accuracy': 0.6390817761421204, 'precision': 0.6659002304077148, 'recall': 0.5585342049598694, 'auc': 0.6796342730522156} \n",
            "324/689 [=============>................] - ETA: 37s - loss: 0.6406 - tp: 2896.0000 - fp: 1453.0000 - tn: 3730.0000 - fn: 2289.0000 - accuracy: 0.6391 - precision: 0.6659 - recall: 0.5585 - auc: 0.6796\n",
            " For Batch Number 325 the model has a loss of {'loss': 0.6407496333122253, 'tp': 2905.0, 'fp': 1453.0, 'tn': 3742.0, 'fn': 2300.0, 'accuracy': 0.6391345858573914, 'precision': 0.66659015417099, 'recall': 0.5581172108650208, 'auc': 0.6795834898948669} \n",
            "325/689 [=============>................] - ETA: 37s - loss: 0.6407 - tp: 2905.0000 - fp: 1453.0000 - tn: 3742.0000 - fn: 2300.0000 - accuracy: 0.6391 - precision: 0.6666 - recall: 0.5581 - auc: 0.6796\n",
            " For Batch Number 326 the model has a loss of {'loss': 0.640794038772583, 'tp': 2914.0, 'fp': 1453.0, 'tn': 3756.0, 'fn': 2309.0, 'accuracy': 0.6393788456916809, 'precision': 0.6672773361206055, 'recall': 0.5579168796539307, 'auc': 0.6797537207603455} \n",
            "326/689 [=============>................] - ETA: 37s - loss: 0.6408 - tp: 2914.0000 - fp: 1453.0000 - tn: 3756.0000 - fn: 2309.0000 - accuracy: 0.6394 - precision: 0.6673 - recall: 0.5579 - auc: 0.6798\n",
            " For Batch Number 327 the model has a loss of {'loss': 0.6404240131378174, 'tp': 2921.0, 'fp': 1454.0, 'tn': 3774.0, 'fn': 2315.0, 'accuracy': 0.639812707901001, 'precision': 0.6676571369171143, 'recall': 0.5578685998916626, 'auc': 0.680378258228302} \n",
            "327/689 [=============>................] - ETA: 37s - loss: 0.6404 - tp: 2921.0000 - fp: 1454.0000 - tn: 3774.0000 - fn: 2315.0000 - accuracy: 0.6398 - precision: 0.6677 - recall: 0.5579 - auc: 0.6804\n",
            " For Batch Number 328 the model has a loss of {'loss': 0.6396239995956421, 'tp': 2929.0, 'fp': 1455.0, 'tn': 3794.0, 'fn': 2318.0, 'accuracy': 0.6405297517776489, 'precision': 0.6681113243103027, 'recall': 0.5582237243652344, 'auc': 0.6814555525779724} \n",
            "328/689 [=============>................] - ETA: 37s - loss: 0.6396 - tp: 2929.0000 - fp: 1455.0000 - tn: 3794.0000 - fn: 2318.0000 - accuracy: 0.6405 - precision: 0.6681 - recall: 0.5582 - auc: 0.6815\n",
            " For Batch Number 329 the model has a loss of {'loss': 0.6398380398750305, 'tp': 2934.0, 'fp': 1459.0, 'tn': 3811.0, 'fn': 2324.0, 'accuracy': 0.640672504901886, 'precision': 0.6678807139396667, 'recall': 0.5580068230628967, 'auc': 0.6813700199127197} \n",
            "329/689 [=============>................] - ETA: 37s - loss: 0.6398 - tp: 2934.0000 - fp: 1459.0000 - tn: 3811.0000 - fn: 2324.0000 - accuracy: 0.6407 - precision: 0.6679 - recall: 0.5580 - auc: 0.6814\n",
            " For Batch Number 330 the model has a loss of {'loss': 0.6403568387031555, 'tp': 2938.0, 'fp': 1467.0, 'tn': 3824.0, 'fn': 2331.0, 'accuracy': 0.6403409242630005, 'precision': 0.666969358921051, 'recall': 0.5576010346412659, 'auc': 0.6807975769042969} \n",
            "330/689 [=============>................] - ETA: 36s - loss: 0.6404 - tp: 2938.0000 - fp: 1467.0000 - tn: 3824.0000 - fn: 2331.0000 - accuracy: 0.6403 - precision: 0.6670 - recall: 0.5576 - auc: 0.6808\n",
            " For Batch Number 331 the model has a loss of {'loss': 0.6406310796737671, 'tp': 2949.0, 'fp': 1467.0, 'tn': 3833.0, 'fn': 2343.0, 'accuracy': 0.6402945518493652, 'precision': 0.6677989363670349, 'recall': 0.5572562217712402, 'auc': 0.680635929107666} \n",
            "331/689 [=============>................] - ETA: 36s - loss: 0.6406 - tp: 2949.0000 - fp: 1467.0000 - tn: 3833.0000 - fn: 2343.0000 - accuracy: 0.6403 - precision: 0.6678 - recall: 0.5573 - auc: 0.6806\n",
            " For Batch Number 332 the model has a loss of {'loss': 0.6405825018882751, 'tp': 2959.0, 'fp': 1472.0, 'tn': 3845.0, 'fn': 2348.0, 'accuracy': 0.6404367685317993, 'precision': 0.6677950620651245, 'recall': 0.557565450668335, 'auc': 0.6808754801750183} \n",
            "332/689 [=============>................] - ETA: 36s - loss: 0.6406 - tp: 2959.0000 - fp: 1472.0000 - tn: 3845.0000 - fn: 2348.0000 - accuracy: 0.6404 - precision: 0.6678 - recall: 0.5576 - auc: 0.6809\n",
            " For Batch Number 333 the model has a loss of {'loss': 0.640643298625946, 'tp': 2970.0, 'fp': 1476.0, 'tn': 3855.0, 'fn': 2355.0, 'accuracy': 0.6404842138290405, 'precision': 0.6680161952972412, 'recall': 0.5577464699745178, 'auc': 0.6807321906089783} \n",
            "333/689 [=============>................] - ETA: 36s - loss: 0.6406 - tp: 2970.0000 - fp: 1476.0000 - tn: 3855.0000 - fn: 2355.0000 - accuracy: 0.6405 - precision: 0.6680 - recall: 0.5577 - auc: 0.6807\n",
            " For Batch Number 334 the model has a loss of {'loss': 0.6410300135612488, 'tp': 2976.0, 'fp': 1484.0, 'tn': 3862.0, 'fn': 2366.0, 'accuracy': 0.6397829055786133, 'precision': 0.6672645807266235, 'recall': 0.5570946931838989, 'auc': 0.6801356077194214} \n",
            "334/689 [=============>................] - ETA: 36s - loss: 0.6410 - tp: 2976.0000 - fp: 1484.0000 - tn: 3862.0000 - fn: 2366.0000 - accuracy: 0.6398 - precision: 0.6673 - recall: 0.5571 - auc: 0.6801\n",
            " For Batch Number 335 the model has a loss of {'loss': 0.6410884261131287, 'tp': 2985.0, 'fp': 1490.0, 'tn': 3869.0, 'fn': 2376.0, 'accuracy': 0.6393656730651855, 'precision': 0.6670390963554382, 'recall': 0.5567991137504578, 'auc': 0.6800065636634827} \n",
            "335/689 [=============>................] - ETA: 36s - loss: 0.6411 - tp: 2985.0000 - fp: 1490.0000 - tn: 3869.0000 - fn: 2376.0000 - accuracy: 0.6394 - precision: 0.6670 - recall: 0.5568 - auc: 0.6800\n",
            " For Batch Number 336 the model has a loss of {'loss': 0.6413773894309998, 'tp': 2996.0, 'fp': 1501.0, 'tn': 3875.0, 'fn': 2380.0, 'accuracy': 0.639043927192688, 'precision': 0.6662219166755676, 'recall': 0.5572916865348816, 'auc': 0.6796913743019104} \n",
            "336/689 [=============>................] - ETA: 36s - loss: 0.6414 - tp: 2996.0000 - fp: 1501.0000 - tn: 3875.0000 - fn: 2380.0000 - accuracy: 0.6390 - precision: 0.6662 - recall: 0.5573 - auc: 0.6797\n",
            " For Batch Number 337 the model has a loss of {'loss': 0.6419747471809387, 'tp': 3005.0, 'fp': 1517.0, 'tn': 3877.0, 'fn': 2385.0, 'accuracy': 0.638167679309845, 'precision': 0.6645289659500122, 'recall': 0.5575138926506042, 'auc': 0.6790698170661926} \n",
            "337/689 [=============>................] - ETA: 36s - loss: 0.6420 - tp: 3005.0000 - fp: 1517.0000 - tn: 3877.0000 - fn: 2385.0000 - accuracy: 0.6382 - precision: 0.6645 - recall: 0.5575 - auc: 0.6791\n",
            " For Batch Number 338 the model has a loss of {'loss': 0.6420473456382751, 'tp': 3017.0, 'fp': 1528.0, 'tn': 3884.0, 'fn': 2387.0, 'accuracy': 0.6380362510681152, 'precision': 0.6638063788414001, 'recall': 0.5582901835441589, 'auc': 0.678884744644165} \n",
            "338/689 [=============>................] - ETA: 36s - loss: 0.6420 - tp: 3017.0000 - fp: 1528.0000 - tn: 3884.0000 - fn: 2387.0000 - accuracy: 0.6380 - precision: 0.6638 - recall: 0.5583 - auc: 0.6789\n",
            " For Batch Number 339 the model has a loss of {'loss': 0.6420139670372009, 'tp': 3027.0, 'fp': 1529.0, 'tn': 3896.0, 'fn': 2396.0, 'accuracy': 0.6381821632385254, 'precision': 0.6643986105918884, 'recall': 0.5581781268119812, 'auc': 0.6789795160293579} \n",
            "339/689 [=============>................] - ETA: 35s - loss: 0.6420 - tp: 3027.0000 - fp: 1529.0000 - tn: 3896.0000 - fn: 2396.0000 - accuracy: 0.6382 - precision: 0.6644 - recall: 0.5582 - auc: 0.6790\n",
            " For Batch Number 340 the model has a loss of {'loss': 0.6421382427215576, 'tp': 3034.0, 'fp': 1532.0, 'tn': 3905.0, 'fn': 2409.0, 'accuracy': 0.637775719165802, 'precision': 0.6644765734672546, 'recall': 0.5574132204055786, 'auc': 0.6787797808647156} \n",
            "340/689 [=============>................] - ETA: 35s - loss: 0.6421 - tp: 3034.0000 - fp: 1532.0000 - tn: 3905.0000 - fn: 2409.0000 - accuracy: 0.6378 - precision: 0.6645 - recall: 0.5574 - auc: 0.6788\n",
            " For Batch Number 341 the model has a loss of {'loss': 0.6422346830368042, 'tp': 3038.0, 'fp': 1536.0, 'tn': 3920.0, 'fn': 2418.0, 'accuracy': 0.6376466155052185, 'precision': 0.6641889214515686, 'recall': 0.5568181872367859, 'auc': 0.6784511208534241} \n",
            "341/689 [=============>................] - ETA: 35s - loss: 0.6422 - tp: 3038.0000 - fp: 1536.0000 - tn: 3920.0000 - fn: 2418.0000 - accuracy: 0.6376 - precision: 0.6642 - recall: 0.5568 - auc: 0.6785\n",
            " For Batch Number 342 the model has a loss of {'loss': 0.6421905159950256, 'tp': 3044.0, 'fp': 1537.0, 'tn': 3935.0, 'fn': 2428.0, 'accuracy': 0.6377010345458984, 'precision': 0.6644837260246277, 'recall': 0.5562865734100342, 'auc': 0.678509533405304} \n",
            "342/689 [=============>................] - ETA: 35s - loss: 0.6422 - tp: 3044.0000 - fp: 1537.0000 - tn: 3935.0000 - fn: 2428.0000 - accuracy: 0.6377 - precision: 0.6645 - recall: 0.5563 - auc: 0.6785\n",
            " For Batch Number 343 the model has a loss of {'loss': 0.6421435475349426, 'tp': 3052.0, 'fp': 1538.0, 'tn': 3950.0, 'fn': 2436.0, 'accuracy': 0.6379373073577881, 'precision': 0.6649237275123596, 'recall': 0.5561224222183228, 'auc': 0.6785417199134827} \n",
            "343/689 [=============>................] - ETA: 35s - loss: 0.6421 - tp: 3052.0000 - fp: 1538.0000 - tn: 3950.0000 - fn: 2436.0000 - accuracy: 0.6379 - precision: 0.6649 - recall: 0.5561 - auc: 0.6785\n",
            " For Batch Number 344 the model has a loss of {'loss': 0.6420919895172119, 'tp': 3058.0, 'fp': 1541.0, 'tn': 3965.0, 'fn': 2444.0, 'accuracy': 0.6379905343055725, 'precision': 0.6649271845817566, 'recall': 0.5557978749275208, 'auc': 0.6785629391670227} \n",
            "344/689 [=============>................] - ETA: 35s - loss: 0.6421 - tp: 3058.0000 - fp: 1541.0000 - tn: 3965.0000 - fn: 2444.0000 - accuracy: 0.6380 - precision: 0.6649 - recall: 0.5558 - auc: 0.6786\n",
            " For Batch Number 345 the model has a loss of {'loss': 0.6418546438217163, 'tp': 3067.0, 'fp': 1543.0, 'tn': 3981.0, 'fn': 2449.0, 'accuracy': 0.6384057998657227, 'precision': 0.6652928590774536, 'recall': 0.5560188293457031, 'auc': 0.6788878440856934} \n",
            "345/689 [==============>...............] - ETA: 35s - loss: 0.6419 - tp: 3067.0000 - fp: 1543.0000 - tn: 3981.0000 - fn: 2449.0000 - accuracy: 0.6384 - precision: 0.6653 - recall: 0.5560 - auc: 0.6789\n",
            " For Batch Number 346 the model has a loss of {'loss': 0.6418551206588745, 'tp': 3072.0, 'fp': 1548.0, 'tn': 3995.0, 'fn': 2457.0, 'accuracy': 0.6382767558097839, 'precision': 0.6649350523948669, 'recall': 0.5556158423423767, 'auc': 0.6788228154182434} \n",
            "346/689 [==============>...............] - ETA: 35s - loss: 0.6419 - tp: 3072.0000 - fp: 1548.0000 - tn: 3995.0000 - fn: 2457.0000 - accuracy: 0.6383 - precision: 0.6649 - recall: 0.5556 - auc: 0.6788\n",
            " For Batch Number 347 the model has a loss of {'loss': 0.6417163610458374, 'tp': 3080.0, 'fp': 1550.0, 'tn': 4011.0, 'fn': 2463.0, 'accuracy': 0.6385986804962158, 'precision': 0.6652267575263977, 'recall': 0.5556557774543762, 'auc': 0.6789606213569641} \n",
            "347/689 [==============>...............] - ETA: 34s - loss: 0.6417 - tp: 3080.0000 - fp: 1550.0000 - tn: 4011.0000 - fn: 2463.0000 - accuracy: 0.6386 - precision: 0.6652 - recall: 0.5557 - auc: 0.6790\n",
            " For Batch Number 348 the model has a loss of {'loss': 0.6416194438934326, 'tp': 3086.0, 'fp': 1554.0, 'tn': 4028.0, 'fn': 2468.0, 'accuracy': 0.6388290524482727, 'precision': 0.6650862097740173, 'recall': 0.5556355714797974, 'auc': 0.6791083812713623} \n",
            "348/689 [==============>...............] - ETA: 34s - loss: 0.6416 - tp: 3086.0000 - fp: 1554.0000 - tn: 4028.0000 - fn: 2468.0000 - accuracy: 0.6388 - precision: 0.6651 - recall: 0.5556 - auc: 0.6791\n",
            " For Batch Number 349 the model has a loss of {'loss': 0.6413559913635254, 'tp': 3091.0, 'fp': 1558.0, 'tn': 4047.0, 'fn': 2472.0, 'accuracy': 0.6391475796699524, 'precision': 0.6648741960525513, 'recall': 0.5556354522705078, 'auc': 0.6795364022254944} \n",
            "349/689 [==============>...............] - ETA: 34s - loss: 0.6414 - tp: 3091.0000 - fp: 1558.0000 - tn: 4047.0000 - fn: 2472.0000 - accuracy: 0.6391 - precision: 0.6649 - recall: 0.5556 - auc: 0.6795\n",
            " For Batch Number 350 the model has a loss of {'loss': 0.6414355635643005, 'tp': 3098.0, 'fp': 1558.0, 'tn': 4062.0, 'fn': 2482.0, 'accuracy': 0.6392857432365417, 'precision': 0.6653780341148376, 'recall': 0.5551971197128296, 'auc': 0.6795064806938171} \n",
            "350/689 [==============>...............] - ETA: 34s - loss: 0.6414 - tp: 3098.0000 - fp: 1558.0000 - tn: 4062.0000 - fn: 2482.0000 - accuracy: 0.6393 - precision: 0.6654 - recall: 0.5552 - auc: 0.6795\n",
            " For Batch Number 351 the model has a loss of {'loss': 0.6419708728790283, 'tp': 3101.0, 'fp': 1559.0, 'tn': 4073.0, 'fn': 2499.0, 'accuracy': 0.6387107968330383, 'precision': 0.6654506325721741, 'recall': 0.5537499785423279, 'auc': 0.6787336468696594} \n",
            "351/689 [==============>...............] - ETA: 34s - loss: 0.6420 - tp: 3101.0000 - fp: 1559.0000 - tn: 4073.0000 - fn: 2499.0000 - accuracy: 0.6387 - precision: 0.6655 - recall: 0.5537 - auc: 0.6787\n",
            " For Batch Number 352 the model has a loss of {'loss': 0.6418912410736084, 'tp': 3105.0, 'fp': 1563.0, 'tn': 4088.0, 'fn': 2508.0, 'accuracy': 0.6385831236839294, 'precision': 0.6651670932769775, 'recall': 0.5531800985336304, 'auc': 0.6787088513374329} \n",
            "352/689 [==============>...............] - ETA: 34s - loss: 0.6419 - tp: 3105.0000 - fp: 1563.0000 - tn: 4088.0000 - fn: 2508.0000 - accuracy: 0.6386 - precision: 0.6652 - recall: 0.5532 - auc: 0.6787\n",
            " For Batch Number 353 the model has a loss of {'loss': 0.6418437957763672, 'tp': 3115.0, 'fp': 1565.0, 'tn': 4098.0, 'fn': 2518.0, 'accuracy': 0.6385446190834045, 'precision': 0.6655982732772827, 'recall': 0.5529913306236267, 'auc': 0.6787999272346497} \n",
            "353/689 [==============>...............] - ETA: 34s - loss: 0.6418 - tp: 3115.0000 - fp: 1565.0000 - tn: 4098.0000 - fn: 2518.0000 - accuracy: 0.6385 - precision: 0.6656 - recall: 0.5530 - auc: 0.6788\n",
            " For Batch Number 354 the model has a loss of {'loss': 0.6417877078056335, 'tp': 3124.0, 'fp': 1568.0, 'tn': 4107.0, 'fn': 2529.0, 'accuracy': 0.638329803943634, 'precision': 0.6658141613006592, 'recall': 0.55262690782547, 'auc': 0.6789092421531677} \n",
            "354/689 [==============>...............] - ETA: 34s - loss: 0.6418 - tp: 3124.0000 - fp: 1568.0000 - tn: 4107.0000 - fn: 2529.0000 - accuracy: 0.6383 - precision: 0.6658 - recall: 0.5526 - auc: 0.6789\n",
            " For Batch Number 355 the model has a loss of {'loss': 0.6416909098625183, 'tp': 3136.0, 'fp': 1574.0, 'tn': 4116.0, 'fn': 2534.0, 'accuracy': 0.6383802890777588, 'precision': 0.6658174395561218, 'recall': 0.5530864000320435, 'auc': 0.6789711713790894} \n",
            "355/689 [==============>...............] - ETA: 34s - loss: 0.6417 - tp: 3136.0000 - fp: 1574.0000 - tn: 4116.0000 - fn: 2534.0000 - accuracy: 0.6384 - precision: 0.6658 - recall: 0.5531 - auc: 0.6790\n",
            " For Batch Number 356 the model has a loss of {'loss': 0.6422224640846252, 'tp': 3145.0, 'fp': 1585.0, 'tn': 4126.0, 'fn': 2536.0, 'accuracy': 0.6382549405097961, 'precision': 0.6649048328399658, 'recall': 0.5535997152328491, 'auc': 0.6784787774085999} \n",
            "356/689 [==============>...............] - ETA: 33s - loss: 0.6422 - tp: 3145.0000 - fp: 1585.0000 - tn: 4126.0000 - fn: 2536.0000 - accuracy: 0.6383 - precision: 0.6649 - recall: 0.5536 - auc: 0.6785\n",
            " For Batch Number 357 the model has a loss of {'loss': 0.6418703198432922, 'tp': 3161.0, 'fp': 1587.0, 'tn': 4135.0, 'fn': 2541.0, 'accuracy': 0.6386554837226868, 'precision': 0.6657540202140808, 'recall': 0.5543668866157532, 'auc': 0.6789013147354126} \n",
            "357/689 [==============>...............] - ETA: 33s - loss: 0.6419 - tp: 3161.0000 - fp: 1587.0000 - tn: 4135.0000 - fn: 2541.0000 - accuracy: 0.6387 - precision: 0.6658 - recall: 0.5544 - auc: 0.6789\n",
            " For Batch Number 358 the model has a loss of {'loss': 0.641867458820343, 'tp': 3172.0, 'fp': 1591.0, 'tn': 4146.0, 'fn': 2547.0, 'accuracy': 0.6387919187545776, 'precision': 0.665966808795929, 'recall': 0.5546424388885498, 'auc': 0.6789736747741699} \n",
            "358/689 [==============>...............] - ETA: 33s - loss: 0.6419 - tp: 3172.0000 - fp: 1591.0000 - tn: 4146.0000 - fn: 2547.0000 - accuracy: 0.6388 - precision: 0.6660 - recall: 0.5546 - auc: 0.6790\n",
            " For Batch Number 359 the model has a loss of {'loss': 0.6419731974601746, 'tp': 3180.0, 'fp': 1595.0, 'tn': 4157.0, 'fn': 2556.0, 'accuracy': 0.6386664509773254, 'precision': 0.6659685969352722, 'recall': 0.5543932914733887, 'auc': 0.6788349747657776} \n",
            "359/689 [==============>...............] - ETA: 33s - loss: 0.6420 - tp: 3180.0000 - fp: 1595.0000 - tn: 4157.0000 - fn: 2556.0000 - accuracy: 0.6387 - precision: 0.6660 - recall: 0.5544 - auc: 0.6788\n",
            " For Batch Number 360 the model has a loss of {'loss': 0.6419420838356018, 'tp': 3190.0, 'fp': 1596.0, 'tn': 4165.0, 'fn': 2569.0, 'accuracy': 0.6384548544883728, 'precision': 0.6665273904800415, 'recall': 0.5539156198501587, 'auc': 0.6788548231124878} \n",
            "360/689 [==============>...............] - ETA: 33s - loss: 0.6419 - tp: 3190.0000 - fp: 1596.0000 - tn: 4165.0000 - fn: 2569.0000 - accuracy: 0.6385 - precision: 0.6665 - recall: 0.5539 - auc: 0.6789\n",
            " For Batch Number 361 the model has a loss of {'loss': 0.6415067911148071, 'tp': 3200.0, 'fp': 1597.0, 'tn': 4181.0, 'fn': 2574.0, 'accuracy': 0.6389369964599609, 'precision': 0.6670836210250854, 'recall': 0.554208517074585, 'auc': 0.6793732643127441} \n",
            "361/689 [==============>...............] - ETA: 33s - loss: 0.6415 - tp: 3200.0000 - fp: 1597.0000 - tn: 4181.0000 - fn: 2574.0000 - accuracy: 0.6389 - precision: 0.6671 - recall: 0.5542 - auc: 0.6794\n",
            " For Batch Number 362 the model has a loss of {'loss': 0.6413378715515137, 'tp': 3209.0, 'fp': 1603.0, 'tn': 4192.0, 'fn': 2580.0, 'accuracy': 0.638898491859436, 'precision': 0.6668744683265686, 'recall': 0.5543271899223328, 'auc': 0.6794180870056152} \n",
            "362/689 [==============>...............] - ETA: 33s - loss: 0.6413 - tp: 3209.0000 - fp: 1603.0000 - tn: 4192.0000 - fn: 2580.0000 - accuracy: 0.6389 - precision: 0.6669 - recall: 0.5543 - auc: 0.6794\n",
            " For Batch Number 363 the model has a loss of {'loss': 0.6409897804260254, 'tp': 3219.0, 'fp': 1605.0, 'tn': 4207.0, 'fn': 2585.0, 'accuracy': 0.6392906308174133, 'precision': 0.6672885417938232, 'recall': 0.5546175241470337, 'auc': 0.6798493266105652} \n",
            "363/689 [==============>...............] - ETA: 33s - loss: 0.6410 - tp: 3219.0000 - fp: 1605.0000 - tn: 4207.0000 - fn: 2585.0000 - accuracy: 0.6393 - precision: 0.6673 - recall: 0.5546 - auc: 0.6798\n",
            " For Batch Number 364 the model has a loss of {'loss': 0.6410402059555054, 'tp': 3226.0, 'fp': 1609.0, 'tn': 4218.0, 'fn': 2595.0, 'accuracy': 0.6390796899795532, 'precision': 0.6672182083129883, 'recall': 0.554200291633606, 'auc': 0.6797735095024109} \n",
            "364/689 [==============>...............] - ETA: 33s - loss: 0.6410 - tp: 3226.0000 - fp: 1609.0000 - tn: 4218.0000 - fn: 2595.0000 - accuracy: 0.6391 - precision: 0.6672 - recall: 0.5542 - auc: 0.6798\n",
            " For Batch Number 365 the model has a loss of {'loss': 0.6407022476196289, 'tp': 3235.0, 'fp': 1611.0, 'tn': 4232.0, 'fn': 2602.0, 'accuracy': 0.6392979621887207, 'precision': 0.667560875415802, 'recall': 0.5542230606079102, 'auc': 0.6801194548606873} \n",
            "365/689 [==============>...............] - ETA: 32s - loss: 0.6407 - tp: 3235.0000 - fp: 1611.0000 - tn: 4232.0000 - fn: 2602.0000 - accuracy: 0.6393 - precision: 0.6676 - recall: 0.5542 - auc: 0.6801\n",
            " For Batch Number 366 the model has a loss of {'loss': 0.6412248611450195, 'tp': 3240.0, 'fp': 1618.0, 'tn': 4247.0, 'fn': 2607.0, 'accuracy': 0.639258861541748, 'precision': 0.6669411063194275, 'recall': 0.5541303157806396, 'auc': 0.6798708438873291} \n",
            "366/689 [==============>...............] - ETA: 32s - loss: 0.6412 - tp: 3240.0000 - fp: 1618.0000 - tn: 4247.0000 - fn: 2607.0000 - accuracy: 0.6393 - precision: 0.6669 - recall: 0.5541 - auc: 0.6799\n",
            " For Batch Number 367 the model has a loss of {'loss': 0.6410921216011047, 'tp': 3250.0, 'fp': 1620.0, 'tn': 4259.0, 'fn': 2615.0, 'accuracy': 0.6393903493881226, 'precision': 0.6673511266708374, 'recall': 0.554134726524353, 'auc': 0.6800674200057983} \n",
            "\n",
            " For Batch Number 368 the model has a loss of {'loss': 0.641013503074646, 'tp': 3256.0, 'fp': 1622.0, 'tn': 4275.0, 'fn': 2623.0, 'accuracy': 0.639521062374115, 'precision': 0.6674866676330566, 'recall': 0.5538356900215149, 'auc': 0.6801707148551941} \n",
            "368/689 [===============>..............] - ETA: 32s - loss: 0.6410 - tp: 3256.0000 - fp: 1622.0000 - tn: 4275.0000 - fn: 2623.0000 - accuracy: 0.6395 - precision: 0.6675 - recall: 0.5538 - auc: 0.6802\n",
            " For Batch Number 369 the model has a loss of {'loss': 0.6410495042800903, 'tp': 3261.0, 'fp': 1625.0, 'tn': 4288.0, 'fn': 2634.0, 'accuracy': 0.6393123269081116, 'precision': 0.6674171090126038, 'recall': 0.5531806349754333, 'auc': 0.6799887418746948} \n",
            "369/689 [===============>..............] - ETA: 32s - loss: 0.6410 - tp: 3261.0000 - fp: 1625.0000 - tn: 4288.0000 - fn: 2634.0000 - accuracy: 0.6393 - precision: 0.6674 - recall: 0.5532 - auc: 0.6800\n",
            " For Batch Number 370 the model has a loss of {'loss': 0.6412839889526367, 'tp': 3269.0, 'fp': 1627.0, 'tn': 4298.0, 'fn': 2646.0, 'accuracy': 0.6391047239303589, 'precision': 0.6676878929138184, 'recall': 0.55266273021698, 'auc': 0.6797654032707214} \n",
            "370/689 [===============>..............] - ETA: 32s - loss: 0.6413 - tp: 3269.0000 - fp: 1627.0000 - tn: 4298.0000 - fn: 2646.0000 - accuracy: 0.6391 - precision: 0.6677 - recall: 0.5527 - auc: 0.6798\n",
            " For Batch Number 371 the model has a loss of {'loss': 0.6409725546836853, 'tp': 3281.0, 'fp': 1631.0, 'tn': 4309.0, 'fn': 2651.0, 'accuracy': 0.6393194198608398, 'precision': 0.6679560542106628, 'recall': 0.5531018376350403, 'auc': 0.6801438331604004} \n",
            "371/689 [===============>..............] - ETA: 32s - loss: 0.6410 - tp: 3281.0000 - fp: 1631.0000 - tn: 4309.0000 - fn: 2651.0000 - accuracy: 0.6393 - precision: 0.6680 - recall: 0.5531 - auc: 0.6801\n",
            " For Batch Number 372 the model has a loss of {'loss': 0.6410202980041504, 'tp': 3294.0, 'fp': 1643.0, 'tn': 4315.0, 'fn': 2652.0, 'accuracy': 0.6391969323158264, 'precision': 0.6672068238258362, 'recall': 0.5539858937263489, 'auc': 0.680098831653595} \n",
            "372/689 [===============>..............] - ETA: 32s - loss: 0.6410 - tp: 3294.0000 - fp: 1643.0000 - tn: 4315.0000 - fn: 2652.0000 - accuracy: 0.6392 - precision: 0.6672 - recall: 0.5540 - auc: 0.6801\n",
            " For Batch Number 373 the model has a loss of {'loss': 0.6419373154640198, 'tp': 3303.0, 'fp': 1657.0, 'tn': 4321.0, 'fn': 2655.0, 'accuracy': 0.6387399435043335, 'precision': 0.6659274101257324, 'recall': 0.5543806552886963, 'auc': 0.6793890595436096} \n",
            "373/689 [===============>..............] - ETA: 31s - loss: 0.6419 - tp: 3303.0000 - fp: 1657.0000 - tn: 4321.0000 - fn: 2655.0000 - accuracy: 0.6387 - precision: 0.6659 - recall: 0.5544 - auc: 0.6794\n",
            " For Batch Number 374 the model has a loss of {'loss': 0.6417792439460754, 'tp': 3317.0, 'fp': 1663.0, 'tn': 4330.0, 'fn': 2658.0, 'accuracy': 0.6389538645744324, 'precision': 0.6660642623901367, 'recall': 0.5551464557647705, 'auc': 0.6797252297401428} \n",
            "374/689 [===============>..............] - ETA: 31s - loss: 0.6418 - tp: 3317.0000 - fp: 1663.0000 - tn: 4330.0000 - fn: 2658.0000 - accuracy: 0.6390 - precision: 0.6661 - recall: 0.5551 - auc: 0.6797\n",
            " For Batch Number 375 the model has a loss of {'loss': 0.6423112154006958, 'tp': 3323.0, 'fp': 1672.0, 'tn': 4337.0, 'fn': 2668.0, 'accuracy': 0.6383333206176758, 'precision': 0.6652652621269226, 'recall': 0.5546653270721436, 'auc': 0.6790161728858948} \n",
            "375/689 [===============>..............] - ETA: 31s - loss: 0.6423 - tp: 3323.0000 - fp: 1672.0000 - tn: 4337.0000 - fn: 2668.0000 - accuracy: 0.6383 - precision: 0.6653 - recall: 0.5547 - auc: 0.6790\n",
            " For Batch Number 376 the model has a loss of {'loss': 0.6424751877784729, 'tp': 3333.0, 'fp': 1675.0, 'tn': 4346.0, 'fn': 2678.0, 'accuracy': 0.6382147669792175, 'precision': 0.6655351519584656, 'recall': 0.5544834733009338, 'auc': 0.6788248419761658} \n",
            "376/689 [===============>..............] - ETA: 31s - loss: 0.6425 - tp: 3333.0000 - fp: 1675.0000 - tn: 4346.0000 - fn: 2678.0000 - accuracy: 0.6382 - precision: 0.6655 - recall: 0.5545 - auc: 0.6788\n",
            " For Batch Number 377 the model has a loss of {'loss': 0.6424422860145569, 'tp': 3342.0, 'fp': 1678.0, 'tn': 4358.0, 'fn': 2686.0, 'accuracy': 0.6382625699043274, 'precision': 0.6657370328903198, 'recall': 0.5544127225875854, 'auc': 0.6787990927696228} \n",
            "377/689 [===============>..............] - ETA: 31s - loss: 0.6424 - tp: 3342.0000 - fp: 1678.0000 - tn: 4358.0000 - fn: 2686.0000 - accuracy: 0.6383 - precision: 0.6657 - recall: 0.5544 - auc: 0.6788\n",
            " For Batch Number 378 the model has a loss of {'loss': 0.6423159837722778, 'tp': 3352.0, 'fp': 1682.0, 'tn': 4370.0, 'fn': 2692.0, 'accuracy': 0.6383928656578064, 'precision': 0.6658720970153809, 'recall': 0.5545995831489563, 'auc': 0.6789059042930603} \n",
            "378/689 [===============>..............] - ETA: 31s - loss: 0.6423 - tp: 3352.0000 - fp: 1682.0000 - tn: 4370.0000 - fn: 2692.0000 - accuracy: 0.6384 - precision: 0.6659 - recall: 0.5546 - auc: 0.6789\n",
            " For Batch Number 379 the model has a loss of {'loss': 0.6422178149223328, 'tp': 3364.0, 'fp': 1691.0, 'tn': 4374.0, 'fn': 2699.0, 'accuracy': 0.6380277276039124, 'precision': 0.6654797196388245, 'recall': 0.5548408627510071, 'auc': 0.6790047287940979} \n",
            "379/689 [===============>..............] - ETA: 31s - loss: 0.6422 - tp: 3364.0000 - fp: 1691.0000 - tn: 4374.0000 - fn: 2699.0000 - accuracy: 0.6380 - precision: 0.6655 - recall: 0.5548 - auc: 0.6790\n",
            " For Batch Number 380 the model has a loss of {'loss': 0.64238041639328, 'tp': 3373.0, 'fp': 1707.0, 'tn': 4378.0, 'fn': 2702.0, 'accuracy': 0.637417733669281, 'precision': 0.6639763712882996, 'recall': 0.5552263259887695, 'auc': 0.6786620020866394} \n",
            "380/689 [===============>..............] - ETA: 31s - loss: 0.6424 - tp: 3373.0000 - fp: 1707.0000 - tn: 4378.0000 - fn: 2702.0000 - accuracy: 0.6374 - precision: 0.6640 - recall: 0.5552 - auc: 0.6787\n",
            " For Batch Number 381 the model has a loss of {'loss': 0.6426423788070679, 'tp': 3384.0, 'fp': 1720.0, 'tn': 4385.0, 'fn': 2703.0, 'accuracy': 0.6372211575508118, 'precision': 0.6630094051361084, 'recall': 0.5559388995170593, 'auc': 0.6783559322357178} \n",
            "381/689 [===============>..............] - ETA: 31s - loss: 0.6426 - tp: 3384.0000 - fp: 1720.0000 - tn: 4385.0000 - fn: 2703.0000 - accuracy: 0.6372 - precision: 0.6630 - recall: 0.5559 - auc: 0.6784\n",
            " For Batch Number 382 the model has a loss of {'loss': 0.6426563262939453, 'tp': 3390.0, 'fp': 1724.0, 'tn': 4397.0, 'fn': 2713.0, 'accuracy': 0.6370255351066589, 'precision': 0.6628862023353577, 'recall': 0.555464506149292, 'auc': 0.6782520413398743} \n",
            "382/689 [===============>..............] - ETA: 30s - loss: 0.6427 - tp: 3390.0000 - fp: 1724.0000 - tn: 4397.0000 - fn: 2713.0000 - accuracy: 0.6370 - precision: 0.6629 - recall: 0.5555 - auc: 0.6783\n",
            " For Batch Number 383 the model has a loss of {'loss': 0.6426510810852051, 'tp': 3396.0, 'fp': 1725.0, 'tn': 4411.0, 'fn': 2724.0, 'accuracy': 0.6369941234588623, 'precision': 0.663151741027832, 'recall': 0.5549019575119019, 'auc': 0.6782038807868958} \n",
            "383/689 [===============>..............] - ETA: 30s - loss: 0.6427 - tp: 3396.0000 - fp: 1725.0000 - tn: 4411.0000 - fn: 2724.0000 - accuracy: 0.6370 - precision: 0.6632 - recall: 0.5549 - auc: 0.6782\n",
            " For Batch Number 384 the model has a loss of {'loss': 0.6427717208862305, 'tp': 3400.0, 'fp': 1729.0, 'tn': 4426.0, 'fn': 2733.0, 'accuracy': 0.6368815302848816, 'precision': 0.6628972291946411, 'recall': 0.5543779730796814, 'auc': 0.6779546737670898} \n",
            "384/689 [===============>..............] - ETA: 30s - loss: 0.6428 - tp: 3400.0000 - fp: 1729.0000 - tn: 4426.0000 - fn: 2733.0000 - accuracy: 0.6369 - precision: 0.6629 - recall: 0.5544 - auc: 0.6780\n",
            " For Batch Number 385 the model has a loss of {'loss': 0.6429529190063477, 'tp': 3404.0, 'fp': 1730.0, 'tn': 4440.0, 'fn': 2746.0, 'accuracy': 0.6366882920265198, 'precision': 0.6630308032035828, 'recall': 0.5534959435462952, 'auc': 0.6776818633079529} \n",
            "385/689 [===============>..............] - ETA: 30s - loss: 0.6430 - tp: 3404.0000 - fp: 1730.0000 - tn: 4440.0000 - fn: 2746.0000 - accuracy: 0.6367 - precision: 0.6630 - recall: 0.5535 - auc: 0.6777\n",
            " For Batch Number 386 the model has a loss of {'loss': 0.6430854201316833, 'tp': 3409.0, 'fp': 1733.0, 'tn': 4452.0, 'fn': 2758.0, 'accuracy': 0.6364151835441589, 'precision': 0.6629716157913208, 'recall': 0.5527809262275696, 'auc': 0.6774895787239075} \n",
            "386/689 [===============>..............] - ETA: 30s - loss: 0.6431 - tp: 3409.0000 - fp: 1733.0000 - tn: 4452.0000 - fn: 2758.0000 - accuracy: 0.6364 - precision: 0.6630 - recall: 0.5528 - auc: 0.6775\n",
            " For Batch Number 387 the model has a loss of {'loss': 0.6431477665901184, 'tp': 3416.0, 'fp': 1736.0, 'tn': 4464.0, 'fn': 2768.0, 'accuracy': 0.6363049149513245, 'precision': 0.6630434989929199, 'recall': 0.5523932576179504, 'auc': 0.6773223876953125} \n",
            "387/689 [===============>..............] - ETA: 30s - loss: 0.6431 - tp: 3416.0000 - fp: 1736.0000 - tn: 4464.0000 - fn: 2768.0000 - accuracy: 0.6363 - precision: 0.6630 - recall: 0.5524 - auc: 0.6773\n",
            " For Batch Number 388 the model has a loss of {'loss': 0.643549919128418, 'tp': 3421.0, 'fp': 1746.0, 'tn': 4474.0, 'fn': 2775.0, 'accuracy': 0.6358730792999268, 'precision': 0.6620863080024719, 'recall': 0.552130401134491, 'auc': 0.6768099665641785} \n",
            "388/689 [===============>..............] - ETA: 30s - loss: 0.6435 - tp: 3421.0000 - fp: 1746.0000 - tn: 4474.0000 - fn: 2775.0000 - accuracy: 0.6359 - precision: 0.6621 - recall: 0.5521 - auc: 0.6768\n",
            " For Batch Number 389 the model has a loss of {'loss': 0.6438030004501343, 'tp': 3427.0, 'fp': 1758.0, 'tn': 4483.0, 'fn': 2780.0, 'accuracy': 0.6354434490203857, 'precision': 0.6609450578689575, 'recall': 0.5521185994148254, 'auc': 0.6763705015182495} \n",
            "389/689 [===============>..............] - ETA: 30s - loss: 0.6438 - tp: 3427.0000 - fp: 1758.0000 - tn: 4483.0000 - fn: 2780.0000 - accuracy: 0.6354 - precision: 0.6609 - recall: 0.5521 - auc: 0.6764\n",
            " For Batch Number 390 the model has a loss of {'loss': 0.6438181400299072, 'tp': 3435.0, 'fp': 1762.0, 'tn': 4497.0, 'fn': 2786.0, 'accuracy': 0.6355769038200378, 'precision': 0.6609582304954529, 'recall': 0.5521620512008667, 'auc': 0.6762987375259399} \n",
            "390/689 [===============>..............] - ETA: 30s - loss: 0.6438 - tp: 3435.0000 - fp: 1762.0000 - tn: 4497.0000 - fn: 2786.0000 - accuracy: 0.6356 - precision: 0.6610 - recall: 0.5522 - auc: 0.6763\n",
            " For Batch Number 391 the model has a loss of {'loss': 0.6439268589019775, 'tp': 3442.0, 'fp': 1763.0, 'tn': 4507.0, 'fn': 2800.0, 'accuracy': 0.6353101134300232, 'precision': 0.661287248134613, 'recall': 0.5514258146286011, 'auc': 0.6761373281478882} \n",
            "391/689 [================>.............] - ETA: 29s - loss: 0.6439 - tp: 3442.0000 - fp: 1763.0000 - tn: 4507.0000 - fn: 2800.0000 - accuracy: 0.6353 - precision: 0.6613 - recall: 0.5514 - auc: 0.6761\n",
            " For Batch Number 392 the model has a loss of {'loss': 0.6443463563919067, 'tp': 3447.0, 'fp': 1767.0, 'tn': 4514.0, 'fn': 2816.0, 'accuracy': 0.6346460580825806, 'precision': 0.6611047387123108, 'recall': 0.55037522315979, 'auc': 0.6753752827644348} \n",
            "392/689 [================>.............] - ETA: 29s - loss: 0.6443 - tp: 3447.0000 - fp: 1767.0000 - tn: 4514.0000 - fn: 2816.0000 - accuracy: 0.6346 - precision: 0.6611 - recall: 0.5504 - auc: 0.6754\n",
            " For Batch Number 393 the model has a loss of {'loss': 0.6444675922393799, 'tp': 3454.0, 'fp': 1772.0, 'tn': 4529.0, 'fn': 2821.0, 'accuracy': 0.6347805261611938, 'precision': 0.6609261631965637, 'recall': 0.5504382252693176, 'auc': 0.6752064824104309} \n",
            "393/689 [================>.............] - ETA: 29s - loss: 0.6445 - tp: 3454.0000 - fp: 1772.0000 - tn: 4529.0000 - fn: 2821.0000 - accuracy: 0.6348 - precision: 0.6609 - recall: 0.5504 - auc: 0.6752\n",
            " For Batch Number 394 the model has a loss of {'loss': 0.6445834040641785, 'tp': 3464.0, 'fp': 1777.0, 'tn': 4535.0, 'fn': 2832.0, 'accuracy': 0.6344384551048279, 'precision': 0.660942554473877, 'recall': 0.5501905679702759, 'auc': 0.6749774217605591} \n",
            "394/689 [================>.............] - ETA: 29s - loss: 0.6446 - tp: 3464.0000 - fp: 1777.0000 - tn: 4535.0000 - fn: 2832.0000 - accuracy: 0.6344 - precision: 0.6609 - recall: 0.5502 - auc: 0.6750\n",
            " For Batch Number 395 the model has a loss of {'loss': 0.6445340514183044, 'tp': 3474.0, 'fp': 1784.0, 'tn': 4541.0, 'fn': 2841.0, 'accuracy': 0.6340981125831604, 'precision': 0.6607074737548828, 'recall': 0.5501187443733215, 'auc': 0.6750005483627319} \n",
            "395/689 [================>.............] - ETA: 29s - loss: 0.6445 - tp: 3474.0000 - fp: 1784.0000 - tn: 4541.0000 - fn: 2841.0000 - accuracy: 0.6341 - precision: 0.6607 - recall: 0.5501 - auc: 0.6750\n",
            " For Batch Number 396 the model has a loss of {'loss': 0.6445947289466858, 'tp': 3487.0, 'fp': 1798.0, 'tn': 4544.0, 'fn': 2843.0, 'accuracy': 0.6337594985961914, 'precision': 0.659791886806488, 'recall': 0.5508688688278198, 'auc': 0.6748304963111877} \n",
            "396/689 [================>.............] - ETA: 29s - loss: 0.6446 - tp: 3487.0000 - fp: 1798.0000 - tn: 4544.0000 - fn: 2843.0000 - accuracy: 0.6338 - precision: 0.6598 - recall: 0.5509 - auc: 0.6748\n",
            " For Batch Number 397 the model has a loss of {'loss': 0.6444924473762512, 'tp': 3504.0, 'fp': 1810.0, 'tn': 4545.0, 'fn': 2845.0, 'accuracy': 0.6335799694061279, 'precision': 0.6593902707099915, 'recall': 0.5518979430198669, 'auc': 0.6749414801597595} \n",
            "397/689 [================>.............] - ETA: 29s - loss: 0.6445 - tp: 3504.0000 - fp: 1810.0000 - tn: 4545.0000 - fn: 2845.0000 - accuracy: 0.6336 - precision: 0.6594 - recall: 0.5519 - auc: 0.6749\n",
            " For Batch Number 398 the model has a loss of {'loss': 0.6443522572517395, 'tp': 3521.0, 'fp': 1822.0, 'tn': 4547.0, 'fn': 2846.0, 'accuracy': 0.63347989320755, 'precision': 0.6589930653572083, 'recall': 0.5530077219009399, 'auc': 0.6750565767288208} \n",
            "398/689 [================>.............] - ETA: 29s - loss: 0.6444 - tp: 3521.0000 - fp: 1822.0000 - tn: 4547.0000 - fn: 2846.0000 - accuracy: 0.6335 - precision: 0.6590 - recall: 0.5530 - auc: 0.6751\n",
            " For Batch Number 399 the model has a loss of {'loss': 0.6444249153137207, 'tp': 3531.0, 'fp': 1830.0, 'tn': 4554.0, 'fn': 2853.0, 'accuracy': 0.6332237124443054, 'precision': 0.658645749092102, 'recall': 0.5531014800071716, 'auc': 0.674927294254303} \n",
            "399/689 [================>.............] - ETA: 29s - loss: 0.6444 - tp: 3531.0000 - fp: 1830.0000 - tn: 4554.0000 - fn: 2853.0000 - accuracy: 0.6332 - precision: 0.6586 - recall: 0.5531 - auc: 0.6749\n",
            " For Batch Number 400 the model has a loss of {'loss': 0.64433753490448, 'tp': 3543.0, 'fp': 1836.0, 'tn': 4562.0, 'fn': 2859.0, 'accuracy': 0.6332031488418579, 'precision': 0.6586726307868958, 'recall': 0.5534207820892334, 'auc': 0.6748672127723694} \n",
            "400/689 [================>.............] - ETA: 29s - loss: 0.6443 - tp: 3543.0000 - fp: 1836.0000 - tn: 4562.0000 - fn: 2859.0000 - accuracy: 0.6332 - precision: 0.6587 - recall: 0.5534 - auc: 0.6749\n",
            " For Batch Number 401 the model has a loss of {'loss': 0.6442535519599915, 'tp': 3549.0, 'fp': 1840.0, 'tn': 4575.0, 'fn': 2868.0, 'accuracy': 0.6331047415733337, 'precision': 0.6585637331008911, 'recall': 0.5530622005462646, 'auc': 0.6748378872871399} \n",
            "401/689 [================>.............] - ETA: 29s - loss: 0.6443 - tp: 3549.0000 - fp: 1840.0000 - tn: 4575.0000 - fn: 2868.0000 - accuracy: 0.6331 - precision: 0.6586 - recall: 0.5531 - auc: 0.6748\n",
            " For Batch Number 402 the model has a loss of {'loss': 0.644278883934021, 'tp': 3552.0, 'fp': 1843.0, 'tn': 4592.0, 'fn': 2877.0, 'accuracy': 0.6330845952033997, 'precision': 0.6583874225616455, 'recall': 0.5524964928627014, 'auc': 0.6747664213180542} \n",
            "402/689 [================>.............] - ETA: 29s - loss: 0.6443 - tp: 3552.0000 - fp: 1843.0000 - tn: 4592.0000 - fn: 2877.0000 - accuracy: 0.6331 - precision: 0.6584 - recall: 0.5525 - auc: 0.6748\n",
            " For Batch Number 403 the model has a loss of {'loss': 0.6443312764167786, 'tp': 3558.0, 'fp': 1845.0, 'tn': 4604.0, 'fn': 2889.0, 'accuracy': 0.6329094171524048, 'precision': 0.6585230231285095, 'recall': 0.5518845915794373, 'auc': 0.6746212840080261} \n",
            "403/689 [================>.............] - ETA: 28s - loss: 0.6443 - tp: 3558.0000 - fp: 1845.0000 - tn: 4604.0000 - fn: 2889.0000 - accuracy: 0.6329 - precision: 0.6585 - recall: 0.5519 - auc: 0.6746\n",
            " For Batch Number 404 the model has a loss of {'loss': 0.6447145342826843, 'tp': 3561.0, 'fp': 1846.0, 'tn': 4617.0, 'fn': 2904.0, 'accuracy': 0.6325804591178894, 'precision': 0.6585907340049744, 'recall': 0.5508120656013489, 'auc': 0.6742055416107178} \n",
            "404/689 [================>.............] - ETA: 28s - loss: 0.6447 - tp: 3561.0000 - fp: 1846.0000 - tn: 4617.0000 - fn: 2904.0000 - accuracy: 0.6326 - precision: 0.6586 - recall: 0.5508 - auc: 0.6742\n",
            " For Batch Number 405 the model has a loss of {'loss': 0.6450055837631226, 'tp': 3565.0, 'fp': 1848.0, 'tn': 4632.0, 'fn': 2915.0, 'accuracy': 0.6324845552444458, 'precision': 0.6585996747016907, 'recall': 0.5501543283462524, 'auc': 0.6739528179168701} \n",
            "405/689 [================>.............] - ETA: 28s - loss: 0.6450 - tp: 3565.0000 - fp: 1848.0000 - tn: 4632.0000 - fn: 2915.0000 - accuracy: 0.6325 - precision: 0.6586 - recall: 0.5502 - auc: 0.6740\n",
            " For Batch Number 406 the model has a loss of {'loss': 0.6454067826271057, 'tp': 3567.0, 'fp': 1854.0, 'tn': 4646.0, 'fn': 2925.0, 'accuracy': 0.6321582794189453, 'precision': 0.657996654510498, 'recall': 0.5494454503059387, 'auc': 0.6733829975128174} \n",
            "406/689 [================>.............] - ETA: 28s - loss: 0.6454 - tp: 3567.0000 - fp: 1854.0000 - tn: 4646.0000 - fn: 2925.0000 - accuracy: 0.6322 - precision: 0.6580 - recall: 0.5494 - auc: 0.6734\n",
            " For Batch Number 407 the model has a loss of {'loss': 0.6453753709793091, 'tp': 3574.0, 'fp': 1854.0, 'tn': 4658.0, 'fn': 2938.0, 'accuracy': 0.6320638656616211, 'precision': 0.6584377288818359, 'recall': 0.5488329529762268, 'auc': 0.6734168529510498} \n",
            "407/689 [================>.............] - ETA: 28s - loss: 0.6454 - tp: 3574.0000 - fp: 1854.0000 - tn: 4658.0000 - fn: 2938.0000 - accuracy: 0.6321 - precision: 0.6584 - recall: 0.5488 - auc: 0.6734\n",
            " For Batch Number 408 the model has a loss of {'loss': 0.6453701257705688, 'tp': 3581.0, 'fp': 1860.0, 'tn': 4673.0, 'fn': 2942.0, 'accuracy': 0.632199764251709, 'precision': 0.6581510901451111, 'recall': 0.5489805340766907, 'auc': 0.6733977198600769} \n",
            "408/689 [================>.............] - ETA: 28s - loss: 0.6454 - tp: 3581.0000 - fp: 1860.0000 - tn: 4673.0000 - fn: 2942.0000 - accuracy: 0.6322 - precision: 0.6582 - recall: 0.5490 - auc: 0.6734\n",
            " For Batch Number 409 the model has a loss of {'loss': 0.6452267169952393, 'tp': 3590.0, 'fp': 1861.0, 'tn': 4688.0, 'fn': 2949.0, 'accuracy': 0.6324877738952637, 'precision': 0.6585947275161743, 'recall': 0.549013614654541, 'auc': 0.6735472083091736} \n",
            "409/689 [================>.............] - ETA: 28s - loss: 0.6452 - tp: 3590.0000 - fp: 1861.0000 - tn: 4688.0000 - fn: 2949.0000 - accuracy: 0.6325 - precision: 0.6586 - recall: 0.5490 - auc: 0.6735\n",
            " For Batch Number 410 the model has a loss of {'loss': 0.6451292634010315, 'tp': 3600.0, 'fp': 1864.0, 'tn': 4701.0, 'fn': 2955.0, 'accuracy': 0.6326981782913208, 'precision': 0.6588580012321472, 'recall': 0.549199104309082, 'auc': 0.6737205982208252} \n",
            "410/689 [================>.............] - ETA: 28s - loss: 0.6451 - tp: 3600.0000 - fp: 1864.0000 - tn: 4701.0000 - fn: 2955.0000 - accuracy: 0.6327 - precision: 0.6589 - recall: 0.5492 - auc: 0.6737\n",
            " For Batch Number 411 the model has a loss of {'loss': 0.6449981331825256, 'tp': 3611.0, 'fp': 1866.0, 'tn': 4712.0, 'fn': 2963.0, 'accuracy': 0.6328315138816833, 'precision': 0.6593025326728821, 'recall': 0.5492850542068481, 'auc': 0.6739287376403809} \n",
            "411/689 [================>.............] - ETA: 28s - loss: 0.6450 - tp: 3611.0000 - fp: 1866.0000 - tn: 4712.0000 - fn: 2963.0000 - accuracy: 0.6328 - precision: 0.6593 - recall: 0.5493 - auc: 0.6739\n",
            " For Batch Number 412 the model has a loss of {'loss': 0.6451286673545837, 'tp': 3618.0, 'fp': 1872.0, 'tn': 4727.0, 'fn': 2967.0, 'accuracy': 0.6329641938209534, 'precision': 0.6590163707733154, 'recall': 0.5494305491447449, 'auc': 0.6737340688705444} \n",
            "412/689 [================>.............] - ETA: 28s - loss: 0.6451 - tp: 3618.0000 - fp: 1872.0000 - tn: 4727.0000 - fn: 2967.0000 - accuracy: 0.6330 - precision: 0.6590 - recall: 0.5494 - auc: 0.6737\n",
            " For Batch Number 413 the model has a loss of {'loss': 0.6450182199478149, 'tp': 3629.0, 'fp': 1874.0, 'tn': 4741.0, 'fn': 2972.0, 'accuracy': 0.6333232522010803, 'precision': 0.6594584584236145, 'recall': 0.5497651696205139, 'auc': 0.6738929748535156} \n",
            "413/689 [================>.............] - ETA: 27s - loss: 0.6450 - tp: 3629.0000 - fp: 1874.0000 - tn: 4741.0000 - fn: 2972.0000 - accuracy: 0.6333 - precision: 0.6595 - recall: 0.5498 - auc: 0.6739\n",
            " For Batch Number 414 the model has a loss of {'loss': 0.6449368000030518, 'tp': 3640.0, 'fp': 1877.0, 'tn': 4752.0, 'fn': 2979.0, 'accuracy': 0.6334540843963623, 'precision': 0.659778892993927, 'recall': 0.5499320030212402, 'auc': 0.6740953922271729} \n",
            "414/689 [=================>............] - ETA: 27s - loss: 0.6449 - tp: 3640.0000 - fp: 1877.0000 - tn: 4752.0000 - fn: 2979.0000 - accuracy: 0.6335 - precision: 0.6598 - recall: 0.5499 - auc: 0.6741\n",
            " For Batch Number 415 the model has a loss of {'loss': 0.644795298576355, 'tp': 3650.0, 'fp': 1880.0, 'tn': 4764.0, 'fn': 2986.0, 'accuracy': 0.6335843205451965, 'precision': 0.6600361466407776, 'recall': 0.5500301122665405, 'auc': 0.6742943525314331} \n",
            "415/689 [=================>............] - ETA: 27s - loss: 0.6448 - tp: 3650.0000 - fp: 1880.0000 - tn: 4764.0000 - fn: 2986.0000 - accuracy: 0.6336 - precision: 0.6600 - recall: 0.5500 - auc: 0.6743\n",
            " For Batch Number 416 the model has a loss of {'loss': 0.6447030305862427, 'tp': 3660.0, 'fp': 1885.0, 'tn': 4778.0, 'fn': 2989.0, 'accuracy': 0.633864164352417, 'precision': 0.660054087638855, 'recall': 0.5504587292671204, 'auc': 0.6744608879089355} \n",
            "416/689 [=================>............] - ETA: 27s - loss: 0.6447 - tp: 3660.0000 - fp: 1885.0000 - tn: 4778.0000 - fn: 2989.0000 - accuracy: 0.6339 - precision: 0.6601 - recall: 0.5505 - auc: 0.6745\n",
            " For Batch Number 417 the model has a loss of {'loss': 0.644447386264801, 'tp': 3674.0, 'fp': 1886.0, 'tn': 4792.0, 'fn': 2992.0, 'accuracy': 0.6344424486160278, 'precision': 0.6607913374900818, 'recall': 0.5511550903320312, 'auc': 0.6748948097229004} \n",
            "417/689 [=================>............] - ETA: 27s - loss: 0.6444 - tp: 3674.0000 - fp: 1886.0000 - tn: 4792.0000 - fn: 2992.0000 - accuracy: 0.6344 - precision: 0.6608 - recall: 0.5512 - auc: 0.6749\n",
            " For Batch Number 418 the model has a loss of {'loss': 0.6441622376441956, 'tp': 3686.0, 'fp': 1888.0, 'tn': 4803.0, 'fn': 2999.0, 'accuracy': 0.6346441507339478, 'precision': 0.6612845063209534, 'recall': 0.5513836741447449, 'auc': 0.6753814220428467} \n",
            "418/689 [=================>............] - ETA: 27s - loss: 0.6442 - tp: 3686.0000 - fp: 1888.0000 - tn: 4803.0000 - fn: 2999.0000 - accuracy: 0.6346 - precision: 0.6613 - recall: 0.5514 - auc: 0.6754\n",
            " For Batch Number 419 the model has a loss of {'loss': 0.6439797282218933, 'tp': 3695.0, 'fp': 1893.0, 'tn': 4815.0, 'fn': 3005.0, 'accuracy': 0.6346957087516785, 'precision': 0.6612383723258972, 'recall': 0.5514925122261047, 'auc': 0.6756411790847778} \n",
            "419/689 [=================>............] - ETA: 27s - loss: 0.6440 - tp: 3695.0000 - fp: 1893.0000 - tn: 4815.0000 - fn: 3005.0000 - accuracy: 0.6347 - precision: 0.6612 - recall: 0.5515 - auc: 0.6756\n",
            " For Batch Number 420 the model has a loss of {'loss': 0.6443169713020325, 'tp': 3705.0, 'fp': 1898.0, 'tn': 4824.0, 'fn': 3013.0, 'accuracy': 0.6345981955528259, 'precision': 0.6612529158592224, 'recall': 0.5515034198760986, 'auc': 0.6753897070884705} \n",
            "420/689 [=================>............] - ETA: 27s - loss: 0.6443 - tp: 3705.0000 - fp: 1898.0000 - tn: 4824.0000 - fn: 3013.0000 - accuracy: 0.6346 - precision: 0.6613 - recall: 0.5515 - auc: 0.6754\n",
            " For Batch Number 421 the model has a loss of {'loss': 0.6442527770996094, 'tp': 3715.0, 'fp': 1907.0, 'tn': 4835.0, 'fn': 3015.0, 'accuracy': 0.6346496343612671, 'precision': 0.6607968807220459, 'recall': 0.5520059466362, 'auc': 0.6755045652389526} \n",
            "421/689 [=================>............] - ETA: 27s - loss: 0.6443 - tp: 3715.0000 - fp: 1907.0000 - tn: 4835.0000 - fn: 3015.0000 - accuracy: 0.6346 - precision: 0.6608 - recall: 0.5520 - auc: 0.6755\n",
            " For Batch Number 422 the model has a loss of {'loss': 0.6440038681030273, 'tp': 3726.0, 'fp': 1913.0, 'tn': 4846.0, 'fn': 3019.0, 'accuracy': 0.6347748637199402, 'precision': 0.660755455493927, 'recall': 0.5524091720581055, 'auc': 0.6757522821426392} \n",
            "422/689 [=================>............] - ETA: 26s - loss: 0.6440 - tp: 3726.0000 - fp: 1913.0000 - tn: 4846.0000 - fn: 3019.0000 - accuracy: 0.6348 - precision: 0.6608 - recall: 0.5524 - auc: 0.6758\n",
            " For Batch Number 423 the model has a loss of {'loss': 0.6439961194992065, 'tp': 3738.0, 'fp': 1916.0, 'tn': 4856.0, 'fn': 3026.0, 'accuracy': 0.6348995566368103, 'precision': 0.6611248850822449, 'recall': 0.5526315569877625, 'auc': 0.675844669342041} \n",
            "423/689 [=================>............] - ETA: 26s - loss: 0.6440 - tp: 3738.0000 - fp: 1916.0000 - tn: 4856.0000 - fn: 3026.0000 - accuracy: 0.6349 - precision: 0.6611 - recall: 0.5526 - auc: 0.6758\n",
            " For Batch Number 424 the model has a loss of {'loss': 0.6439909338951111, 'tp': 3748.0, 'fp': 1920.0, 'tn': 4867.0, 'fn': 3033.0, 'accuracy': 0.6349498629570007, 'precision': 0.6612561941146851, 'recall': 0.552720844745636, 'auc': 0.6758488416671753} \n",
            "424/689 [=================>............] - ETA: 26s - loss: 0.6440 - tp: 3748.0000 - fp: 1920.0000 - tn: 4867.0000 - fn: 3033.0000 - accuracy: 0.6349 - precision: 0.6613 - recall: 0.5527 - auc: 0.6758\n",
            " For Batch Number 425 the model has a loss of {'loss': 0.6437709927558899, 'tp': 3759.0, 'fp': 1925.0, 'tn': 4879.0, 'fn': 3037.0, 'accuracy': 0.6351470351219177, 'precision': 0.6613300442695618, 'recall': 0.5531194806098938, 'auc': 0.6761301755905151} \n",
            "425/689 [=================>............] - ETA: 26s - loss: 0.6438 - tp: 3759.0000 - fp: 1925.0000 - tn: 4879.0000 - fn: 3037.0000 - accuracy: 0.6351 - precision: 0.6613 - recall: 0.5531 - auc: 0.6761\n",
            " For Batch Number 426 the model has a loss of {'loss': 0.6436851620674133, 'tp': 3768.0, 'fp': 1927.0, 'tn': 4892.0, 'fn': 3045.0, 'accuracy': 0.6352699398994446, 'precision': 0.6616330146789551, 'recall': 0.5530603528022766, 'auc': 0.6761360168457031} \n",
            "426/689 [=================>............] - ETA: 26s - loss: 0.6437 - tp: 3768.0000 - fp: 1927.0000 - tn: 4892.0000 - fn: 3045.0000 - accuracy: 0.6353 - precision: 0.6616 - recall: 0.5531 - auc: 0.6761\n",
            " For Batch Number 427 the model has a loss of {'loss': 0.6442887783050537, 'tp': 3776.0, 'fp': 1933.0, 'tn': 4899.0, 'fn': 3056.0, 'accuracy': 0.634880006313324, 'precision': 0.6614118218421936, 'recall': 0.5526931881904602, 'auc': 0.6754169464111328} \n",
            "427/689 [=================>............] - ETA: 26s - loss: 0.6443 - tp: 3776.0000 - fp: 1933.0000 - tn: 4899.0000 - fn: 3056.0000 - accuracy: 0.6349 - precision: 0.6614 - recall: 0.5527 - auc: 0.6754\n",
            " For Batch Number 428 the model has a loss of {'loss': 0.6444823145866394, 'tp': 3784.0, 'fp': 1939.0, 'tn': 4910.0, 'fn': 3063.0, 'accuracy': 0.6347838640213013, 'precision': 0.6611917018890381, 'recall': 0.5526508092880249, 'auc': 0.6751347184181213} \n",
            "428/689 [=================>............] - ETA: 26s - loss: 0.6445 - tp: 3784.0000 - fp: 1939.0000 - tn: 4910.0000 - fn: 3063.0000 - accuracy: 0.6348 - precision: 0.6612 - recall: 0.5527 - auc: 0.6751\n",
            " For Batch Number 429 the model has a loss of {'loss': 0.6442874073982239, 'tp': 3797.0, 'fp': 1941.0, 'tn': 4920.0, 'fn': 3070.0, 'accuracy': 0.6349796056747437, 'precision': 0.6617287993431091, 'recall': 0.5529343485832214, 'auc': 0.6753406524658203} \n",
            "429/689 [=================>............] - ETA: 26s - loss: 0.6443 - tp: 3797.0000 - fp: 1941.0000 - tn: 4920.0000 - fn: 3070.0000 - accuracy: 0.6350 - precision: 0.6617 - recall: 0.5529 - auc: 0.6753\n",
            " For Batch Number 430 the model has a loss of {'loss': 0.6441854238510132, 'tp': 3806.0, 'fp': 1942.0, 'tn': 4933.0, 'fn': 3079.0, 'accuracy': 0.6351017355918884, 'precision': 0.662143349647522, 'recall': 0.552795946598053, 'auc': 0.6754721403121948} \n",
            "430/689 [=================>............] - ETA: 26s - loss: 0.6442 - tp: 3806.0000 - fp: 1942.0000 - tn: 4933.0000 - fn: 3079.0000 - accuracy: 0.6351 - precision: 0.6621 - recall: 0.5528 - auc: 0.6755\n",
            " For Batch Number 431 the model has a loss of {'loss': 0.6443194150924683, 'tp': 3815.0, 'fp': 1947.0, 'tn': 4940.0, 'fn': 3090.0, 'accuracy': 0.6347882747650146, 'precision': 0.6620965003967285, 'recall': 0.5524981617927551, 'auc': 0.6753933429718018} \n",
            "431/689 [=================>............] - ETA: 26s - loss: 0.6443 - tp: 3815.0000 - fp: 1947.0000 - tn: 4940.0000 - fn: 3090.0000 - accuracy: 0.6348 - precision: 0.6621 - recall: 0.5525 - auc: 0.6754\n",
            " For Batch Number 432 the model has a loss of {'loss': 0.6444669365882874, 'tp': 3824.0, 'fp': 1952.0, 'tn': 4951.0, 'fn': 3097.0, 'accuracy': 0.634765625, 'precision': 0.6620498895645142, 'recall': 0.552521288394928, 'auc': 0.6752533316612244} \n",
            "432/689 [=================>............] - ETA: 26s - loss: 0.6445 - tp: 3824.0000 - fp: 1952.0000 - tn: 4951.0000 - fn: 3097.0000 - accuracy: 0.6348 - precision: 0.6620 - recall: 0.5525 - auc: 0.6753\n",
            " For Batch Number 433 the model has a loss of {'loss': 0.6445247530937195, 'tp': 3835.0, 'fp': 1959.0, 'tn': 4961.0, 'fn': 3101.0, 'accuracy': 0.6348152160644531, 'precision': 0.6618916392326355, 'recall': 0.5529123544692993, 'auc': 0.6751786470413208} \n",
            "433/689 [=================>............] - ETA: 25s - loss: 0.6445 - tp: 3835.0000 - fp: 1959.0000 - tn: 4961.0000 - fn: 3101.0000 - accuracy: 0.6348 - precision: 0.6619 - recall: 0.5529 - auc: 0.6752\n",
            " For Batch Number 434 the model has a loss of {'loss': 0.6445562243461609, 'tp': 3844.0, 'fp': 1968.0, 'tn': 4969.0, 'fn': 3107.0, 'accuracy': 0.6345766186714172, 'precision': 0.6613902449607849, 'recall': 0.5530139803886414, 'auc': 0.675090491771698} \n",
            "434/689 [=================>............] - ETA: 25s - loss: 0.6446 - tp: 3844.0000 - fp: 1968.0000 - tn: 4969.0000 - fn: 3107.0000 - accuracy: 0.6346 - precision: 0.6614 - recall: 0.5530 - auc: 0.6751\n",
            " For Batch Number 435 the model has a loss of {'loss': 0.6444898843765259, 'tp': 3853.0, 'fp': 1970.0, 'tn': 4983.0, 'fn': 3114.0, 'accuracy': 0.6347700953483582, 'precision': 0.6616864204406738, 'recall': 0.5530357360839844, 'auc': 0.6751235723495483} \n",
            "435/689 [=================>............] - ETA: 25s - loss: 0.6445 - tp: 3853.0000 - fp: 1970.0000 - tn: 4983.0000 - fn: 3114.0000 - accuracy: 0.6348 - precision: 0.6617 - recall: 0.5530 - auc: 0.6751\n",
            " For Batch Number 436 the model has a loss of {'loss': 0.6444517970085144, 'tp': 3858.0, 'fp': 1972.0, 'tn': 4997.0, 'fn': 3125.0, 'accuracy': 0.6346760392189026, 'precision': 0.661749541759491, 'recall': 0.5524846315383911, 'auc': 0.6750486493110657} \n",
            "436/689 [=================>............] - ETA: 25s - loss: 0.6445 - tp: 3858.0000 - fp: 1972.0000 - tn: 4997.0000 - fn: 3125.0000 - accuracy: 0.6347 - precision: 0.6617 - recall: 0.5525 - auc: 0.6750\n",
            " For Batch Number 437 the model has a loss of {'loss': 0.6443392038345337, 'tp': 3866.0, 'fp': 1973.0, 'tn': 5012.0, 'fn': 3133.0, 'accuracy': 0.6348684430122375, 'precision': 0.6620996594429016, 'recall': 0.5523646473884583, 'auc': 0.6751766204833984} \n",
            "437/689 [==================>...........] - ETA: 25s - loss: 0.6443 - tp: 3866.0000 - fp: 1973.0000 - tn: 5012.0000 - fn: 3133.0000 - accuracy: 0.6349 - precision: 0.6621 - recall: 0.5524 - auc: 0.6752\n",
            " For Batch Number 438 the model has a loss of {'loss': 0.6443019509315491, 'tp': 3874.0, 'fp': 1974.0, 'tn': 5027.0, 'fn': 3141.0, 'accuracy': 0.6350599527359009, 'precision': 0.6624487042427063, 'recall': 0.5522451996803284, 'auc': 0.675186276435852} \n",
            "438/689 [==================>...........] - ETA: 25s - loss: 0.6443 - tp: 3874.0000 - fp: 1974.0000 - tn: 5027.0000 - fn: 3141.0000 - accuracy: 0.6351 - precision: 0.6624 - recall: 0.5522 - auc: 0.6752\n",
            " For Batch Number 439 the model has a loss of {'loss': 0.644245982170105, 'tp': 3880.0, 'fp': 1977.0, 'tn': 5041.0, 'fn': 3150.0, 'accuracy': 0.6350370049476624, 'precision': 0.6624552011489868, 'recall': 0.5519203543663025, 'auc': 0.6751935482025146} \n",
            "439/689 [==================>...........] - ETA: 25s - loss: 0.6442 - tp: 3880.0000 - fp: 1977.0000 - tn: 5041.0000 - fn: 3150.0000 - accuracy: 0.6350 - precision: 0.6625 - recall: 0.5519 - auc: 0.6752\n",
            " For Batch Number 440 the model has a loss of {'loss': 0.6440989375114441, 'tp': 3886.0, 'fp': 1979.0, 'tn': 5058.0, 'fn': 3157.0, 'accuracy': 0.6352272629737854, 'precision': 0.6625745892524719, 'recall': 0.5517535209655762, 'auc': 0.6753876209259033} \n",
            "440/689 [==================>...........] - ETA: 25s - loss: 0.6441 - tp: 3886.0000 - fp: 1979.0000 - tn: 5058.0000 - fn: 3157.0000 - accuracy: 0.6352 - precision: 0.6626 - recall: 0.5518 - auc: 0.6754\n",
            " For Batch Number 441 the model has a loss of {'loss': 0.6443632245063782, 'tp': 3893.0, 'fp': 1981.0, 'tn': 5067.0, 'fn': 3171.0, 'accuracy': 0.6349206566810608, 'precision': 0.6627510786056519, 'recall': 0.5511041879653931, 'auc': 0.6748827695846558} \n",
            "441/689 [==================>...........] - ETA: 25s - loss: 0.6444 - tp: 3893.0000 - fp: 1981.0000 - tn: 5067.0000 - fn: 3171.0000 - accuracy: 0.6349 - precision: 0.6628 - recall: 0.5511 - auc: 0.6749\n",
            " For Batch Number 442 the model has a loss of {'loss': 0.6444421410560608, 'tp': 3899.0, 'fp': 1984.0, 'tn': 5082.0, 'fn': 3179.0, 'accuracy': 0.6349688768386841, 'precision': 0.6627570986747742, 'recall': 0.5508618354797363, 'auc': 0.6747627258300781} \n",
            "442/689 [==================>...........] - ETA: 25s - loss: 0.6444 - tp: 3899.0000 - fp: 1984.0000 - tn: 5082.0000 - fn: 3179.0000 - accuracy: 0.6350 - precision: 0.6628 - recall: 0.5509 - auc: 0.6748\n",
            " For Batch Number 443 the model has a loss of {'loss': 0.6443029046058655, 'tp': 3908.0, 'fp': 1986.0, 'tn': 5096.0, 'fn': 3186.0, 'accuracy': 0.6351580023765564, 'precision': 0.663047194480896, 'recall': 0.5508880615234375, 'auc': 0.6748959422111511} \n",
            "443/689 [==================>...........] - ETA: 24s - loss: 0.6443 - tp: 3908.0000 - fp: 1986.0000 - tn: 5096.0000 - fn: 3186.0000 - accuracy: 0.6352 - precision: 0.6630 - recall: 0.5509 - auc: 0.6749\n",
            " For Batch Number 444 the model has a loss of {'loss': 0.6443063616752625, 'tp': 3917.0, 'fp': 1990.0, 'tn': 5110.0, 'fn': 3191.0, 'accuracy': 0.6353462934494019, 'precision': 0.6631115674972534, 'recall': 0.5510692000389099, 'auc': 0.674915611743927} \n",
            "444/689 [==================>...........] - ETA: 24s - loss: 0.6443 - tp: 3917.0000 - fp: 1990.0000 - tn: 5110.0000 - fn: 3191.0000 - accuracy: 0.6353 - precision: 0.6631 - recall: 0.5511 - auc: 0.6749\n",
            " For Batch Number 445 the model has a loss of {'loss': 0.6441771984100342, 'tp': 3927.0, 'fp': 1994.0, 'tn': 5125.0, 'fn': 3194.0, 'accuracy': 0.6356741786003113, 'precision': 0.6632325649261475, 'recall': 0.5514674782752991, 'auc': 0.6749821901321411} \n",
            "445/689 [==================>...........] - ETA: 24s - loss: 0.6442 - tp: 3927.0000 - fp: 1994.0000 - tn: 5125.0000 - fn: 3194.0000 - accuracy: 0.6357 - precision: 0.6632 - recall: 0.5515 - auc: 0.6750\n",
            " For Batch Number 446 the model has a loss of {'loss': 0.6439791917800903, 'tp': 3937.0, 'fp': 1997.0, 'tn': 5139.0, 'fn': 3199.0, 'accuracy': 0.6359304785728455, 'precision': 0.6634647846221924, 'recall': 0.5517096519470215, 'auc': 0.6752550601959229} \n",
            "446/689 [==================>...........] - ETA: 24s - loss: 0.6440 - tp: 3937.0000 - fp: 1997.0000 - tn: 5139.0000 - fn: 3199.0000 - accuracy: 0.6359 - precision: 0.6635 - recall: 0.5517 - auc: 0.6753\n",
            " For Batch Number 447 the model has a loss of {'loss': 0.6441411972045898, 'tp': 3944.0, 'fp': 2000.0, 'tn': 5149.0, 'fn': 3211.0, 'accuracy': 0.635696291923523, 'precision': 0.6635262370109558, 'recall': 0.5512229204177856, 'auc': 0.6750244498252869} \n",
            "447/689 [==================>...........] - ETA: 24s - loss: 0.6441 - tp: 3944.0000 - fp: 2000.0000 - tn: 5149.0000 - fn: 3211.0000 - accuracy: 0.6357 - precision: 0.6635 - recall: 0.5512 - auc: 0.6750\n",
            " For Batch Number 448 the model has a loss of {'loss': 0.6442515254020691, 'tp': 3953.0, 'fp': 2005.0, 'tn': 5159.0, 'fn': 3219.0, 'accuracy': 0.6356026530265808, 'precision': 0.6634776592254639, 'recall': 0.5511712431907654, 'auc': 0.6749794483184814} \n",
            "448/689 [==================>...........] - ETA: 24s - loss: 0.6443 - tp: 3953.0000 - fp: 2005.0000 - tn: 5159.0000 - fn: 3219.0000 - accuracy: 0.6356 - precision: 0.6635 - recall: 0.5512 - auc: 0.6750\n",
            " For Batch Number 449 the model has a loss of {'loss': 0.6441853642463684, 'tp': 3962.0, 'fp': 2010.0, 'tn': 5171.0, 'fn': 3225.0, 'accuracy': 0.6356486678123474, 'precision': 0.663429319858551, 'recall': 0.5512731075286865, 'auc': 0.675041913986206} \n",
            "449/689 [==================>...........] - ETA: 24s - loss: 0.6442 - tp: 3962.0000 - fp: 2010.0000 - tn: 5171.0000 - fn: 3225.0000 - accuracy: 0.6356 - precision: 0.6634 - recall: 0.5513 - auc: 0.6750\n",
            " For Batch Number 450 the model has a loss of {'loss': 0.6443613171577454, 'tp': 3969.0, 'fp': 2018.0, 'tn': 5181.0, 'fn': 3232.0, 'accuracy': 0.6354166865348816, 'precision': 0.6629363894462585, 'recall': 0.5511734485626221, 'auc': 0.6747308969497681} \n",
            "450/689 [==================>...........] - ETA: 24s - loss: 0.6444 - tp: 3969.0000 - fp: 2018.0000 - tn: 5181.0000 - fn: 3232.0000 - accuracy: 0.6354 - precision: 0.6629 - recall: 0.5512 - auc: 0.6747\n",
            " For Batch Number 451 the model has a loss of {'loss': 0.6442169547080994, 'tp': 3978.0, 'fp': 2019.0, 'tn': 5197.0, 'fn': 3238.0, 'accuracy': 0.6357400417327881, 'precision': 0.6633316874504089, 'recall': 0.5512749552726746, 'auc': 0.6750001311302185} \n",
            "451/689 [==================>...........] - ETA: 24s - loss: 0.6442 - tp: 3978.0000 - fp: 2019.0000 - tn: 5197.0000 - fn: 3238.0000 - accuracy: 0.6357 - precision: 0.6633 - recall: 0.5513 - auc: 0.6750\n",
            " For Batch Number 452 the model has a loss of {'loss': 0.6440490484237671, 'tp': 3988.0, 'fp': 2022.0, 'tn': 5211.0, 'fn': 3243.0, 'accuracy': 0.6359928250312805, 'precision': 0.6635607481002808, 'recall': 0.5515143275260925, 'auc': 0.6752210259437561} \n",
            "452/689 [==================>...........] - ETA: 23s - loss: 0.6440 - tp: 3988.0000 - fp: 2022.0000 - tn: 5211.0000 - fn: 3243.0000 - accuracy: 0.6360 - precision: 0.6636 - recall: 0.5515 - auc: 0.6752\n",
            " For Batch Number 453 the model has a loss of {'loss': 0.6439617276191711, 'tp': 3996.0, 'fp': 2024.0, 'tn': 5226.0, 'fn': 3250.0, 'accuracy': 0.6361755132675171, 'precision': 0.6637873649597168, 'recall': 0.5514766573905945, 'auc': 0.6752625703811646} \n",
            "453/689 [==================>...........] - ETA: 23s - loss: 0.6440 - tp: 3996.0000 - fp: 2024.0000 - tn: 5226.0000 - fn: 3250.0000 - accuracy: 0.6362 - precision: 0.6638 - recall: 0.5515 - auc: 0.6753\n",
            " For Batch Number 454 the model has a loss of {'loss': 0.6440414786338806, 'tp': 4006.0, 'fp': 2026.0, 'tn': 5235.0, 'fn': 3261.0, 'accuracy': 0.6360820531845093, 'precision': 0.6641246676445007, 'recall': 0.5512591004371643, 'auc': 0.675214946269989} \n",
            "454/689 [==================>...........] - ETA: 23s - loss: 0.6440 - tp: 4006.0000 - fp: 2026.0000 - tn: 5235.0000 - fn: 3261.0000 - accuracy: 0.6361 - precision: 0.6641 - recall: 0.5513 - auc: 0.6752\n",
            " For Batch Number 455 the model has a loss of {'loss': 0.6439878344535828, 'tp': 4019.0, 'fp': 2027.0, 'tn': 5245.0, 'fn': 3269.0, 'accuracy': 0.6362637281417847, 'precision': 0.6647370457649231, 'recall': 0.5514544248580933, 'auc': 0.6753140091896057} \n",
            "455/689 [==================>...........] - ETA: 23s - loss: 0.6440 - tp: 4019.0000 - fp: 2027.0000 - tn: 5245.0000 - fn: 3269.0000 - accuracy: 0.6363 - precision: 0.6647 - recall: 0.5515 - auc: 0.6753\n",
            " For Batch Number 456 the model has a loss of {'loss': 0.6439869403839111, 'tp': 4029.0, 'fp': 2031.0, 'tn': 5256.0, 'fn': 3276.0, 'accuracy': 0.6363075375556946, 'precision': 0.6648514866828918, 'recall': 0.5515400171279907, 'auc': 0.6752895712852478} \n",
            "456/689 [==================>...........] - ETA: 23s - loss: 0.6440 - tp: 4029.0000 - fp: 2031.0000 - tn: 5256.0000 - fn: 3276.0000 - accuracy: 0.6363 - precision: 0.6649 - recall: 0.5515 - auc: 0.6753\n",
            " For Batch Number 457 the model has a loss of {'loss': 0.6439833641052246, 'tp': 4040.0, 'fp': 2039.0, 'tn': 5262.0, 'fn': 3283.0, 'accuracy': 0.6360777020454407, 'precision': 0.6645829677581787, 'recall': 0.5516864657402039, 'auc': 0.6751836538314819} \n",
            "457/689 [==================>...........] - ETA: 23s - loss: 0.6440 - tp: 4040.0000 - fp: 2039.0000 - tn: 5262.0000 - fn: 3283.0000 - accuracy: 0.6361 - precision: 0.6646 - recall: 0.5517 - auc: 0.6752\n",
            " For Batch Number 458 the model has a loss of {'loss': 0.6443560719490051, 'tp': 4050.0, 'fp': 2050.0, 'tn': 5267.0, 'fn': 3289.0, 'accuracy': 0.6357123255729675, 'precision': 0.6639344096183777, 'recall': 0.5518463253974915, 'auc': 0.674826443195343} \n",
            "458/689 [==================>...........] - ETA: 23s - loss: 0.6444 - tp: 4050.0000 - fp: 2050.0000 - tn: 5267.0000 - fn: 3289.0000 - accuracy: 0.6357 - precision: 0.6639 - recall: 0.5518 - auc: 0.6748\n",
            " For Batch Number 459 the model has a loss of {'loss': 0.6444824934005737, 'tp': 4061.0, 'fp': 2061.0, 'tn': 5274.0, 'fn': 3292.0, 'accuracy': 0.6355528235435486, 'precision': 0.6633453369140625, 'recall': 0.5522915720939636, 'auc': 0.6746451258659363} \n",
            "459/689 [==================>...........] - ETA: 23s - loss: 0.6445 - tp: 4061.0000 - fp: 2061.0000 - tn: 5274.0000 - fn: 3292.0000 - accuracy: 0.6356 - precision: 0.6633 - recall: 0.5523 - auc: 0.6746\n",
            " For Batch Number 460 the model has a loss of {'loss': 0.6450595259666443, 'tp': 4067.0, 'fp': 2073.0, 'tn': 5284.0, 'fn': 3296.0, 'accuracy': 0.635258138179779, 'precision': 0.6623778343200684, 'recall': 0.5523563623428345, 'auc': 0.6741621494293213} \n",
            "460/689 [===================>..........] - ETA: 23s - loss: 0.6451 - tp: 4067.0000 - fp: 2073.0000 - tn: 5284.0000 - fn: 3296.0000 - accuracy: 0.6353 - precision: 0.6624 - recall: 0.5524 - auc: 0.6742\n",
            " For Batch Number 461 the model has a loss of {'loss': 0.6449975967407227, 'tp': 4077.0, 'fp': 2078.0, 'tn': 5295.0, 'fn': 3302.0, 'accuracy': 0.6353036761283875, 'precision': 0.6623883247375488, 'recall': 0.5525138974189758, 'auc': 0.6741876006126404} \n",
            "461/689 [===================>..........] - ETA: 23s - loss: 0.6450 - tp: 4077.0000 - fp: 2078.0000 - tn: 5295.0000 - fn: 3302.0000 - accuracy: 0.6353 - precision: 0.6624 - recall: 0.5525 - auc: 0.6742\n",
            " For Batch Number 462 the model has a loss of {'loss': 0.6448475122451782, 'tp': 4088.0, 'fp': 2080.0, 'tn': 5307.0, 'fn': 3309.0, 'accuracy': 0.6354842782020569, 'precision': 0.6627756357192993, 'recall': 0.5526564717292786, 'auc': 0.6743794679641724} \n",
            "462/689 [===================>..........] - ETA: 22s - loss: 0.6448 - tp: 4088.0000 - fp: 2080.0000 - tn: 5307.0000 - fn: 3309.0000 - accuracy: 0.6355 - precision: 0.6628 - recall: 0.5527 - auc: 0.6744\n",
            " For Batch Number 463 the model has a loss of {'loss': 0.6446793079376221, 'tp': 4098.0, 'fp': 2083.0, 'tn': 5319.0, 'fn': 3316.0, 'accuracy': 0.6355966329574585, 'precision': 0.6629995107650757, 'recall': 0.5527380704879761, 'auc': 0.6746861338615417} \n",
            "463/689 [===================>..........] - ETA: 22s - loss: 0.6447 - tp: 4098.0000 - fp: 2083.0000 - tn: 5319.0000 - fn: 3316.0000 - accuracy: 0.6356 - precision: 0.6630 - recall: 0.5527 - auc: 0.6747\n",
            " For Batch Number 464 the model has a loss of {'loss': 0.6444095969200134, 'tp': 4106.0, 'fp': 2087.0, 'tn': 5336.0, 'fn': 3319.0, 'accuracy': 0.6359105706214905, 'precision': 0.663006603717804, 'recall': 0.5529966354370117, 'auc': 0.6751678586006165} \n",
            "464/689 [===================>..........] - ETA: 22s - loss: 0.6444 - tp: 4106.0000 - fp: 2087.0000 - tn: 5336.0000 - fn: 3319.0000 - accuracy: 0.6359 - precision: 0.6630 - recall: 0.5530 - auc: 0.6752\n",
            " For Batch Number 465 the model has a loss of {'loss': 0.6441540122032166, 'tp': 4115.0, 'fp': 2088.0, 'tn': 5352.0, 'fn': 3325.0, 'accuracy': 0.6362231373786926, 'precision': 0.6633886694908142, 'recall': 0.5530914068222046, 'auc': 0.675564706325531} \n",
            "465/689 [===================>..........] - ETA: 22s - loss: 0.6442 - tp: 4115.0000 - fp: 2088.0000 - tn: 5352.0000 - fn: 3325.0000 - accuracy: 0.6362 - precision: 0.6634 - recall: 0.5531 - auc: 0.6756\n",
            " For Batch Number 466 the model has a loss of {'loss': 0.6439805030822754, 'tp': 4123.0, 'fp': 2088.0, 'tn': 5367.0, 'fn': 3334.0, 'accuracy': 0.6364002227783203, 'precision': 0.6638222336769104, 'recall': 0.5529032945632935, 'auc': 0.6758010387420654} \n",
            "466/689 [===================>..........] - ETA: 22s - loss: 0.6440 - tp: 4123.0000 - fp: 2088.0000 - tn: 5367.0000 - fn: 3334.0000 - accuracy: 0.6364 - precision: 0.6638 - recall: 0.5529 - auc: 0.6758\n",
            " For Batch Number 467 the model has a loss of {'loss': 0.6440491676330566, 'tp': 4133.0, 'fp': 2089.0, 'tn': 5377.0, 'fn': 3345.0, 'accuracy': 0.6363757848739624, 'precision': 0.6642558574676514, 'recall': 0.5526878833770752, 'auc': 0.6757491230964661} \n",
            "467/689 [===================>..........] - ETA: 22s - loss: 0.6440 - tp: 4133.0000 - fp: 2089.0000 - tn: 5377.0000 - fn: 3345.0000 - accuracy: 0.6364 - precision: 0.6643 - recall: 0.5527 - auc: 0.6757\n",
            " For Batch Number 468 the model has a loss of {'loss': 0.6441617012023926, 'tp': 4140.0, 'fp': 2096.0, 'tn': 5390.0, 'fn': 3350.0, 'accuracy': 0.636351466178894, 'precision': 0.663887083530426, 'recall': 0.5527369976043701, 'auc': 0.6756352782249451} \n",
            "468/689 [===================>..........] - ETA: 22s - loss: 0.6442 - tp: 4140.0000 - fp: 2096.0000 - tn: 5390.0000 - fn: 3350.0000 - accuracy: 0.6364 - precision: 0.6639 - recall: 0.5527 - auc: 0.6756\n",
            " For Batch Number 469 the model has a loss of {'loss': 0.6441124081611633, 'tp': 4149.0, 'fp': 2101.0, 'tn': 5402.0, 'fn': 3356.0, 'accuracy': 0.6363939046859741, 'precision': 0.6638399958610535, 'recall': 0.5528314709663391, 'auc': 0.6756911277770996} \n",
            "469/689 [===================>..........] - ETA: 22s - loss: 0.6441 - tp: 4149.0000 - fp: 2101.0000 - tn: 5402.0000 - fn: 3356.0000 - accuracy: 0.6364 - precision: 0.6638 - recall: 0.5528 - auc: 0.6757\n",
            " For Batch Number 470 the model has a loss of {'loss': 0.6441885232925415, 'tp': 4157.0, 'fp': 2109.0, 'tn': 5410.0, 'fn': 3364.0, 'accuracy': 0.6361037492752075, 'precision': 0.663421630859375, 'recall': 0.5527190566062927, 'auc': 0.675493597984314} \n",
            "470/689 [===================>..........] - ETA: 22s - loss: 0.6442 - tp: 4157.0000 - fp: 2109.0000 - tn: 5410.0000 - fn: 3364.0000 - accuracy: 0.6361 - precision: 0.6634 - recall: 0.5527 - auc: 0.6755\n",
            " For Batch Number 471 the model has a loss of {'loss': 0.6438333988189697, 'tp': 4171.0, 'fp': 2110.0, 'tn': 5422.0, 'fn': 3369.0, 'accuracy': 0.6364782452583313, 'precision': 0.6640662550926208, 'recall': 0.5531830191612244, 'auc': 0.6758711338043213} \n",
            "471/689 [===================>..........] - ETA: 21s - loss: 0.6438 - tp: 4171.0000 - fp: 2110.0000 - tn: 5422.0000 - fn: 3369.0000 - accuracy: 0.6365 - precision: 0.6641 - recall: 0.5532 - auc: 0.6759\n",
            " For Batch Number 472 the model has a loss of {'loss': 0.6440548300743103, 'tp': 4178.0, 'fp': 2118.0, 'tn': 5433.0, 'fn': 3375.0, 'accuracy': 0.636321485042572, 'precision': 0.6635959148406982, 'recall': 0.5531576871871948, 'auc': 0.6756440997123718} \n",
            "472/689 [===================>..........] - ETA: 21s - loss: 0.6441 - tp: 4178.0000 - fp: 2118.0000 - tn: 5433.0000 - fn: 3375.0000 - accuracy: 0.6363 - precision: 0.6636 - recall: 0.5532 - auc: 0.6756\n",
            " For Batch Number 473 the model has a loss of {'loss': 0.6438723802566528, 'tp': 4186.0, 'fp': 2123.0, 'tn': 5446.0, 'fn': 3381.0, 'accuracy': 0.6363636255264282, 'precision': 0.6634966135025024, 'recall': 0.5531914830207825, 'auc': 0.6757998466491699} \n",
            "473/689 [===================>..........] - ETA: 21s - loss: 0.6439 - tp: 4186.0000 - fp: 2123.0000 - tn: 5446.0000 - fn: 3381.0000 - accuracy: 0.6364 - precision: 0.6635 - recall: 0.5532 - auc: 0.6758\n",
            " For Batch Number 474 the model has a loss of {'loss': 0.6437721848487854, 'tp': 4194.0, 'fp': 2125.0, 'tn': 5462.0, 'fn': 3387.0, 'accuracy': 0.6366033554077148, 'precision': 0.6637126207351685, 'recall': 0.5532251596450806, 'auc': 0.6760294437408447} \n",
            "474/689 [===================>..........] - ETA: 21s - loss: 0.6438 - tp: 4194.0000 - fp: 2125.0000 - tn: 5462.0000 - fn: 3387.0000 - accuracy: 0.6366 - precision: 0.6637 - recall: 0.5532 - auc: 0.6760\n",
            " For Batch Number 475 the model has a loss of {'loss': 0.6438162326812744, 'tp': 4198.0, 'fp': 2129.0, 'tn': 5475.0, 'fn': 3398.0, 'accuracy': 0.6363815665245056, 'precision': 0.6635056138038635, 'recall': 0.552659273147583, 'auc': 0.6758922934532166} \n",
            "475/689 [===================>..........] - ETA: 21s - loss: 0.6438 - tp: 4198.0000 - fp: 2129.0000 - tn: 5475.0000 - fn: 3398.0000 - accuracy: 0.6364 - precision: 0.6635 - recall: 0.5527 - auc: 0.6759\n",
            " For Batch Number 476 the model has a loss of {'loss': 0.6440210342407227, 'tp': 4205.0, 'fp': 2130.0, 'tn': 5488.0, 'fn': 3409.0, 'accuracy': 0.6363576650619507, 'precision': 0.663772702217102, 'recall': 0.5522721409797668, 'auc': 0.6756811738014221} \n",
            "476/689 [===================>..........] - ETA: 21s - loss: 0.6440 - tp: 4205.0000 - fp: 2130.0000 - tn: 5488.0000 - fn: 3409.0000 - accuracy: 0.6364 - precision: 0.6638 - recall: 0.5523 - auc: 0.6757\n",
            " For Batch Number 477 the model has a loss of {'loss': 0.6439918279647827, 'tp': 4213.0, 'fp': 2130.0, 'tn': 5503.0, 'fn': 3418.0, 'accuracy': 0.6365303993225098, 'precision': 0.6641967296600342, 'recall': 0.5520901679992676, 'auc': 0.6757388114929199} \n",
            "477/689 [===================>..........] - ETA: 21s - loss: 0.6440 - tp: 4213.0000 - fp: 2130.0000 - tn: 5503.0000 - fn: 3418.0000 - accuracy: 0.6365 - precision: 0.6642 - recall: 0.5521 - auc: 0.6757\n",
            " For Batch Number 478 the model has a loss of {'loss': 0.6439595222473145, 'tp': 4222.0, 'fp': 2132.0, 'tn': 5516.0, 'fn': 3426.0, 'accuracy': 0.6366370320320129, 'precision': 0.6644633412361145, 'recall': 0.5520397424697876, 'auc': 0.6758335828781128} \n",
            "478/689 [===================>..........] - ETA: 21s - loss: 0.6440 - tp: 4222.0000 - fp: 2132.0000 - tn: 5516.0000 - fn: 3426.0000 - accuracy: 0.6366 - precision: 0.6645 - recall: 0.5520 - auc: 0.6758\n",
            " For Batch Number 479 the model has a loss of {'loss': 0.6437026262283325, 'tp': 4233.0, 'fp': 2134.0, 'tn': 5530.0, 'fn': 3431.0, 'accuracy': 0.6369389295578003, 'precision': 0.6648343205451965, 'recall': 0.5523225665092468, 'auc': 0.6761642694473267} \n",
            "479/689 [===================>..........] - ETA: 21s - loss: 0.6437 - tp: 4233.0000 - fp: 2134.0000 - tn: 5530.0000 - fn: 3431.0000 - accuracy: 0.6369 - precision: 0.6648 - recall: 0.5523 - auc: 0.6762\n",
            " For Batch Number 480 the model has a loss of {'loss': 0.6436349153518677, 'tp': 4241.0, 'fp': 2139.0, 'tn': 5545.0, 'fn': 3435.0, 'accuracy': 0.6371093988418579, 'precision': 0.6647335290908813, 'recall': 0.5525013208389282, 'auc': 0.6762560606002808} \n",
            "480/689 [===================>..........] - ETA: 21s - loss: 0.6436 - tp: 4241.0000 - fp: 2139.0000 - tn: 5545.0000 - fn: 3435.0000 - accuracy: 0.6371 - precision: 0.6647 - recall: 0.5525 - auc: 0.6763\n",
            " For Batch Number 481 the model has a loss of {'loss': 0.6437954306602478, 'tp': 4250.0, 'fp': 2145.0, 'tn': 5556.0, 'fn': 3441.0, 'accuracy': 0.6370841860771179, 'precision': 0.6645817160606384, 'recall': 0.5525939464569092, 'auc': 0.6761888861656189} \n",
            "481/689 [===================>..........] - ETA: 21s - loss: 0.6438 - tp: 4250.0000 - fp: 2145.0000 - tn: 5556.0000 - fn: 3441.0000 - accuracy: 0.6371 - precision: 0.6646 - recall: 0.5526 - auc: 0.6762\n",
            " For Batch Number 482 the model has a loss of {'loss': 0.644030749797821, 'tp': 4257.0, 'fp': 2149.0, 'tn': 5568.0, 'fn': 3450.0, 'accuracy': 0.6369943022727966, 'precision': 0.664533257484436, 'recall': 0.5523549914360046, 'auc': 0.6759888529777527} \n",
            "482/689 [===================>..........] - ETA: 20s - loss: 0.6440 - tp: 4257.0000 - fp: 2149.0000 - tn: 5568.0000 - fn: 3450.0000 - accuracy: 0.6370 - precision: 0.6645 - recall: 0.5524 - auc: 0.6760\n",
            " For Batch Number 483 the model has a loss of {'loss': 0.6440250873565674, 'tp': 4266.0, 'fp': 2154.0, 'tn': 5579.0, 'fn': 3457.0, 'accuracy': 0.6369694471359253, 'precision': 0.6644859910011292, 'recall': 0.5523760318756104, 'auc': 0.676002562046051} \n",
            "483/689 [====================>.........] - ETA: 20s - loss: 0.6440 - tp: 4266.0000 - fp: 2154.0000 - tn: 5579.0000 - fn: 3457.0000 - accuracy: 0.6370 - precision: 0.6645 - recall: 0.5524 - auc: 0.6760\n",
            " For Batch Number 484 the model has a loss of {'loss': 0.6439810991287231, 'tp': 4276.0, 'fp': 2158.0, 'tn': 5590.0, 'fn': 3464.0, 'accuracy': 0.63700932264328, 'precision': 0.6645943522453308, 'recall': 0.5524547696113586, 'auc': 0.6761532425880432} \n",
            "484/689 [====================>.........] - ETA: 20s - loss: 0.6440 - tp: 4276.0000 - fp: 2158.0000 - tn: 5590.0000 - fn: 3464.0000 - accuracy: 0.6370 - precision: 0.6646 - recall: 0.5525 - auc: 0.6762\n",
            " For Batch Number 485 the model has a loss of {'loss': 0.6441733837127686, 'tp': 4286.0, 'fp': 2163.0, 'tn': 5599.0, 'fn': 3472.0, 'accuracy': 0.6369200944900513, 'precision': 0.6645991802215576, 'recall': 0.5524619817733765, 'auc': 0.6758784651756287} \n",
            "485/689 [====================>.........] - ETA: 20s - loss: 0.6442 - tp: 4286.0000 - fp: 2163.0000 - tn: 5599.0000 - fn: 3472.0000 - accuracy: 0.6369 - precision: 0.6646 - recall: 0.5525 - auc: 0.6759\n",
            " For Batch Number 486 the model has a loss of {'loss': 0.6442364454269409, 'tp': 4292.0, 'fp': 2168.0, 'tn': 5612.0, 'fn': 3480.0, 'accuracy': 0.6368312835693359, 'precision': 0.6643962860107422, 'recall': 0.5522388219833374, 'auc': 0.6759326457977295} \n",
            "486/689 [====================>.........] - ETA: 20s - loss: 0.6442 - tp: 4292.0000 - fp: 2168.0000 - tn: 5612.0000 - fn: 3480.0000 - accuracy: 0.6368 - precision: 0.6644 - recall: 0.5522 - auc: 0.6759\n",
            " For Batch Number 487 the model has a loss of {'loss': 0.6441673040390015, 'tp': 4299.0, 'fp': 2174.0, 'tn': 5627.0, 'fn': 3484.0, 'accuracy': 0.636935293674469, 'precision': 0.6641433835029602, 'recall': 0.5523576736450195, 'auc': 0.6759448647499084} \n",
            "487/689 [====================>.........] - ETA: 20s - loss: 0.6442 - tp: 4299.0000 - fp: 2174.0000 - tn: 5627.0000 - fn: 3484.0000 - accuracy: 0.6369 - precision: 0.6641 - recall: 0.5524 - auc: 0.6759\n",
            " For Batch Number 488 the model has a loss of {'loss': 0.6442489624023438, 'tp': 4308.0, 'fp': 2176.0, 'tn': 5636.0, 'fn': 3496.0, 'accuracy': 0.6367827653884888, 'precision': 0.6644046902656555, 'recall': 0.5520246028900146, 'auc': 0.6757724285125732} \n",
            "488/689 [====================>.........] - ETA: 20s - loss: 0.6442 - tp: 4308.0000 - fp: 2176.0000 - tn: 5636.0000 - fn: 3496.0000 - accuracy: 0.6368 - precision: 0.6644 - recall: 0.5520 - auc: 0.6758\n",
            " For Batch Number 489 the model has a loss of {'loss': 0.6444652676582336, 'tp': 4313.0, 'fp': 2184.0, 'tn': 5645.0, 'fn': 3506.0, 'accuracy': 0.6363752484321594, 'precision': 0.6638448238372803, 'recall': 0.5516050457954407, 'auc': 0.6754584908485413} \n",
            "489/689 [====================>.........] - ETA: 20s - loss: 0.6445 - tp: 4313.0000 - fp: 2184.0000 - tn: 5645.0000 - fn: 3506.0000 - accuracy: 0.6364 - precision: 0.6638 - recall: 0.5516 - auc: 0.6755\n",
            " For Batch Number 490 the model has a loss of {'loss': 0.644441545009613, 'tp': 4325.0, 'fp': 2184.0, 'tn': 5653.0, 'fn': 3518.0, 'accuracy': 0.6363520622253418, 'precision': 0.6644645929336548, 'recall': 0.5514471530914307, 'auc': 0.6755520105361938} \n",
            "490/689 [====================>.........] - ETA: 20s - loss: 0.6444 - tp: 4325.0000 - fp: 2184.0000 - tn: 5653.0000 - fn: 3518.0000 - accuracy: 0.6364 - precision: 0.6645 - recall: 0.5514 - auc: 0.6756\n",
            " For Batch Number 491 the model has a loss of {'loss': 0.6443341970443726, 'tp': 4337.0, 'fp': 2191.0, 'tn': 5664.0, 'fn': 3520.0, 'accuracy': 0.6365198493003845, 'precision': 0.6643688678741455, 'recall': 0.551991879940033, 'auc': 0.6755926012992859} \n",
            "491/689 [====================>.........] - ETA: 20s - loss: 0.6443 - tp: 4337.0000 - fp: 2191.0000 - tn: 5664.0000 - fn: 3520.0000 - accuracy: 0.6365 - precision: 0.6644 - recall: 0.5520 - auc: 0.6756\n",
            " For Batch Number 492 the model has a loss of {'loss': 0.6442610025405884, 'tp': 4355.0, 'fp': 2203.0, 'tn': 5665.0, 'fn': 3521.0, 'accuracy': 0.636432945728302, 'precision': 0.6640744209289551, 'recall': 0.5529456734657288, 'auc': 0.6756873726844788} \n",
            "492/689 [====================>.........] - ETA: 20s - loss: 0.6443 - tp: 4355.0000 - fp: 2203.0000 - tn: 5665.0000 - fn: 3521.0000 - accuracy: 0.6364 - precision: 0.6641 - recall: 0.5529 - auc: 0.6757\n",
            " For Batch Number 493 the model has a loss of {'loss': 0.6444087028503418, 'tp': 4370.0, 'fp': 2217.0, 'tn': 5667.0, 'fn': 3522.0, 'accuracy': 0.6362195611000061, 'precision': 0.6634279489517212, 'recall': 0.5537253022193909, 'auc': 0.6755607724189758} \n",
            "493/689 [====================>.........] - ETA: 19s - loss: 0.6444 - tp: 4370.0000 - fp: 2217.0000 - tn: 5667.0000 - fn: 3522.0000 - accuracy: 0.6362 - precision: 0.6634 - recall: 0.5537 - auc: 0.6756\n",
            " For Batch Number 494 the model has a loss of {'loss': 0.6445043087005615, 'tp': 4382.0, 'fp': 2232.0, 'tn': 5670.0, 'fn': 3524.0, 'accuracy': 0.6358805894851685, 'precision': 0.6625339984893799, 'recall': 0.5542625784873962, 'auc': 0.6753970384597778} \n",
            "494/689 [====================>.........] - ETA: 19s - loss: 0.6445 - tp: 4382.0000 - fp: 2232.0000 - tn: 5670.0000 - fn: 3524.0000 - accuracy: 0.6359 - precision: 0.6625 - recall: 0.5543 - auc: 0.6754\n",
            " For Batch Number 495 the model has a loss of {'loss': 0.6446263194084167, 'tp': 4390.0, 'fp': 2241.0, 'tn': 5680.0, 'fn': 3529.0, 'accuracy': 0.6357323527336121, 'precision': 0.6620419025421143, 'recall': 0.554362952709198, 'auc': 0.6752080321311951} \n",
            "495/689 [====================>.........] - ETA: 19s - loss: 0.6446 - tp: 4390.0000 - fp: 2241.0000 - tn: 5680.0000 - fn: 3529.0000 - accuracy: 0.6357 - precision: 0.6620 - recall: 0.5544 - auc: 0.6752\n",
            " For Batch Number 496 the model has a loss of {'loss': 0.6447005867958069, 'tp': 4398.0, 'fp': 2246.0, 'tn': 5692.0, 'fn': 3536.0, 'accuracy': 0.6357106566429138, 'precision': 0.6619506478309631, 'recall': 0.554323136806488, 'auc': 0.6751064658164978} \n",
            "496/689 [====================>.........] - ETA: 19s - loss: 0.6447 - tp: 4398.0000 - fp: 2246.0000 - tn: 5692.0000 - fn: 3536.0000 - accuracy: 0.6357 - precision: 0.6620 - recall: 0.5543 - auc: 0.6751\n",
            " For Batch Number 497 the model has a loss of {'loss': 0.6445919275283813, 'tp': 4407.0, 'fp': 2246.0, 'tn': 5709.0, 'fn': 3542.0, 'accuracy': 0.6360663771629333, 'precision': 0.6624079346656799, 'recall': 0.554409384727478, 'auc': 0.6752220988273621} \n",
            "497/689 [====================>.........] - ETA: 19s - loss: 0.6446 - tp: 4407.0000 - fp: 2246.0000 - tn: 5709.0000 - fn: 3542.0000 - accuracy: 0.6361 - precision: 0.6624 - recall: 0.5544 - auc: 0.6752\n",
            " For Batch Number 498 the model has a loss of {'loss': 0.6444322466850281, 'tp': 4414.0, 'fp': 2248.0, 'tn': 5725.0, 'fn': 3549.0, 'accuracy': 0.6362324357032776, 'precision': 0.6625638008117676, 'recall': 0.5543137192726135, 'auc': 0.6754972338676453} \n",
            "498/689 [====================>.........] - ETA: 19s - loss: 0.6444 - tp: 4414.0000 - fp: 2248.0000 - tn: 5725.0000 - fn: 3549.0000 - accuracy: 0.6362 - precision: 0.6626 - recall: 0.5543 - auc: 0.6755\n",
            " For Batch Number 499 the model has a loss of {'loss': 0.6444097757339478, 'tp': 4424.0, 'fp': 2248.0, 'tn': 5737.0, 'fn': 3559.0, 'accuracy': 0.6363351941108704, 'precision': 0.6630695462226868, 'recall': 0.5541776418685913, 'auc': 0.6755233407020569} \n",
            "499/689 [====================>.........] - ETA: 19s - loss: 0.6444 - tp: 4424.0000 - fp: 2248.0000 - tn: 5737.0000 - fn: 3559.0000 - accuracy: 0.6363 - precision: 0.6631 - recall: 0.5542 - auc: 0.6755\n",
            " For Batch Number 500 the model has a loss of {'loss': 0.6443873643875122, 'tp': 4433.0, 'fp': 2251.0, 'tn': 5749.0, 'fn': 3567.0, 'accuracy': 0.6363750100135803, 'precision': 0.6632255911827087, 'recall': 0.5541250109672546, 'auc': 0.6755493879318237} \n",
            "500/689 [====================>.........] - ETA: 19s - loss: 0.6444 - tp: 4433.0000 - fp: 2251.0000 - tn: 5749.0000 - fn: 3567.0000 - accuracy: 0.6364 - precision: 0.6632 - recall: 0.5541 - auc: 0.6755\n",
            " For Batch Number 501 the model has a loss of {'loss': 0.6442881226539612, 'tp': 4445.0, 'fp': 2257.0, 'tn': 5757.0, 'fn': 3573.0, 'accuracy': 0.6363523006439209, 'precision': 0.6632348299026489, 'recall': 0.5543776750564575, 'auc': 0.6756461262702942} \n",
            "501/689 [====================>.........] - ETA: 19s - loss: 0.6443 - tp: 4445.0000 - fp: 2257.0000 - tn: 5757.0000 - fn: 3573.0000 - accuracy: 0.6364 - precision: 0.6632 - recall: 0.5544 - auc: 0.6756\n",
            " For Batch Number 502 the model has a loss of {'loss': 0.6443731784820557, 'tp': 4459.0, 'fp': 2275.0, 'tn': 5757.0, 'fn': 3573.0, 'accuracy': 0.6359561681747437, 'precision': 0.662162184715271, 'recall': 0.5551543831825256, 'auc': 0.6754817366600037} \n",
            "502/689 [====================>.........] - ETA: 19s - loss: 0.6444 - tp: 4459.0000 - fp: 2275.0000 - tn: 5757.0000 - fn: 3573.0000 - accuracy: 0.6360 - precision: 0.6622 - recall: 0.5552 - auc: 0.6755\n",
            " For Batch Number 503 the model has a loss of {'loss': 0.6445208787918091, 'tp': 4468.0, 'fp': 2281.0, 'tn': 5764.0, 'fn': 3583.0, 'accuracy': 0.6356858611106873, 'precision': 0.6620240211486816, 'recall': 0.5549620985984802, 'auc': 0.675297200679779} \n",
            "503/689 [====================>.........] - ETA: 19s - loss: 0.6445 - tp: 4468.0000 - fp: 2281.0000 - tn: 5764.0000 - fn: 3583.0000 - accuracy: 0.6357 - precision: 0.6620 - recall: 0.5550 - auc: 0.6753\n",
            " For Batch Number 504 the model has a loss of {'loss': 0.6447432041168213, 'tp': 4477.0, 'fp': 2285.0, 'tn': 5774.0, 'fn': 3592.0, 'accuracy': 0.6356026530265808, 'precision': 0.6620821952819824, 'recall': 0.5548394918441772, 'auc': 0.6750651597976685} \n",
            "504/689 [====================>.........] - ETA: 18s - loss: 0.6447 - tp: 4477.0000 - fp: 2285.0000 - tn: 5774.0000 - fn: 3592.0000 - accuracy: 0.6356 - precision: 0.6621 - recall: 0.5548 - auc: 0.6751\n",
            " For Batch Number 505 the model has a loss of {'loss': 0.6446688771247864, 'tp': 4485.0, 'fp': 2288.0, 'tn': 5787.0, 'fn': 3600.0, 'accuracy': 0.6356435418128967, 'precision': 0.6621881127357483, 'recall': 0.554731011390686, 'auc': 0.6751158237457275} \n",
            "505/689 [====================>.........] - ETA: 18s - loss: 0.6447 - tp: 4485.0000 - fp: 2288.0000 - tn: 5787.0000 - fn: 3600.0000 - accuracy: 0.6356 - precision: 0.6622 - recall: 0.5547 - auc: 0.6751\n",
            " For Batch Number 506 the model has a loss of {'loss': 0.6446826457977295, 'tp': 4492.0, 'fp': 2293.0, 'tn': 5798.0, 'fn': 3609.0, 'accuracy': 0.6354990005493164, 'precision': 0.6620486378669739, 'recall': 0.5544994473457336, 'auc': 0.6750391721725464} \n",
            "506/689 [=====================>........] - ETA: 18s - loss: 0.6447 - tp: 4492.0000 - fp: 2293.0000 - tn: 5798.0000 - fn: 3609.0000 - accuracy: 0.6355 - precision: 0.6620 - recall: 0.5545 - auc: 0.6750\n",
            " For Batch Number 507 the model has a loss of {'loss': 0.6450435519218445, 'tp': 4497.0, 'fp': 2299.0, 'tn': 5806.0, 'fn': 3622.0, 'accuracy': 0.6350468397140503, 'precision': 0.6617127656936646, 'recall': 0.5538859367370605, 'auc': 0.6743804216384888} \n",
            "507/689 [=====================>........] - ETA: 18s - loss: 0.6450 - tp: 4497.0000 - fp: 2299.0000 - tn: 5806.0000 - fn: 3622.0000 - accuracy: 0.6350 - precision: 0.6617 - recall: 0.5539 - auc: 0.6744\n",
            " For Batch Number 508 the model has a loss of {'loss': 0.6449354290962219, 'tp': 4509.0, 'fp': 2299.0, 'tn': 5818.0, 'fn': 3630.0, 'accuracy': 0.6352731585502625, 'precision': 0.6623090505599976, 'recall': 0.5539992451667786, 'auc': 0.6744795441627502} \n",
            "508/689 [=====================>........] - ETA: 18s - loss: 0.6449 - tp: 4509.0000 - fp: 2299.0000 - tn: 5818.0000 - fn: 3630.0000 - accuracy: 0.6353 - precision: 0.6623 - recall: 0.5540 - auc: 0.6745\n",
            " For Batch Number 509 the model has a loss of {'loss': 0.6450532674789429, 'tp': 4520.0, 'fp': 2312.0, 'tn': 5825.0, 'fn': 3631.0, 'accuracy': 0.6351301670074463, 'precision': 0.6615924835205078, 'recall': 0.5545331835746765, 'auc': 0.6742556095123291} \n",
            "509/689 [=====================>........] - ETA: 18s - loss: 0.6451 - tp: 4520.0000 - fp: 2312.0000 - tn: 5825.0000 - fn: 3631.0000 - accuracy: 0.6351 - precision: 0.6616 - recall: 0.5545 - auc: 0.6743\n",
            " For Batch Number 510 the model has a loss of {'loss': 0.6454291343688965, 'tp': 4530.0, 'fp': 2322.0, 'tn': 5831.0, 'fn': 3637.0, 'accuracy': 0.6348652243614197, 'precision': 0.6611208319664001, 'recall': 0.5546712279319763, 'auc': 0.6739947199821472} \n",
            "510/689 [=====================>........] - ETA: 18s - loss: 0.6454 - tp: 4530.0000 - fp: 2322.0000 - tn: 5831.0000 - fn: 3637.0000 - accuracy: 0.6349 - precision: 0.6611 - recall: 0.5547 - auc: 0.6740\n",
            " For Batch Number 511 the model has a loss of {'loss': 0.6453580856323242, 'tp': 4538.0, 'fp': 2327.0, 'tn': 5841.0, 'fn': 3646.0, 'accuracy': 0.6347236037254333, 'precision': 0.6610342264175415, 'recall': 0.5544965863227844, 'auc': 0.6740615963935852} \n",
            "511/689 [=====================>........] - ETA: 18s - loss: 0.6454 - tp: 4538.0000 - fp: 2327.0000 - tn: 5841.0000 - fn: 3646.0000 - accuracy: 0.6347 - precision: 0.6610 - recall: 0.5545 - auc: 0.6741\n",
            " For Batch Number 512 the model has a loss of {'loss': 0.6453213095664978, 'tp': 4546.0, 'fp': 2328.0, 'tn': 5855.0, 'fn': 3655.0, 'accuracy': 0.63482666015625, 'precision': 0.6613325476646423, 'recall': 0.5543226599693298, 'auc': 0.6741430163383484} \n",
            "512/689 [=====================>........] - ETA: 18s - loss: 0.6453 - tp: 4546.0000 - fp: 2328.0000 - tn: 5855.0000 - fn: 3655.0000 - accuracy: 0.6348 - precision: 0.6613 - recall: 0.5543 - auc: 0.6741\n",
            " For Batch Number 513 the model has a loss of {'loss': 0.6455335021018982, 'tp': 4550.0, 'fp': 2334.0, 'tn': 5869.0, 'fn': 3663.0, 'accuracy': 0.6346856951713562, 'precision': 0.6609529256820679, 'recall': 0.5539997816085815, 'auc': 0.6738771200180054} \n",
            "513/689 [=====================>........] - ETA: 18s - loss: 0.6455 - tp: 4550.0000 - fp: 2334.0000 - tn: 5869.0000 - fn: 3663.0000 - accuracy: 0.6347 - precision: 0.6610 - recall: 0.5540 - auc: 0.6739\n",
            " For Batch Number 514 the model has a loss of {'loss': 0.645534336566925, 'tp': 4556.0, 'fp': 2337.0, 'tn': 5882.0, 'fn': 3673.0, 'accuracy': 0.6346060037612915, 'precision': 0.6609603762626648, 'recall': 0.5536516904830933, 'auc': 0.6738807559013367} \n",
            "514/689 [=====================>........] - ETA: 18s - loss: 0.6455 - tp: 4556.0000 - fp: 2337.0000 - tn: 5882.0000 - fn: 3673.0000 - accuracy: 0.6346 - precision: 0.6610 - recall: 0.5537 - auc: 0.6739\n",
            " For Batch Number 515 the model has a loss of {'loss': 0.6454135179519653, 'tp': 4563.0, 'fp': 2339.0, 'tn': 5899.0, 'fn': 3679.0, 'accuracy': 0.634830117225647, 'precision': 0.6611127257347107, 'recall': 0.5536277890205383, 'auc': 0.6740726828575134} \n",
            "515/689 [=====================>........] - ETA: 17s - loss: 0.6454 - tp: 4563.0000 - fp: 2339.0000 - tn: 5899.0000 - fn: 3679.0000 - accuracy: 0.6348 - precision: 0.6611 - recall: 0.5536 - auc: 0.6741\n",
            " For Batch Number 516 the model has a loss of {'loss': 0.6452305912971497, 'tp': 4568.0, 'fp': 2342.0, 'tn': 5919.0, 'fn': 3683.0, 'accuracy': 0.6351138353347778, 'precision': 0.6610708832740784, 'recall': 0.5536298751831055, 'auc': 0.6743590831756592} \n",
            "516/689 [=====================>........] - ETA: 17s - loss: 0.6452 - tp: 4568.0000 - fp: 2342.0000 - tn: 5919.0000 - fn: 3683.0000 - accuracy: 0.6351 - precision: 0.6611 - recall: 0.5536 - auc: 0.6744\n",
            " For Batch Number 517 the model has a loss of {'loss': 0.6451069712638855, 'tp': 4574.0, 'fp': 2345.0, 'tn': 5933.0, 'fn': 3692.0, 'accuracy': 0.6350942850112915, 'precision': 0.6610782146453857, 'recall': 0.553351104259491, 'auc': 0.6745667457580566} \n",
            "517/689 [=====================>........] - ETA: 17s - loss: 0.6451 - tp: 4574.0000 - fp: 2345.0000 - tn: 5933.0000 - fn: 3692.0000 - accuracy: 0.6351 - precision: 0.6611 - recall: 0.5534 - auc: 0.6746\n",
            " For Batch Number 518 the model has a loss of {'loss': 0.645178496837616, 'tp': 4579.0, 'fp': 2348.0, 'tn': 5949.0, 'fn': 3700.0, 'accuracy': 0.6351351141929626, 'precision': 0.6610365509986877, 'recall': 0.5530861020088196, 'auc': 0.6746127605438232} \n",
            "518/689 [=====================>........] - ETA: 17s - loss: 0.6452 - tp: 4579.0000 - fp: 2348.0000 - tn: 5949.0000 - fn: 3700.0000 - accuracy: 0.6351 - precision: 0.6610 - recall: 0.5531 - auc: 0.6746\n",
            " For Batch Number 519 the model has a loss of {'loss': 0.6452440023422241, 'tp': 4585.0, 'fp': 2352.0, 'tn': 5962.0, 'fn': 3709.0, 'accuracy': 0.635055422782898, 'precision': 0.6609485149383545, 'recall': 0.5528092384338379, 'auc': 0.6745811104774475} \n",
            "519/689 [=====================>........] - ETA: 17s - loss: 0.6452 - tp: 4585.0000 - fp: 2352.0000 - tn: 5962.0000 - fn: 3709.0000 - accuracy: 0.6351 - precision: 0.6609 - recall: 0.5528 - auc: 0.6746\n",
            " For Batch Number 520 the model has a loss of {'loss': 0.6451709866523743, 'tp': 4591.0, 'fp': 2354.0, 'tn': 5978.0, 'fn': 3717.0, 'accuracy': 0.6351562738418579, 'precision': 0.6610510945320129, 'recall': 0.5525999069213867, 'auc': 0.6746371984481812} \n",
            "520/689 [=====================>........] - ETA: 17s - loss: 0.6452 - tp: 4591.0000 - fp: 2354.0000 - tn: 5978.0000 - fn: 3717.0000 - accuracy: 0.6352 - precision: 0.6611 - recall: 0.5526 - auc: 0.6746\n",
            " For Batch Number 521 the model has a loss of {'loss': 0.6453275084495544, 'tp': 4599.0, 'fp': 2358.0, 'tn': 5988.0, 'fn': 3727.0, 'accuracy': 0.6350167989730835, 'precision': 0.6610608100891113, 'recall': 0.5523660778999329, 'auc': 0.6745129823684692} \n",
            "521/689 [=====================>........] - ETA: 17s - loss: 0.6453 - tp: 4599.0000 - fp: 2358.0000 - tn: 5988.0000 - fn: 3727.0000 - accuracy: 0.6350 - precision: 0.6611 - recall: 0.5524 - auc: 0.6745\n",
            " For Batch Number 522 the model has a loss of {'loss': 0.6454260349273682, 'tp': 4607.0, 'fp': 2363.0, 'tn': 5999.0, 'fn': 3735.0, 'accuracy': 0.6349377632141113, 'precision': 0.6609756350517273, 'recall': 0.5522656440734863, 'auc': 0.6744953393936157} \n",
            "522/689 [=====================>........] - ETA: 17s - loss: 0.6454 - tp: 4607.0000 - fp: 2363.0000 - tn: 5999.0000 - fn: 3735.0000 - accuracy: 0.6349 - precision: 0.6610 - recall: 0.5523 - auc: 0.6745\n",
            " For Batch Number 523 the model has a loss of {'loss': 0.6452133655548096, 'tp': 4618.0, 'fp': 2366.0, 'tn': 6013.0, 'fn': 3739.0, 'accuracy': 0.6352174878120422, 'precision': 0.6612256765365601, 'recall': 0.5525906682014465, 'auc': 0.674778938293457} \n",
            "523/689 [=====================>........] - ETA: 17s - loss: 0.6452 - tp: 4618.0000 - fp: 2366.0000 - tn: 6013.0000 - fn: 3739.0000 - accuracy: 0.6352 - precision: 0.6612 - recall: 0.5526 - auc: 0.6748\n",
            " For Batch Number 524 the model has a loss of {'loss': 0.6450470685958862, 'tp': 4627.0, 'fp': 2372.0, 'tn': 6027.0, 'fn': 3742.0, 'accuracy': 0.6353769302368164, 'precision': 0.6610944271087646, 'recall': 0.5528736710548401, 'auc': 0.6749029159545898} \n",
            "524/689 [=====================>........] - ETA: 17s - loss: 0.6450 - tp: 4627.0000 - fp: 2372.0000 - tn: 6027.0000 - fn: 3742.0000 - accuracy: 0.6354 - precision: 0.6611 - recall: 0.5529 - auc: 0.6749\n",
            " For Batch Number 525 the model has a loss of {'loss': 0.6452281475067139, 'tp': 4637.0, 'fp': 2379.0, 'tn': 6038.0, 'fn': 3746.0, 'accuracy': 0.6354166865348816, 'precision': 0.6609178781509399, 'recall': 0.5531432628631592, 'auc': 0.6747452616691589} \n",
            "525/689 [=====================>........] - ETA: 17s - loss: 0.6452 - tp: 4637.0000 - fp: 2379.0000 - tn: 6038.0000 - fn: 3746.0000 - accuracy: 0.6354 - precision: 0.6609 - recall: 0.5531 - auc: 0.6747\n",
            " For Batch Number 526 the model has a loss of {'loss': 0.645321249961853, 'tp': 4643.0, 'fp': 2382.0, 'tn': 6052.0, 'fn': 3755.0, 'accuracy': 0.6353968381881714, 'precision': 0.6609252691268921, 'recall': 0.5528697371482849, 'auc': 0.6746849417686462} \n",
            "526/689 [=====================>........] - ETA: 16s - loss: 0.6453 - tp: 4643.0000 - fp: 2382.0000 - tn: 6052.0000 - fn: 3755.0000 - accuracy: 0.6354 - precision: 0.6609 - recall: 0.5529 - auc: 0.6747\n",
            " For Batch Number 527 the model has a loss of {'loss': 0.6452731490135193, 'tp': 4649.0, 'fp': 2384.0, 'tn': 6066.0, 'fn': 3765.0, 'accuracy': 0.6353771090507507, 'precision': 0.6610265970230103, 'recall': 0.5525314807891846, 'auc': 0.6747063398361206} \n",
            "527/689 [=====================>........] - ETA: 16s - loss: 0.6453 - tp: 4649.0000 - fp: 2384.0000 - tn: 6066.0000 - fn: 3765.0000 - accuracy: 0.6354 - precision: 0.6610 - recall: 0.5525 - auc: 0.6747\n",
            " For Batch Number 528 the model has a loss of {'loss': 0.6452339887619019, 'tp': 4655.0, 'fp': 2385.0, 'tn': 6079.0, 'fn': 3777.0, 'accuracy': 0.6352983117103577, 'precision': 0.6612215638160706, 'recall': 0.5520635843276978, 'auc': 0.6747328639030457} \n",
            "528/689 [=====================>........] - ETA: 16s - loss: 0.6452 - tp: 4655.0000 - fp: 2385.0000 - tn: 6079.0000 - fn: 3777.0000 - accuracy: 0.6353 - precision: 0.6612 - recall: 0.5521 - auc: 0.6747\n",
            " For Batch Number 529 the model has a loss of {'loss': 0.6451616883277893, 'tp': 4662.0, 'fp': 2388.0, 'tn': 6094.0, 'fn': 3784.0, 'accuracy': 0.6353969573974609, 'precision': 0.6612765789031982, 'recall': 0.551977276802063, 'auc': 0.6748793721199036} \n",
            "529/689 [======================>.......] - ETA: 16s - loss: 0.6452 - tp: 4662.0000 - fp: 2388.0000 - tn: 6094.0000 - fn: 3784.0000 - accuracy: 0.6354 - precision: 0.6613 - recall: 0.5520 - auc: 0.6749\n",
            " For Batch Number 530 the model has a loss of {'loss': 0.6451312303543091, 'tp': 4668.0, 'fp': 2391.0, 'tn': 6110.0, 'fn': 3791.0, 'accuracy': 0.6354953050613403, 'precision': 0.6612834930419922, 'recall': 0.5518382787704468, 'auc': 0.6748756766319275} \n",
            "530/689 [======================>.......] - ETA: 16s - loss: 0.6451 - tp: 4668.0000 - fp: 2391.0000 - tn: 6110.0000 - fn: 3791.0000 - accuracy: 0.6355 - precision: 0.6613 - recall: 0.5518 - auc: 0.6749\n",
            " For Batch Number 531 the model has a loss of {'loss': 0.6451458930969238, 'tp': 4677.0, 'fp': 2392.0, 'tn': 6122.0, 'fn': 3801.0, 'accuracy': 0.6355343461036682, 'precision': 0.6616211533546448, 'recall': 0.5516631007194519, 'auc': 0.6748811602592468} \n",
            "531/689 [======================>.......] - ETA: 16s - loss: 0.6451 - tp: 4677.0000 - fp: 2392.0000 - tn: 6122.0000 - fn: 3801.0000 - accuracy: 0.6355 - precision: 0.6616 - recall: 0.5517 - auc: 0.6749\n",
            " For Batch Number 532 the model has a loss of {'loss': 0.644945502281189, 'tp': 4689.0, 'fp': 2395.0, 'tn': 6134.0, 'fn': 3806.0, 'accuracy': 0.6357495188713074, 'precision': 0.6619141697883606, 'recall': 0.5519717335700989, 'auc': 0.6751800775527954} \n",
            "532/689 [======================>.......] - ETA: 16s - loss: 0.6449 - tp: 4689.0000 - fp: 2395.0000 - tn: 6134.0000 - fn: 3806.0000 - accuracy: 0.6357 - precision: 0.6619 - recall: 0.5520 - auc: 0.6752\n",
            " For Batch Number 533 the model has a loss of {'loss': 0.6451714038848877, 'tp': 4696.0, 'fp': 2402.0, 'tn': 6145.0, 'fn': 3813.0, 'accuracy': 0.6356121301651001, 'precision': 0.661594808101654, 'recall': 0.551886260509491, 'auc': 0.6749760508537292} \n",
            "533/689 [======================>.......] - ETA: 16s - loss: 0.6452 - tp: 4696.0000 - fp: 2402.0000 - tn: 6145.0000 - fn: 3813.0000 - accuracy: 0.6356 - precision: 0.6616 - recall: 0.5519 - auc: 0.6750\n",
            " For Batch Number 534 the model has a loss of {'loss': 0.6450285315513611, 'tp': 4712.0, 'fp': 2404.0, 'tn': 6153.0, 'fn': 3819.0, 'accuracy': 0.6358262896537781, 'precision': 0.6621697545051575, 'recall': 0.5523385405540466, 'auc': 0.6753181219100952} \n",
            "534/689 [======================>.......] - ETA: 16s - loss: 0.6450 - tp: 4712.0000 - fp: 2404.0000 - tn: 6153.0000 - fn: 3819.0000 - accuracy: 0.6358 - precision: 0.6622 - recall: 0.5523 - auc: 0.6753\n",
            " For Batch Number 535 the model has a loss of {'loss': 0.645295262336731, 'tp': 4720.0, 'fp': 2415.0, 'tn': 6163.0, 'fn': 3822.0, 'accuracy': 0.6356892585754395, 'precision': 0.661527693271637, 'recall': 0.5525637865066528, 'auc': 0.6750800609588623} \n",
            "535/689 [======================>.......] - ETA: 16s - loss: 0.6453 - tp: 4720.0000 - fp: 2415.0000 - tn: 6163.0000 - fn: 3822.0000 - accuracy: 0.6357 - precision: 0.6615 - recall: 0.5526 - auc: 0.6751\n",
            " For Batch Number 536 the model has a loss of {'loss': 0.645031213760376, 'tp': 4732.0, 'fp': 2419.0, 'tn': 6177.0, 'fn': 3824.0, 'accuracy': 0.6360191106796265, 'precision': 0.661725640296936, 'recall': 0.5530622005462646, 'auc': 0.6754274368286133} \n",
            "536/689 [======================>.......] - ETA: 15s - loss: 0.6450 - tp: 4732.0000 - fp: 2419.0000 - tn: 6177.0000 - fn: 3824.0000 - accuracy: 0.6360 - precision: 0.6617 - recall: 0.5531 - auc: 0.6754\n",
            " For Batch Number 537 the model has a loss of {'loss': 0.6449466347694397, 'tp': 4741.0, 'fp': 2424.0, 'tn': 6188.0, 'fn': 3831.0, 'accuracy': 0.6359986066818237, 'precision': 0.6616887450218201, 'recall': 0.5530797839164734, 'auc': 0.6755250096321106} \n",
            "537/689 [======================>.......] - ETA: 15s - loss: 0.6449 - tp: 4741.0000 - fp: 2424.0000 - tn: 6188.0000 - fn: 3831.0000 - accuracy: 0.6360 - precision: 0.6617 - recall: 0.5531 - auc: 0.6755\n",
            " For Batch Number 538 the model has a loss of {'loss': 0.6449364423751831, 'tp': 4749.0, 'fp': 2426.0, 'tn': 6201.0, 'fn': 3840.0, 'accuracy': 0.636036217212677, 'precision': 0.6618815064430237, 'recall': 0.5529165267944336, 'auc': 0.6755942106246948} \n",
            "538/689 [======================>.......] - ETA: 15s - loss: 0.6449 - tp: 4749.0000 - fp: 2426.0000 - tn: 6201.0000 - fn: 3840.0000 - accuracy: 0.6360 - precision: 0.6619 - recall: 0.5529 - auc: 0.6756\n",
            " For Batch Number 539 the model has a loss of {'loss': 0.6450745463371277, 'tp': 4756.0, 'fp': 2431.0, 'tn': 6210.0, 'fn': 3851.0, 'accuracy': 0.635783851146698, 'precision': 0.6617503762245178, 'recall': 0.5525735020637512, 'auc': 0.6754575371742249} \n",
            "539/689 [======================>.......] - ETA: 15s - loss: 0.6451 - tp: 4756.0000 - fp: 2431.0000 - tn: 6210.0000 - fn: 3851.0000 - accuracy: 0.6358 - precision: 0.6618 - recall: 0.5526 - auc: 0.6755\n",
            " For Batch Number 540 the model has a loss of {'loss': 0.6449066996574402, 'tp': 4766.0, 'fp': 2432.0, 'tn': 6223.0, 'fn': 3859.0, 'accuracy': 0.635937511920929, 'precision': 0.6621283888816833, 'recall': 0.5525797009468079, 'auc': 0.6756842136383057} \n",
            "540/689 [======================>.......] - ETA: 15s - loss: 0.6449 - tp: 4766.0000 - fp: 2432.0000 - tn: 6223.0000 - fn: 3859.0000 - accuracy: 0.6359 - precision: 0.6621 - recall: 0.5526 - auc: 0.6757\n",
            " For Batch Number 541 the model has a loss of {'loss': 0.644860029220581, 'tp': 4775.0, 'fp': 2436.0, 'tn': 6235.0, 'fn': 3866.0, 'accuracy': 0.6359750628471375, 'precision': 0.6621827483177185, 'recall': 0.5525980591773987, 'auc': 0.6756994128227234} \n",
            "541/689 [======================>.......] - ETA: 15s - loss: 0.6449 - tp: 4775.0000 - fp: 2436.0000 - tn: 6235.0000 - fn: 3866.0000 - accuracy: 0.6360 - precision: 0.6622 - recall: 0.5526 - auc: 0.6757\n",
            " For Batch Number 542 the model has a loss of {'loss': 0.6446837782859802, 'tp': 4786.0, 'fp': 2439.0, 'tn': 6245.0, 'fn': 3874.0, 'accuracy': 0.6360124349594116, 'precision': 0.6624221205711365, 'recall': 0.5526558756828308, 'auc': 0.6760067343711853} \n",
            "542/689 [======================>.......] - ETA: 15s - loss: 0.6447 - tp: 4786.0000 - fp: 2439.0000 - tn: 6245.0000 - fn: 3874.0000 - accuracy: 0.6360 - precision: 0.6624 - recall: 0.5527 - auc: 0.6760\n",
            " For Batch Number 543 the model has a loss of {'loss': 0.6447358131408691, 'tp': 4797.0, 'fp': 2447.0, 'tn': 6253.0, 'fn': 3879.0, 'accuracy': 0.6359346508979797, 'precision': 0.6622031927108765, 'recall': 0.5529045462608337, 'auc': 0.6758816242218018} \n",
            "543/689 [======================>.......] - ETA: 15s - loss: 0.6447 - tp: 4797.0000 - fp: 2447.0000 - tn: 6253.0000 - fn: 3879.0000 - accuracy: 0.6359 - precision: 0.6622 - recall: 0.5529 - auc: 0.6759\n",
            " For Batch Number 544 the model has a loss of {'loss': 0.6445667147636414, 'tp': 4812.0, 'fp': 2454.0, 'tn': 6260.0, 'fn': 3882.0, 'accuracy': 0.6360294222831726, 'precision': 0.6622626185417175, 'recall': 0.5534851551055908, 'auc': 0.6761252880096436} \n",
            "544/689 [======================>.......] - ETA: 15s - loss: 0.6446 - tp: 4812.0000 - fp: 2454.0000 - tn: 6260.0000 - fn: 3882.0000 - accuracy: 0.6360 - precision: 0.6623 - recall: 0.5535 - auc: 0.6761\n",
            " For Batch Number 545 the model has a loss of {'loss': 0.6445986032485962, 'tp': 4823.0, 'fp': 2460.0, 'tn': 6272.0, 'fn': 3885.0, 'accuracy': 0.6361811757087708, 'precision': 0.6622270941734314, 'recall': 0.5538585186004639, 'auc': 0.6763191223144531} \n",
            "545/689 [======================>.......] - ETA: 15s - loss: 0.6446 - tp: 4823.0000 - fp: 2460.0000 - tn: 6272.0000 - fn: 3885.0000 - accuracy: 0.6362 - precision: 0.6622 - recall: 0.5539 - auc: 0.6763\n",
            " For Batch Number 546 the model has a loss of {'loss': 0.6446359157562256, 'tp': 4834.0, 'fp': 2468.0, 'tn': 6281.0, 'fn': 3889.0, 'accuracy': 0.6361607313156128, 'precision': 0.6620104312896729, 'recall': 0.5541671514511108, 'auc': 0.6764592528343201} \n",
            "546/689 [======================>.......] - ETA: 14s - loss: 0.6446 - tp: 4834.0000 - fp: 2468.0000 - tn: 6281.0000 - fn: 3889.0000 - accuracy: 0.6362 - precision: 0.6620 - recall: 0.5542 - auc: 0.6765\n",
            " For Batch Number 547 the model has a loss of {'loss': 0.6442524790763855, 'tp': 4845.0, 'fp': 2468.0, 'tn': 6295.0, 'fn': 3896.0, 'accuracy': 0.6364259719848633, 'precision': 0.6625187993049622, 'recall': 0.554284393787384, 'auc': 0.6769471168518066} \n",
            "547/689 [======================>.......] - ETA: 14s - loss: 0.6443 - tp: 4845.0000 - fp: 2468.0000 - tn: 6295.0000 - fn: 3896.0000 - accuracy: 0.6364 - precision: 0.6625 - recall: 0.5543 - auc: 0.6769\n",
            " For Batch Number 548 the model has a loss of {'loss': 0.6439771056175232, 'tp': 4857.0, 'fp': 2470.0, 'tn': 6308.0, 'fn': 3901.0, 'accuracy': 0.6366902589797974, 'precision': 0.6628906726837158, 'recall': 0.5545786619186401, 'auc': 0.6773266196250916} \n",
            "548/689 [======================>.......] - ETA: 14s - loss: 0.6440 - tp: 4857.0000 - fp: 2470.0000 - tn: 6308.0000 - fn: 3901.0000 - accuracy: 0.6367 - precision: 0.6629 - recall: 0.5546 - auc: 0.6773\n",
            " For Batch Number 549 the model has a loss of {'loss': 0.6439980268478394, 'tp': 4868.0, 'fp': 2471.0, 'tn': 6319.0, 'fn': 3910.0, 'accuracy': 0.6367827653884888, 'precision': 0.6633056402206421, 'recall': 0.5545682311058044, 'auc': 0.6773576140403748} \n",
            "549/689 [======================>.......] - ETA: 14s - loss: 0.6440 - tp: 4868.0000 - fp: 2471.0000 - tn: 6319.0000 - fn: 3910.0000 - accuracy: 0.6368 - precision: 0.6633 - recall: 0.5546 - auc: 0.6774\n",
            " For Batch Number 550 the model has a loss of {'loss': 0.6436765789985657, 'tp': 4879.0, 'fp': 2474.0, 'tn': 6334.0, 'fn': 3913.0, 'accuracy': 0.6371022462844849, 'precision': 0.6635386943817139, 'recall': 0.5549362897872925, 'auc': 0.6778508424758911} \n",
            "550/689 [======================>.......] - ETA: 14s - loss: 0.6437 - tp: 4879.0000 - fp: 2474.0000 - tn: 6334.0000 - fn: 3913.0000 - accuracy: 0.6371 - precision: 0.6635 - recall: 0.5549 - auc: 0.6779\n",
            " For Batch Number 551 the model has a loss of {'loss': 0.6434519290924072, 'tp': 4893.0, 'fp': 2477.0, 'tn': 6344.0, 'fn': 3918.0, 'accuracy': 0.6373071670532227, 'precision': 0.6639077067375183, 'recall': 0.5553285479545593, 'auc': 0.6781861186027527} \n",
            "551/689 [======================>.......] - ETA: 14s - loss: 0.6435 - tp: 4893.0000 - fp: 2477.0000 - tn: 6344.0000 - fn: 3918.0000 - accuracy: 0.6373 - precision: 0.6639 - recall: 0.5553 - auc: 0.6782\n",
            " For Batch Number 552 the model has a loss of {'loss': 0.6431201696395874, 'tp': 4908.0, 'fp': 2479.0, 'tn': 6354.0, 'fn': 3923.0, 'accuracy': 0.637567937374115, 'precision': 0.6644104719161987, 'recall': 0.5557694435119629, 'auc': 0.6785770654678345} \n",
            "552/689 [=======================>......] - ETA: 14s - loss: 0.6431 - tp: 4908.0000 - fp: 2479.0000 - tn: 6354.0000 - fn: 3923.0000 - accuracy: 0.6376 - precision: 0.6644 - recall: 0.5558 - auc: 0.6786\n",
            " For Batch Number 553 the model has a loss of {'loss': 0.642953634262085, 'tp': 4922.0, 'fp': 2484.0, 'tn': 6364.0, 'fn': 3926.0, 'accuracy': 0.6377712488174438, 'precision': 0.6645962595939636, 'recall': 0.5562838912010193, 'auc': 0.6788302659988403} \n",
            "553/689 [=======================>......] - ETA: 14s - loss: 0.6430 - tp: 4922.0000 - fp: 2484.0000 - tn: 6364.0000 - fn: 3926.0000 - accuracy: 0.6378 - precision: 0.6646 - recall: 0.5563 - auc: 0.6788\n",
            " For Batch Number 554 the model has a loss of {'loss': 0.642768919467926, 'tp': 4934.0, 'fp': 2488.0, 'tn': 6376.0, 'fn': 3930.0, 'accuracy': 0.6379738450050354, 'precision': 0.6647803783416748, 'recall': 0.5566335916519165, 'auc': 0.6790806651115417} \n",
            "554/689 [=======================>......] - ETA: 14s - loss: 0.6428 - tp: 4934.0000 - fp: 2488.0000 - tn: 6376.0000 - fn: 3930.0000 - accuracy: 0.6380 - precision: 0.6648 - recall: 0.5566 - auc: 0.6791\n",
            " For Batch Number 555 the model has a loss of {'loss': 0.6426185369491577, 'tp': 4945.0, 'fp': 2496.0, 'tn': 6387.0, 'fn': 3932.0, 'accuracy': 0.6380630731582642, 'precision': 0.6645612120628357, 'recall': 0.5570575594902039, 'auc': 0.6792352199554443} \n",
            "555/689 [=======================>......] - ETA: 14s - loss: 0.6426 - tp: 4945.0000 - fp: 2496.0000 - tn: 6387.0000 - fn: 3932.0000 - accuracy: 0.6381 - precision: 0.6646 - recall: 0.5571 - auc: 0.6792\n",
            " For Batch Number 556 the model has a loss of {'loss': 0.6423357129096985, 'tp': 4959.0, 'fp': 2498.0, 'tn': 6400.0, 'fn': 3935.0, 'accuracy': 0.6384329795837402, 'precision': 0.6650127172470093, 'recall': 0.5575668811798096, 'auc': 0.6796635389328003} \n",
            "556/689 [=======================>......] - ETA: 13s - loss: 0.6423 - tp: 4959.0000 - fp: 2498.0000 - tn: 6400.0000 - fn: 3935.0000 - accuracy: 0.6384 - precision: 0.6650 - recall: 0.5576 - auc: 0.6797\n",
            " For Batch Number 557 the model has a loss of {'loss': 0.6427890658378601, 'tp': 4968.0, 'fp': 2504.0, 'tn': 6410.0, 'fn': 3942.0, 'accuracy': 0.6383528113365173, 'precision': 0.664882242679596, 'recall': 0.5575757622718811, 'auc': 0.6793621778488159} \n",
            "557/689 [=======================>......] - ETA: 13s - loss: 0.6428 - tp: 4968.0000 - fp: 2504.0000 - tn: 6410.0000 - fn: 3942.0000 - accuracy: 0.6384 - precision: 0.6649 - recall: 0.5576 - auc: 0.6794\n",
            " For Batch Number 558 the model has a loss of {'loss': 0.6427514553070068, 'tp': 4976.0, 'fp': 2509.0, 'tn': 6424.0, 'fn': 3947.0, 'accuracy': 0.6384408473968506, 'precision': 0.6647962331771851, 'recall': 0.5576599836349487, 'auc': 0.6793903112411499} \n",
            "558/689 [=======================>......] - ETA: 13s - loss: 0.6428 - tp: 4976.0000 - fp: 2509.0000 - tn: 6424.0000 - fn: 3947.0000 - accuracy: 0.6384 - precision: 0.6648 - recall: 0.5577 - auc: 0.6794\n",
            " For Batch Number 559 the model has a loss of {'loss': 0.6427106857299805, 'tp': 4982.0, 'fp': 2511.0, 'tn': 6442.0, 'fn': 3953.0, 'accuracy': 0.6386404037475586, 'precision': 0.6648872494697571, 'recall': 0.5575825572013855, 'auc': 0.6795309782028198} \n",
            "559/689 [=======================>......] - ETA: 13s - loss: 0.6427 - tp: 4982.0000 - fp: 2511.0000 - tn: 6442.0000 - fn: 3953.0000 - accuracy: 0.6386 - precision: 0.6649 - recall: 0.5576 - auc: 0.6795\n",
            " For Batch Number 560 the model has a loss of {'loss': 0.6430060267448425, 'tp': 4993.0, 'fp': 2515.0, 'tn': 6454.0, 'fn': 3958.0, 'accuracy': 0.6387834548950195, 'precision': 0.6650239825248718, 'recall': 0.5578147768974304, 'auc': 0.6795724034309387} \n",
            "560/689 [=======================>......] - ETA: 13s - loss: 0.6430 - tp: 4993.0000 - fp: 2515.0000 - tn: 6454.0000 - fn: 3958.0000 - accuracy: 0.6388 - precision: 0.6650 - recall: 0.5578 - auc: 0.6796\n",
            " For Batch Number 561 the model has a loss of {'loss': 0.6428468823432922, 'tp': 5000.0, 'fp': 2516.0, 'tn': 6472.0, 'fn': 3964.0, 'accuracy': 0.6390374302864075, 'precision': 0.6652474999427795, 'recall': 0.5577867031097412, 'auc': 0.679831862449646} \n",
            "561/689 [=======================>......] - ETA: 13s - loss: 0.6428 - tp: 5000.0000 - fp: 2516.0000 - tn: 6472.0000 - fn: 3964.0000 - accuracy: 0.6390 - precision: 0.6652 - recall: 0.5578 - auc: 0.6798\n",
            " For Batch Number 562 the model has a loss of {'loss': 0.6431324481964111, 'tp': 5005.0, 'fp': 2521.0, 'tn': 6485.0, 'fn': 3973.0, 'accuracy': 0.6389012336730957, 'precision': 0.665027916431427, 'recall': 0.5574738383293152, 'auc': 0.6795511841773987} \n",
            "562/689 [=======================>......] - ETA: 13s - loss: 0.6431 - tp: 5005.0000 - fp: 2521.0000 - tn: 6485.0000 - fn: 3973.0000 - accuracy: 0.6389 - precision: 0.6650 - recall: 0.5575 - auc: 0.6796\n",
            " For Batch Number 563 the model has a loss of {'loss': 0.6430583596229553, 'tp': 5012.0, 'fp': 2525.0, 'tn': 6499.0, 'fn': 3980.0, 'accuracy': 0.6389320492744446, 'precision': 0.6649860739707947, 'recall': 0.5573843121528625, 'auc': 0.6796554327011108} \n",
            "563/689 [=======================>......] - ETA: 13s - loss: 0.6431 - tp: 5012.0000 - fp: 2525.0000 - tn: 6499.0000 - fn: 3980.0000 - accuracy: 0.6389 - precision: 0.6650 - recall: 0.5574 - auc: 0.6797\n",
            " For Batch Number 564 the model has a loss of {'loss': 0.6431125402450562, 'tp': 5017.0, 'fp': 2529.0, 'tn': 6514.0, 'fn': 3988.0, 'accuracy': 0.6389073729515076, 'precision': 0.6648555397987366, 'recall': 0.5571349263191223, 'auc': 0.6796697378158569} \n",
            "564/689 [=======================>......] - ETA: 13s - loss: 0.6431 - tp: 5017.0000 - fp: 2529.0000 - tn: 6514.0000 - fn: 3988.0000 - accuracy: 0.6389 - precision: 0.6649 - recall: 0.5571 - auc: 0.6797\n",
            " For Batch Number 565 the model has a loss of {'loss': 0.6434748768806458, 'tp': 5024.0, 'fp': 2532.0, 'tn': 6525.0, 'fn': 3999.0, 'accuracy': 0.6387721300125122, 'precision': 0.6649020910263062, 'recall': 0.5567992925643921, 'auc': 0.6792818307876587} \n",
            "565/689 [=======================>......] - ETA: 13s - loss: 0.6435 - tp: 5024.0000 - fp: 2532.0000 - tn: 6525.0000 - fn: 3999.0000 - accuracy: 0.6388 - precision: 0.6649 - recall: 0.5568 - auc: 0.6793\n",
            " For Batch Number 566 the model has a loss of {'loss': 0.6435256004333496, 'tp': 5028.0, 'fp': 2536.0, 'tn': 6539.0, 'fn': 4009.0, 'accuracy': 0.638637363910675, 'precision': 0.6647276282310486, 'recall': 0.5563793182373047, 'auc': 0.6791151762008667} \n",
            "566/689 [=======================>......] - ETA: 12s - loss: 0.6435 - tp: 5028.0000 - fp: 2536.0000 - tn: 6539.0000 - fn: 4009.0000 - accuracy: 0.6386 - precision: 0.6647 - recall: 0.5564 - auc: 0.6791\n",
            " For Batch Number 567 the model has a loss of {'loss': 0.6434243321418762, 'tp': 5038.0, 'fp': 2540.0, 'tn': 6550.0, 'fn': 4016.0, 'accuracy': 0.638668417930603, 'precision': 0.6648192405700684, 'recall': 0.5564391613006592, 'auc': 0.6792615056037903} \n",
            "567/689 [=======================>......] - ETA: 12s - loss: 0.6434 - tp: 5038.0000 - fp: 2540.0000 - tn: 6550.0000 - fn: 4016.0000 - accuracy: 0.6387 - precision: 0.6648 - recall: 0.5564 - auc: 0.6793\n",
            " For Batch Number 568 the model has a loss of {'loss': 0.6435364484786987, 'tp': 5047.0, 'fp': 2547.0, 'tn': 6557.0, 'fn': 4025.0, 'accuracy': 0.638424277305603, 'precision': 0.6646036505699158, 'recall': 0.5563271641731262, 'auc': 0.6791135668754578} \n",
            "568/689 [=======================>......] - ETA: 12s - loss: 0.6435 - tp: 5047.0000 - fp: 2547.0000 - tn: 6557.0000 - fn: 4025.0000 - accuracy: 0.6384 - precision: 0.6646 - recall: 0.5563 - auc: 0.6791\n",
            " For Batch Number 569 the model has a loss of {'loss': 0.6434631943702698, 'tp': 5060.0, 'fp': 2553.0, 'tn': 6567.0, 'fn': 4028.0, 'accuracy': 0.6385654807090759, 'precision': 0.6646525859832764, 'recall': 0.5567781925201416, 'auc': 0.6791648864746094} \n",
            "569/689 [=======================>......] - ETA: 12s - loss: 0.6435 - tp: 5060.0000 - fp: 2553.0000 - tn: 6567.0000 - fn: 4028.0000 - accuracy: 0.6386 - precision: 0.6647 - recall: 0.5568 - auc: 0.6792\n",
            " For Batch Number 570 the model has a loss of {'loss': 0.6435799598693848, 'tp': 5072.0, 'fp': 2567.0, 'tn': 6570.0, 'fn': 4031.0, 'accuracy': 0.6382675170898438, 'precision': 0.6639612317085266, 'recall': 0.5571789741516113, 'auc': 0.6789788007736206} \n",
            "570/689 [=======================>......] - ETA: 12s - loss: 0.6436 - tp: 5072.0000 - fp: 2567.0000 - tn: 6570.0000 - fn: 4031.0000 - accuracy: 0.6383 - precision: 0.6640 - recall: 0.5572 - auc: 0.6790\n",
            " For Batch Number 571 the model has a loss of {'loss': 0.6435450315475464, 'tp': 5091.0, 'fp': 2576.0, 'tn': 6572.0, 'fn': 4033.0, 'accuracy': 0.6382990479469299, 'precision': 0.6640146374702454, 'recall': 0.5579789280891418, 'auc': 0.6790657043457031} \n",
            "571/689 [=======================>......] - ETA: 12s - loss: 0.6435 - tp: 5091.0000 - fp: 2576.0000 - tn: 6572.0000 - fn: 4033.0000 - accuracy: 0.6383 - precision: 0.6640 - recall: 0.5580 - auc: 0.6791\n",
            " For Batch Number 572 the model has a loss of {'loss': 0.6436628103256226, 'tp': 5104.0, 'fp': 2591.0, 'tn': 6574.0, 'fn': 4035.0, 'accuracy': 0.6380026340484619, 'precision': 0.663287878036499, 'recall': 0.5584856271743774, 'auc': 0.6788887977600098} \n",
            "572/689 [=======================>......] - ETA: 12s - loss: 0.6437 - tp: 5104.0000 - fp: 2591.0000 - tn: 6574.0000 - fn: 4035.0000 - accuracy: 0.6380 - precision: 0.6633 - recall: 0.5585 - auc: 0.6789\n",
            " For Batch Number 573 the model has a loss of {'loss': 0.6435794234275818, 'tp': 5122.0, 'fp': 2597.0, 'tn': 6582.0, 'fn': 4035.0, 'accuracy': 0.6383071541786194, 'precision': 0.6635574698448181, 'recall': 0.5593534708023071, 'auc': 0.6790434122085571} \n",
            "573/689 [=======================>......] - ETA: 12s - loss: 0.6436 - tp: 5122.0000 - fp: 2597.0000 - tn: 6582.0000 - fn: 4035.0000 - accuracy: 0.6383 - precision: 0.6636 - recall: 0.5594 - auc: 0.6790\n",
            " For Batch Number 574 the model has a loss of {'loss': 0.6436840891838074, 'tp': 5133.0, 'fp': 2606.0, 'tn': 6588.0, 'fn': 4041.0, 'accuracy': 0.6381206512451172, 'precision': 0.6632639765739441, 'recall': 0.5595160126686096, 'auc': 0.678901731967926} \n",
            "574/689 [=======================>......] - ETA: 12s - loss: 0.6437 - tp: 5133.0000 - fp: 2606.0000 - tn: 6588.0000 - fn: 4041.0000 - accuracy: 0.6381 - precision: 0.6633 - recall: 0.5595 - auc: 0.6789\n",
            " For Batch Number 575 the model has a loss of {'loss': 0.6437865495681763, 'tp': 5140.0, 'fp': 2614.0, 'tn': 6601.0, 'fn': 4045.0, 'accuracy': 0.6380978226661682, 'precision': 0.6628836989402771, 'recall': 0.5596080422401428, 'auc': 0.6787079572677612} \n",
            "575/689 [========================>.....] - ETA: 11s - loss: 0.6438 - tp: 5140.0000 - fp: 2614.0000 - tn: 6601.0000 - fn: 4045.0000 - accuracy: 0.6381 - precision: 0.6629 - recall: 0.5596 - auc: 0.6787\n",
            " For Batch Number 576 the model has a loss of {'loss': 0.6437040567398071, 'tp': 5150.0, 'fp': 2616.0, 'tn': 6617.0, 'fn': 4049.0, 'accuracy': 0.6384006142616272, 'precision': 0.6631470322608948, 'recall': 0.5598434805870056, 'auc': 0.6788156032562256} \n",
            "576/689 [========================>.....] - ETA: 11s - loss: 0.6437 - tp: 5150.0000 - fp: 2616.0000 - tn: 6617.0000 - fn: 4049.0000 - accuracy: 0.6384 - precision: 0.6631 - recall: 0.5598 - auc: 0.6788\n",
            " For Batch Number 577 the model has a loss of {'loss': 0.6435680389404297, 'tp': 5157.0, 'fp': 2617.0, 'tn': 6635.0, 'fn': 4055.0, 'accuracy': 0.6386481523513794, 'precision': 0.6633650660514832, 'recall': 0.5598132610321045, 'auc': 0.6789829730987549} \n",
            "577/689 [========================>.....] - ETA: 11s - loss: 0.6436 - tp: 5157.0000 - fp: 2617.0000 - tn: 6635.0000 - fn: 4055.0000 - accuracy: 0.6386 - precision: 0.6634 - recall: 0.5598 - auc: 0.6790\n",
            " For Batch Number 578 the model has a loss of {'loss': 0.6436404585838318, 'tp': 5160.0, 'fp': 2618.0, 'tn': 6648.0, 'fn': 4070.0, 'accuracy': 0.6384083032608032, 'precision': 0.6634095907211304, 'recall': 0.5590465664863586, 'auc': 0.6788693070411682} \n",
            "578/689 [========================>.....] - ETA: 11s - loss: 0.6436 - tp: 5160.0000 - fp: 2618.0000 - tn: 6648.0000 - fn: 4070.0000 - accuracy: 0.6384 - precision: 0.6634 - recall: 0.5590 - auc: 0.6789\n",
            " For Batch Number 579 the model has a loss of {'loss': 0.6436381936073303, 'tp': 5166.0, 'fp': 2619.0, 'tn': 6663.0, 'fn': 4080.0, 'accuracy': 0.6384391188621521, 'precision': 0.6635838150978088, 'recall': 0.5587280988693237, 'auc': 0.678888201713562} \n",
            "579/689 [========================>.....] - ETA: 11s - loss: 0.6436 - tp: 5166.0000 - fp: 2619.0000 - tn: 6663.0000 - fn: 4080.0000 - accuracy: 0.6384 - precision: 0.6636 - recall: 0.5587 - auc: 0.6789\n",
            " For Batch Number 580 the model has a loss of {'loss': 0.6438153386116028, 'tp': 5173.0, 'fp': 2620.0, 'tn': 6674.0, 'fn': 4093.0, 'accuracy': 0.6383081674575806, 'precision': 0.663800835609436, 'recall': 0.5582775473594666, 'auc': 0.6786852478981018} \n",
            "580/689 [========================>.....] - ETA: 11s - loss: 0.6438 - tp: 5173.0000 - fp: 2620.0000 - tn: 6674.0000 - fn: 4093.0000 - accuracy: 0.6383 - precision: 0.6638 - recall: 0.5583 - auc: 0.6787\n",
            " For Batch Number 581 the model has a loss of {'loss': 0.6439818143844604, 'tp': 5179.0, 'fp': 2623.0, 'tn': 6686.0, 'fn': 4104.0, 'accuracy': 0.6381776928901672, 'precision': 0.6638041734695435, 'recall': 0.5579015612602234, 'auc': 0.678493320941925} \n",
            "581/689 [========================>.....] - ETA: 11s - loss: 0.6440 - tp: 5179.0000 - fp: 2623.0000 - tn: 6686.0000 - fn: 4104.0000 - accuracy: 0.6382 - precision: 0.6638 - recall: 0.5579 - auc: 0.6785\n",
            " For Batch Number 582 the model has a loss of {'loss': 0.6439031958580017, 'tp': 5191.0, 'fp': 2626.0, 'tn': 6694.0, 'fn': 4113.0, 'accuracy': 0.6381550431251526, 'precision': 0.6640654802322388, 'recall': 0.5579320788383484, 'auc': 0.6785765290260315} \n",
            "582/689 [========================>.....] - ETA: 11s - loss: 0.6439 - tp: 5191.0000 - fp: 2626.0000 - tn: 6694.0000 - fn: 4113.0000 - accuracy: 0.6382 - precision: 0.6641 - recall: 0.5579 - auc: 0.6786\n",
            " For Batch Number 583 the model has a loss of {'loss': 0.6437510251998901, 'tp': 5203.0, 'fp': 2633.0, 'tn': 6702.0, 'fn': 4118.0, 'accuracy': 0.6381325125694275, 'precision': 0.6639867424964905, 'recall': 0.5582019090652466, 'auc': 0.6787068247795105} \n",
            "583/689 [========================>.....] - ETA: 11s - loss: 0.6438 - tp: 5203.0000 - fp: 2633.0000 - tn: 6702.0000 - fn: 4118.0000 - accuracy: 0.6381 - precision: 0.6640 - recall: 0.5582 - auc: 0.6787\n",
            " For Batch Number 584 the model has a loss of {'loss': 0.6437638401985168, 'tp': 5216.0, 'fp': 2644.0, 'tn': 6707.0, 'fn': 4121.0, 'accuracy': 0.6380029916763306, 'precision': 0.6636132597923279, 'recall': 0.5586376786231995, 'auc': 0.6786463856697083} \n",
            "584/689 [========================>.....] - ETA: 11s - loss: 0.6438 - tp: 5216.0000 - fp: 2644.0000 - tn: 6707.0000 - fn: 4121.0000 - accuracy: 0.6380 - precision: 0.6636 - recall: 0.5586 - auc: 0.6786\n",
            " For Batch Number 585 the model has a loss of {'loss': 0.6437066793441772, 'tp': 5232.0, 'fp': 2651.0, 'tn': 6711.0, 'fn': 4126.0, 'accuracy': 0.6379807591438293, 'precision': 0.6637067198753357, 'recall': 0.5590938329696655, 'auc': 0.6787883639335632} \n",
            "585/689 [========================>.....] - ETA: 10s - loss: 0.6437 - tp: 5232.0000 - fp: 2651.0000 - tn: 6711.0000 - fn: 4126.0000 - accuracy: 0.6380 - precision: 0.6637 - recall: 0.5591 - auc: 0.6788\n",
            " For Batch Number 586 the model has a loss of {'loss': 0.6438988447189331, 'tp': 5242.0, 'fp': 2665.0, 'tn': 6717.0, 'fn': 4128.0, 'accuracy': 0.6377453207969666, 'precision': 0.6629568934440613, 'recall': 0.5594450235366821, 'auc': 0.6785596609115601} \n",
            "586/689 [========================>.....] - ETA: 10s - loss: 0.6439 - tp: 5242.0000 - fp: 2665.0000 - tn: 6717.0000 - fn: 4128.0000 - accuracy: 0.6377 - precision: 0.6630 - recall: 0.5594 - auc: 0.6786\n",
            " For Batch Number 587 the model has a loss of {'loss': 0.643947958946228, 'tp': 5254.0, 'fp': 2674.0, 'tn': 6725.0, 'fn': 4131.0, 'accuracy': 0.6377235651016235, 'precision': 0.662714421749115, 'recall': 0.5598295331001282, 'auc': 0.6785435080528259} \n",
            "587/689 [========================>.....] - ETA: 10s - loss: 0.6439 - tp: 5254.0000 - fp: 2674.0000 - tn: 6725.0000 - fn: 4131.0000 - accuracy: 0.6377 - precision: 0.6627 - recall: 0.5598 - auc: 0.6785\n",
            " For Batch Number 588 the model has a loss of {'loss': 0.643902063369751, 'tp': 5264.0, 'fp': 2679.0, 'tn': 6734.0, 'fn': 4139.0, 'accuracy': 0.6376488208770752, 'precision': 0.6627218723297119, 'recall': 0.5598213076591492, 'auc': 0.6786155700683594} \n",
            "588/689 [========================>.....] - ETA: 10s - loss: 0.6439 - tp: 5264.0000 - fp: 2679.0000 - tn: 6734.0000 - fn: 4139.0000 - accuracy: 0.6376 - precision: 0.6627 - recall: 0.5598 - auc: 0.6786\n",
            " For Batch Number 589 the model has a loss of {'loss': 0.6438618898391724, 'tp': 5274.0, 'fp': 2680.0, 'tn': 6746.0, 'fn': 4148.0, 'accuracy': 0.6377334594726562, 'precision': 0.6630626320838928, 'recall': 0.5597537755966187, 'auc': 0.6786647439002991} \n",
            "589/689 [========================>.....] - ETA: 10s - loss: 0.6439 - tp: 5274.0000 - fp: 2680.0000 - tn: 6746.0000 - fn: 4148.0000 - accuracy: 0.6377 - precision: 0.6631 - recall: 0.5598 - auc: 0.6787\n",
            " For Batch Number 590 the model has a loss of {'loss': 0.6436796188354492, 'tp': 5284.0, 'fp': 2681.0, 'tn': 6760.0, 'fn': 4155.0, 'accuracy': 0.6379237174987793, 'precision': 0.6634023785591125, 'recall': 0.5598050355911255, 'auc': 0.6788694858551025} \n",
            "590/689 [========================>.....] - ETA: 10s - loss: 0.6437 - tp: 5284.0000 - fp: 2681.0000 - tn: 6760.0000 - fn: 4155.0000 - accuracy: 0.6379 - precision: 0.6634 - recall: 0.5598 - auc: 0.6789\n",
            " For Batch Number 591 the model has a loss of {'loss': 0.643620491027832, 'tp': 5294.0, 'fp': 2683.0, 'tn': 6773.0, 'fn': 4162.0, 'accuracy': 0.6380605101585388, 'precision': 0.6636580228805542, 'recall': 0.5598561763763428, 'auc': 0.678955614566803} \n",
            "591/689 [========================>.....] - ETA: 10s - loss: 0.6436 - tp: 5294.0000 - fp: 2683.0000 - tn: 6773.0000 - fn: 4162.0000 - accuracy: 0.6381 - precision: 0.6637 - recall: 0.5599 - auc: 0.6790\n",
            " For Batch Number 592 the model has a loss of {'loss': 0.643351137638092, 'tp': 5306.0, 'fp': 2684.0, 'tn': 6789.0, 'fn': 4165.0, 'accuracy': 0.6384607553482056, 'precision': 0.6640800833702087, 'recall': 0.5602365136146545, 'auc': 0.6792763471603394} \n",
            "592/689 [========================>.....] - ETA: 10s - loss: 0.6434 - tp: 5306.0000 - fp: 2684.0000 - tn: 6789.0000 - fn: 4165.0000 - accuracy: 0.6385 - precision: 0.6641 - recall: 0.5602 - auc: 0.6793\n",
            " For Batch Number 593 the model has a loss of {'loss': 0.6437462568283081, 'tp': 5316.0, 'fp': 2688.0, 'tn': 6800.0, 'fn': 4172.0, 'accuracy': 0.6384907364845276, 'precision': 0.6641679406166077, 'recall': 0.5602867007255554, 'auc': 0.6791590452194214} \n",
            "593/689 [========================>.....] - ETA: 10s - loss: 0.6437 - tp: 5316.0000 - fp: 2688.0000 - tn: 6800.0000 - fn: 4172.0000 - accuracy: 0.6385 - precision: 0.6642 - recall: 0.5603 - auc: 0.6792\n",
            " For Batch Number 594 the model has a loss of {'loss': 0.6435946822166443, 'tp': 5325.0, 'fp': 2693.0, 'tn': 6813.0, 'fn': 4177.0, 'accuracy': 0.6385732293128967, 'precision': 0.664130687713623, 'recall': 0.560408353805542, 'auc': 0.6792625784873962} \n",
            "594/689 [========================>.....] - ETA: 9s - loss: 0.6436 - tp: 5325.0000 - fp: 2693.0000 - tn: 6813.0000 - fn: 4177.0000 - accuracy: 0.6386 - precision: 0.6641 - recall: 0.5604 - auc: 0.6793 \n",
            " For Batch Number 595 the model has a loss of {'loss': 0.6435633897781372, 'tp': 5335.0, 'fp': 2699.0, 'tn': 6822.0, 'fn': 4184.0, 'accuracy': 0.6384978890419006, 'precision': 0.6640527844429016, 'recall': 0.5604580044746399, 'auc': 0.6792215704917908} \n",
            "595/689 [========================>.....] - ETA: 9s - loss: 0.6436 - tp: 5335.0000 - fp: 2699.0000 - tn: 6822.0000 - fn: 4184.0000 - accuracy: 0.6385 - precision: 0.6641 - recall: 0.5605 - auc: 0.6792\n",
            " For Batch Number 596 the model has a loss of {'loss': 0.6434351205825806, 'tp': 5345.0, 'fp': 2701.0, 'tn': 6839.0, 'fn': 4187.0, 'accuracy': 0.6388422846794128, 'precision': 0.6643052697181702, 'recall': 0.5607427358627319, 'auc': 0.6794682741165161} \n",
            "596/689 [========================>.....] - ETA: 9s - loss: 0.6434 - tp: 5345.0000 - fp: 2701.0000 - tn: 6839.0000 - fn: 4187.0000 - accuracy: 0.6388 - precision: 0.6643 - recall: 0.5607 - auc: 0.6795\n",
            " For Batch Number 597 the model has a loss of {'loss': 0.6432722210884094, 'tp': 5354.0, 'fp': 2703.0, 'tn': 6855.0, 'fn': 4192.0, 'accuracy': 0.639080822467804, 'precision': 0.6645153164863586, 'recall': 0.560863196849823, 'auc': 0.6797970533370972} \n",
            "597/689 [========================>.....] - ETA: 9s - loss: 0.6433 - tp: 5354.0000 - fp: 2703.0000 - tn: 6855.0000 - fn: 4192.0000 - accuracy: 0.6391 - precision: 0.6645 - recall: 0.5609 - auc: 0.6798\n",
            " For Batch Number 598 the model has a loss of {'loss': 0.6434938311576843, 'tp': 5361.0, 'fp': 2706.0, 'tn': 6867.0, 'fn': 4202.0, 'accuracy': 0.6390050053596497, 'precision': 0.6645593047142029, 'recall': 0.5605981349945068, 'auc': 0.679655909538269} \n",
            "598/689 [=========================>....] - ETA: 9s - loss: 0.6435 - tp: 5361.0000 - fp: 2706.0000 - tn: 6867.0000 - fn: 4202.0000 - accuracy: 0.6390 - precision: 0.6646 - recall: 0.5606 - auc: 0.6797\n",
            " For Batch Number 599 the model has a loss of {'loss': 0.6438518762588501, 'tp': 5367.0, 'fp': 2709.0, 'tn': 6882.0, 'fn': 4210.0, 'accuracy': 0.6390337944030762, 'precision': 0.6645616888999939, 'recall': 0.5604051351547241, 'auc': 0.6795192360877991} \n",
            "599/689 [=========================>....] - ETA: 9s - loss: 0.6439 - tp: 5367.0000 - fp: 2709.0000 - tn: 6882.0000 - fn: 4210.0000 - accuracy: 0.6390 - precision: 0.6646 - recall: 0.5604 - auc: 0.6795\n",
            " For Batch Number 600 the model has a loss of {'loss': 0.6437477469444275, 'tp': 5374.0, 'fp': 2712.0, 'tn': 6898.0, 'fn': 4216.0, 'accuracy': 0.6391666531562805, 'precision': 0.6646054983139038, 'recall': 0.5603753924369812, 'auc': 0.6796581745147705} \n",
            "600/689 [=========================>....] - ETA: 9s - loss: 0.6437 - tp: 5374.0000 - fp: 2712.0000 - tn: 6898.0000 - fn: 4216.0000 - accuracy: 0.6392 - precision: 0.6646 - recall: 0.5604 - auc: 0.6797\n",
            " For Batch Number 601 the model has a loss of {'loss': 0.6435250043869019, 'tp': 5382.0, 'fp': 2716.0, 'tn': 6913.0, 'fn': 4221.0, 'accuracy': 0.6392990946769714, 'precision': 0.6646085381507874, 'recall': 0.5604498386383057, 'auc': 0.6799014806747437} \n",
            "601/689 [=========================>....] - ETA: 9s - loss: 0.6435 - tp: 5382.0000 - fp: 2716.0000 - tn: 6913.0000 - fn: 4221.0000 - accuracy: 0.6393 - precision: 0.6646 - recall: 0.5604 - auc: 0.6799\n",
            " For Batch Number 602 the model has a loss of {'loss': 0.643371045589447, 'tp': 5392.0, 'fp': 2719.0, 'tn': 6925.0, 'fn': 4228.0, 'accuracy': 0.6393791437149048, 'precision': 0.6647762060165405, 'recall': 0.5604989528656006, 'auc': 0.680134117603302} \n",
            "602/689 [=========================>....] - ETA: 9s - loss: 0.6434 - tp: 5392.0000 - fp: 2719.0000 - tn: 6925.0000 - fn: 4228.0000 - accuracy: 0.6394 - precision: 0.6648 - recall: 0.5605 - auc: 0.6801\n",
            " For Batch Number 603 the model has a loss of {'loss': 0.643368124961853, 'tp': 5404.0, 'fp': 2721.0, 'tn': 6934.0, 'fn': 4237.0, 'accuracy': 0.6394071578979492, 'precision': 0.6651076674461365, 'recall': 0.5605227947235107, 'auc': 0.6800816655158997} \n",
            "603/689 [=========================>....] - ETA: 9s - loss: 0.6434 - tp: 5404.0000 - fp: 2721.0000 - tn: 6934.0000 - fn: 4237.0000 - accuracy: 0.6394 - precision: 0.6651 - recall: 0.5605 - auc: 0.6801\n",
            " For Batch Number 604 the model has a loss of {'loss': 0.643397867679596, 'tp': 5419.0, 'fp': 2730.0, 'tn': 6940.0, 'fn': 4239.0, 'accuracy': 0.6394349932670593, 'precision': 0.6649895906448364, 'recall': 0.561089277267456, 'auc': 0.6800807118415833} \n",
            "604/689 [=========================>....] - ETA: 8s - loss: 0.6434 - tp: 5419.0000 - fp: 2730.0000 - tn: 6940.0000 - fn: 4239.0000 - accuracy: 0.6394 - precision: 0.6650 - recall: 0.5611 - auc: 0.6801\n",
            " For Batch Number 605 the model has a loss of {'loss': 0.6434075236320496, 'tp': 5435.0, 'fp': 2743.0, 'tn': 6943.0, 'fn': 4239.0, 'accuracy': 0.6393595337867737, 'precision': 0.6645879149436951, 'recall': 0.5618152022361755, 'auc': 0.680049479007721} \n",
            "605/689 [=========================>....] - ETA: 8s - loss: 0.6434 - tp: 5435.0000 - fp: 2743.0000 - tn: 6943.0000 - fn: 4239.0000 - accuracy: 0.6394 - precision: 0.6646 - recall: 0.5618 - auc: 0.6800\n",
            " For Batch Number 606 the model has a loss of {'loss': 0.6434250473976135, 'tp': 5449.0, 'fp': 2752.0, 'tn': 6947.0, 'fn': 4244.0, 'accuracy': 0.6392326951026917, 'precision': 0.6644311547279358, 'recall': 0.5621582865715027, 'auc': 0.6800554394721985} \n",
            "606/689 [=========================>....] - ETA: 8s - loss: 0.6434 - tp: 5449.0000 - fp: 2752.0000 - tn: 6947.0000 - fn: 4244.0000 - accuracy: 0.6392 - precision: 0.6644 - recall: 0.5622 - auc: 0.6801\n",
            " For Batch Number 607 the model has a loss of {'loss': 0.6433545351028442, 'tp': 5460.0, 'fp': 2759.0, 'tn': 6957.0, 'fn': 4248.0, 'accuracy': 0.6392607092857361, 'precision': 0.6643143892288208, 'recall': 0.5624227523803711, 'auc': 0.6801137924194336} \n",
            "607/689 [=========================>....] - ETA: 8s - loss: 0.6434 - tp: 5460.0000 - fp: 2759.0000 - tn: 6957.0000 - fn: 4248.0000 - accuracy: 0.6393 - precision: 0.6643 - recall: 0.5624 - auc: 0.6801\n",
            " For Batch Number 608 the model has a loss of {'loss': 0.6434513926506042, 'tp': 5466.0, 'fp': 2762.0, 'tn': 6967.0, 'fn': 4261.0, 'accuracy': 0.6390316486358643, 'precision': 0.6643169522285461, 'recall': 0.5619409680366516, 'auc': 0.6799184083938599} \n",
            "608/689 [=========================>....] - ETA: 8s - loss: 0.6435 - tp: 5466.0000 - fp: 2762.0000 - tn: 6967.0000 - fn: 4261.0000 - accuracy: 0.6390 - precision: 0.6643 - recall: 0.5619 - auc: 0.6799\n",
            " For Batch Number 609 the model has a loss of {'loss': 0.6433237791061401, 'tp': 5474.0, 'fp': 2766.0, 'tn': 6980.0, 'fn': 4268.0, 'accuracy': 0.6390599608421326, 'precision': 0.6643204092979431, 'recall': 0.5618969202041626, 'auc': 0.6801031231880188} \n",
            "609/689 [=========================>....] - ETA: 8s - loss: 0.6433 - tp: 5474.0000 - fp: 2766.0000 - tn: 6980.0000 - fn: 4268.0000 - accuracy: 0.6391 - precision: 0.6643 - recall: 0.5619 - auc: 0.6801\n",
            " For Batch Number 610 the model has a loss of {'loss': 0.6434694528579712, 'tp': 5483.0, 'fp': 2768.0, 'tn': 6988.0, 'fn': 4281.0, 'accuracy': 0.6388831734657288, 'precision': 0.6645255088806152, 'recall': 0.5615526437759399, 'auc': 0.679935097694397} \n",
            "610/689 [=========================>....] - ETA: 8s - loss: 0.6435 - tp: 5483.0000 - fp: 2768.0000 - tn: 6988.0000 - fn: 4281.0000 - accuracy: 0.6389 - precision: 0.6645 - recall: 0.5616 - auc: 0.6799\n",
            " For Batch Number 611 the model has a loss of {'loss': 0.6434482336044312, 'tp': 5495.0, 'fp': 2777.0, 'tn': 6998.0, 'fn': 4282.0, 'accuracy': 0.6389627456665039, 'precision': 0.6642891764640808, 'recall': 0.5620333552360535, 'auc': 0.6799642443656921} \n",
            "611/689 [=========================>....] - ETA: 8s - loss: 0.6434 - tp: 5495.0000 - fp: 2777.0000 - tn: 6998.0000 - fn: 4282.0000 - accuracy: 0.6390 - precision: 0.6643 - recall: 0.5620 - auc: 0.6800\n",
            " For Batch Number 612 the model has a loss of {'loss': 0.6435867547988892, 'tp': 5505.0, 'fp': 2789.0, 'tn': 7006.0, 'fn': 4284.0, 'accuracy': 0.6388378143310547, 'precision': 0.6637328267097473, 'recall': 0.5623659491539001, 'auc': 0.6798573136329651} \n",
            "612/689 [=========================>....] - ETA: 8s - loss: 0.6436 - tp: 5505.0000 - fp: 2789.0000 - tn: 7006.0000 - fn: 4284.0000 - accuracy: 0.6388 - precision: 0.6637 - recall: 0.5624 - auc: 0.6799\n",
            " For Batch Number 613 the model has a loss of {'loss': 0.6433753967285156, 'tp': 5518.0, 'fp': 2795.0, 'tn': 7015.0, 'fn': 4288.0, 'accuracy': 0.6389172077178955, 'precision': 0.663779616355896, 'recall': 0.5627167224884033, 'auc': 0.6801189184188843} \n",
            "613/689 [=========================>....] - ETA: 7s - loss: 0.6434 - tp: 5518.0000 - fp: 2795.0000 - tn: 7015.0000 - fn: 4288.0000 - accuracy: 0.6389 - precision: 0.6638 - recall: 0.5627 - auc: 0.6801\n",
            " For Batch Number 614 the model has a loss of {'loss': 0.6432921290397644, 'tp': 5531.0, 'fp': 2797.0, 'tn': 7025.0, 'fn': 4295.0, 'accuracy': 0.6390472054481506, 'precision': 0.6641450524330139, 'recall': 0.562894344329834, 'auc': 0.6802892684936523} \n",
            "614/689 [=========================>....] - ETA: 7s - loss: 0.6433 - tp: 5531.0000 - fp: 2797.0000 - tn: 7025.0000 - fn: 4295.0000 - accuracy: 0.6390 - precision: 0.6641 - recall: 0.5629 - auc: 0.6803\n",
            " For Batch Number 615 the model has a loss of {'loss': 0.6432440280914307, 'tp': 5542.0, 'fp': 2803.0, 'tn': 7034.0, 'fn': 4301.0, 'accuracy': 0.6390243768692017, 'precision': 0.6641102433204651, 'recall': 0.5630397200584412, 'auc': 0.6803737282752991} \n",
            "615/689 [=========================>....] - ETA: 7s - loss: 0.6432 - tp: 5542.0000 - fp: 2803.0000 - tn: 7034.0000 - fn: 4301.0000 - accuracy: 0.6390 - precision: 0.6641 - recall: 0.5630 - auc: 0.6804\n",
            " For Batch Number 616 the model has a loss of {'loss': 0.6430892944335938, 'tp': 5554.0, 'fp': 2807.0, 'tn': 7044.0, 'fn': 4307.0, 'accuracy': 0.6391030550003052, 'precision': 0.6642746329307556, 'recall': 0.5632289052009583, 'auc': 0.6805908679962158} \n",
            "616/689 [=========================>....] - ETA: 7s - loss: 0.6431 - tp: 5554.0000 - fp: 2807.0000 - tn: 7044.0000 - fn: 4307.0000 - accuracy: 0.6391 - precision: 0.6643 - recall: 0.5632 - auc: 0.6806\n",
            " For Batch Number 617 the model has a loss of {'loss': 0.6430529952049255, 'tp': 5568.0, 'fp': 2811.0, 'tn': 7054.0, 'fn': 4311.0, 'accuracy': 0.6392828226089478, 'precision': 0.664518415927887, 'recall': 0.5636197924613953, 'auc': 0.6807594895362854} \n",
            "617/689 [=========================>....] - ETA: 7s - loss: 0.6431 - tp: 5568.0000 - fp: 2811.0000 - tn: 7054.0000 - fn: 4311.0000 - accuracy: 0.6393 - precision: 0.6645 - recall: 0.5636 - auc: 0.6808\n",
            " For Batch Number 618 the model has a loss of {'loss': 0.6429672241210938, 'tp': 5582.0, 'fp': 2817.0, 'tn': 7062.0, 'fn': 4315.0, 'accuracy': 0.6393608450889587, 'precision': 0.6646029353141785, 'recall': 0.5640093088150024, 'auc': 0.6809514760971069} \n",
            "618/689 [=========================>....] - ETA: 7s - loss: 0.6430 - tp: 5582.0000 - fp: 2817.0000 - tn: 7062.0000 - fn: 4315.0000 - accuracy: 0.6394 - precision: 0.6646 - recall: 0.5640 - auc: 0.6810\n",
            " For Batch Number 619 the model has a loss of {'loss': 0.6431081295013428, 'tp': 5591.0, 'fp': 2824.0, 'tn': 7072.0, 'fn': 4321.0, 'accuracy': 0.6392871737480164, 'precision': 0.664408802986145, 'recall': 0.5640637874603271, 'auc': 0.6808976531028748} \n",
            "619/689 [=========================>....] - ETA: 7s - loss: 0.6431 - tp: 5591.0000 - fp: 2824.0000 - tn: 7072.0000 - fn: 4321.0000 - accuracy: 0.6393 - precision: 0.6644 - recall: 0.5641 - auc: 0.6809\n",
            " For Batch Number 620 the model has a loss of {'loss': 0.6434471011161804, 'tp': 5598.0, 'fp': 2833.0, 'tn': 7079.0, 'fn': 4330.0, 'accuracy': 0.638961672782898, 'precision': 0.6639781594276428, 'recall': 0.563859760761261, 'auc': 0.6805716156959534} \n",
            "620/689 [=========================>....] - ETA: 7s - loss: 0.6434 - tp: 5598.0000 - fp: 2833.0000 - tn: 7079.0000 - fn: 4330.0000 - accuracy: 0.6390 - precision: 0.6640 - recall: 0.5639 - auc: 0.6806\n",
            " For Batch Number 621 the model has a loss of {'loss': 0.6432157754898071, 'tp': 5612.0, 'fp': 2837.0, 'tn': 7091.0, 'fn': 4332.0, 'accuracy': 0.6392411589622498, 'precision': 0.6642206311225891, 'recall': 0.5643604397773743, 'auc': 0.6808806657791138} \n",
            "621/689 [==========================>...] - ETA: 7s - loss: 0.6432 - tp: 5612.0000 - fp: 2837.0000 - tn: 7091.0000 - fn: 4332.0000 - accuracy: 0.6392 - precision: 0.6642 - recall: 0.5644 - auc: 0.6809\n",
            " For Batch Number 622 the model has a loss of {'loss': 0.6431347727775574, 'tp': 5623.0, 'fp': 2841.0, 'tn': 7100.0, 'fn': 4340.0, 'accuracy': 0.639218270778656, 'precision': 0.6643431186676025, 'recall': 0.5643882155418396, 'auc': 0.6809149980545044} \n",
            "622/689 [==========================>...] - ETA: 6s - loss: 0.6431 - tp: 5623.0000 - fp: 2841.0000 - tn: 7100.0000 - fn: 4340.0000 - accuracy: 0.6392 - precision: 0.6643 - recall: 0.5644 - auc: 0.6809\n",
            " For Batch Number 623 the model has a loss of {'loss': 0.6429165601730347, 'tp': 5636.0, 'fp': 2842.0, 'tn': 7111.0, 'fn': 4347.0, 'accuracy': 0.639396071434021, 'precision': 0.6647794246673584, 'recall': 0.5645597577095032, 'auc': 0.6812071800231934} \n",
            "623/689 [==========================>...] - ETA: 6s - loss: 0.6429 - tp: 5636.0000 - fp: 2842.0000 - tn: 7111.0000 - fn: 4347.0000 - accuracy: 0.6394 - precision: 0.6648 - recall: 0.5646 - auc: 0.6812\n",
            " For Batch Number 624 the model has a loss of {'loss': 0.6428174376487732, 'tp': 5647.0, 'fp': 2848.0, 'tn': 7124.0, 'fn': 4349.0, 'accuracy': 0.639573335647583, 'precision': 0.664743959903717, 'recall': 0.5649259686470032, 'auc': 0.681419849395752} \n",
            "624/689 [==========================>...] - ETA: 6s - loss: 0.6428 - tp: 5647.0000 - fp: 2848.0000 - tn: 7124.0000 - fn: 4349.0000 - accuracy: 0.6396 - precision: 0.6647 - recall: 0.5649 - auc: 0.6814\n",
            " For Batch Number 625 the model has a loss of {'loss': 0.6428265571594238, 'tp': 5655.0, 'fp': 2853.0, 'tn': 7137.0, 'fn': 4355.0, 'accuracy': 0.6395999789237976, 'precision': 0.6646685600280762, 'recall': 0.5649350881576538, 'auc': 0.6814601421356201} \n",
            "625/689 [==========================>...] - ETA: 6s - loss: 0.6428 - tp: 5655.0000 - fp: 2853.0000 - tn: 7137.0000 - fn: 4355.0000 - accuracy: 0.6396 - precision: 0.6647 - recall: 0.5649 - auc: 0.6815\n",
            " For Batch Number 626 the model has a loss of {'loss': 0.6428715586662292, 'tp': 5666.0, 'fp': 2856.0, 'tn': 7148.0, 'fn': 4362.0, 'accuracy': 0.6396765112876892, 'precision': 0.6648674011230469, 'recall': 0.5650179386138916, 'auc': 0.6814174652099609} \n",
            "626/689 [==========================>...] - ETA: 6s - loss: 0.6429 - tp: 5666.0000 - fp: 2856.0000 - tn: 7148.0000 - fn: 4362.0000 - accuracy: 0.6397 - precision: 0.6649 - recall: 0.5650 - auc: 0.6814\n",
            " For Batch Number 627 the model has a loss of {'loss': 0.6430293917655945, 'tp': 5677.0, 'fp': 2859.0, 'tn': 7154.0, 'fn': 4374.0, 'accuracy': 0.6395035982131958, 'precision': 0.665065586566925, 'recall': 0.5648193955421448, 'auc': 0.6812632083892822} \n",
            "627/689 [==========================>...] - ETA: 6s - loss: 0.6430 - tp: 5677.0000 - fp: 2859.0000 - tn: 7154.0000 - fn: 4374.0000 - accuracy: 0.6395 - precision: 0.6651 - recall: 0.5648 - auc: 0.6813\n",
            " For Batch Number 628 the model has a loss of {'loss': 0.6430452466011047, 'tp': 5686.0, 'fp': 2865.0, 'tn': 7163.0, 'fn': 4382.0, 'accuracy': 0.6393809914588928, 'precision': 0.6649514436721802, 'recall': 0.5647596120834351, 'auc': 0.6812939047813416} \n",
            "628/689 [==========================>...] - ETA: 6s - loss: 0.6430 - tp: 5686.0000 - fp: 2865.0000 - tn: 7163.0000 - fn: 4382.0000 - accuracy: 0.6394 - precision: 0.6650 - recall: 0.5648 - auc: 0.6813\n",
            " For Batch Number 629 the model has a loss of {'loss': 0.6429133415222168, 'tp': 5698.0, 'fp': 2871.0, 'tn': 7173.0, 'fn': 4386.0, 'accuracy': 0.6394574642181396, 'precision': 0.6649550795555115, 'recall': 0.5650535225868225, 'auc': 0.6814334392547607} \n",
            "629/689 [==========================>...] - ETA: 6s - loss: 0.6429 - tp: 5698.0000 - fp: 2871.0000 - tn: 7173.0000 - fn: 4386.0000 - accuracy: 0.6395 - precision: 0.6650 - recall: 0.5651 - auc: 0.6814\n",
            " For Batch Number 630 the model has a loss of {'loss': 0.6428588628768921, 'tp': 5711.0, 'fp': 2877.0, 'tn': 7180.0, 'fn': 4392.0, 'accuracy': 0.6394345164299011, 'precision': 0.6649976968765259, 'recall': 0.565277636051178, 'auc': 0.6814970374107361} \n",
            "630/689 [==========================>...] - ETA: 6s - loss: 0.6429 - tp: 5711.0000 - fp: 2877.0000 - tn: 7180.0000 - fn: 4392.0000 - accuracy: 0.6394 - precision: 0.6650 - recall: 0.5653 - auc: 0.6815\n",
            " For Batch Number 631 the model has a loss of {'loss': 0.6427823305130005, 'tp': 5725.0, 'fp': 2882.0, 'tn': 7188.0, 'fn': 4397.0, 'accuracy': 0.6395106911659241, 'precision': 0.6651562452316284, 'recall': 0.5655996799468994, 'auc': 0.6816099286079407} \n",
            "631/689 [==========================>...] - ETA: 6s - loss: 0.6428 - tp: 5725.0000 - fp: 2882.0000 - tn: 7188.0000 - fn: 4397.0000 - accuracy: 0.6395 - precision: 0.6652 - recall: 0.5656 - auc: 0.6816\n",
            " For Batch Number 632 the model has a loss of {'loss': 0.6430156826972961, 'tp': 5738.0, 'fp': 2895.0, 'tn': 7191.0, 'fn': 4400.0, 'accuracy': 0.6392899751663208, 'precision': 0.6646588444709778, 'recall': 0.5659893751144409, 'auc': 0.6813994646072388} \n",
            "632/689 [==========================>...] - ETA: 5s - loss: 0.6430 - tp: 5738.0000 - fp: 2895.0000 - tn: 7191.0000 - fn: 4400.0000 - accuracy: 0.6393 - precision: 0.6647 - recall: 0.5660 - auc: 0.6814\n",
            " For Batch Number 633 the model has a loss of {'loss': 0.642959713935852, 'tp': 5750.0, 'fp': 2901.0, 'tn': 7199.0, 'fn': 4406.0, 'accuracy': 0.6392673850059509, 'precision': 0.6646630167961121, 'recall': 0.5661677718162537, 'auc': 0.6814619302749634} \n",
            "633/689 [==========================>...] - ETA: 5s - loss: 0.6430 - tp: 5750.0000 - fp: 2901.0000 - tn: 7199.0000 - fn: 4406.0000 - accuracy: 0.6393 - precision: 0.6647 - recall: 0.5662 - auc: 0.6815\n",
            " For Batch Number 634 the model has a loss of {'loss': 0.6427431702613831, 'tp': 5765.0, 'fp': 2904.0, 'tn': 7209.0, 'fn': 4410.0, 'accuracy': 0.6394913196563721, 'precision': 0.6650132536888123, 'recall': 0.5665847659111023, 'auc': 0.6817066073417664} \n",
            "634/689 [==========================>...] - ETA: 5s - loss: 0.6427 - tp: 5765.0000 - fp: 2904.0000 - tn: 7209.0000 - fn: 4410.0000 - accuracy: 0.6395 - precision: 0.6650 - recall: 0.5666 - auc: 0.6817\n",
            " For Batch Number 635 the model has a loss of {'loss': 0.6427720189094543, 'tp': 5777.0, 'fp': 2911.0, 'tn': 7217.0, 'fn': 4415.0, 'accuracy': 0.6394684910774231, 'precision': 0.6649401187896729, 'recall': 0.5668171048164368, 'auc': 0.6817125678062439} \n",
            "635/689 [==========================>...] - ETA: 5s - loss: 0.6428 - tp: 5777.0000 - fp: 2911.0000 - tn: 7217.0000 - fn: 4415.0000 - accuracy: 0.6395 - precision: 0.6649 - recall: 0.5668 - auc: 0.6817\n",
            " For Batch Number 636 the model has a loss of {'loss': 0.6429607272148132, 'tp': 5786.0, 'fp': 2919.0, 'tn': 7225.0, 'fn': 4422.0, 'accuracy': 0.6392983198165894, 'precision': 0.6646754741668701, 'recall': 0.5668103694915771, 'auc': 0.6814904808998108} \n",
            "636/689 [==========================>...] - ETA: 5s - loss: 0.6430 - tp: 5786.0000 - fp: 2919.0000 - tn: 7225.0000 - fn: 4422.0000 - accuracy: 0.6393 - precision: 0.6647 - recall: 0.5668 - auc: 0.6815\n",
            " For Batch Number 637 the model has a loss of {'loss': 0.6428787112236023, 'tp': 5799.0, 'fp': 2922.0, 'tn': 7236.0, 'fn': 4427.0, 'accuracy': 0.6394721269607544, 'precision': 0.6649466753005981, 'recall': 0.5670838952064514, 'auc': 0.6815876364707947} \n",
            "637/689 [==========================>...] - ETA: 5s - loss: 0.6429 - tp: 5799.0000 - fp: 2922.0000 - tn: 7236.0000 - fn: 4427.0000 - accuracy: 0.6395 - precision: 0.6649 - recall: 0.5671 - auc: 0.6816\n",
            " For Batch Number 638 the model has a loss of {'loss': 0.6428871154785156, 'tp': 5809.0, 'fp': 2926.0, 'tn': 7247.0, 'fn': 4434.0, 'accuracy': 0.6394984126091003, 'precision': 0.6650257706642151, 'recall': 0.5671190023422241, 'auc': 0.6815433502197266} \n",
            "638/689 [==========================>...] - ETA: 5s - loss: 0.6429 - tp: 5809.0000 - fp: 2926.0000 - tn: 7247.0000 - fn: 4434.0000 - accuracy: 0.6395 - precision: 0.6650 - recall: 0.5671 - auc: 0.6815\n",
            " For Batch Number 639 the model has a loss of {'loss': 0.6429922580718994, 'tp': 5817.0, 'fp': 2932.0, 'tn': 7255.0, 'fn': 4444.0, 'accuracy': 0.6392801403999329, 'precision': 0.6648759841918945, 'recall': 0.566903829574585, 'auc': 0.6813883781433105} \n",
            "639/689 [==========================>...] - ETA: 5s - loss: 0.6430 - tp: 5817.0000 - fp: 2932.0000 - tn: 7255.0000 - fn: 4444.0000 - accuracy: 0.6393 - precision: 0.6649 - recall: 0.5669 - auc: 0.6814\n",
            " For Batch Number 640 the model has a loss of {'loss': 0.642938494682312, 'tp': 5825.0, 'fp': 2937.0, 'tn': 7269.0, 'fn': 4449.0, 'accuracy': 0.639355480670929, 'precision': 0.6648025512695312, 'recall': 0.5669651627540588, 'auc': 0.6813797354698181} \n",
            "640/689 [==========================>...] - ETA: 5s - loss: 0.6429 - tp: 5825.0000 - fp: 2937.0000 - tn: 7269.0000 - fn: 4449.0000 - accuracy: 0.6394 - precision: 0.6648 - recall: 0.5670 - auc: 0.6814\n",
            " For Batch Number 641 the model has a loss of {'loss': 0.643086850643158, 'tp': 5830.0, 'fp': 2944.0, 'tn': 7281.0, 'fn': 4457.0, 'accuracy': 0.6391867995262146, 'precision': 0.6644631624221802, 'recall': 0.5667347311973572, 'auc': 0.6811270117759705} \n",
            "641/689 [==========================>...] - ETA: 5s - loss: 0.6431 - tp: 5830.0000 - fp: 2944.0000 - tn: 7281.0000 - fn: 4457.0000 - accuracy: 0.6392 - precision: 0.6645 - recall: 0.5667 - auc: 0.6811\n",
            " For Batch Number 642 the model has a loss of {'loss': 0.6432665586471558, 'tp': 5836.0, 'fp': 2947.0, 'tn': 7295.0, 'fn': 4466.0, 'accuracy': 0.6391647458076477, 'precision': 0.6644654273986816, 'recall': 0.566491961479187, 'auc': 0.6809387803077698} \n",
            "642/689 [==========================>...] - ETA: 4s - loss: 0.6433 - tp: 5836.0000 - fp: 2947.0000 - tn: 7295.0000 - fn: 4466.0000 - accuracy: 0.6392 - precision: 0.6645 - recall: 0.5665 - auc: 0.6809\n",
            " For Batch Number 643 the model has a loss of {'loss': 0.6431522369384766, 'tp': 5842.0, 'fp': 2947.0, 'tn': 7313.0, 'fn': 4474.0, 'accuracy': 0.6393370628356934, 'precision': 0.6646944880485535, 'recall': 0.5663047432899475, 'auc': 0.6810608506202698} \n",
            "643/689 [==========================>...] - ETA: 4s - loss: 0.6432 - tp: 5842.0000 - fp: 2947.0000 - tn: 7313.0000 - fn: 4474.0000 - accuracy: 0.6393 - precision: 0.6647 - recall: 0.5663 - auc: 0.6811\n",
            " For Batch Number 644 the model has a loss of {'loss': 0.6432595252990723, 'tp': 5848.0, 'fp': 2949.0, 'tn': 7324.0, 'fn': 4487.0, 'accuracy': 0.6391692757606506, 'precision': 0.664772093296051, 'recall': 0.5658442378044128, 'auc': 0.6809320449829102} \n",
            "644/689 [===========================>..] - ETA: 4s - loss: 0.6433 - tp: 5848.0000 - fp: 2949.0000 - tn: 7324.0000 - fn: 4487.0000 - accuracy: 0.6392 - precision: 0.6648 - recall: 0.5658 - auc: 0.6809\n",
            " For Batch Number 645 the model has a loss of {'loss': 0.6432480216026306, 'tp': 5853.0, 'fp': 2951.0, 'tn': 7338.0, 'fn': 4498.0, 'accuracy': 0.6390988230705261, 'precision': 0.6648114323616028, 'recall': 0.5654526352882385, 'auc': 0.6809601187705994} \n",
            "645/689 [===========================>..] - ETA: 4s - loss: 0.6432 - tp: 5853.0000 - fp: 2951.0000 - tn: 7338.0000 - fn: 4498.0000 - accuracy: 0.6391 - precision: 0.6648 - recall: 0.5655 - auc: 0.6810\n",
            " For Batch Number 646 the model has a loss of {'loss': 0.6431293487548828, 'tp': 5865.0, 'fp': 2952.0, 'tn': 7350.0, 'fn': 4505.0, 'accuracy': 0.6392704844474792, 'precision': 0.6651922464370728, 'recall': 0.5655737519264221, 'auc': 0.6811530590057373} \n",
            "646/689 [===========================>..] - ETA: 4s - loss: 0.6431 - tp: 5865.0000 - fp: 2952.0000 - tn: 7350.0000 - fn: 4505.0000 - accuracy: 0.6393 - precision: 0.6652 - recall: 0.5656 - auc: 0.6812\n",
            " For Batch Number 647 the model has a loss of {'loss': 0.6429600715637207, 'tp': 5874.0, 'fp': 2954.0, 'tn': 7367.0, 'fn': 4509.0, 'accuracy': 0.6395382285118103, 'precision': 0.6653828620910645, 'recall': 0.5657324194908142, 'auc': 0.6813622117042542} \n",
            "647/689 [===========================>..] - ETA: 4s - loss: 0.6430 - tp: 5874.0000 - fp: 2954.0000 - tn: 7367.0000 - fn: 4509.0000 - accuracy: 0.6395 - precision: 0.6654 - recall: 0.5657 - auc: 0.6814\n",
            " For Batch Number 648 the model has a loss of {'loss': 0.6428430080413818, 'tp': 5882.0, 'fp': 2957.0, 'tn': 7381.0, 'fn': 4516.0, 'accuracy': 0.6396122574806213, 'precision': 0.6654598712921143, 'recall': 0.5656856894493103, 'auc': 0.6815096735954285} \n",
            "648/689 [===========================>..] - ETA: 4s - loss: 0.6428 - tp: 5882.0000 - fp: 2957.0000 - tn: 7381.0000 - fn: 4516.0000 - accuracy: 0.6396 - precision: 0.6655 - recall: 0.5657 - auc: 0.6815\n",
            " For Batch Number 649 the model has a loss of {'loss': 0.6426602005958557, 'tp': 5893.0, 'fp': 2960.0, 'tn': 7393.0, 'fn': 4522.0, 'accuracy': 0.6397342085838318, 'precision': 0.6656500697135925, 'recall': 0.5658185482025146, 'auc': 0.6817323565483093} \n",
            "649/689 [===========================>..] - ETA: 4s - loss: 0.6427 - tp: 5893.0000 - fp: 2960.0000 - tn: 7393.0000 - fn: 4522.0000 - accuracy: 0.6397 - precision: 0.6657 - recall: 0.5658 - auc: 0.6817\n",
            " For Batch Number 650 the model has a loss of {'loss': 0.6425091624259949, 'tp': 5902.0, 'fp': 2965.0, 'tn': 7405.0, 'fn': 4528.0, 'accuracy': 0.6397596001625061, 'precision': 0.6656140685081482, 'recall': 0.5658676624298096, 'auc': 0.6818957328796387} \n",
            "650/689 [===========================>..] - ETA: 4s - loss: 0.6425 - tp: 5902.0000 - fp: 2965.0000 - tn: 7405.0000 - fn: 4528.0000 - accuracy: 0.6398 - precision: 0.6656 - recall: 0.5659 - auc: 0.6819\n",
            " For Batch Number 651 the model has a loss of {'loss': 0.6424447894096375, 'tp': 5910.0, 'fp': 2969.0, 'tn': 7418.0, 'fn': 4535.0, 'accuracy': 0.6397849321365356, 'precision': 0.6656154990196228, 'recall': 0.5658209919929504, 'auc': 0.6819698214530945} \n",
            "651/689 [===========================>..] - ETA: 3s - loss: 0.6424 - tp: 5910.0000 - fp: 2969.0000 - tn: 7418.0000 - fn: 4535.0000 - accuracy: 0.6398 - precision: 0.6656 - recall: 0.5658 - auc: 0.6820\n",
            " For Batch Number 652 the model has a loss of {'loss': 0.6421640515327454, 'tp': 5920.0, 'fp': 2972.0, 'tn': 7432.0, 'fn': 4540.0, 'accuracy': 0.6399539709091187, 'precision': 0.6657669544219971, 'recall': 0.5659655928611755, 'auc': 0.6823611855506897} \n",
            "652/689 [===========================>..] - ETA: 3s - loss: 0.6422 - tp: 5920.0000 - fp: 2972.0000 - tn: 7432.0000 - fn: 4540.0000 - accuracy: 0.6400 - precision: 0.6658 - recall: 0.5660 - auc: 0.6824\n",
            " For Batch Number 653 the model has a loss of {'loss': 0.6419152617454529, 'tp': 5929.0, 'fp': 2973.0, 'tn': 7447.0, 'fn': 4547.0, 'accuracy': 0.6401225328445435, 'precision': 0.6660301089286804, 'recall': 0.5659602880477905, 'auc': 0.6826273202896118} \n",
            "653/689 [===========================>..] - ETA: 3s - loss: 0.6419 - tp: 5929.0000 - fp: 2973.0000 - tn: 7447.0000 - fn: 4547.0000 - accuracy: 0.6401 - precision: 0.6660 - recall: 0.5660 - auc: 0.6826\n",
            " For Batch Number 654 the model has a loss of {'loss': 0.6413928270339966, 'tp': 5941.0, 'fp': 2975.0, 'tn': 7465.0, 'fn': 4547.0, 'accuracy': 0.6405771970748901, 'precision': 0.6663302183151245, 'recall': 0.5664569139480591, 'auc': 0.6832646131515503} \n",
            "654/689 [===========================>..] - ETA: 3s - loss: 0.6414 - tp: 5941.0000 - fp: 2975.0000 - tn: 7465.0000 - fn: 4547.0000 - accuracy: 0.6406 - precision: 0.6663 - recall: 0.5665 - auc: 0.6833\n",
            " For Batch Number 655 the model has a loss of {'loss': 0.6414889693260193, 'tp': 5948.0, 'fp': 2981.0, 'tn': 7477.0, 'fn': 4554.0, 'accuracy': 0.6405057311058044, 'precision': 0.6661440134048462, 'recall': 0.5663682818412781, 'auc': 0.6832886934280396} \n",
            "655/689 [===========================>..] - ETA: 3s - loss: 0.6415 - tp: 5948.0000 - fp: 2981.0000 - tn: 7477.0000 - fn: 4554.0000 - accuracy: 0.6405 - precision: 0.6661 - recall: 0.5664 - auc: 0.6833\n",
            " For Batch Number 656 the model has a loss of {'loss': 0.6408997774124146, 'tp': 5964.0, 'fp': 2982.0, 'tn': 7491.0, 'fn': 4555.0, 'accuracy': 0.6409584879875183, 'precision': 0.6666666865348816, 'recall': 0.5669740438461304, 'auc': 0.6839994192123413} \n",
            "656/689 [===========================>..] - ETA: 3s - loss: 0.6409 - tp: 5964.0000 - fp: 2982.0000 - tn: 7491.0000 - fn: 4555.0000 - accuracy: 0.6410 - precision: 0.6667 - recall: 0.5670 - auc: 0.6840\n",
            " For Batch Number 657 the model has a loss of {'loss': 0.6407108306884766, 'tp': 5974.0, 'fp': 2986.0, 'tn': 7504.0, 'fn': 4560.0, 'accuracy': 0.6410768628120422, 'precision': 0.6667410731315613, 'recall': 0.5671160221099854, 'auc': 0.6842736601829529} \n",
            "657/689 [===========================>..] - ETA: 3s - loss: 0.6407 - tp: 5974.0000 - fp: 2986.0000 - tn: 7504.0000 - fn: 4560.0000 - accuracy: 0.6411 - precision: 0.6667 - recall: 0.5671 - auc: 0.6843\n",
            " For Batch Number 658 the model has a loss of {'loss': 0.6408408880233765, 'tp': 5986.0, 'fp': 2989.0, 'tn': 7514.0, 'fn': 4567.0, 'accuracy': 0.6411474347114563, 'precision': 0.6669638156890869, 'recall': 0.567232072353363, 'auc': 0.6844016909599304} \n",
            "658/689 [===========================>..] - ETA: 3s - loss: 0.6408 - tp: 5986.0000 - fp: 2989.0000 - tn: 7514.0000 - fn: 4567.0000 - accuracy: 0.6411 - precision: 0.6670 - recall: 0.5672 - auc: 0.6844\n",
            " For Batch Number 659 the model has a loss of {'loss': 0.6410703063011169, 'tp': 5997.0, 'fp': 2995.0, 'tn': 7525.0, 'fn': 4571.0, 'accuracy': 0.6412177681922913, 'precision': 0.6669261455535889, 'recall': 0.5674678087234497, 'auc': 0.6845031976699829} \n",
            "659/689 [===========================>..] - ETA: 3s - loss: 0.6411 - tp: 5997.0000 - fp: 2995.0000 - tn: 7525.0000 - fn: 4571.0000 - accuracy: 0.6412 - precision: 0.6669 - recall: 0.5675 - auc: 0.6845\n",
            " For Batch Number 660 the model has a loss of {'loss': 0.6410486698150635, 'tp': 6006.0, 'fp': 3002.0, 'tn': 7538.0, 'fn': 4574.0, 'accuracy': 0.6412878632545471, 'precision': 0.6667406558990479, 'recall': 0.5676748752593994, 'auc': 0.6846055388450623} \n",
            "660/689 [===========================>..] - ETA: 3s - loss: 0.6410 - tp: 6006.0000 - fp: 3002.0000 - tn: 7538.0000 - fn: 4574.0000 - accuracy: 0.6413 - precision: 0.6667 - recall: 0.5677 - auc: 0.6846\n",
            " For Batch Number 661 the model has a loss of {'loss': 0.6411676406860352, 'tp': 6015.0, 'fp': 3007.0, 'tn': 7553.0, 'fn': 4577.0, 'accuracy': 0.6414523720741272, 'precision': 0.6667036414146423, 'recall': 0.5678814053535461, 'auc': 0.6846928000450134} \n",
            "661/689 [===========================>..] - ETA: 2s - loss: 0.6412 - tp: 6015.0000 - fp: 3007.0000 - tn: 7553.0000 - fn: 4577.0000 - accuracy: 0.6415 - precision: 0.6667 - recall: 0.5679 - auc: 0.6847\n",
            " For Batch Number 662 the model has a loss of {'loss': 0.6411933898925781, 'tp': 6023.0, 'fp': 3012.0, 'tn': 7569.0, 'fn': 4580.0, 'accuracy': 0.6416162848472595, 'precision': 0.6666297912597656, 'recall': 0.5680468082427979, 'auc': 0.6848506927490234} \n",
            "662/689 [===========================>..] - ETA: 2s - loss: 0.6412 - tp: 6023.0000 - fp: 3012.0000 - tn: 7569.0000 - fn: 4580.0000 - accuracy: 0.6416 - precision: 0.6666 - recall: 0.5680 - auc: 0.6849\n",
            " For Batch Number 663 the model has a loss of {'loss': 0.6411917805671692, 'tp': 6030.0, 'fp': 3013.0, 'tn': 7585.0, 'fn': 4588.0, 'accuracy': 0.6417326331138611, 'precision': 0.6668140888214111, 'recall': 0.5679035782814026, 'auc': 0.684985339641571} \n",
            "663/689 [===========================>..] - ETA: 2s - loss: 0.6412 - tp: 6030.0000 - fp: 3013.0000 - tn: 7585.0000 - fn: 4588.0000 - accuracy: 0.6417 - precision: 0.6668 - recall: 0.5679 - auc: 0.6850\n",
            " For Batch Number 664 the model has a loss of {'loss': 0.6414950489997864, 'tp': 6035.0, 'fp': 3015.0, 'tn': 7598.0, 'fn': 4600.0, 'accuracy': 0.6416133046150208, 'precision': 0.6668508052825928, 'recall': 0.5674659013748169, 'auc': 0.6847447752952576} \n",
            "664/689 [===========================>..] - ETA: 2s - loss: 0.6415 - tp: 6035.0000 - fp: 3015.0000 - tn: 7598.0000 - fn: 4600.0000 - accuracy: 0.6416 - precision: 0.6669 - recall: 0.5675 - auc: 0.6847\n",
            " For Batch Number 665 the model has a loss of {'loss': 0.6414033770561218, 'tp': 6041.0, 'fp': 3020.0, 'tn': 7615.0, 'fn': 4604.0, 'accuracy': 0.6417292952537537, 'precision': 0.666703462600708, 'recall': 0.5674964785575867, 'auc': 0.6848912835121155} \n",
            "665/689 [===========================>..] - ETA: 2s - loss: 0.6414 - tp: 6041.0000 - fp: 3020.0000 - tn: 7615.0000 - fn: 4604.0000 - accuracy: 0.6417 - precision: 0.6667 - recall: 0.5675 - auc: 0.6849\n",
            " For Batch Number 666 the model has a loss of {'loss': 0.6415180563926697, 'tp': 6049.0, 'fp': 3020.0, 'tn': 7626.0, 'fn': 4617.0, 'accuracy': 0.641657292842865, 'precision': 0.666997492313385, 'recall': 0.5671291947364807, 'auc': 0.6846771836280823} \n",
            "666/689 [===========================>..] - ETA: 2s - loss: 0.6415 - tp: 6049.0000 - fp: 3020.0000 - tn: 7626.0000 - fn: 4617.0000 - accuracy: 0.6417 - precision: 0.6670 - recall: 0.5671 - auc: 0.6847\n",
            " For Batch Number 667 the model has a loss of {'loss': 0.6416109800338745, 'tp': 6059.0, 'fp': 3025.0, 'tn': 7635.0, 'fn': 4625.0, 'accuracy': 0.6415854692459106, 'precision': 0.6669968962669373, 'recall': 0.5671097040176392, 'auc': 0.6845616698265076} \n",
            "667/689 [============================>.] - ETA: 2s - loss: 0.6416 - tp: 6059.0000 - fp: 3025.0000 - tn: 7635.0000 - fn: 4625.0000 - accuracy: 0.6416 - precision: 0.6670 - recall: 0.5671 - auc: 0.6846\n",
            " For Batch Number 668 the model has a loss of {'loss': 0.641669750213623, 'tp': 6073.0, 'fp': 3038.0, 'tn': 7640.0, 'fn': 4625.0, 'accuracy': 0.6415138244628906, 'precision': 0.6665568947792053, 'recall': 0.5676761865615845, 'auc': 0.684478759765625} \n",
            "668/689 [============================>.] - ETA: 2s - loss: 0.6417 - tp: 6073.0000 - fp: 3038.0000 - tn: 7640.0000 - fn: 4625.0000 - accuracy: 0.6415 - precision: 0.6666 - recall: 0.5677 - auc: 0.6845\n",
            " For Batch Number 669 the model has a loss of {'loss': 0.6416967511177063, 'tp': 6086.0, 'fp': 3055.0, 'tn': 7642.0, 'fn': 4625.0, 'accuracy': 0.6412556171417236, 'precision': 0.6657915115356445, 'recall': 0.5682008862495422, 'auc': 0.684339165687561} \n",
            "669/689 [============================>.] - ETA: 2s - loss: 0.6417 - tp: 6086.0000 - fp: 3055.0000 - tn: 7642.0000 - fn: 4625.0000 - accuracy: 0.6413 - precision: 0.6658 - recall: 0.5682 - auc: 0.6843\n",
            " For Batch Number 670 the model has a loss of {'loss': 0.6418358087539673, 'tp': 6097.0, 'fp': 3068.0, 'tn': 7646.0, 'fn': 4629.0, 'accuracy': 0.640998125076294, 'precision': 0.6652482151985168, 'recall': 0.5684318542480469, 'auc': 0.6841698288917542} \n",
            "670/689 [============================>.] - ETA: 1s - loss: 0.6418 - tp: 6097.0000 - fp: 3068.0000 - tn: 7646.0000 - fn: 4629.0000 - accuracy: 0.6410 - precision: 0.6652 - recall: 0.5684 - auc: 0.6842\n",
            " For Batch Number 671 the model has a loss of {'loss': 0.6417785882949829, 'tp': 6107.0, 'fp': 3074.0, 'tn': 7655.0, 'fn': 4636.0, 'accuracy': 0.6409277319908142, 'precision': 0.6651780605316162, 'recall': 0.5684632062911987, 'auc': 0.6842345595359802} \n",
            "671/689 [============================>.] - ETA: 1s - loss: 0.6418 - tp: 6107.0000 - fp: 3074.0000 - tn: 7655.0000 - fn: 4636.0000 - accuracy: 0.6409 - precision: 0.6652 - recall: 0.5685 - auc: 0.6842\n",
            " For Batch Number 672 the model has a loss of {'loss': 0.6417272686958313, 'tp': 6114.0, 'fp': 3077.0, 'tn': 7669.0, 'fn': 4644.0, 'accuracy': 0.6409505009651184, 'precision': 0.6652159690856934, 'recall': 0.5683212280273438, 'auc': 0.6842325925827026} \n",
            "672/689 [============================>.] - ETA: 1s - loss: 0.6417 - tp: 6114.0000 - fp: 3077.0000 - tn: 7669.0000 - fn: 4644.0000 - accuracy: 0.6410 - precision: 0.6652 - recall: 0.5683 - auc: 0.6842\n",
            " For Batch Number 673 the model has a loss of {'loss': 0.6416168808937073, 'tp': 6121.0, 'fp': 3079.0, 'tn': 7687.0, 'fn': 4649.0, 'accuracy': 0.6411589980125427, 'precision': 0.6653260588645935, 'recall': 0.5683379769325256, 'auc': 0.6844266653060913} \n",
            "673/689 [============================>.] - ETA: 1s - loss: 0.6416 - tp: 6121.0000 - fp: 3079.0000 - tn: 7687.0000 - fn: 4649.0000 - accuracy: 0.6412 - precision: 0.6653 - recall: 0.5683 - auc: 0.6844\n",
            " For Batch Number 674 the model has a loss of {'loss': 0.6417033672332764, 'tp': 6128.0, 'fp': 3080.0, 'tn': 7700.0, 'fn': 4660.0, 'accuracy': 0.641135036945343, 'precision': 0.6655082702636719, 'recall': 0.5680385828018188, 'auc': 0.6843492984771729} \n",
            "674/689 [============================>.] - ETA: 1s - loss: 0.6417 - tp: 6128.0000 - fp: 3080.0000 - tn: 7700.0000 - fn: 4660.0000 - accuracy: 0.6411 - precision: 0.6655 - recall: 0.5680 - auc: 0.6843\n",
            " For Batch Number 675 the model has a loss of {'loss': 0.6419338583946228, 'tp': 6134.0, 'fp': 3082.0, 'tn': 7713.0, 'fn': 4671.0, 'accuracy': 0.6410648226737976, 'precision': 0.6655815839767456, 'recall': 0.5677001476287842, 'auc': 0.6841803193092346} \n",
            "675/689 [============================>.] - ETA: 1s - loss: 0.6419 - tp: 6134.0000 - fp: 3082.0000 - tn: 7713.0000 - fn: 4671.0000 - accuracy: 0.6411 - precision: 0.6656 - recall: 0.5677 - auc: 0.6842\n",
            " For Batch Number 676 the model has a loss of {'loss': 0.6420764923095703, 'tp': 6141.0, 'fp': 3086.0, 'tn': 7726.0, 'fn': 4679.0, 'accuracy': 0.6410410404205322, 'precision': 0.6655467748641968, 'recall': 0.567560076713562, 'auc': 0.684005618095398} \n",
            "676/689 [============================>.] - ETA: 1s - loss: 0.6421 - tp: 6141.0000 - fp: 3086.0000 - tn: 7726.0000 - fn: 4679.0000 - accuracy: 0.6410 - precision: 0.6655 - recall: 0.5676 - auc: 0.6840\n",
            " For Batch Number 677 the model has a loss of {'loss': 0.6421352624893188, 'tp': 6150.0, 'fp': 3091.0, 'tn': 7738.0, 'fn': 4685.0, 'accuracy': 0.6410635113716125, 'precision': 0.6655123829841614, 'recall': 0.5676049590110779, 'auc': 0.6839913725852966} \n",
            "677/689 [============================>.] - ETA: 1s - loss: 0.6421 - tp: 6150.0000 - fp: 3091.0000 - tn: 7738.0000 - fn: 4685.0000 - accuracy: 0.6411 - precision: 0.6655 - recall: 0.5676 - auc: 0.6840\n",
            " For Batch Number 678 the model has a loss of {'loss': 0.642325758934021, 'tp': 6161.0, 'fp': 3096.0, 'tn': 7746.0, 'fn': 4693.0, 'accuracy': 0.6409937143325806, 'precision': 0.6655504107475281, 'recall': 0.5676248669624329, 'auc': 0.683853030204773} \n",
            "678/689 [============================>.] - ETA: 1s - loss: 0.6423 - tp: 6161.0000 - fp: 3096.0000 - tn: 7746.0000 - fn: 4693.0000 - accuracy: 0.6410 - precision: 0.6656 - recall: 0.5676 - auc: 0.6839\n",
            " For Batch Number 679 the model has a loss of {'loss': 0.6424102783203125, 'tp': 6171.0, 'fp': 3105.0, 'tn': 7753.0, 'fn': 4699.0, 'accuracy': 0.6408321261405945, 'precision': 0.6652652025222778, 'recall': 0.5677092671394348, 'auc': 0.6837133169174194} \n",
            "679/689 [============================>.] - ETA: 1s - loss: 0.6424 - tp: 6171.0000 - fp: 3105.0000 - tn: 7753.0000 - fn: 4699.0000 - accuracy: 0.6408 - precision: 0.6653 - recall: 0.5677 - auc: 0.6837\n",
            " For Batch Number 680 the model has a loss of {'loss': 0.6423166394233704, 'tp': 6183.0, 'fp': 3112.0, 'tn': 7762.0, 'fn': 4703.0, 'accuracy': 0.6408547759056091, 'precision': 0.6651963591575623, 'recall': 0.5679771900177002, 'auc': 0.6837775707244873} \n",
            "680/689 [============================>.] - ETA: 0s - loss: 0.6423 - tp: 6183.0000 - fp: 3112.0000 - tn: 7762.0000 - fn: 4703.0000 - accuracy: 0.6409 - precision: 0.6652 - recall: 0.5680 - auc: 0.6838\n",
            " For Batch Number 681 the model has a loss of {'loss': 0.6422441601753235, 'tp': 6192.0, 'fp': 3116.0, 'tn': 7775.0, 'fn': 4709.0, 'accuracy': 0.640923261642456, 'precision': 0.6652342081069946, 'recall': 0.568021297454834, 'auc': 0.6838056445121765} \n",
            "681/689 [============================>.] - ETA: 0s - loss: 0.6422 - tp: 6192.0000 - fp: 3116.0000 - tn: 7775.0000 - fn: 4709.0000 - accuracy: 0.6409 - precision: 0.6652 - recall: 0.5680 - auc: 0.6838\n",
            " For Batch Number 682 the model has a loss of {'loss': 0.6422901749610901, 'tp': 6200.0, 'fp': 3120.0, 'tn': 7788.0, 'fn': 4716.0, 'accuracy': 0.6409457325935364, 'precision': 0.6652360558509827, 'recall': 0.5679736137390137, 'auc': 0.6837122440338135} \n",
            "682/689 [============================>.] - ETA: 0s - loss: 0.6423 - tp: 6200.0000 - fp: 3120.0000 - tn: 7788.0000 - fn: 4716.0000 - accuracy: 0.6409 - precision: 0.6652 - recall: 0.5680 - auc: 0.6837\n",
            " For Batch Number 683 the model has a loss of {'loss': 0.6422923803329468, 'tp': 6208.0, 'fp': 3122.0, 'tn': 7800.0, 'fn': 4726.0, 'accuracy': 0.6409224271774292, 'precision': 0.6653804779052734, 'recall': 0.56777024269104, 'auc': 0.6837106347084045} \n",
            "683/689 [============================>.] - ETA: 0s - loss: 0.6423 - tp: 6208.0000 - fp: 3122.0000 - tn: 7800.0000 - fn: 4726.0000 - accuracy: 0.6409 - precision: 0.6654 - recall: 0.5678 - auc: 0.6837\n",
            " For Batch Number 684 the model has a loss of {'loss': 0.6421611905097961, 'tp': 6213.0, 'fp': 3123.0, 'tn': 7816.0, 'fn': 4736.0, 'accuracy': 0.6409448385238647, 'precision': 0.6654884219169617, 'recall': 0.5674490928649902, 'auc': 0.6838741302490234} \n",
            "684/689 [============================>.] - ETA: 0s - loss: 0.6422 - tp: 6213.0000 - fp: 3123.0000 - tn: 7816.0000 - fn: 4736.0000 - accuracy: 0.6409 - precision: 0.6655 - recall: 0.5674 - auc: 0.6839\n",
            " For Batch Number 685 the model has a loss of {'loss': 0.6421625018119812, 'tp': 6217.0, 'fp': 3125.0, 'tn': 7832.0, 'fn': 4746.0, 'accuracy': 0.6409215331077576, 'precision': 0.6654891967773438, 'recall': 0.567089319229126, 'auc': 0.6837905645370483} \n",
            "685/689 [============================>.] - ETA: 0s - loss: 0.6422 - tp: 6217.0000 - fp: 3125.0000 - tn: 7832.0000 - fn: 4746.0000 - accuracy: 0.6409 - precision: 0.6655 - recall: 0.5671 - auc: 0.6838\n",
            " For Batch Number 686 the model has a loss of {'loss': 0.6420652270317078, 'tp': 6226.0, 'fp': 3127.0, 'tn': 7845.0, 'fn': 4754.0, 'accuracy': 0.6409894227981567, 'precision': 0.665668785572052, 'recall': 0.5670309662818909, 'auc': 0.683880090713501} \n",
            "686/689 [============================>.] - ETA: 0s - loss: 0.6421 - tp: 6226.0000 - fp: 3127.0000 - tn: 7845.0000 - fn: 4754.0000 - accuracy: 0.6410 - precision: 0.6657 - recall: 0.5670 - auc: 0.6839\n",
            " For Batch Number 687 the model has a loss of {'loss': 0.6419040560722351, 'tp': 6235.0, 'fp': 3130.0, 'tn': 7861.0, 'fn': 4758.0, 'accuracy': 0.6411935687065125, 'precision': 0.6657768487930298, 'recall': 0.5671791434288025, 'auc': 0.6840611100196838} \n",
            "687/689 [============================>.] - ETA: 0s - loss: 0.6419 - tp: 6235.0000 - fp: 3130.0000 - tn: 7861.0000 - fn: 4758.0000 - accuracy: 0.6412 - precision: 0.6658 - recall: 0.5672 - auc: 0.6841\n",
            " For Batch Number 688 the model has a loss of {'loss': 0.6417788863182068, 'tp': 6248.0, 'fp': 3132.0, 'tn': 7875.0, 'fn': 4761.0, 'accuracy': 0.6414880156517029, 'precision': 0.6660980582237244, 'recall': 0.5675356388092041, 'auc': 0.684257984161377} \n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.6418 - tp: 6248.0000 - fp: 3132.0000 - tn: 7875.0000 - fn: 4761.0000 - accuracy: 0.6415 - precision: 0.6661 - recall: 0.5675 - auc: 0.6843\n",
            " For Batch Number 689 the model has a loss of {'loss': 0.6419808268547058, 'tp': 6253.0, 'fp': 3141.0, 'tn': 7883.0, 'fn': 4769.0, 'accuracy': 0.6412047743797302, 'precision': 0.6656376123428345, 'recall': 0.567319929599762, 'auc': 0.6839980483055115} \n",
            "689/689 [==============================] - ETA: 0s - loss: 0.6420 - tp: 6253.0000 - fp: 3141.0000 - tn: 7883.0000 - fn: 4769.0000 - accuracy: 0.6412 - precision: 0.6656 - recall: 0.5673 - auc: 0.6840\n",
            " For Epoch Number 3 the model has a loss of 0.6419808268547058\n",
            "689/689 [==============================] - 74s 108ms/step - loss: 0.6420 - tp: 6253.0000 - fp: 3141.0000 - tn: 7883.0000 - fn: 4769.0000 - accuracy: 0.6412 - precision: 0.6656 - recall: 0.5673 - auc: 0.6840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation and testing"
      ],
      "metadata": {
        "id": "ESNgbJCBkOk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.batch(1)\n",
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNFV6v-tkLVe",
        "outputId": "d438ad43-83fb-4a75-e198-fc22e8d24382"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mzxhsUtsAbJ",
        "outputId": "753de971-7cd3-44f3-e32f-3ca342297fc8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2757/2757 [==============================] - 25s 5ms/step - loss: 366205.4375 - tp: 1323.0000 - fp: 1332.0000 - tn: 61.0000 - fn: 41.0000 - accuracy: 0.5020 - precision: 0.4983 - recall: 0.9699 - auc: 0.5072\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[366205.4375,\n",
              " 1323.0,\n",
              " 1332.0,\n",
              " 61.0,\n",
              " 41.0,\n",
              " 0.5019949078559875,\n",
              " 0.498305082321167,\n",
              " 0.9699413776397705,\n",
              " 0.5072140693664551]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parasite_or_not(x):\n",
        "  if (x < 0.5):\n",
        "    return str('P')\n",
        "  else:\n",
        "    return str('U')"
      ],
      "metadata": {
        "id": "kLYoAfans_Jo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Confusion Matrix"
      ],
      "metadata": {
        "id": "9TLo9Kc-pOoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "inp = []\n",
        "\n",
        "for x, y in test_dataset.as_numpy_iterator():\n",
        "  labels.append(y)\n",
        "  inp.append(x)"
      ],
      "metadata": {
        "id": "R4q5F6DGpVKV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(inp).shape)\n",
        "print(np.array(inp)[:, 0, ...].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DdMS325qrnj",
        "outputId": "60993192-d256-49c9-dc76-bd41ff283370"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2757, 1, 224, 224, 3)\n",
            "(2757, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)\n",
        "labels = np.array([i[0] for i in labels])\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDfdWOHkp61O",
        "outputId": "6246a130-b634-4ecf-c99d-421b3327fd1b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([0]), array([0]), array([1]), array([0]), array([1])]\n",
            "[0 1 0 ... 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = lenet_model.predict(np.array(inp)[:, 0, ...])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzQCZm6XrYlh",
        "outputId": "022f19bc-b319-40d8-ddda-bd820b5354d7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87/87 [==============================] - 1s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted[:, 0].shape)\n",
        "print(predicted[:, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW4x1NCz0wQ6",
        "outputId": "aedd102a-205d-4f50-a616-32b59f6640ac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2757,)\n",
            "[1. 1. 1. ... 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "\n",
        "cm = confusion_matrix(labels, predicted > threshold)\n",
        "print(cm)\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "sns.heatmap(cm, annot=True,)\n",
        "plt.title('Confusion matrix - {}'.format(threshold))\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "x2XkbOvI1ZqE",
        "outputId": "67420180-4991-4635-e96b-bacb871333c5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  61 1329]\n",
            " [  42 1325]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 58.7222222222222, 'Predicted')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC plot"
      ],
      "metadata": {
        "id": "7EkuEtXbWz4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fp, tp, thresholds = roc_curve(labels, predicted)\n",
        "plt.plot(fp, tp)\n",
        "plt.xlabel(\"False Positive rate\")\n",
        "plt.ylabel(\"True Positive rate\")\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "skip = 20\n",
        "\n",
        "for i in range(0, len(thresholds), skip):\n",
        "  plt.text(fp[i], tp[i], thresholds[i])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "UcAKjnStW4S-",
        "outputId": "cd522696-91ba-44a2-e91b-5fc3364c5ec0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parasite_or_not(lenet_model.predict(test_dataset.take(1))[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_pig0ipDtwEX",
        "outputId": "43260e76-305c-4076-c49d-8b896f8755d8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 10s 10s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'U'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(test_dataset.take(9)):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image[0])\n",
        "  plt.title(str(parasite_or_not(label.numpy()[0])) + \":\" + str(parasite_or_not(lenet_model.predict(image)[0][0])))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "xdoRmgVTushb",
        "outputId": "353c9896-8c25-444a-a338-e50ac5e54727"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Jh5xmE7fzT2S"
      }
    }
  ]
}